{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install charmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json_without_escape(filepath, dataframe):\n",
    "    with open(filepath, 'w', encoding=\"utf-8\") as f:\n",
    "        json.dump(dataframe.to_dict(orient='records'), f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "# Load your dataset\n",
    "with open('dataset/haveMD_302.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: Generic policy\n",
      "\n",
      "Total repositories in dataset: 302\n",
      "Train dataset:\n",
      "has_generic_policy\n",
      "True     0.687204\n",
      "False    0.312796\n",
      "Name: proportion, dtype: float64\n",
      "Total projects in Training set: 211\n",
      "\n",
      "Validation dataset:\n",
      "has_generic_policy\n",
      "True     0.683333\n",
      "False    0.316667\n",
      "Name: proportion, dtype: float64\n",
      "Total projects in Validation set: 60\n",
      "\n",
      "Test dataset:\n",
      "has_generic_policy\n",
      "True     0.677419\n",
      "False    0.322581\n",
      "Name: proportion, dtype: float64\n",
      "Total projects in Test set: 31\n",
      "----------------------------------------\n",
      "Category: Scope of practice\n",
      "\n",
      "Total repositories in dataset: 302\n",
      "Train dataset:\n",
      "has_scope_of_practice\n",
      "False    0.587678\n",
      "True     0.412322\n",
      "Name: proportion, dtype: float64\n",
      "Total projects in Training set: 211\n",
      "\n",
      "Validation dataset:\n",
      "has_scope_of_practice\n",
      "False    0.583333\n",
      "True     0.416667\n",
      "Name: proportion, dtype: float64\n",
      "Total projects in Validation set: 60\n",
      "\n",
      "Test dataset:\n",
      "has_scope_of_practice\n",
      "False    0.580645\n",
      "True     0.419355\n",
      "Name: proportion, dtype: float64\n",
      "Total projects in Test set: 31\n",
      "----------------------------------------\n",
      "Category: Reporting mechanism\n",
      "\n",
      "Total repositories in dataset: 302\n",
      "Train dataset:\n",
      "has_reporting_mechanism\n",
      "True     0.881517\n",
      "False    0.118483\n",
      "Name: proportion, dtype: float64\n",
      "Total projects in Training set: 211\n",
      "\n",
      "Validation dataset:\n",
      "has_reporting_mechanism\n",
      "True     0.883333\n",
      "False    0.116667\n",
      "Name: proportion, dtype: float64\n",
      "Total projects in Validation set: 60\n",
      "\n",
      "Test dataset:\n",
      "has_reporting_mechanism\n",
      "True     0.870968\n",
      "False    0.129032\n",
      "Name: proportion, dtype: float64\n",
      "Total projects in Test set: 31\n",
      "----------------------------------------\n",
      "Category: User guideline\n",
      "\n",
      "Total repositories in dataset: 302\n",
      "Train dataset:\n",
      "has_user_guideline\n",
      "False    0.853081\n",
      "True     0.146919\n",
      "Name: proportion, dtype: float64\n",
      "Total projects in Training set: 211\n",
      "\n",
      "Validation dataset:\n",
      "has_user_guideline\n",
      "False    0.85\n",
      "True     0.15\n",
      "Name: proportion, dtype: float64\n",
      "Total projects in Validation set: 60\n",
      "\n",
      "Test dataset:\n",
      "has_user_guideline\n",
      "False    0.83871\n",
      "True     0.16129\n",
      "Name: proportion, dtype: float64\n",
      "Total projects in Test set: 31\n",
      "----------------------------------------\n",
      "Data preprocessing complete. JSON files saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Categories of interest\n",
    "categories_of_interest = {\"Generic policy\", \"Reporting mechanism\", \"Scope of practice\", \"User guideline\"}\n",
    "\n",
    "splits = {}\n",
    "for category in categories_of_interest:\n",
    "    df[f'has_{category.replace(\" \", \"_\").lower()}'] = df['SecurityPolicy_content_category'].apply(\n",
    "        lambda x: category in x if isinstance(x, list) else False\n",
    "    )\n",
    "    \n",
    "    X = df.drop(f'has_{category.replace(\" \", \"_\").lower()}', axis=1)\n",
    "    y = df[f'has_{category.replace(\" \", \"_\").lower()}']\n",
    "    \n",
    "    # Stratified train-test split 70-30\n",
    "    train_df, temp_df = train_test_split(df, test_size=0.3, stratify=y, random_state=42)\n",
    "    \n",
    "    # Split temp_df into validation and test sets 20-10\n",
    "    validation_df, test_df = train_test_split(temp_df, test_size=(1/3), stratify=temp_df[f'has_{category.replace(\" \", \"_\").lower()}'], random_state=42)\n",
    "    \n",
    "    splits[category] = {\"train\": train_df, \"val\": validation_df, \"test\": test_df}\n",
    "    \n",
    "    # Print the counts and distributions for verification\n",
    "    print(f\"Category: {category}\\n\")\n",
    "    print(\"Train dataset:\")\n",
    "    print(train_df[f'has_{category.replace(\" \", \"_\").lower()}'].value_counts(normalize=True))\n",
    "    print()\n",
    "    \n",
    "    print(\"Validation dataset:\")\n",
    "    print(validation_df[f'has_{category.replace(\" \", \"_\").lower()}'].value_counts(normalize=True))\n",
    "    print()\n",
    "    \n",
    "    print(\"Test dataset:\")\n",
    "    print(test_df[f'has_{category.replace(\" \", \"_\").lower()}'].value_counts(normalize=True))\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# Save processed data\n",
    "for category, datasets in splits.items():\n",
    "    for split_name, dataset in datasets.items():\n",
    "        save_json_without_escape(f\"set/{category.replace(' ', '_')}_{split_name}.json\", dataset)\n",
    "\n",
    "print(\"Data preprocessing complete. JSON files saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Dataset: Total Packages = 211\n",
      "Category Counts in Train Dataset:\n",
      "Generic policy: 145\n",
      "Scope of practice: 93\n",
      "Reporting mechanism: 202\n",
      "User guideline: 87\n",
      "Projects practice: 16\n",
      "History of vulnerability: 8\n",
      "Information on maintainer: 4\n",
      "Additional information: 4\n",
      "\n",
      "Validation Dataset: Total Packages = 60\n",
      "Category Counts in Validation Dataset:\n",
      "Generic policy: 44\n",
      "Scope of practice: 22\n",
      "Reporting mechanism: 57\n",
      "Additional information: 2\n",
      "User guideline: 21\n",
      "Projects practice: 3\n",
      "\n",
      "Test Dataset: Total Packages = 31\n",
      "Category Counts in Test Dataset:\n",
      "Generic policy: 21\n",
      "User guideline: 5\n",
      "Reporting mechanism: 23\n",
      "Scope of practice: 11\n",
      "Projects practice: 1\n",
      "Additional information: 1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def read_json(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        return pd.DataFrame(json.load(f))\n",
    "\n",
    "categories_of_interest = {\"Generic policy\", \"Reporting mechanism\", \"Scope of practice\", \"User guideline\"}\n",
    "\n",
    "# Binary encoding for each category\n",
    "for category in categories_of_interest:\n",
    "    train_df = read_json(f'set/{category.replace(' ', '_')}_train.json')\n",
    "    validation_df = read_json(f'set/{category.replace(' ', '_')}_val.json')\n",
    "    test_df = read_json(f'set/{category.replace(' ', '_')}_test.json')\n",
    "\n",
    "datasets = {\"Train\": train_df, \"Validation\": validation_df, \"Test\": test_df}\n",
    "\n",
    "# Process each set\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    # Total number of packages\n",
    "    total_packages = len(dataset)\n",
    "    print(f\"\\n{dataset_name} Dataset: Total Packages = {total_packages}\")\n",
    "    \n",
    "    # Count packages for each category\n",
    "    category_counts = Counter(\n",
    "        category for categories in dataset['SecurityPolicy_content_category'] for category in categories\n",
    "    )\n",
    "    print(f\"Category Counts in {dataset_name} Dataset:\")\n",
    "    for category, count in category_counts.items():\n",
    "\n",
    "        print(f\"{category}: {count}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
