{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import shap\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "from shap.plots import waterfall, beeswarm\n",
    "from shap import Explanation, KernelExplainer\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, r2_score\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_features=1, min_samples_leaf=6, min_samples_split=7,\n",
      "                       n_estimators=512, n_jobs=1, random_state=1,\n",
      "                       warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py:1389: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC - ROC Score: 0.69\n",
      "Accuracy: 0.6147540983606558\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.55      0.60        64\n",
      "           1       0.58      0.69      0.63        58\n",
      "\n",
      "    accuracy                           0.61       122\n",
      "   macro avg       0.62      0.62      0.61       122\n",
      "weighted avg       0.62      0.61      0.61       122\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_types = {\n",
    "    \"project_feature\": [\"num_commits\", \"project_age_days\", \"num_issues\", \"num_pull\", \n",
    "                        \"num_stargazers\", \"num_watchers\", \"num_forks\", \"num_subscribers\", \n",
    "                        \"num_contributors\", \"project_size(kB)\"],\n",
    "    \"security_practice\": [\"ssf0_Binary-Artifacts\", \"ssf1_Branch-Protection\",\n",
    "                          \"ssf3_CII-Best-Practices\", \"ssf7_Dependency-Update-Tool\",\n",
    "                          \"ssf8_Fuzzing\", \"ssf9_License\", \"ssf10_Maintained\", \"ssf13_SAST\",\n",
    "                          \"ssf17_Vulnerabilities\"],\n",
    "    \"project_quality\": ['num_sonarQube_BUG_HIGH', 'num_sonarQube_BUG_MEDIUM', 'num_sonarQube_BUG_LOW', 'num_sonarQube_BUG_BLOCKER',\n",
    "            'num_sonarQube_VULNERABILITY_HIGH', 'num_sonarQube_VULNERABILITY_MEDIUM', 'num_sonarQube_VULNERABILITY_LOW',\n",
    "            'num_sonarQube_VULNERABILITY_BLOCKER', 'num_sonarQube_CODE_SMELL_HIGH', 'num_sonarQube_CODE_SMELL_MEDIUM',\n",
    "            'num_sonarQube_CODE_SMELL_LOW', 'num_sonarQube_CODE_SMELL_BLOCKER'],\n",
    "}\n",
    "\n",
    "# Define features and target\n",
    "# à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸Ÿà¸µà¹€à¸ˆà¹‰à¸­à¸ˆà¸£à¸‡à¸™à¸µà¹‰à¹‰ ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡\n",
    "feature = \"project_feature\"\n",
    "# à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™categoryà¸ˆà¸£à¸‡à¸™à¸µà¹‰à¹‰ ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡\n",
    "cate = \"Generic policy\"\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "X_train = pd.read_csv(f\"auto/{cate}_{feature}_X_train.csv\")\n",
    "X_test = pd.read_csv(f\"auto/{cate}_{feature}_X_test.csv\")\n",
    "y_train = pd.read_csv(f\"auto/{cate}_{feature}_y_train.csv\")\n",
    "y_test = pd.read_csv(f\"auto/{cate}_{feature}_y_test.csv\")\n",
    "        \n",
    "# Train the RandomForestClassifier with given parameters\n",
    "### Generic policy ###\n",
    "if feature == \"project_feature\" and cate == \"Generic policy\":\n",
    "    model = RandomForestClassifier(\n",
    "        max_features=1, min_samples_leaf=6, min_samples_split=7,\n",
    "        n_estimators=512, n_jobs=1, random_state=1, warm_start=True\n",
    "    )\n",
    "    model_type = \"tree\"\n",
    "elif feature == \"security_practice\" and cate == \"Generic policy\":\n",
    "    model = RandomForestClassifier(\n",
    "        bootstrap=False, max_features=1, min_samples_leaf=3,\n",
    "        min_samples_split=14, n_estimators=512, n_jobs=1,\n",
    "        random_state=1, warm_start=True\n",
    "    )\n",
    "    model_type = \"tree\"\n",
    "elif feature == \"project_quality\" and cate == \"Generic policy\":\n",
    "    model = AdaBoostClassifier(algorithm='SAMME',\n",
    "                   estimator=DecisionTreeClassifier(max_depth=10),\n",
    "                   learning_rate=0.010381491760996881, n_estimators=362,\n",
    "                   random_state=1)\n",
    "    model_type = \"ada\"\n",
    "### Reporting mechanism ###\n",
    "elif feature == \"project_feature\" and cate == \"Reporting mechanism\":\n",
    "    model = ExtraTreesClassifier(bootstrap=True, criterion='entropy', max_features=1,\n",
    "                     min_samples_split=7, n_estimators=512, n_jobs=1,\n",
    "                     random_state=1, warm_start=True)\n",
    "    model_type = \"tree\"\n",
    "elif feature == \"security_practice\" and cate == \"Reporting mechanism\":\n",
    "    model = HistGradientBoostingClassifier(early_stopping=True,\n",
    "                               l2_regularization=8.908183652101429e-05,\n",
    "                               learning_rate=0.19911994270380215,\n",
    "                               max_iter=512, max_leaf_nodes=955,\n",
    "                               min_samples_leaf=33, n_iter_no_change=2,\n",
    "                               random_state=1, validation_fraction=None,\n",
    "                               warm_start=True)\n",
    "    model_type = \"hist\"\n",
    "elif feature == \"project_quality\" and cate == \"Reporting mechanism\":\n",
    "    model = KNeighborsClassifier(n_neighbors=2, p=1, weights='distance') ####ðŸ¥¶ðŸ¥¶ðŸ¥¶ðŸ¥¶ðŸ¥¶\n",
    "    model_type = \"kernel\"\n",
    "### Scope of practice ###\n",
    "elif feature == \"project_feature\" and cate == \"Scope of practice\":\n",
    "    model = RandomForestClassifier(max_features=15, min_samples_leaf=5,\n",
    "                       min_samples_split=20, n_estimators=512, n_jobs=1,\n",
    "                       random_state=1, warm_start=True)\n",
    "    model_type = \"tree\"\n",
    "elif feature == \"security_practice\" and cate == \"Scope of practice\":\n",
    "    model = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=9),\n",
    "                   learning_rate=1.9701455892241493, n_estimators=101,\n",
    "                   random_state=1)\n",
    "    model_type = \"ada\"\n",
    "elif feature == \"project_quality\" and cate == \"Scope of practice\":\n",
    "    model = RandomForestClassifier(bootstrap=False, criterion='entropy', max_features=4,\n",
    "                       min_samples_leaf=7, n_estimators=512, n_jobs=1,\n",
    "                       random_state=1, warm_start=True)\n",
    "    model_type = \"tree\"\n",
    "### User guideline ###\n",
    "elif feature == \"project_feature\" and cate == \"User guideline\":\n",
    "    model = ExtraTreesClassifier(criterion='entropy', max_features=2, n_estimators=512,\n",
    "                     n_jobs=1, random_state=1, warm_start=True)\n",
    "    model_type = \"tree\"\n",
    "elif feature == \"security_practice\" and cate == \"User guideline\":\n",
    "    model = HistGradientBoostingClassifier(early_stopping=True,\n",
    "                               l2_regularization=0.1144885415414585,\n",
    "                               learning_rate=0.35651231429733377, \n",
    "                               max_iter=128, max_leaf_nodes=570,\n",
    "                               min_samples_leaf=52, n_iter_no_change=20,\n",
    "                               random_state=1,\n",
    "                               validation_fraction=0.26745137407982933,\n",
    "                               warm_start=True)\n",
    "    model_type = \"hist\"\n",
    "elif feature == \"project_quality\" and cate == \"User guideline\":\n",
    "    model = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=2),\n",
    "                   learning_rate=0.16884660398877008, n_estimators=144,\n",
    "                   random_state=1)\n",
    "    model_type = \"ada\"\n",
    "else:\n",
    "    raise ValueError(\"Invalid feature or category selection.\")\n",
    "\n",
    "print(model)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# AUC\n",
    "# Predict the probabilities for the test set\n",
    "y_probs = model.predict_proba(X_test)[:, 1]\n",
    "# Predict the classes for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the AUC - ROC score\n",
    "roc_auc = roc_auc_score(y_test, y_probs) \n",
    "\n",
    "# Calculate other metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"AUC - ROC Score: {roc_auc:.2f}\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_pred, y_test)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how to read graph: https://www.aidancooper.co.uk/a-non-technical-guide-to-interpreting-shap-analyses/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tree explainer: https://medium.com/analytics-vidhya/shap-part-3-tree-shap-3af9bcd7cd9b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shap index 0 or 1: https://github.com/shap/shap/issues/1252"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "readability shap: https://medium.com/towards-data-science/how-to-easily-customize-shap-plots-in-python-fdff9c0483f2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TreeExplainer (Optimized for Trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "keyword argument repeated: range (2257177185.py, line 99)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[74]\u001b[39m\u001b[32m, line 99\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mrange=[0, 0.1],\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m keyword argument repeated: range\n"
     ]
    }
   ],
   "source": [
    "if model_type == \"tree\":\n",
    "    #### Tree explainer ####\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values_tree = explainer.shap_values(X_test)\n",
    "\n",
    "    print(\"Data in SHAP values:\")\n",
    "    print(shap_values_tree) # print data for check\n",
    "\n",
    "    print(\"-\"*40)\n",
    "    ##############################################################################################\n",
    "\n",
    "    #### TMean and Absolute ####\n",
    "    shap_df = pd.DataFrame(shap_values_tree[:, :, 1], columns=X_test.columns)\n",
    "\n",
    "    # Compute and print raw mean SHAP values\n",
    "    abs_mean_shap_raw = shap_df.abs().mean(0).sort_values(ascending=False)\n",
    "    print(\"Absolute Mean SHAP raw:\")\n",
    "    print(abs_mean_shap_raw)\n",
    "    # Compute and print raw mean SHAP values\n",
    "    mean_shap_raw = shap_df.mean(0).sort_values(ascending=False)\n",
    "    print(\"Mean SHAP raw:\")\n",
    "    print(mean_shap_raw)\n",
    "\n",
    "    print(\"-\"*40)\n",
    "    ##############################################################################################\n",
    "\n",
    "    #### Plot by SHAP ####\n",
    "    custom_cmap = mcolors.LinearSegmentedColormap.from_list(\"pink_skyblue\", [\"mediumturquoise\", \"crimson\"])#cmap\n",
    "    shap.summary_plot(shap_values_tree[:, :, 1], X_test, cmap=custom_cmap) # Create the SHAP summary plot\n",
    "    # shap.summary_plot(shap_values_tree[:, :, 1], X_test, plot_type=\"bar\", show=True)\n",
    "    ##############################################################################################\n",
    "\n",
    "    #### get data to plot by me ####\n",
    "    feature_names = X_test.columns.tolist() # Get feature names from X_test\n",
    "\n",
    "    num_samples, num_features, num_classes = shap_values_tree.shape  # Convert SHAP values to a 2D format\n",
    "    reshaped_values = shap_values_tree.reshape(num_samples, num_features * num_classes)\n",
    "\n",
    "    columns = [f\"{feature_names[i]}_Class_{j}\" for i in range(num_features) for j in range(num_classes)] # Create dynamic column names using real feature names\n",
    "\n",
    "    df = pd.DataFrame(reshaped_values, columns=columns)# Convert to DataFrame\n",
    "\n",
    "    # print(df.head()) # Display first few rows\n",
    "\n",
    "    # Select only columns corresponding to Class 1\n",
    "    class_1_columns = [col for col in columns if \"_Class_1\" in col]  # Filter Class 1 columns\n",
    "    df_class_1 = df[class_1_columns]  # Select only Class 1 SHAP values\n",
    "\n",
    "    df_class_1.columns = [col.replace(\"_Class_1\", \"\") for col in df_class_1.columns] # Rename columns to remove \"_Class_1\" suffix for clarity\n",
    "\n",
    "    # Display first few rows\n",
    "    print(df_class_1.head())\n",
    "    print(\"-\"*40)\n",
    "    ##############################################################################################\n",
    "\n",
    "    #### Plot by Me ####\n",
    "    # Compute absolute mean SHAP values for correct sorting\n",
    "    df_mean = df_class_1.abs().mean(numeric_only=True).reset_index()  # Use absolute values for sorting\n",
    "    df_mean.columns = ['Feature', 'Mean |SHAP Value|']\n",
    "    df_mean = df_mean.sort_values(by=\"Mean |SHAP Value|\", ascending=True)  # Sort by absolute impact\n",
    "\n",
    "    # Compute actual mean SHAP values for correct bar coloring\n",
    "    df_signed_mean = df_class_1.mean(numeric_only=True).reset_index()\n",
    "    df_signed_mean.columns = ['Feature', 'Mean SHAP Value']\n",
    "\n",
    "    # Merge both to get proper ordering and sign information\n",
    "    df_final = df_mean.merge(df_signed_mean, on=\"Feature\")\n",
    "\n",
    "    # Assign colors: red for positive, blue for negative values\n",
    "    df_final[\"Color\"] = df_final[\"Mean SHAP Value\"].apply(lambda x: \"mediumturquoise\" if x >= 0 else \"crimson\")\n",
    "\n",
    "    # Creating the horizontal bar plot with correct order\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=df_final[\"Mean |SHAP Value|\"],\n",
    "        y=df_final[\"Feature\"],\n",
    "        orientation='h',\n",
    "        marker=dict(color=df_final[\"Color\"]),\n",
    "        text=[f\"{v:.3f}\" for v in df_final[\"Mean |SHAP Value|\"]],  # Annotate absolute SHAP values\n",
    "        textposition=\"outside\"\n",
    "    ))\n",
    "\n",
    "    # Updating layout to match SHAP importance plot style\n",
    "    fig.update_layout(\n",
    "\n",
    "        title=f\"{cate}:{feature}\",\n",
    "        title_font_size=24,\n",
    "        xaxis_title=\"Mean SHAP Value (Average Impact on Model Output)\",\n",
    "        xaxis_title_font_size=20, \n",
    "        yaxis_title=\"Features\",\n",
    "        yaxis_title_font_size=21,\n",
    "        template=\"plotly_white\",\n",
    "        font=dict(size=18),  # Increase overall font size\n",
    "        xaxis=dict(\n",
    "            range=[0, 0.1],\n",
    "            tickfont=dict(size=18),  # Increase x-axis tick label font size\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            tickfont=dict(size=18)  # Increase y-axis tick label font size\n",
    "        ),\n",
    "        showlegend=False,  # No legend needed\n",
    "        width=1200,  # Set figure width\n",
    "        height=500,  # Set figure height\n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "    # Ensure the \"shap\" directory exists before saving\n",
    "    directory = \"shap\"\n",
    "    os.makedirs(directory, exist_ok=True)  # Create folder if it doesn't exist\n",
    "\n",
    "    # Define save path\n",
    "    save_path = f\"{directory}/{cate}_{feature}_bar_left_plot.png\"\n",
    "\n",
    "    # Save the figure as an image\n",
    "    fig.write_image(save_path)\n",
    "    print(f\"Figure saved successfully at: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree: HistGradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == \"hist\":\n",
    "    #### Tree explainer ####\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values_tree = explainer.shap_values(X_test)\n",
    "\n",
    "\n",
    "    # Check if SHAP values are a list (Binary classification case)\n",
    "    if isinstance(shap_values_tree, list):  \n",
    "        shap_values_tree = shap_values_tree[1]  # Use Class 1 SHAP values\n",
    "\n",
    "    # Ensure it's a NumPy array\n",
    "    shap_values_tree = np.array(shap_values_tree)\n",
    "\n",
    "    print(\"SHAP values shape:\", shap_values_tree.shape)  # Debugging\n",
    "\n",
    "    print(\"Data in SHAP values:\")\n",
    "    print(shap_values_tree)  # Print data for check\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "    ##############################################################################################\n",
    "\n",
    "    #### Mean and Absolute Mean SHAP values ####\n",
    "    shap_df = pd.DataFrame(shap_values_tree, columns=X_test.columns)\n",
    "\n",
    "    # Compute absolute mean SHAP values\n",
    "    abs_mean_shap_raw = shap_df.abs().mean(0).sort_values(ascending=False)\n",
    "    print(\"Absolute Mean SHAP raw:\")\n",
    "    print(abs_mean_shap_raw)\n",
    "\n",
    "    # Compute actual mean SHAP values\n",
    "    mean_shap_raw = shap_df.mean(0).sort_values(ascending=False)\n",
    "    print(\"Mean SHAP raw:\")\n",
    "    print(mean_shap_raw)\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "    ##############################################################################################\n",
    "\n",
    "    #### Plot by SHAP ####\n",
    "    custom_cmap = mcolors.LinearSegmentedColormap.from_list(\"pink_skyblue\", [\"mediumturquoise\", \"crimson\"])#cmap\n",
    "    shap.summary_plot(shap_values_tree, X_test, cmap=custom_cmap) # Create the SHAP summary plot\n",
    "\n",
    "    ##############################################################################################\n",
    "\n",
    "    #### Prepare Data for Custom Plot ####\n",
    "    feature_names = X_test.columns.tolist()  # Get feature names from X_test\n",
    "\n",
    "    # Convert SHAP values to DataFrame\n",
    "    df_class_1 = pd.DataFrame(shap_values_tree, columns=feature_names)\n",
    "\n",
    "    # Display first few rows\n",
    "    print(df_class_1.head())\n",
    "    print(\"-\" * 40)\n",
    "    ##############################################################################################\n",
    "\n",
    "    #### Plot by Me ####\n",
    "    # Compute absolute mean SHAP values for correct sorting\n",
    "    df_mean = df_class_1.abs().mean().reset_index()\n",
    "    df_mean.columns = ['Feature', 'Mean |SHAP Value|']\n",
    "    df_mean = df_mean.sort_values(by=\"Mean |SHAP Value|\", ascending=True)  # Sort by absolute impact\n",
    "\n",
    "    # Compute actual mean SHAP values for correct bar coloring\n",
    "    df_signed_mean = df_class_1.mean(numeric_only=True).reset_index()\n",
    "    df_signed_mean.columns = ['Feature', 'Mean SHAP Value']\n",
    "\n",
    "    # Merge both to get proper ordering and sign information\n",
    "    df_final = df_mean.merge(df_signed_mean, on=\"Feature\")\n",
    "\n",
    "    # Assign colors: red for positive, blue for negative values\n",
    "    df_final[\"Color\"] = df_final[\"Mean SHAP Value\"].apply(lambda x: \"mediumturquoise\" if x >= 0 else \"crimson\")\n",
    "\n",
    "    # Creating the horizontal bar plot with correct order\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=df_final[\"Mean |SHAP Value|\"],\n",
    "        y=df_final[\"Feature\"],\n",
    "        orientation='h',\n",
    "        marker=dict(color=df_final[\"Color\"]),\n",
    "        text=[f\"{v:.3f}\" for v in df_final[\"Mean |SHAP Value|\"]],  # Annotate absolute SHAP values\n",
    "        textposition=\"outside\"\n",
    "    ))\n",
    "\n",
    "    # Updating layout to match SHAP importance plot style\n",
    "    fig.update_layout(\n",
    "\n",
    "        title=f\"{cate}:{feature}\",\n",
    "        title_font_size=24,\n",
    "        xaxis_title=\"Mean SHAP Value (Average Impact on Model Output)\",\n",
    "        xaxis_title_font_size=20, \n",
    "        yaxis_title=\"Features\",\n",
    "        yaxis_title_font_size=21,\n",
    "        template=\"plotly_white\",\n",
    "        font=dict(size=18),  # Increase overall font size\n",
    "        xaxis=dict(\n",
    "            range=[0, 1.8],\n",
    "            tickfont=dict(size=18),  # Increase x-axis tick label font size\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            tickfont=dict(size=18)  # Increase y-axis tick label font size\n",
    "        ),\n",
    "        showlegend=False,  # No legend needed\n",
    "        width=1200,  # Set figure width\n",
    "        height=500,  # Set figure height\n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "    # Ensure the \"shap\" directory exists before saving\n",
    "    directory = \"shap\"\n",
    "    os.makedirs(directory, exist_ok=True)  # Create folder if it doesn't exist\n",
    "\n",
    "    # Define save path\n",
    "    save_path = f\"{directory}/{cate}_{feature}_bar_left_plot.png\"\n",
    "\n",
    "    # Save the figure as an image\n",
    "    fig.write_image(save_path)\n",
    "    print(f\"Figure saved successfully at: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KernelExplainer (Model-Agnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2. KernelExplainer (Model-Agnostic)\n",
    "# kernel_explainer = shap.KernelExplainer(model.predict, X_train)  # Use a small sample for efficiency\n",
    "# shap_values_kernel = kernel_explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(shap_values_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.summary_plot(shap_values_kernel, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == \"kernel\" or model_type == \"ada\":\n",
    "    #### Kernel Explainer ####\n",
    "    background = X_train.sample(n=50, random_state=42)  # Sample background data for SHAP\n",
    "    explainer = shap.KernelExplainer(model.predict, background)\n",
    "    shap_values_kernel = explainer.shap_values(X_test, nsamples=100)\n",
    "\n",
    "    # Ensure SHAP values are a NumPy array\n",
    "    shap_values_kernel = np.array(shap_values_kernel)\n",
    "\n",
    "    print(\"SHAP values shape:\", shap_values_kernel.shape)  # Debugging\n",
    "    print(\"Data in SHAP values:\")\n",
    "    print(shap_values_kernel)  # Print data for check\n",
    "    print(\"-\" * 40)\n",
    "    ##############################################################################################\n",
    "\n",
    "    #### Mean and Absolute Mean SHAP values ####\n",
    "    shap_df = pd.DataFrame(shap_values_kernel, columns=X_test.columns)\n",
    "\n",
    "    # Compute absolute mean SHAP values\n",
    "    abs_mean_shap_raw = shap_df.abs().mean(0).sort_values(ascending=False)\n",
    "    print(\"Absolute Mean SHAP raw:\")\n",
    "    print(abs_mean_shap_raw)\n",
    "\n",
    "    # Compute actual mean SHAP values\n",
    "    mean_shap_raw = shap_df.mean(0).sort_values(ascending=False)\n",
    "    print(\"Mean SHAP raw:\")\n",
    "    print(mean_shap_raw)\n",
    "    print(\"-\" * 40)\n",
    "    ##############################################################################################\n",
    "\n",
    "    #### Plot by SHAP ####\n",
    "    custom_cmap = mcolors.LinearSegmentedColormap.from_list(\"pink_skyblue\", [\"mediumturquoise\", \"crimson\"])\n",
    "    shap.summary_plot(shap_values_kernel, X_test, cmap=custom_cmap)  # Create the SHAP summary plot\n",
    "\n",
    "    ##############################################################################################\n",
    "\n",
    "    #### Prepare Data for Custom Plot ####\n",
    "    feature_names = X_test.columns.tolist()  # Get feature names from X_test\n",
    "    df_class_1 = pd.DataFrame(shap_values_kernel, columns=feature_names)\n",
    "\n",
    "    # Display first few rows\n",
    "    print(df_class_1.head())\n",
    "    print(\"-\" * 40)\n",
    "    ##############################################################################################\n",
    "\n",
    "    #### Plot by Me ####\n",
    "    # Compute absolute mean SHAP values for correct sorting\n",
    "    df_mean = df_class_1.abs().mean().reset_index()\n",
    "    df_mean.columns = ['Feature', 'Mean |SHAP Value|']\n",
    "    df_mean = df_mean.sort_values(by=\"Mean |SHAP Value|\", ascending=True)\n",
    "\n",
    "    # Compute actual mean SHAP values for correct bar coloring\n",
    "    df_signed_mean = df_class_1.mean(numeric_only=True).reset_index()\n",
    "    df_signed_mean.columns = ['Feature', 'Mean SHAP Value']\n",
    "\n",
    "    # Merge both to get proper ordering and sign information\n",
    "    df_final = df_mean.merge(df_signed_mean, on=\"Feature\")\n",
    "\n",
    "    # Assign colors: red for positive, blue for negative values\n",
    "    df_final[\"Color\"] = df_final[\"Mean SHAP Value\"].apply(lambda x: \"mediumturquoise\" if x >= 0 else \"crimson\")\n",
    "\n",
    "    # Creating the horizontal bar plot with correct order\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=df_final[\"Mean |SHAP Value|\"],\n",
    "        y=df_final[\"Feature\"],\n",
    "        orientation='h',\n",
    "        marker=dict(color=df_final[\"Color\"]),\n",
    "        text=[f\"{v:.3f}\" for v in df_final[\"Mean |SHAP Value|\"]],  # Annotate absolute SHAP values\n",
    "        textposition=\"outside\"\n",
    "    ))\n",
    "\n",
    "    # Updating layout to match SHAP importance plot style\n",
    "    fig.update_layout(\n",
    "        title=f\"{cate}:{feature}\",\n",
    "        title_font_size=24,\n",
    "        xaxis_title=\"Mean SHAP Value (Average Impact on Model Output)\",\n",
    "        xaxis_title_font_size=20,\n",
    "        yaxis_title=\"Features\",\n",
    "        yaxis_title_font_size=21,\n",
    "        template=\"plotly_white\",\n",
    "        font=dict(size=18),\n",
    "        xaxis=dict(\n",
    "            range=[0, 1.8],\n",
    "            tickfont=dict(size=18),\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            tickfont=dict(size=18)\n",
    "        ),\n",
    "        showlegend=False,\n",
    "        width=1200,\n",
    "        height=500,\n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "\n",
    "    # Ensure the \"shap\" directory exists before saving\n",
    "    directory = \"shap\"\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    # Define save path\n",
    "    save_path = f\"{directory}/{cate}_{feature}_bar_left_plot.png\"\n",
    "\n",
    "    # Save the figure as an image\n",
    "    fig.write_image(save_path)\n",
    "    print(f\"Figure saved successfully at: {save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
